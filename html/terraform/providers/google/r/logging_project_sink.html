<h1 id="google_logging_project_sink">  google_logging_project_sink </h1> <p>Manages a project-level logging sink. For more information see <a href="https://cloud.google.com/logging/docs/">the official documentation</a>, <a href="https://cloud.google.com/logging/docs/api/tasks/exporting-logs">Exporting Logs in the API</a> and <a href="https://cloud.google.com/logging/docs/reference/v2/rest/">API</a>.</p> <p>Note that you must have the "Logs Configuration Writer" IAM role (<code>roles/logging.configWriter</code>) granted to the credentials used with terraform.</p> <h2 id="example-usage">  Example Usage </h2> <pre data-language="ruby">resource "google_logging_project_sink" "my-sink" {
    name = "my-pubsub-instance-sink"

    # Can export to pubsub, cloud storage, or bigtable
    destination = "pubsub.googleapis.com/projects/my-project/topics/instance-activity"

    # Log all WARN or higher severity messages relating to instances
    filter = "resource.type = gce_instance AND severity &gt;= WARN"

    # Use a unique writer (creates a unique service account used for writing)
    unique_writer_identity = true
}
</pre>
<p>A more complete example follows: this creates a compute instance, as well as a log sink that logs all activity to a cloud storage bucket. Because we are using <code>unique_writer_identity</code>, we must grant it access to the bucket. Note that this grant requires the "Project IAM Admin" IAM role (<code>roles/resourcemanager.projectIamAdmin</code>) granted to the credentials used with terraform.</p> <pre data-language="ruby"># Our logged compute instance
resource "google_compute_instance" "my-logged-instance" {
  name         = "my-instance"
  machine_type = "n1-standard-1"
  zone         = "us-central1-a"

  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-8"
    }
  }

  network_interface {
    network = "default"

    access_config {}
  }
}

# A bucket to store logs in
resource "google_storage_bucket" "log-bucket" {
    name     = "my-unique-logging-bucket"
}

# Our sink; this logs all activity related to our "my-logged-instance" instance
resource "google_logging_project_sink" "instance-sink" {
    name = "my-instance-sink"
    destination = "storage.googleapis.com/${google_storage_bucket.log-bucket.name}"
    filter = "resource.type = gce_instance AND resource.labels.instance_id = \"${google_compute_instance.my-logged-instance.instance_id}\""

    unique_writer_identity = true
}

# Because our sink uses a unique_writer, we must grant that writer access to the bucket.
resource "google_project_iam_binding" "log-writer" {
    role = "roles/storage.objectCreator"

    members = [
        "${google_logging_project_sink.instance-sink.writer_identity}",
    ]
}

</pre>
<h2 id="argument-reference">  Argument Reference </h2> <p>The following arguments are supported:</p> <ul> <li>
<p><a href="#name"><code>name</code></a> - (Required) The name of the logging sink.</p> </li> <li>
<p><a href="#destination"><code>destination</code></a> - (Required) The destination of the sink (or, in other words, where logs are written to). Can be a Cloud Storage bucket, a PubSub topic, or a BigQuery dataset. Examples: <code>
"storage.googleapis.com/[GCS_BUCKET]"
"bigquery.googleapis.com/projects/[PROJECT_ID]/datasets/[DATASET]"
"pubsub.googleapis.com/projects/[PROJECT_ID]/topics/[TOPIC_ID]"
</code> The writer associated with the sink must have access to write to the above resource.</p> </li> <li>
<p><a href="#filter"><code>filter</code></a> - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported. See <a href="https://cloud.google.com/logging/docs/view/advanced_filters">Advanced Log Filters</a> for information on how to write a filter.</p> </li> <li>
<p><a href="#project"><code>project</code></a> - (Optional) The ID of the project to create the sink in. If omitted, the project associated with the provider is used.</p> </li> <li>
<p><a href="#unique_writer_identity"><code>unique_writer_identity</code></a> - (Optional) Whether or not to create a unique identity associated with this sink. If <code>false</code> (the default), then the <code>writer_identity</code> used is <code>serviceAccount:cloud-logs@system.gserviceaccount.com</code>. If <code>true</code>, then a unique service account is created and used for this sink. If you wish to publish logs across projects, you must set <code>unique_writer_identity</code> to true.</p> </li> </ul> <h2 id="attributes-reference">  Attributes Reference </h2> <p>In addition to the arguments listed above, the following computed attributes are exported:</p> <ul> <li>
<a href="#writer_identity"><code>writer_identity</code></a> - The identity associated with this sink. This identity must be granted write access to the configured <code>destination</code>. </li> </ul> <h2 id="import">  Import </h2> <p>Project-level logging sinks can be imported using their URI, e.g.</p> <pre>$ terraform import google_logging_project_sink.my_sink projects/my-project/sinks/my-sink
</pre><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2018 HashiCorp</br>Licensed under the MPL 2.0 License.<br>
    <a href="https://www.terraform.io/docs/providers/google/r/logging_project_sink.html" class="_attribution-link">https://www.terraform.io/docs/providers/google/r/logging_project_sink.html</a>
  </p>
</div>
