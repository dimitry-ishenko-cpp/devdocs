<h1 id="runtime-control">5.7. Runtime system (RTS) options</h1>
<div class="_sphinx"> <div itemprop="articleBody"> <section id="runtime-system-rts-options">  <p id="index-0">To make an executable program, the GHC system compiles your code and then links it with a non-trivial runtime system, which handles storage management, thread scheduling, profiling, and so on.</p> <p>The RTS has a lot of options to control its behaviour. For example, you can change the context-switch interval, the default size of the heap, and enable heap profiling. These options can be passed to the runtime system in a variety of different ways; the next section (<a class="reference internal" href="#setting-rts-options"><span class="std std-ref">Setting RTS options</span></a>) describes the various methods, and the following sections describe the RTS options themselves.</p> <section id="setting-rts-options"> <h2 id="id1">
<span class="section-number">5.7.1. </span>Setting RTS options</h2> <p id="index-1">There are four ways to set RTS options:</p> <ul class="simple"> <li>on the command line between <code>+RTS ... -RTS</code>, when running the program (<a class="reference internal" href="#rts-opts-cmdline"><span class="std std-ref">Setting RTS options on the command line</span></a>)</li> <li>at compile-time, using <a class="reference internal" href="phases.html#ghc-flag-with-rtsopts-opts"><code>-with-rtsopts=⟨opts⟩</code></a> (<a class="reference internal" href="#rts-opts-compile-time"><span class="std std-ref">Setting RTS options at compile time</span></a>)</li> <li>with the environment variable <a class="reference internal" href="#envvar-GHCRTS" id="index-2"><code>GHCRTS</code></a> (<a class="reference internal" href="#rts-options-environment"><span class="std std-ref">Setting RTS options with the GHCRTS environment variable</span></a>)</li> <li>by overriding “hooks” in the runtime system (<a class="reference internal" href="#rts-hooks"><span class="std std-ref">“Hooks” to change RTS behaviour</span></a>)</li> </ul> <section id="setting-rts-options-on-the-command-line"> <h3 id="rts-opts-cmdline">
<span class="section-number">5.7.1.1. </span>Setting RTS options on the command line</h3> <p id="index-3">If you set the <a class="reference internal" href="phases.html#ghc-flag-rtsopts-none-some-all-ignore-ignoreAll"><code>-rtsopts[=⟨none|some|all|ignore|ignoreAll⟩]</code></a> flag appropriately when linking (see <a class="reference internal" href="phases.html#options-linker"><span class="std std-ref">Options affecting linking</span></a>), you can give RTS options on the command line when running your program.</p> <p>When your Haskell program starts up, the RTS extracts command-line arguments bracketed between <code>+RTS</code> and <code>-RTS</code> as its own. For example:</p> <pre data-language="none">$ ghc prog.hs -rtsopts
[1 of 1] Compiling Main             ( prog.hs, prog.o )
Linking prog ...
$ ./prog -f +RTS -H32m -S -RTS -h foo bar
</pre> <p>The RTS will snaffle <code>-H32m -S</code> for itself, and the remaining arguments <code>-f -h foo bar</code> will be available to your program if/when it calls <code>System.Environment.getArgs</code>.</p> <p>No <code>-RTS</code> option is required if the runtime-system options extend to the end of the command line, as in this example:</p> <pre data-language="none">% hls -ltr /usr/etc +RTS -A5m
</pre> <p>If you absolutely positively want all the rest of the options in a command line to go to the program (and not the RTS), use a <code>--RTS</code> or <code>--</code>. The difference is that <code>--RTS</code> will not be passed to the program, while <code>--</code> will.</p> <p>As always, for RTS options that take ⟨size⟩s: If the last character of ⟨size⟩ is a K or k, multiply by 1024; if an M or m, by 1024*1024; if a G or G, by 1024^3. (And any wraparound in the counters is <em>your</em> fault!)</p> <p>Giving a <code>+RTS -?</code> RTS option will print out the RTS options actually available in your program (which vary, depending on how you compiled).</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Since GHC is itself compiled by GHC, you can change RTS options in the compiler using the normal <code>+RTS ... -RTS</code> combination. For instance, to set the maximum heap size for a compilation to 128M, you would add <code>+RTS -M128m -RTS</code> to the command line.</p> </div> </section> <section id="setting-rts-options-at-compile-time"> <h3 id="rts-opts-compile-time">
<span class="section-number">5.7.1.2. </span>Setting RTS options at compile time</h3> <p>GHC lets you change the default RTS options for a program at compile time, using the <code>-with-rtsopts</code> flag (<a class="reference internal" href="phases.html#options-linker"><span class="std std-ref">Options affecting linking</span></a>). A common use for this is to give your program a default heap and/or stack size that is greater than the default. For example, to set <code>-H128m -K64m</code>, link with <code>-with-rtsopts="-H128m -K64m"</code>.</p> </section> <section id="setting-rts-options-with-the-ghcrts-environment-variable"> <h3 id="rts-options-environment">
<span class="section-number">5.7.1.3. </span>Setting RTS options with the <code>GHCRTS</code> environment variable</h3> <dl class="std envvar" id="index-4"> <dt class="sig sig-object std" id="envvar-GHCRTS">
<code>GHCRTS</code> </dt> <dd>
<p>If the <code>-rtsopts</code> flag is set to something other than <code>none</code> or <code>ignoreAll</code> when linking, RTS options are also taken from the environment variable <a class="reference internal" href="#envvar-GHCRTS" id="index-5"><code>GHCRTS</code></a>. For example, to set the maximum heap size to 2G for all GHC-compiled programs (using an <code>sh</code>-like shell):</p> <pre data-language="sh">GHCRTS='-M2G'
export GHCRTS
</pre> <p>RTS options taken from the <a class="reference internal" href="#envvar-GHCRTS" id="index-6"><code>GHCRTS</code></a> environment variable can be overridden by options given on the command line.</p> </dd>
</dl> <div class="admonition tip"> <p class="admonition-title">Tip</p> <p>Setting something like <code>GHCRTS=-M2G</code> in your environment is a handy way to avoid Haskell programs growing beyond the real memory in your machine, which is easy to do by accident and can cause the machine to slow to a crawl until the OS decides to kill the process (and you hope it kills the right one).</p> </div> </section> <section id="hooks-to-change-rts-behaviour"> <h3 id="rts-hooks">
<span class="section-number">5.7.1.4. </span>“Hooks” to change RTS behaviour</h3> <p id="index-7">GHC lets you exercise rudimentary control over certain RTS settings for any given program, by compiling in a “hook” that is called by the run-time system. The RTS contains stub definitions for these hooks, but by writing your own version and linking it on the GHC command line, you can override the defaults.</p> <p>Owing to the vagaries of DLL linking, these hooks don’t work under Windows when the program is built dynamically.</p> <section id="runtime-events"> <h4>
<span class="section-number">5.7.1.4.1. </span>Runtime events</h4> <p>You can change the messages printed when the runtime system “blows up,” e.g., on stack overflow. The hooks for these are as follows:</p> <dl class="c function"> <dt class="sig sig-object c" id="c.OutOfHeapHook">
<code>void OutOfHeapHook(unsigned long, unsigned long)</code> </dt> <dd>
<p>The heap-overflow message.</p> </dd>
</dl> <dl class="c function"> <dt class="sig sig-object c" id="c.StackOverflowHook">
<code>void StackOverflowHook(long int)</code> </dt> <dd>
<p>The stack-overflow message.</p> </dd>
</dl> <dl class="c function"> <dt class="sig sig-object c" id="c.MallocFailHook">
<code>void MallocFailHook(long int)</code> </dt> <dd>
<p>The message printed if <code>malloc</code> fails.</p> </dd>
</dl> </section> <section id="event-log-output"> <h4 id="event-log-output-api">
<span class="section-number">5.7.1.4.2. </span>Event log output</h4> <p>Furthermore GHC lets you specify the way event log data (see <a class="reference internal" href="#rts-flag-l-flags"><code>-l
⟨flags⟩</code></a>) is written through a custom <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a>:</p> <dl class="c type"> <dt class="sig sig-object c" id="c.size_t">
<code>type size_t</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Hidden<span class="colon">:</span>
</dt>  </dl> </dd>
</dl> <dl class="c type"> <dt class="sig sig-object c" id="c.EventLogWriter">
<code>type EventLogWriter</code> </dt> <dd>
<p>A sink of event-log data.</p> <dl class="c member"> <dt class="sig sig-object c" id="c.EventLogWriter.initEventLogWriter">
<code>void initEventLogWriter(void)</code> </dt> <dd>
<p>Initializes your <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a>. This is optional.</p> </dd>
</dl> <dl class="c member"> <dt class="sig sig-object c" id="c.EventLogWriter.writeEventLog">
<code>bool writeEventLog(void *eventlog, size_t eventlog_size)</code> </dt> <dd>
<p>Hands buffered event log data to your event log writer. Return true on success. Required for a custom <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a>.</p> <p>Note that this function may be called by multiple threads simultaneously.</p> </dd>
</dl> <dl class="c member"> <dt class="sig sig-object c" id="c.EventLogWriter.flushEventLog">
<code>void flushEventLog(void)</code> </dt> <dd>
<p>Flush buffers (if any) of your custom <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a>. This can be <code>NULL</code>.</p> <p>Note that this function may be called by multiple threads simultaneously.</p> </dd>
</dl> <dl class="c member"> <dt class="sig sig-object c" id="c.EventLogWriter.stopEventLogWriter">
<code>void stopEventLogWriter(void)</code> </dt> <dd>
<p>Called when event logging is about to stop. This can be <code>NULL</code>.</p> </dd>
</dl> </dd>
</dl> <p>To use an <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a> the RTS API provides the following functions:</p> <dl class="c function"> <dt class="sig sig-object c" id="c.eventLogStatus">
<code>EventLogStatus eventLogStatus(void)</code> </dt> <dd>
<p>Query whether the current runtime system supports the eventlog (e.g. whether the current executable was linked with <a class="reference internal" href="phases.html#ghc-flag-eventlog"><code>-eventlog</code></a>) and, if it is supported, whether it is currently logging.</p> </dd>
</dl> <dl class="c function"> <dt class="sig sig-object c" id="c.startEventLogging">
<code>bool startEventLogging(const EventLogWriter *writer)</code> </dt> <dd>
<p>Start logging events to the given <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a>. Returns true on success or false if another writer has already been configured.</p> </dd>
</dl> <dl class="c function"> <dt class="sig sig-object c" id="c.endEventLogging">
<code>void endEventLogging()</code> </dt> <dd>
<p>Tear down the active <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a>.</p> </dd>
</dl> <p>where the <code>enum</code> <a class="reference internal" href="#c.EventLogStatus" title="EventLogStatus"><code>EventLogStatus</code></a> is:</p> <dl class="c type"> <dt class="sig sig-object c" id="c.EventLogStatus">
<code>type EventLogStatus</code> </dt> <dd>
<ul class="simple"> <li>
<code>EVENTLOG_NOT_SUPPORTED</code>: The runtime system wasn’t compiled with eventlog support.</li> <li>
<code>EVENTLOG_NOT_CONFIGURED</code>: An <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a> has not yet been configured.</li> <li>
<code>EVENTLOG_RUNNING</code>: An <a class="reference internal" href="#c.EventLogWriter" title="EventLogWriter"><code>EventLogWriter</code></a> has been configured and is running.</li> </ul> </dd>
</dl> </section> </section> </section> <section id="miscellaneous-rts-options"> <h2 id="rts-options-misc">
<span class="section-number">5.7.2. </span>Miscellaneous RTS options</h2> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-install-signal-handlers-yes-no">
<code>--install-signal-handlers=⟨yes|no⟩</code> </dt> <dd>
<p>If yes (the default), the RTS installs signal handlers to catch things like <kbd class="kbd compound docutils literal notranslate"><kbd class="kbd docutils literal notranslate">Ctrl</kbd>-<kbd class="kbd docutils literal notranslate">C</kbd></kbd>. This option is primarily useful for when you are using the Haskell code as a DLL, and want to set your own signal handlers.</p> <p>Note that even with <code>--install-signal-handlers=no</code>, the RTS interval timer signal is still enabled. The timer signal is either SIGVTALRM or SIGALRM, depending on the RTS configuration and OS capabilities. To disable the timer signal, use the <code>-V0</code> RTS option (see <a class="reference internal" href="profiling.html#rts-flag-V-secs"><code>-V ⟨secs⟩</code></a>).</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-install-seh-handlers-yes-no">
<code>--install-seh-handlers=⟨yes|no⟩</code> </dt> <dd>
<p>If yes (the default), the RTS on Windows installs exception handlers to catch unhandled exceptions using the Windows exception handling mechanism. This option is primarily useful for when you are using the Haskell code as a DLL, and don’t want the RTS to ungracefully terminate your application on errors such as segfaults.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-generate-crash-dumps">
<code>--generate-crash-dumps</code> </dt> <dd>
<p>If yes (the default), the RTS on Windows will generate a core dump on any crash. These dumps can be inspected using debuggers such as WinDBG. The dumps record all code, registers and threading information at the time of the crash. Note that this implies <code>--install-seh-handlers=yes</code>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-generate-stack-traces-yes-no">
<code>--generate-stack-traces=&lt;yes|no&gt;</code> </dt> <dd>
<p>If yes (the default), the RTS on Windows will generate a stack trace on crashes if exception handling are enabled. In order to get more information in compiled executables, C code or DLLs symbols need to be available.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-disable-delayed-os-memory-return">
<code>--disable-delayed-os-memory-return</code> </dt> <dd>
<p>If given, uses <code>MADV_DONTNEED</code> instead of <code>MADV_FREE</code> on platforms where this results in more accurate resident memory usage of the program as shown in memory usage reporting tools (e.g. the <code>RSS</code> column in <code>top</code> and <code>htop</code>).</p> <p>Using this is expected to make the program slightly slower.</p> <p>On Linux, MADV_FREE is newer and faster because it can avoid zeroing pages if they are re-used by the process later (see <code>man 2 madvise</code>), but for the trade-off that memory inspection tools like <code>top</code> will not immediately reflect the freeing in their display of resident memory (RSS column): Only under memory pressure will Linux actually remove the freed pages from the process and update its RSS statistics. Until then, the pages show up as <code>LazyFree</code> in <code>/proc/PID/smaps</code> (see <code>man 5 proc</code>).</p> <p>The delayed RSS update can confuse programmers debugging memory issues, production memory monitoring tools, and end users who may complain about undue memory usage shown in reporting tools, so with this flag it can be turned off.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-io-manager-name">
<code>--io-manager=(name)</code> </dt> <dd>
<p>Select the I/O manager to use. On some combinations of platform and threaded/non-threaded RTS way there is a choice of more than one implementation of I/O manager. This flag lets you override the default and select one by name.</p> <p>Currently the available I/O managers are:</p> <table class="docutils align-default"> <thead> <tr>
<th class="head"><p>Name</p></th> <th class="head"><p>Platforms</p></th> <th class="head"><p>RTS way</p></th> </tr> </thead>  <tr>
<td><p><code>select</code></p></td> <td><p>Posix</p></td> <td><p>Non-threaded</p></td> </tr> <tr>
<td><p><code>mio</code></p></td> <td><p>All</p></td> <td><p>Threaded</p></td> </tr> <tr>
<td><p><code>win32-legacy</code></p></td> <td><p>Windows</p></td> <td><p>Non-threaded</p></td> </tr> <tr>
<td><p><code>winio</code></p></td> <td><p>Windows</p></td> <td><p>All</p></td> </tr>  </table> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-xp">
<code>-xp</code> </dt> <dd>
<p>On 64-bit machines, the runtime linker usually needs to map object code into the low 2Gb of the address space, due to the x86_64 small memory model where most symbol references are 32 bits. The problem is that this 2Gb of address space can fill up, especially if you’re loading a very large number of object files into GHCi.</p> <p>This flag offers a workaround, albeit a slightly convoluted one. To be able to load an object file outside of the low 2Gb, the object code needs to be compiled with <code>-fPIC -fexternal-dynamic-refs</code>. When the <code>+RTS -xp</code> flag is passed, the linker will assume that all object files were compiled with <code>-fPIC -fexternal-dynamic-refs</code> and load them anywhere in the address space. It’s up to you to arrange that the object files you load (including all packages) were compiled in the right way. If this is not the case for an object, the linker will probably fail with an error message when the problem is detected.</p> <p>On some platforms where PIC is always the case, e.g. macOS and OpenBSD on x86_64, and macOS and Linux on aarch64 this flag is enabled by default. One repercussion of this is that referenced system libraries also need to be compiled with <code>-fPIC</code> if we need to load them in the runtime linker.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-xm-address">
<code>-xm ⟨address⟩</code> </dt> <dd>
<div class="admonition warning" id="index-8"> <p class="admonition-title">Warning</p> <p>This option is for working around memory allocation problems only. Do not use unless GHCi fails with a message like “<code>failed to mmap() memory below 2Gb</code>”. Consider recompiling the objects with <code>-fPIC -fexternal-dynamic-refs</code> and using the <code>-xp</code> flag instead. If you need to use this option to get GHCi working on your machine, please file a bug.</p> </div> <p>On 64-bit machines, the RTS needs to allocate memory in the low 2Gb of the address space. Support for this across different operating systems is patchy, and sometimes fails. This option is there to give the RTS a hint about where it should be able to allocate memory in the low 2Gb of the address space. For example, <code>+RTS -xm20000000 -RTS</code> would hint that the RTS should allocate starting at the 0.5Gb mark. The default is to use the OS’s built-in support for allocating memory in the low 2Gb if available (e.g. <code>mmap</code> with <code>MAP_32BIT</code> on Linux), or otherwise <code>-xm40000000</code>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-xq-size">
<code>-xq ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>100k</p> </dd> </dl> <p>This option relates to allocation limits; for more about this see <a class="reference external" href="../libraries/base-4.21.0.0-8e62/ghc-conc.html#v:enableAllocationLimit">GHC.Conc.enableAllocationLimit</a>. When a thread hits its allocation limit, the RTS throws an exception to the thread, and the thread gets an additional quota of allocation before the exception is raised again, the idea being so that the thread can execute its exception handlers. The <code>-xq</code> controls the size of this additional quota.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-xr-size">
<code>-xr ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>1T</p> </dd> </dl> <p>This option controls the size of virtual memory address space reserved by the two step allocator on a 64-bit platform. It can be useful in scenarios where even reserving a large address range without committing can be expensive (e.g. WSL1), or when you actually have enough physical memory and want to support a Haskell heap larger than 1T. <code>-xr</code> is a no-op if GHC is configured with <code>--disable-large-address-space</code> or if the platform is 32-bit.</p> </dd>
</dl> </section> <section id="rts-options-to-control-the-garbage-collector"> <h2 id="rts-options-gc">
<span class="section-number">5.7.3. </span>RTS options to control the garbage collector</h2> <p id="index-9">There are several options to give you precise control over garbage collection. Hopefully, you won’t need any of these in normal operation, but there are several things that can be tweaked for maximum performance.</p> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-copying-gc">
<code>--copying-gc</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>8.10.2</p> </dd> <dt class="field-odd">Reverse<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>–nonmoving-gc</p> </dd> </dl> <p>Uses the generational copying garbage collector for all generations. This is the default.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-nonmoving-gc">
<code>--nonmoving-gc</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>8.10.1</p> </dd> <dt class="field-odd">Reverse<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>–copying-gc</p> </dd> </dl> <p id="index-10">Enable the concurrent mark-and-sweep garbage collector for old generation collectors. Typically GHC uses a stop-the-world copying garbage collector for all generations. This can cause long pauses in execution during major garbage collections. <a class="reference internal" href="#rts-flag-nonmoving-gc"><code>--nonmoving-gc</code></a> enables the use of a concurrent mark-and-sweep garbage collector for oldest generation collections. Under this collection strategy oldest-generation garbage collection can proceed concurrently with mutation.</p> <p>Note that <a class="reference internal" href="#rts-flag-nonmoving-gc"><code>--nonmoving-gc</code></a> cannot be used with <code>-G1</code>, <a class="reference internal" href="profiling.html#rts-flag-hc"><code>profiling</code></a> nor <a class="reference internal" href="#rts-flag-c"><code>-c</code></a>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-xn">
<code>-xn</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>8.10.1</p> </dd> </dl> <p>An alias for <a class="reference internal" href="#rts-flag-nonmoving-gc"><code>--nonmoving-gc</code></a></p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-nonmoving-dense-allocator-count-count">
<code>--nonmoving-dense-allocator-count=⟨count⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>16</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.10.1</p> </dd> <dt class="field-odd">Reverse<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>none</p> </dd> </dl> <p>Specify the amount of dense allocators used by the non-moving garbage collector.</p> <p>Increasing this value is likely to decrease the amount of memory lost to internal fragmentation while marginally increasing the baseline memory requirements and potentially regressing other metrics.</p> <p>Large values are likely to lead to diminishing returns as , in practice, the Haskell heap tends to be dominated by small objects.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-w">
<code>-w</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>a long time ago</p> </dd> <dt class="field-odd">Reverse<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>none</p> </dd> </dl> <p>Uses a mark-region garbage collection strategy for the oldest-generation heap. Note that this cannot be used in conjunction with heap profiling (<a class="reference internal" href="#rts-flag-hT"><code>-hT</code></a>) unless linked against the profiling runtime system with <a class="reference internal" href="profiling.html#ghc-flag-prof"><code>-prof</code></a>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-A-size">
<code>-A ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>4MB</p> </dd> </dl> <p id="index-11">Set the allocation area size used by the garbage collector. The allocation area (actually generation 0 step 0) is fixed and is never resized (unless you use <a class="reference internal" href="#rts-flag-H-size"><code>-H [⟨size⟩]</code></a>, below).</p> <p>Optimal settings depend on the actual machine, program, and other RTS options. Increasing the allocation area size means worse cache behaviour but fewer garbage collections and less promotion.</p> <p>In general settings &gt;= 4MB can reduce performance in some cases, in particular for single threaded operation. However in a parallel setting increasing the allocation area to <code>16MB</code>, or even <code>64MB</code> can increase gc throughput significantly.</p> <p>With only 1 generation (e.g. <code>-G1</code>, see <a class="reference internal" href="#rts-flag-G-generations"><code>-G ⟨generations⟩</code></a>) the <code>-A</code> option specifies the minimum allocation area, since the actual size of the allocation area will be resized according to the amount of data in the heap (see <a class="reference internal" href="#rts-flag-F-factor"><code>-F ⟨factor⟩</code></a>, below).</p> <p>When heap profiling using a smaller allocation area can increase accuracy as more frequent major garbage collections also results in more frequent heap snapshots</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-AL-size">
<code>-AL ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p><a class="reference internal" href="#rts-flag-A-size"><code>-A</code></a> value</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>8.2.1</p> </dd> </dl> <p id="index-12">Sets the limit on the total size of “large objects” (objects larger than about 3KB) that can be allocated before a GC is triggered. By default this limit is the same as the <a class="reference internal" href="#rts-flag-A-size"><code>-A</code></a> value.</p> <p>Large objects are not allocated from the normal allocation area set by the <code>-A</code> flag, which is why there is a separate limit for these. Large objects tend to be much rarer than small objects, so most programs hit the <code>-A</code> limit before the <code>-AL</code> limit. However, the <code>-A</code> limit is per-capability, whereas the <code>-AL</code> limit is global, so as <code>-N</code> gets larger it becomes more likely that we hit the <code>-AL</code> limit first. To counteract this, it might be necessary to use a larger <code>-AL</code> limit when using a large <code>-N</code>.</p> <p>To see whether you’re making good use of all the memory reseverd for the allocation area (<code>-A</code> times <code>-N</code>), look at the output of <code>+RTS -S</code> and check whether the amount of memory allocated between GCs is equal to <code>-A</code> times <code>-N</code>. If not, there are two possible remedies: use <code>-n</code> to set a nursery chunk size, or use <code>-AL</code> to increase the limit for large objects.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-O-size">
<code>-O ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>1m</p> </dd> </dl> <p id="index-13">Set the minimum size of the old generation.</p> <p>The old generation is collected whenever it grows to this size or the value of the <a class="reference internal" href="#rts-flag-F-factor"><code>-F ⟨factor⟩</code></a> option multiplied by the size of the live data at the previous major collection, whichever is larger.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-n-size">
<code>-n ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>4m with <a class="reference internal" href="#rts-flag-A-size"><code>-A16m</code></a> or larger, otherwise 0.</p> </dd> </dl> <p id="index-14">Set the allocation area chunksize. Setting <code>-n0</code> means the allocation area is not divided into chunks.</p> <p>[Example: <code>-n4m</code> ] When set to a non-zero value, this option divides the allocation area (<code>-A</code> value) into chunks of the specified size. During execution, when a processor exhausts its current chunk, it is given another chunk from the pool until the pool is exhausted, at which point a collection is triggered.</p> <p>This option is only useful when running in parallel (<code>-N2</code> or greater). It allows the processor cores to make better use of the available allocation area, even when cores are allocating at different rates. Without <code>-n</code>, each core gets a fixed-size allocation area specified by the <code>-A</code>, and the first core to exhaust its allocation area triggers a GC across all the cores. This can result in a collection happening when the allocation areas of some cores are only partially full, so the purpose of the <code>-n</code> is to allow cores that are allocating faster to get more of the allocation area. This means less frequent GC, leading a lower GC overhead for the same heap size.</p> <p>This is particularly useful in conjunction with larger <code>-A</code> values, for example <code>-A64m -n4m</code> is a useful combination on larger core counts (8+).</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-c">
<code>-c</code> </dt> <dd>
<p id="index-15">Use a compacting algorithm for collecting the oldest generation. By default, the oldest generation is collected using a copying algorithm; this option causes it to be compacted in-place instead. The compaction algorithm is slower than the copying algorithm, but the savings in memory use can be considerable.</p> <p>For a given heap size (using the <a class="reference internal" href="#rts-flag-H-size"><code>-H [⟨size⟩]</code></a> option), compaction can in fact reduce the GC cost by allowing fewer GCs to be performed. This is more likely when the ratio of live data to heap size is high, say greater than 30%.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Compaction doesn’t currently work when a single generation is requested using the <code>-G1</code> option.</p> </div> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-c-n">
<code>-c ⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>30</p> </dd> </dl> <p>Automatically enable compacting collection when the live data exceeds ⟨n⟩% of the maximum heap size (see the <a class="reference internal" href="#rts-flag-M-size"><code>-M ⟨size⟩</code></a> option). Note that the maximum heap size is unlimited by default, so this option has no effect unless the maximum heap size is set with <a class="reference internal" href="#rts-flag-M-size"><code>-M ⟨size⟩</code></a>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-F-factor">
<code>-F ⟨factor⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2</p> </dd> </dl> <p id="index-16">This option controls the amount of memory reserved for the older generations (and in the case of a two space collector the size of the allocation area) as a factor of the amount of live data. For example, if there was 2M of live data in the oldest generation when we last collected it, then by default we’ll wait until it grows to 4M before collecting it again.</p> <p>The default seems to work well here. If you have plenty of memory, it is usually better to use <code>-H ⟨size⟩</code> (see <a class="reference internal" href="#rts-flag-H-size"><code>-H [⟨size⟩]</code></a>) than to increase <a class="reference internal" href="#rts-flag-F-factor"><code>-F ⟨factor⟩</code></a>.</p> <p>The <a class="reference internal" href="#rts-flag-F-factor"><code>-F ⟨factor⟩</code></a> setting will be automatically reduced by the garbage collector when the maximum heap size (the <a class="reference internal" href="#rts-flag-M-size"><code>-M ⟨size⟩</code></a> setting) is approaching.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Fd-factor">
<code>-Fd ⟨factor⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>4</p> </dd> </dl> <p id="index-17">The inverse rate at which unused memory is returned to the OS when it is no longer needed. After a large amount of allocation the RTS will start by retaining a lot of allocated blocks in case it will need them again shortly but then it will gradually release them based on the <a class="reference internal" href="#rts-flag-Fd-factor"><code>-Fd ⟨factor⟩</code></a>. On each subsequent major collection which is not caused by a heap overflow a little more memory will attempt to be returned until the amount retained is similar to the amount of live bytes.</p> <p>Increasing this factor will make the rate memory is returned slower, decreasing it will make memory be returned more eagerly. Setting it to 0 will disable the memory return (which will emulate the behaviour in releases prior to 9.2).</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-G-generations">
<code>-G ⟨generations⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2</p> </dd> </dl> <p id="index-18">Set the number of generations used by the garbage collector. The default of 2 seems to be good, but the garbage collector can support any number of generations. Anything larger than about 4 is probably not a good idea unless your program runs for a <em>long</em> time, because the oldest generation will hardly ever get collected.</p> <p>Specifying 1 generation with <code>+RTS -G1</code> gives you a simple 2-space collector, as you would expect. In a 2-space collector, the <a class="reference internal" href="#rts-flag-A-size"><code>-A
⟨size⟩</code></a> option specifies the <em>minimum</em> allocation area size, since the allocation area will grow with the amount of live data in the heap. In a multi-generational collector the allocation area is a fixed size (unless you use the <a class="reference internal" href="#rts-flag-H-size"><code>-H [⟨size⟩]</code></a> option).</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-qg-gen">
<code>-qg ⟨gen⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>0</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>6.12.1</p> </dd> </dl> <p>Use parallel GC in generation ⟨gen⟩ and higher. Omitting ⟨gen⟩ turns off the parallel GC completely, reverting to sequential GC.</p> <p>The default parallel GC settings are usually suitable for parallel programs (i.e. those using <a class="reference external" href="../libraries/base-4.21.0.0-8e62/ghc-conc.html#v:par">GHC.Conc.par</a>, Strategies, or with multiple threads). However, it is sometimes beneficial to enable the parallel GC for a single-threaded sequential program too, especially if the program has a large amount of heap data and GC is a significant fraction of runtime. To use the parallel GC in a sequential program, enable the parallel runtime with a suitable <a class="reference internal" href="using-concurrent.html#rts-flag-N-x"><code>-N ⟨x⟩</code></a> option, and additionally it might be beneficial to restrict parallel GC to the old generation with <code>-qg1</code>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-qb-gen">
<code>-qb ⟨gen⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>1 for <a class="reference internal" href="#rts-flag-A-size"><code>-A</code></a> &lt; 32M, 0 otherwise</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>6.12.1</p> </dd> </dl> <p>Use load-balancing in the parallel GC in generation ⟨gen⟩ and higher. Omitting ⟨gen⟩ disables load-balancing entirely.</p> <p>Load-balancing shares out the work of GC between the available cores. This is a good idea when the heap is large and we need to parallelise the GC work, however it is also pessimal for the short young-generation collections in a parallel program, because it can harm locality by moving data from the cache of the CPU where is it being used to the cache of another CPU. Hence the default is to do load-balancing only in the old-generation. In fact, for a parallel program it is sometimes beneficial to disable load-balancing entirely with <code>-qb</code>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-qn-x">
<code>-qn ⟨x⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>the value of <a class="reference internal" href="using-concurrent.html#rts-flag-N-x"><code>-N</code></a> or the number of CPU cores, whichever is smaller.</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>8.2.1</p> </dd> </dl> <p id="index-19">Set the number of threads to use for the parallel GC.</p> <p>By default, all of the capabilities participate in parallel garbage collection. If we want to use a very large <code>-N</code> value, however, this can reduce the performance of the GC. For this reason, the <code>-qn</code> flag can be used to specify a lower number for the threads that should participate in GC. During GC, if there are more than this number of workers active, some of them will sleep for the duration of the GC.</p> <p>The <code>-qn</code> flag may be useful when running with a large <code>-A</code> value (so that GC is infrequent), and a large <code>-N</code> value (so as to make use of hyperthreaded cores, for example). For example, on a 24-core machine with 2 hyperthreads per core, we might use <code>-N48 -qn24 -A128m</code> to specify that the mutator should use hyperthreads but the GC should only use real cores. Note that this configuration would use 6GB for the allocation area.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-H-size">
<code>-H [⟨size⟩]</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>0</p> </dd> </dl> <p id="index-20">This option provides a “suggested heap size” for the garbage collector. Think of <code>-Hsize</code> as a variable <a class="reference internal" href="#rts-flag-A-size"><code>-A ⟨size⟩</code></a> option. It says: I want to use at least ⟨size⟩ bytes, so use whatever is left over to increase the <code>-A</code> value.</p> <p>This option does not put a <em>limit</em> on the heap size: the heap may grow beyond the given size as usual.</p> <p>If ⟨size⟩ is omitted, then the garbage collector will take the size of the heap at the previous GC as the ⟨size⟩. This has the effect of allowing for a larger <code>-A</code> value but without increasing the overall memory requirements of the program. It can be useful when the default small <code>-A</code> value is suboptimal, as it can be in programs that create large amounts of long-lived data.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-I-seconds">
<code>-I ⟨seconds⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>0.3 seconds in the threaded runtime, 0 in the non-threaded runtime</p> </dd> </dl> <p id="index-21">Set the amount of idle time which must pass before a idle GC is performed. Setting <code>-I0</code> disables the idle GC.</p> <p>In the threaded and SMP versions of the RTS (see <a class="reference internal" href="phases.html#ghc-flag--single-threaded"><code>-threaded</code></a>, <a class="reference internal" href="phases.html#options-linker"><span class="std std-ref">Options affecting linking</span></a>), a major GC is automatically performed if the runtime has been idle (no Haskell computation has been running) for a period of time.</p> <p>For an interactive application, it is probably a good idea to use the idle GC, because this will allow finalizers to run and deadlocked threads to be detected in the idle time when no Haskell computation is happening. Also, it will mean that a GC is less likely to happen when the application is busy, and so responsiveness may be improved. However, if the amount of live data in the heap is particularly large, then the idle GC can cause a significant delay, and too small an interval could adversely affect interactive responsiveness.</p> <p>The idle period timer only resets after some activity by a Haskell thread. If your program is doing literally nothing then after the first idle collection is triggered then no more future collections will be scheduled until more work is performed.</p> <p>This is an experimental feature, please let us know if it causes problems and/or could benefit from further tuning.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Iw-seconds">
<code>-Iw ⟨seconds⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>0 seconds</p> </dd> </dl> <p id="index-22">Set the minimum wait time between runs of the idle GC.</p> <p>By default, if idle GC is enabled in the threaded runtime, a major GC will be performed every time the process goes idle for a sufficiently long duration (see <a class="reference internal" href="#rts-flag-I-seconds"><code>-I ⟨seconds⟩</code></a>). For large server processes accepting regular but infrequent requests (e.g., once per second), an expensive, major GC may run after every request. As an alternative to shutting off idle GC entirely (with <code>-I0</code>), a minimum wait time between idle GCs can be specified with this flag. For example, <code>-Iw60</code> will ensure that an idle GC runs at most once per minute.</p> <p>This is an experimental feature, please let us know if it causes problems and/or could benefit from further tuning.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-ki-size">
<code>-ki ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>1k</p> </dd> </dl> <p id="index-23">Set the initial stack size for new threads.</p> <p>Thread stacks (including the main thread’s stack) live on the heap. As the stack grows, new stack chunks are added as required; if the stack shrinks again, these extra stack chunks are reclaimed by the garbage collector. The default initial stack size is deliberately small, in order to keep the time and space overhead for thread creation to a minimum, and to make it practical to spawn threads for even tiny pieces of work.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This flag used to be simply <code>-k</code>, but was renamed to <code>-ki</code> in GHC 7.2.1. The old name is still accepted for backwards compatibility, but that may be removed in a future version.</p> </div> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-kc-size">
<code>-kc ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>32k</p> </dd> </dl> <p id="index-24">Set the size of “stack chunks”. When a thread’s current stack overflows, a new stack chunk is created and added to the thread’s stack, until the limit set by <a class="reference internal" href="#rts-flag-K-size"><code>-K ⟨size⟩</code></a> is reached.</p> <p>The advantage of smaller stack chunks is that the garbage collector can avoid traversing stack chunks if they are known to be unmodified since the last collection, so reducing the chunk size means that the garbage collector can identify more stack as unmodified, and the GC overhead might be reduced. On the other hand, making stack chunks too small adds some overhead as there will be more overflow/underflow between chunks. The default setting of 32k appears to be a reasonable compromise in most cases.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-kb-size">
<code>-kb ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>1k</p> </dd> </dl> <p id="index-25">Sets the stack chunk buffer size. When a stack chunk overflows and a new stack chunk is created, some of the data from the previous stack chunk is moved into the new chunk, to avoid an immediate underflow and repeated overflow/underflow at the boundary. The amount of stack moved is set by the <code>-kb</code> option.</p> <p>Note that to avoid wasting space, this value should typically be less than 10% of the size of a stack chunk (<a class="reference internal" href="#rts-flag-kc-size"><code>-kc ⟨size⟩</code></a>), because in a chain of stack chunks, each chunk will have a gap of unused space of this size.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-K-size">
<code>-K ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>80% of physical memory</p> </dd> </dl> <p id="index-26">Set the maximum stack size for an individual thread to ⟨size⟩ bytes. If the thread attempts to exceed this limit, it will be sent the <code>StackOverflow</code> exception. The limit can be disabled entirely by specifying a size of zero.</p> <p>This option is there mainly to stop the program eating up all the available memory in the machine if it gets into an infinite loop.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-m-n">
<code>-m ⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>3%</p> </dd> </dl> <p id="index-27">Minimum % ⟨n⟩ of heap which must be available for allocation.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-M-size">
<code>-M ⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>unlimited</p> </dd> </dl> <p id="index-28">Set the maximum heap size to ⟨size⟩ bytes. The heap normally grows and shrinks according to the memory requirements of the program. The only reason for having this option is to stop the heap growing without bound and filling up all the available swap space, which at the least will result in the program being summarily killed by the operating system.</p> <p>The maximum heap size also affects other garbage collection parameters: when the amount of live data in the heap exceeds a certain fraction of the maximum heap size, compacting collection will be automatically enabled for the oldest generation, and the <code>-F</code> parameter will be reduced in order to avoid exceeding the maximum heap size.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Mgrace-size">
<code>-Mgrace=⟨size⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>1M</p> </dd> </dl> <p id="index-29">If the program’s heap exceeds the value set by <a class="reference internal" href="#rts-flag-M-size"><code>-M ⟨size⟩</code></a>, the RTS throws an exception to the program, and the program gets an additional quota of allocation before the exception is raised again, the idea being so that the program can execute its exception handlers. <code>-Mgrace=</code> controls the size of this additional quota.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-numa">
<code>--numa</code> </dt> <dt class="sig sig-object std" id="rts-flag-numa-mask">
<code>--numa=&lt;mask&gt;</code> </dt> <dd>
<p id="index-30">Enable NUMA-aware memory allocation in the runtime (only available with <code>-threaded</code>, and only on Linux and Windows currently).</p> <p>Background: some systems have a Non-Uniform Memory Architecture, whereby main memory is split into banks which are “local” to specific CPU cores. Accessing local memory is faster than accessing remote memory. The OS provides APIs for allocating local memory and binding threads to particular CPU cores, so that we can ensure certain memory accesses are using local memory.</p> <p>The <code>--numa</code> option tells the RTS to tune its memory usage to maximize local memory accesses. In particular, the RTS will:</p>  <ul class="simple"> <li>Determine the number of NUMA nodes (N) by querying the OS.</li> <li>Manage separate memory pools for each node.</li> <li>Map capabilities to NUMA nodes. Capability C is mapped to NUMA node C mod N.</li> <li>Bind worker threads on a capability to the appropriate node.</li> <li>Allocate the nursery from node-local memory.</li> <li>Perform other memory allocation, including in the GC, from node-local memory.</li> <li>When load-balancing, we prefer to migrate threads to another Capability on the same node.</li> </ul>  <p>The <code>--numa</code> flag is typically beneficial when a program is using all cores of a large multi-core NUMA system, with a large allocation area (<code>-A</code>). All memory accesses to the allocation area will go to local memory, which can save a significant amount of remote memory access. A runtime speedup on the order of 10% is typical, but can vary a lot depending on the hardware and the memory behaviour of the program.</p> <p>Note that the RTS will not set CPU affinity for bound threads and threads entering Haskell from C/C++, so if your program uses bound threads you should ensure that each bound thread calls the RTS API <code>rts_setInCallCapability(c,1)</code> from C/C++ before calling into Haskell. Otherwise there could be a mismatch between the CPU that the thread is running on and the memory it is using while running Haskell code, which will negate any benefits of <code>--numa</code>.</p> <p>If given an explicit &lt;mask&gt;, the &lt;mask&gt; is interpreted as a bitmap that indicates the NUMA nodes on which to run the program. For example, <code>--numa=3</code> would run the program on NUMA nodes 0 and 1.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-long-gc-sync">
<code>--long-gc-sync</code> </dt> <dt class="sig sig-object std" id="rts-flag-long-gc-sync-seconds">
<code>--long-gc-sync=&lt;seconds&gt;</code> </dt> <dd>
<p id="index-31">When a GC starts, all the running mutator threads have to stop and synchronise. The period between when the GC is initiated and all the mutator threads are stopped is called the GC synchronisation phase. If this phase is taking a long time (longer than 1ms is considered long), then it can have a severe impact on overall throughput.</p> <p>A long GC sync can be caused by a mutator thread that is inside an <code>unsafe</code> FFI call, or running in a loop that doesn’t allocate memory and so doesn’t yield. To fix the former, make the call <code>safe</code>, and to fix the latter, either avoid calling the code in question or compile it with <a class="reference internal" href="using-optimisation.html#ghc-flag-fomit-yields"><code>-fomit-yields</code></a>.</p> <p>By default, the flag will cause a warning to be emitted to stderr when the sync time exceeds the specified time. This behaviour can be overridden, however: the <code>longGCSync()</code> hook is called when the sync time is exceeded during the sync period, and the <code>longGCSyncEnd()</code> hook at the end. Both of these hooks can be overridden in the <code>RtsConfig</code> when the runtime is started with <code>hs_init_ghc()</code>. The default implementations of these hooks (<code>LongGcSync()</code> and <code>LongGCSyncEnd()</code> respectively) print warnings to stderr.</p> <p>One way to use this flag is to set a breakpoint on <code>LongGCSync()</code> in the debugger, and find the thread that is delaying the sync. You probably want to use <a class="reference internal" href="debug-info.html#ghc-flag-g"><code>-g</code></a> to provide more info to the debugger.</p> <p>The GC sync time, along with other GC stats, are available by calling the <code>getRTSStats()</code> function from C, or <code>GHC.Stats.getRTSStats</code> from Haskell.</p> </dd>
</dl> </section> <section id="rts-options-to-produce-runtime-statistics"> <h2 id="rts-options-statistics">
<span class="section-number">5.7.4. </span>RTS options to produce runtime statistics</h2> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-T">
<code>-T</code> </dt> <dt class="sig sig-object std" id="rts-flag-t-file">
<code>-t [⟨file⟩]</code> </dt> <dt class="sig sig-object std" id="rts-flag-s-file">
<code>-s [⟨file⟩]</code> </dt> <dt class="sig sig-object std" id="rts-flag-S-file">
<code>-S [⟨file⟩]</code> </dt> <dt class="sig sig-object std" id="rts-flag-machine-readable">
<code>--machine-readable</code> </dt> <dt class="sig sig-object std" id="rts-flag-internal-counters">
<code>--internal-counters</code> </dt> <dd>
<p>These options produce runtime-system statistics, such as the amount of time spent executing the program and in the garbage collector, the amount of memory allocated, the maximum size of the heap, and so on. The three variants give different levels of detail: <code>-T</code> collects the data but produces no output <code>-t</code> produces a single line of output in the same format as GHC’s <code>-Rghc-timing</code> option, <code>-s</code> produces a more detailed summary at the end of the program, and <code>-S</code> additionally produces information about each and every garbage collection. Passing <code>--internal-counters</code> to a threaded runtime will cause a detailed summary to include various internal counts accumulated during the run; note that these are unspecified and may change between releases.</p> <p>The output is placed in ⟨file⟩. If ⟨file⟩ is omitted, then the output is sent to <code>stderr</code>.</p> <p>If you use the <code>-T</code> flag then, you should access the statistics using <a class="reference external" href="../libraries/base-4.21.0.0-8e62/ghc-stats.html">GHC.Stats</a>.</p> <p>If you use the <code>-t</code> flag then, when your program finishes, you will see something like this:</p> <pre data-language="none">&lt;&lt;ghc: 36169392 bytes, 69 GCs, 603392/1065272 avg/max bytes residency (2 samples), 3M in use, 0.00 INIT (0.00 elapsed), 0.02 MUT (0.02 elapsed), 0.07 GC (0.07 elapsed) :ghc&gt;&gt;
</pre> <p>This tells you:</p> <ul class="simple"> <li>The total number of bytes allocated by the program over the whole run.</li> <li>The total number of garbage collections performed.</li> <li>The average and maximum “residency”, which is the amount of live data in bytes. The runtime can only determine the amount of live data during a major GC, which is why the number of samples corresponds to the number of major GCs (and is usually relatively small). To get a better picture of the heap profile of your program, use the <a class="reference internal" href="#rts-flag-hT"><code>-hT</code></a> RTS option (<a class="reference internal" href="#rts-profiling"><span class="std std-ref">RTS options for profiling</span></a>).</li> <li>The peak memory the RTS has allocated from the OS.</li> <li>The amount of CPU time and elapsed wall clock time while initialising the runtime system (INIT), running the program itself (MUT, the mutator), and garbage collecting (GC).</li> </ul> <p>You can also get this in a more future-proof, machine readable format, with <code>-t --machine-readable</code>:</p> <pre data-language="haskell">[("bytes allocated", "36169392")
,("num_GCs", "69")
,("average_bytes_used", "603392")
,("max_bytes_used", "1065272")
,("num_byte_usage_samples", "2")
,("peak_megabytes_allocated", "3")
,("init_cpu_seconds", "0.00")
,("init_wall_seconds", "0.00")
,("mutator_cpu_seconds", "0.02")
,("mutator_wall_seconds", "0.02")
,("GC_cpu_seconds", "0.07")
,("GC_wall_seconds", "0.07")
]
</pre> <p>If you use the <code>-s</code> flag then, when your program finishes, you will see something like this (the exact details will vary depending on what sort of RTS you have, e.g. you will only see profiling data if your RTS is compiled for profiling):</p> <pre data-language="none">    36,169,392 bytes allocated in the heap
     4,057,632 bytes copied during GC
     1,065,272 bytes maximum residency (2 sample(s))
        54,312 bytes maximum slop
             3 MB total memory in use (0 MB lost due to fragmentation)

Generation 0:    67 collections,     0 parallel,  0.04s,  0.03s elapsed
Generation 1:     2 collections,     0 parallel,  0.03s,  0.04s elapsed

SPARKS: 359207 (557 converted, 149591 pruned)

INIT  time    0.00s  (  0.00s elapsed)
MUT   time    0.01s  (  0.02s elapsed)
GC    time    0.07s  (  0.07s elapsed)
EXIT  time    0.00s  (  0.00s elapsed)
Total time    0.08s  (  0.09s elapsed)

%GC time      89.5%  (75.3% elapsed)

Alloc rate    4,520,608,923 bytes per MUT second

Productivity  10.5% of total user, 9.1% of total elapsed
</pre> <ul> <li>The “bytes allocated in the heap” is the total bytes allocated by the program over the whole run.</li> <li>GHC uses a copying garbage collector by default. “bytes copied during GC” tells you how many bytes it had to copy during garbage collection.</li> <li>The maximum space actually used by your program is the “bytes maximum residency” figure. This is only checked during major garbage collections, so it is only an approximation; the number of samples tells you how many times it is checked.</li> <li>The “bytes maximum slop” tells you the most space that is ever wasted due to the way GHC allocates memory in blocks. Slop is memory at the end of a block that was wasted. There’s no way to control this; we just like to see how much memory is being lost this way.</li> <li>The “total memory in use” tells you the peak memory the RTS has allocated from the OS.</li> <li>Next there is information about the garbage collections done. For each generation it says how many garbage collections were done, how many of those collections were done in parallel, the total CPU time used for garbage collecting that generation, and the total wall clock time elapsed while garbage collecting that generation.</li> <li>The <code>SPARKS</code> statistic refers to the use of <code>Control.Parallel.par</code> and related functionality in the program. Each spark represents a call to <code>par</code>; a spark is “converted” when it is executed in parallel; and a spark is “pruned” when it is found to be already evaluated and is discarded from the pool by the garbage collector. Any remaining sparks are discarded at the end of execution, so “converted” plus “pruned” does not necessarily add up to the total.</li> <li>
<p>Next there is the CPU time and wall clock time elapsed broken down by what the runtime system was doing at the time. INIT is the runtime system initialisation. MUT is the mutator time, i.e. the time spent actually running your code. GC is the time spent doing garbage collection. RP is the time spent doing retainer profiling. PROF is the time spent doing other profiling. EXIT is the runtime system shutdown time. And finally, Total is, of course, the total.</p> <p>%GC time tells you what percentage GC is of Total. “Alloc rate” tells you the “bytes allocated in the heap” divided by the MUT CPU time. “Productivity” tells you what percentage of the Total CPU and wall clock elapsed times are spent in the mutator (MUT).</p> </li> </ul> <p>The <code>-S</code> flag, as well as giving the same output as the <code>-s</code> flag, prints information about each GC as it happens:</p> <pre data-language="none">    Alloc    Copied     Live    GC    GC     TOT     TOT  Page Flts
    bytes     bytes     bytes  user  elap    user    elap
   528496     47728    141512  0.01  0.02    0.02    0.02    0    0  (Gen:  1)
[...]
   524944    175944   1726384  0.00  0.00    0.08    0.11    0    0  (Gen:  0)
</pre> <p>For each garbage collection, we print:</p> <ul class="simple"> <li>How many bytes we allocated this garbage collection.</li> <li>How many bytes we copied this garbage collection.</li> <li>How many bytes are currently live.</li> <li>How long this garbage collection took (CPU time and elapsed wall clock time).</li> <li>How long the program has been running (CPU time and elapsed wall clock time).</li> <li>How many page faults occurred this garbage collection.</li> <li>How many page faults occurred since the end of the last garbage collection.</li> <li>Which generation is being garbage collected.</li> </ul> </dd>
</dl> </section> <section id="rts-options-for-concurrency-and-parallelism"> <h2>
<span class="section-number">5.7.5. </span>RTS options for concurrency and parallelism</h2> <p>The RTS options related to concurrency are described in <a class="reference internal" href="using-concurrent.html#using-concurrent"><span class="std std-ref">Using Concurrent Haskell</span></a>, and those for parallelism in <a class="reference internal" href="using-concurrent.html#parallel-options"><span class="std std-ref">RTS options for SMP parallelism</span></a>.</p> </section> <section id="rts-options-for-profiling"> <h2 id="rts-profiling">
<span class="section-number">5.7.6. </span>RTS options for profiling</h2> <p>Most profiling runtime options are only available when you compile your program for profiling (see <a class="reference internal" href="profiling.html#prof-compiler-options"><span class="std std-ref">Compiler options for profiling</span></a>, and <a class="reference internal" href="profiling.html#rts-options-heap-prof"><span class="std std-ref">RTS options for heap profiling</span></a> for the runtime options). However, there is one profiling option that is available for ordinary non-profiled executables:</p> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-hT">
<code>-hT</code> </dt> <dt class="sig sig-object std" id="rts-flag-h">
<code>-h</code> </dt> <dd>
<p>Generates a basic heap profile, in the file <code>prog.hp</code>. To produce the heap profile graph, use <strong class="command">hp2ps</strong> (see <a class="reference internal" href="profiling.html#hp2ps"><span class="std std-ref">hp2ps – Rendering heap profiles to PostScript</span></a>). The basic heap profile is broken down by data constructor, with other types of closures (functions, thunks, etc.) grouped into broad categories (e.g. <code>FUN</code>, <code>THUNK</code>). To get a more detailed profile, use the full profiling support (<a class="reference internal" href="profiling.html#profiling"><span class="std std-ref">Profiling</span></a>). Can be shortened to <a class="reference internal" href="#rts-flag-h"><code>-h</code></a>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The meaning of the shortened <a class="reference internal" href="#rts-flag-h"><code>-h</code></a> is dependent on whether your program was compiled for profiling. (See <a class="reference internal" href="profiling.html#rts-options-heap-prof"><span class="std std-ref">RTS options for heap profiling</span></a> for details.)</p> </div> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-L-n">
<code>-L ⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>25 characters</p> </dd> </dl> <p>Sets the maximum length of the cost-centre names listed in the heap profile.</p> </dd>
</dl> </section> <section id="tracing"> <h2 id="rts-eventlog">
<span class="section-number">5.7.7. </span>Tracing</h2> <p id="index-32">When the program is linked with the <a class="reference internal" href="phases.html#ghc-flag-eventlog"><code>-eventlog</code></a> option (<a class="reference internal" href="phases.html#options-linker"><span class="std std-ref">Options affecting linking</span></a>), runtime events can be logged in several ways:</p> <ul class="simple"> <li>In binary format to a file for later analysis by a variety of tools. One such tool is <a class="reference external" href="https://www.haskell.org/haskellwiki/ThreadScope">ThreadScope</a>, which interprets the event log to produce a visual parallel execution profile of the program.</li> <li>In binary format to customized event log writer. This enables live analysis of the events while the program is running.</li> <li>As text to standard output, for debugging purposes.</li> </ul> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-l-flags">
<code>-l ⟨flags⟩</code> </dt> <dd>
<p>Log events in binary format. Without any ⟨flags⟩ specified, this logs a default set of events, suitable for use with tools like ThreadScope.</p> <p>Per default the events are written to <code><em>program</em>.eventlog</code> though the mechanism for writing event log data can be overridden with a custom <code>EventLogWriter</code>.</p> <p>For some special use cases you may want more control over which events are included. The ⟨flags⟩ is a sequence of zero or more characters indicating which classes of events to log. Currently these the classes of events that can be enabled/disabled:</p> <ul class="simple"> <li>
<code>s</code> — scheduler events, including Haskell thread creation and start/stop events. Enabled by default.</li> <li>
<code>g</code> — GC events, including GC start/stop. Enabled by default.</li> <li>
<code>n</code> — non-moving garbage collector (see <a class="reference internal" href="#rts-flag-nonmoving-gc"><code>--nonmoving-gc</code></a>) events including start and end of the concurrent mark and census information to characterise heap fragmentation. Disabled by default.</li> <li>
<code>p</code> — parallel sparks (sampled). Enabled by default.</li> <li>
<code>f</code> — parallel sparks (fully accurate). Disabled by default.</li> <li>
<code>T</code> — <a class="reference internal" href="profiling.html#ghc-flag-ticky"><code>ticky-ticky profiler</code></a> events (see <a class="reference internal" href="eventlog-formats.html#ticky-event-format"><span class="std std-ref">Ticky counters</span></a> for details). Disabled by default.</li> <li>
<code>u</code> — user events. These are events emitted from Haskell code using functions such as <code>Debug.Trace.traceEvent</code>. Enabled by default.</li> </ul> <p>You can disable specific classes, or enable/disable all classes at once:</p> <ul class="simple"> <li>
<code>a</code> — enable all event classes listed above</li> <li>
<code>-⟨x⟩</code> — disable the given class of events, for any event class listed above</li> <li>
<code>-a</code> — disable all classes</li> </ul> <p>For example, <code>-l-ag</code> would disable all event classes (<code>-a</code>) except for GC events (<code>g</code>).</p> <p>For spark events there are two modes: sampled and fully accurate. There are various events in the life cycle of each spark, usually just creating and running, but there are some more exceptional possibilities. In the sampled mode the number of occurrences of each kind of spark event is sampled at frequent intervals. In the fully accurate mode every spark event is logged individually. The latter has a higher runtime overhead and is not enabled by default.</p> <p>The format of the log file is described in this users guide in <a class="reference internal" href="eventlog-formats.html#eventlog-encodings"><span class="std std-ref">Eventlog encodings</span></a> It can be parsed in Haskell using the <a class="reference external" href="https://hackage.haskell.org/package/ghc-events">ghc-events</a> library. To dump the contents of a <code>.eventlog</code> file as text, use the tool <code>ghc-events show</code> that comes with the <a class="reference external" href="https://hackage.haskell.org/package/ghc-events">ghc-events</a> package.</p> <p>Each event is associated with a timestamp which is the number of nanoseconds since the start of executation of the running program. This is the elapsed time, not the CPU time.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-olfilename">
<code>-ol⟨filename⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p><code>⟨program⟩.eventlog</code></p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>8.8</p> </dd> </dl> <p>Sets the destination for the eventlog produced with the <a class="reference internal" href="#rts-flag-l-flags"><code>-l ⟨flags⟩</code></a> flag.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-eventlog-flush-interval-seconds">
<code>--eventlog-flush-interval=⟨seconds⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>disabled</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.2</p> </dd> </dl> <p>When enabled, the eventlog will be flushed periodically every ⟨seconds⟩. This can be useful in live-monitoring situations where the eventlog is consumed in real-time by another process.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-v-flags">
<code>-v [⟨flags⟩]</code> </dt> <dd>
<p>Log events as text to standard output, instead of to the <code>.eventlog</code> file. The ⟨flags⟩ are the same as for <code>-l</code>, with the additional option <code>t</code> which indicates that the each event printed should be preceded by a timestamp value (in the binary <code>.eventlog</code> file, all events are automatically associated with a timestamp).</p> </dd>
</dl> <p>The debugging options <code>-Dx</code> also generate events which are logged using the tracing framework. By default those events are dumped as text to stdout (<code>-Dx</code> implies <code>-v</code>), but they may instead be stored in the binary eventlog file by using the <code>-l</code> option.</p> </section> <section id="rts-options-for-haskell-program-coverage"> <h2 id="rts-options-debugging">
<span class="section-number">5.7.8. </span>RTS options for Haskell program coverage</h2> <p>When a program is compiled with the <a class="reference internal" href="profiling.html#ghc-flag-fhpc"><code>-fhpc</code></a> flag, then the generated code is instrumented with instructions which keep track of which code was executed while the program runs. This functionality is implemented in the runtime system and can be controlled by the following flags.</p> <dl class="std rts-flag" id="index-33"> <dt class="sig sig-object std" id="rts-flag-read-tix-file-yes-no">
<code>--read-tix-file=&lt;yes|no&gt;</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>enabled</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.12</p> </dd> </dl> <p>The RTS can be instructed to read a <code>&lt;program&gt;.tix</code> file during the startup phase. The datastructures which accumulate the coverage information during program execution are then initialized with the information from this file. This option is useful for aggregating coverage information over multiple runs of an executable.</p> <p>The default for this flag is currently <code>--read-tix-file=yes</code> but will change to <code>-read-tix-file=no</code> in a future version of GHC according to the accepted <a class="reference external" href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0612-fhpc-accumulation.md">GHC proposal 612</a>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-write-tix-file-yes-no">
<code>--write-tix-file=&lt;yes|no&gt;</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>enabled</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.10</p> </dd> </dl> <p>By default, the runtime system writes a file <code>&lt;program&gt;.tix</code> at the end of execution if the executable is compiled with the <code>-fhpc</code> option. This file is not written if the <code>--write-tix-file=no</code> option is passed to the runtime system.</p> <p>This option is useful if you want to use the functionality provided by the <code>Trace.Hpc.Reflect</code> module of the <a class="reference external" href="https://hackage.haskell.org/package/hpc">hpc</a> library. These functions allow to inspect the state of the Tix data structures during runtime, so that the executable can write Tix files to disk itself.</p> </dd>
</dl> </section> <section id="rts-options-for-hackers-debuggers-and-over-interested-souls"> <h2>
<span class="section-number">5.7.9. </span>RTS options for hackers, debuggers, and over-interested souls</h2> <p id="index-34">These RTS options might be used (a) to avoid a GHC bug, (b) to see “what’s really happening”, or (c) because you feel like it. Not recommended for everyday use!</p> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-B">
<code>-B</code> </dt> <dd>
<p>Sound the bell at the start of each garbage collection.</p> <p>Oddly enough, people really do use this option! Our pal in Durham (England), Paul Callaghan, writes: “Some people here use it for a variety of purposes—honestly!—e.g., confirmation that the code/machine is doing something, infinite loop detection, gauging cost of recently added code. Certain people can even tell what stage [the program] is in by the beep pattern. But the major use is for annoying others in the same office…”</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-D-x">
<code>-D ⟨x⟩</code> </dt> <dd>
<p>An RTS debugging flag; only available if the program was linked with the <a class="reference internal" href="phases.html#ghc-flag-debug"><code>-debug</code></a> option. Various values of ⟨x⟩ are provided to enable debug messages and additional runtime sanity checks in different subsystems in the RTS, for example <code>+RTS -Ds -RTS</code> enables debug messages from the scheduler. Use <code>+RTS -?</code> to find out which debug flags are supported.</p> <p>Full list of currently supported flags:</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Ds-DEBUG-scheduler">
<code>-Ds DEBUG: scheduler</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Di-DEBUG-interpreter">
<code>-Di DEBUG: interpreter</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dw-DEBUG-weak">
<code>-Dw DEBUG: weak</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-DG-DEBUG-gccafs">
<code>-DG DEBUG: gccafs</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dg-DEBUG-gc">
<code>-Dg DEBUG: gc</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Db-DEBUG-block">
<code>-Db DEBUG: block</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-DS-DEBUG-sanity">
<code>-DS DEBUG: sanity</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-DZ-DEBUG-zero-freed-memory-on-GC">
<code>-DZ DEBUG: zero freed memory on GC</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dt-DEBUG-stable">
<code>-Dt DEBUG: stable</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dp-DEBUG-prof">
<code>-Dp DEBUG: prof</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Da-DEBUG-apply">
<code>-Da DEBUG: apply</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dl-DEBUG-linker">
<code>-Dl DEBUG: linker</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-DL-DEBUG-linker-verbose-implies-rts-flag-Dl">
<code>-DL DEBUG: linker (verbose); implies :rts-flag:`-Dl`</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dm-DEBUG-stm">
<code>-Dm DEBUG: stm</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dn-DEBUG-non-moving-garbage-collector">
<code>-Dn DEBUG: non-moving garbage collector</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dz-DEBUG-stack-squeezing">
<code>-Dz DEBUG: stack squeezing</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dc-DEBUG-program-coverage">
<code>-Dc DEBUG: program coverage</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dr-DEBUG-sparks">
<code>-Dr DEBUG: sparks</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-DC-DEBUG-compact">
<code>-DC DEBUG: compact</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Dk-DEBUG-continuation">
<code>-Dk DEBUG: continuation</code> </dt> 
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Do-DEBUG-iomanager">
<code>-Do DEBUG: iomanager</code> </dt> <dd>
<p>Debug messages will be sent to the binary event log file instead of stdout if the <a class="reference internal" href="#rts-flag-l-flags"><code>-l ⟨flags⟩</code></a> option is added. This might be useful for reducing the overhead of debug tracing.</p> <p>To figure out what exactly they do, the least bad way is to grep the rts/ directory in the ghc code for macros like <code>DEBUG(scheduler</code> or <code>DEBUG_scheduler</code>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-r-file">
<code>-r ⟨file⟩</code> </dt> <dd>
<p id="index-35">Produce “ticky-ticky” statistics at the end of the program run (only available if the program was linked with <a class="reference internal" href="phases.html#ghc-flag-debug"><code>-debug</code></a>). The ⟨file⟩ business works just like on the <a class="reference internal" href="#rts-flag-S-file"><code>-S [⟨file⟩]</code></a> RTS option, above.</p> <p>For more information on ticky-ticky profiling, see <a class="reference internal" href="profiling.html#ticky-ticky"><span class="std std-ref">Using “ticky-ticky” profiling (for implementors)</span></a>.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-xc">
<code>-xc</code> </dt> <dd>
<p>(Only available when the program is compiled for profiling.) When an exception is raised in the program, this option causes a stack trace to be dumped to <code>stderr</code>.</p> <p>This can be particularly useful for debugging: if your program is complaining about a <code>head []</code> error and you haven’t got a clue which bit of code is causing it, compiling with <code>-prof -fprof-auto</code> (see <a class="reference internal" href="profiling.html#ghc-flag-prof"><code>-prof</code></a>) and running with <code>+RTS -xc
-RTS</code> will tell you exactly the call stack at the point the error was raised.</p> <p>The output contains one report for each exception raised in the program (the program might raise and catch several exceptions during its execution), where each report looks something like this:</p> <pre data-language="none">*** Exception raised (reporting due to +RTS -xc), stack trace:
  GHC.List.CAF
  --&gt; evaluated by: Main.polynomial.table_search,
  called from Main.polynomial.theta_index,
  called from Main.polynomial,
  called from Main.zonal_pressure,
  called from Main.make_pressure.p,
  called from Main.make_pressure,
  called from Main.compute_initial_state.p,
  called from Main.compute_initial_state,
  called from Main.CAF
  ...
</pre> <p>The stack trace may often begin with something uninformative like <code>GHC.List.CAF</code>; this is an artifact of GHC’s optimiser, which lifts out exceptions to the top-level where the profiling system assigns them to the cost centre “CAF”. However, <code>+RTS -xc</code> doesn’t just print the current stack, it looks deeper and reports the stack at the time the CAF was evaluated, and it may report further stacks until a non-CAF stack is found. In the example above, the next stack (after <code>--&gt; evaluated by</code>) contains plenty of information about what the program was doing when it evaluated <code>head []</code>.</p> <p>Implementation details aside, the function names in the stack should hopefully give you enough clues to track down the bug.</p> <p>See also the function <code>traceStack</code> in the module <code>Debug.Trace</code> for another way to view call stacks.</p> </dd>
</dl> <dl class="std rts-flag"> <dt class="sig sig-object std" id="rts-flag-Z">
<code>-Z</code> </dt> <dd>
<p>Turn <em>off</em> update frame squeezing on context switch. (There’s no particularly good reason to turn it off, except to ensure the accuracy of certain data collected regarding thunk entry counts.)</p> </dd>
</dl> </section> <section id="getting-information-about-the-rts"> <h2 id="ghc-info">
<span class="section-number">5.7.10. </span>Getting information about the RTS</h2> <dl class="std rts-flag" id="index-36"> <dt class="sig sig-object std" id="rts-flag-info">
<code>--info</code> </dt> <dd>
<p>It is possible to ask the RTS to give some information about itself. To do this, use the <a class="reference internal" href="#rts-flag-info"><code>--info</code></a> flag, e.g.</p> <pre data-language="none">$ ./a.out +RTS --info
[("GHC RTS", "YES")
,("GHC version", "6.7")
,("RTS way", "rts_p")
,("Host platform", "x86_64-unknown-linux")
,("Host architecture", "x86_64")
,("Host OS", "linux")
,("Host vendor", "unknown")
,("Build platform", "x86_64-unknown-linux")
,("Build architecture", "x86_64")
,("Build OS", "linux")
,("Build vendor", "unknown")
,("Target platform", "x86_64-unknown-linux")
,("Target architecture", "x86_64")
,("Target OS", "linux")
,("Target vendor", "unknown")
,("Word size", "64")
,("Compiler unregisterised", "NO")
,("Tables next to code", "YES")
,("Flag -with-rtsopts", "")
,("I/O manager default", "select")
]
</pre> <p>The information is formatted such that it can be read as a of type <code>[(String, String)]</code>. Currently the following fields are present:</p> <dl class="simple"> <dt>
<code>GHC RTS</code> </dt>
<dd>
<p>Is this program linked against the GHC RTS? (always “YES”).</p> </dd> <dt>
<code>GHC version</code> </dt>
<dd>
<p>The version of GHC used to compile this program.</p> </dd> <dt>
<code>RTS way</code> </dt>
<dd>
<p>The variant (“way”) of the runtime. The most common values are <code>rts_v</code> (vanilla), <code>rts_thr</code> (threaded runtime, i.e. linked using the <a class="reference internal" href="phases.html#ghc-flag--single-threaded"><code>-threaded</code></a> option) and <code>rts_p</code> (profiling runtime, i.e. linked using the <a class="reference internal" href="profiling.html#ghc-flag-prof"><code>-prof</code></a> option). Other variants include <code>debug</code> (linked using <a class="reference internal" href="phases.html#ghc-flag-debug"><code>-debug</code></a>), and <code>dyn</code> (the RTS is linked in dynamically, i.e. a shared library, rather than statically linked into the executable itself). These can be combined, e.g. you might have <code>rts_thr_debug_p</code>.</p> </dd> <dt>
<code>Target platformTarget architectureTarget OSTarget vendor</code> </dt>
<dd>
<p>These are the platform the program is compiled to run on.</p> </dd> <dt>
<code>Build platformBuild architectureBuild OSBuild vendor</code> </dt>
<dd>
<p>These are the platform where the program was built on. (That is, the target platform of GHC itself.) Ordinarily this is identical to the target platform. (It could potentially be different if cross-compiling.)</p> </dd> <dt>
<code>Host platformHost architectureHost OSHost vendor</code> </dt>
<dd>
<p>These are the platform where GHC itself was compiled. Again, this would normally be identical to the build and target platforms.</p> </dd> <dt>
<code>Word size</code> </dt>
<dd>
<p>Either <code>"32"</code> or <code>"64"</code>, reflecting the word size of the target platform.</p> </dd> <dt>
<code>Compiler unregistered</code> </dt>
<dd>
<p>Was this program compiled with an <a class="reference internal" href="codegens.html#unreg"><span class="std std-ref">“unregistered”</span></a> version of GHC? (I.e., a version of GHC that has no platform-specific optimisations compiled in, usually because this is a currently unsupported platform.) This value will usually be no, unless you’re using an experimental build of GHC.</p> </dd> <dt>
<code>Tables next to code</code> </dt>
<dd>
<p>Putting info tables directly next to entry code is a useful performance optimisation that is not available on all platforms. This field tells you whether the program has been compiled with this optimisation. (Usually yes, except on unusual platforms.)</p> </dd> <dt>
<code>Flag -with-rtsopts</code> </dt>
<dd>
<p>The value of the GHC flag <a class="reference internal" href="phases.html#ghc-flag-with-rtsopts-opts"><code>-with-rtsopts=⟨opts⟩</code></a> at compile/link time.</p> </dd> <dt>
<code>I/O manager default</code> </dt>
<dd>
<p>The name of the I/O manager subsystem that will be used by default for this program. This can be overridden with the <a class="reference internal" href="#rts-flag-io-manager-name"><code>--io-manager=(name)</code></a> RTS flag.</p> </dd> </dl> </dd>
</dl> </section> </section> </div> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2002&ndash;2007 The University Court of the University of Glasgow. All rights reserved.<br>Licensed under the Glasgow Haskell Compiler License.<br>
    <a href="https://downloads.haskell.org/~ghc/9.12.1/docs/users_guide/runtime_control.html" class="_attribution-link">https://downloads.haskell.org/~ghc/9.12.1/docs/users_guide/runtime_control.html</a>
  </p>
</div>
