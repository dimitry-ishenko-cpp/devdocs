<h1 id="options-optimise">5.3. Optimisation (code improvement)</h1>
<div class="_sphinx"> <div itemprop="articleBody"> <section id="optimisation-code-improvement">  <p id="index-0">The <code>-O*</code> options specify convenient “packages” of optimisation flags; the <code>-f*</code> options described later on specify <em>individual</em> optimisations to be turned on/off; the <code>-m*</code> options specify <em>machine-specific</em> optimisations to be turned on/off.</p> <p>Most of these options are boolean and have options to turn them both “on” and “off” (beginning with the prefix <code>no-</code>). For instance, while <code>-fspecialise</code> enables specialisation, <code>-fno-specialise</code> disables it. When multiple flags for the same option appear in the command-line they are evaluated from left to right. For instance, <code>-fno-specialise -fspecialise</code> will enable specialisation.</p> <p>It is important to note that the <code>-O*</code> flags are roughly equivalent to combinations of <code>-f*</code> flags. For this reason, the effect of the <code>-O*</code> and <code>-f*</code> flags is dependent upon the order in which they occur on the command line.</p> <p>For instance, take the example of <code>-fno-specialise -O1</code>. Despite the <code>-fno-specialise</code> appearing in the command line, specialisation will still be enabled. This is the case as <code>-O1</code> implies <code>-fspecialise</code>, overriding the previous flag. By contrast, <code>-O1 -fno-specialise</code> will compile without specialisation, as one would expect.</p> <section id="o-convenient-packages-of-optimisation-flags"> <h2 id="optimise-pkgs">
<span class="section-number">5.3.1. </span><code>-O*</code>: convenient “packages” of optimisation flags.</h2> <p>There are <em>many</em> options that affect the quality of code produced by GHC. Most people only have a general goal, something like “Compile quickly” or “Make my program run like greased lightning.” The following “packages” of optimisations (or lack thereof) should suffice.</p> <p>Note that higher optimisation levels cause more cross-module optimisation to be performed, which can have an impact on how much of your program needs to be recompiled when you change something. This is one reason to stick to no-optimisation when developing code.</p> <p><strong>No ``-O*``-type option specified:</strong> This is taken to mean “Please compile quickly; I’m not over-bothered about compiled-code quality.” So, for example, <code>ghc -c Foo.hs</code></p> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-O0">
<code>-O0</code> </dt> <dd>
<p>Means “turn off all optimisation”, reverting to the same settings as if no <code>-O</code> options had been specified. Saying <code>-O0</code> can be useful if e.g. <code>make</code> has inserted a <code>-O</code> on the command line already.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-O">
<code>-O</code> </dt> <dt class="sig sig-object std" id="ghc-flag-O1">
<code>-O1</code> </dt> <dd>
<p id="index-1">Means: “Generate good-quality code without taking too long about it.” Thus, for example: <code>ghc -c -O Main.lhs</code></p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-O2">
<code>-O2</code> </dt> <dd>
<p id="index-2">Means: “Apply every non-dangerous optimisation, even if it means significantly longer compile times.”</p> <p>The avoided “dangerous” optimisations are those that can make runtime or space <em>worse</em> if you’re unlucky. They are normally turned on or off individually.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-On">
<code>-O⟨n⟩</code> </dt> <dd>
<p id="index-3">Any -On where n &gt; 2 is the same as -O2.</p> </dd>
</dl> <p>We don’t use a <code>-O*</code> flag for day-to-day work. We use <code>-O</code> to get respectable speed; e.g., when we want to measure something. When we want to go for broke, we tend to use <code>-O2</code> (and we go for lots of coffee breaks).</p> <p>The easiest way to see what <code>-O</code> (etc.) “really mean” is to run with <a class="reference internal" href="using.html#ghc-flag-v"><code>-v</code></a>, then stand back in amazement.</p> </section> <section id="f-platform-independent-flags"> <h2 id="options-f">
<span class="section-number">5.3.2. </span><code>-f*</code>: platform-independent flags</h2> <p id="index-4">These flags turn on and off individual optimisations. Flags marked as <em>on</em> by default are enabled at all optimisation levels by default, and as such you shouldn’t need to set any of them explicitly. A flag <code>-fwombat</code> can be negated by saying <code>-fno-wombat</code>.</p> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcore-constant-folding">
<code>-fcore-constant-folding</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables Core-level constant folding, i.e. propagation of values that can be computed at compile time.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcase-merge">
<code>-fcase-merge</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Merge immediately-nested case expressions that scrutinise the same variable. For example,</p> <pre data-language="haskell">case x of
   Red -&gt; e1
   _   -&gt; case x of
            Blue -&gt; e2
            Green -&gt; e3
</pre> <p>Is transformed to,</p> <pre data-language="haskell">case x of
   Red -&gt; e1
   Blue -&gt; e2
   Green -&gt; e2
</pre> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcase-folding">
<code>-fcase-folding</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Allow constant folding in case expressions that scrutinise some primops: For example,</p> <pre data-language="haskell">case x `minusWord#` 10## of
   10## -&gt; e1
   20## -&gt; e2
   v    -&gt; e3
</pre> <p>Is transformed to,</p> <pre data-language="haskell">case x of
   20## -&gt; e1
   30## -&gt; e2
   _    -&gt; let v = x `minusWord#` 10## in e3
</pre> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcall-arity">
<code>-fcall-arity</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enable call-arity analysis.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fexitification">
<code>-fexitification</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables the floating of exit paths out of recursive functions.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcmm-elim-common-blocks">
<code>-fcmm-elim-common-blocks</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables the common block elimination optimisation in the code generator. This optimisation attempts to find identical Cmm blocks and eliminate the duplicates.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcmm-sink">
<code>-fcmm-sink</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables the sinking pass in the code generator. This optimisation attempts to find identical Cmm blocks and eliminate the duplicates attempts to move variable bindings closer to their usage sites. It also inlines simple expressions like literals or registers.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcmm-static-pred">
<code>-fcmm-static-pred</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>This enables static control flow prediction on the final Cmm code. If enabled GHC will apply certain heuristics to identify loops and hot code paths. This information is then used by the register allocation and code layout passes.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcmm-control-flow">
<code>-fcmm-control-flow</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables some control flow optimisations in the Cmm code generator, merging basic blocks and avoiding jumps right after jumps.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fasm-shortcutting">
<code>-fasm-shortcutting</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O2"><code>-O2</code></a>.</p> </dd> </dl> <p>This enables shortcutting at the assembly stage of the code generator. In simpler terms shortcutting means if a block of instructions A only consists of a unconditionally jump, we replace all jumps to A by jumps to the successor of A.</p> <p>This is mostly done during Cmm passes. However this can miss corner cases. So at <code>-O2</code> this flag runs the pass again at the assembly stage to catch these. Note that due to platform limitations (<a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/21972">#21972</a>) this flag does nothing on macOS.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fblock-layout-cfg">
<code>-fblock-layout-cfg</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>The new algorithm considers all outgoing edges of a basic blocks for code layout instead of only the last jump instruction. It also builds a control flow graph for functions, tries to find hot code paths and place them sequentially leading to better cache utilization and performance.</p> <p>This is expected to improve performance on average, but actual performance difference can vary.</p> <p>If you find cases of significant performance regressions, which can be traced back to obviously bad code layout please open a ticket.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fblock-layout-weights">
<code>-fblock-layout-weights</code> </dt> <dd>
<p>This flag is hacker territory. The main purpose of this flag is to make it easy to debug and tune the new code layout algorithm. There is no guarantee that values giving better results now won’t be worse with the next release.</p> <p>If you feel your code warrants modifying these settings please consult the source code for default values and documentation. But I strongly advise against this.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fblock-layout-weightless">
<code>-fblock-layout-weightless</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>When not using the cfg based blocklayout layout is determined either by the last jump in a basic block or the heaviest outgoing edge of the block in the cfg.</p> <p>With this flag enabled we use the last jump instruction in blocks. Without this flags the old algorithm also uses the heaviest outgoing edge.</p> <p>When this flag is enabled and <a class="reference internal" href="#ghc-flag-fblock-layout-cfg"><code>-fblock-layout-cfg</code></a> is disabled block layout behaves the same as in 8.6 and earlier.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcpr-anal">
<code>-fcpr-anal</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Turn on CPR analysis, which enables the worker/wrapper transformation (cf. <a class="reference internal" href="#ghc-flag-fworker-wrapper"><code>-fworker-wrapper</code></a>) to unbox the result of a function, such as</p> <pre data-language="haskell">sum :: [Int] -&gt; Int
sum []     = 0
sum (x:xs) = x + sum xs
</pre> <p>CPR analysis will see that each code path produces a <em>constructed product</em> such as <code>I# 0#</code> in the first branch (where <code>GHC.Exts.I#</code> is the data constructor of <code>Int</code>, boxing up the primitive integer literal <code>0#</code> of type <code>Int#</code>) and optimise to</p> <pre data-language="haskell">sum xs = I# ($wsum xs)
$wsum []        = 0#
$wsum (I# x:xs) = x# +# $wsum xs
</pre> <p>and then <code>sum</code> can inline to potentially cancel away the <code>I#</code> box.</p> <p>Here’s an example of the function that <em>does not</em> return a constructed product:</p> <pre data-language="haskell">f :: [Int] -&gt; (Int -&gt; Int) -&gt; Int
f []     g = g 0
f (x:xs) g = x + f xs g
</pre> <p>The expression <code>g 0</code> is not a constructed product, because we don’t know anything about <code>g</code>.</p> <p>CPR analysis also works <em>nestedly</em>, for example</p> <pre data-language="haskell">sumIO :: [Int] -&gt; IO Int
sumIO []     = return 0
sumIO (x:xs) = do
  r &lt;- sumIO xs
  return $! x + r
</pre> <p>Note the use of <code>$!</code>: Without it, GHC would be unable to see that evaluation of <code>r</code> and <code>x</code> terminates (and rapidly, at that). An alternative would be to evaluate both with a bang pattern or a <code>seq</code>, but the <code>return $! &lt;res&gt;</code> idiom should work more reliably and needs less thinking. The above example will be optimised to</p> <pre data-language="haskell">sumIO :: [Int] -&gt; IO Int
sumIO xs = IO $ \s -&gt; case $wsum xs s of
  (# s', r #) -&gt; (# s', I# r #)
$wsumIO :: [Int] -&gt; (# State# RealWorld, Int# #)
$wsumIO []        s = (# s, 0# #)
$wsumIO (I# x:xs) s = case $wsumIO xs of
  (# s', r #) -&gt; (# s', x +# r#)
</pre> <p>And the latter can inline <code>sumIO</code> and cancel away the <code>I#</code> constructor. Unboxing the result of a <code>State</code> action should work similarly.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcse">
<code>-fcse</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables the common-sub-expression elimination optimisation. Switching this off can be useful if you have some <code>unsafePerformIO</code> expressions that you don’t want commoned-up.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstg-cse">
<code>-fstg-cse</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enables the common-sub-expression elimination optimisation on the STG intermediate language, where it is able to common up some subexpressions that differ in their types, but not their representation.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdicts-cheap">
<code>-fdicts-cheap</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>A very experimental flag that makes dictionary-valued expressions seem cheap to the optimiser.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdicts-strict">
<code>-fdicts-strict</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O2"><code>-O2</code></a>.</p> </dd> </dl> <p>Make dictionaries strict.</p> <p>This enables WW to fire on dictionary constraints which usually results in better runtime. In niche cases it can lead to significant compile time regressions because of changed inlining behaviour. Rarely this can also affect runtime negatively.</p> <p>If enabling this flag leads to regressions try increasing the unfolding threshold using <a class="reference internal" href="#ghc-flag-funfolding-use-threshold-n"><code>-funfolding-use-threshold=⟨n⟩</code></a> by a modest amount (~30) as this is likely a result of a known limitation described in <code>#18421</code>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdmd-tx-dict-sel">
<code>-fdmd-tx-dict-sel</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>Use a special demand transformer for dictionary selectors. Behaviour is unconditionally enabled starting with 9.2</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdo-eta-reduction">
<code>-fdo-eta-reduction</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>Eta-reduce lambda expressions, if doing so gets rid of a whole group of lambdas.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdo-lambda-eta-expansion">
<code>-fdo-lambda-eta-expansion</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>Eta-expand let-bindings to increase their arity.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdo-clever-arg-eta-expansion">
<code>-fdo-clever-arg-eta-expansion</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Eta-expand arguments to increase their arity to avoid allocating unnecessary thunks for them.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-feager-blackholing">
<code>-feager-blackholing</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Usually GHC black-holes a thunk only when it switches threads. This flag makes it do so as soon as the thunk is entered. See <a class="reference external" href="https://simonmar.github.io/bib/papers/multiproc.pdf">Haskell on a shared-memory multiprocessor</a>.</p> <p>See <a class="reference internal" href="using-concurrent.html#parallel-compile-options"><span class="std std-ref">Compile-time options for SMP parallelism</span></a> for a discussion on its use.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fexcess-precision">
<code>-fexcess-precision</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>When this option is given, intermediate floating point values can have a <em>greater</em> precision/range than the final type. Generally this is a good thing, but some programs may rely on the exact precision/range of <code>Float</code>/<code>Double</code> values and should not use this option for their compilation.</p> <p>Note that the 32-bit x86 native code generator only supports excess-precision mode, so neither <code>-fexcess-precision</code> nor <code>-fno-excess-precision</code> has any effect. This is a known bug, see <a class="reference internal" href="bugs.html#bugs-ghc"><span class="std std-ref">Bugs in GHC</span></a>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fexpose-all-unfoldings">
<code>-fexpose-all-unfoldings</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>A flag to expose all unfoldings, even for very large or recursive functions.</p> <p>However GHC will still use the usual heuristics to make inlining and specialization choices. This means further measures are needed to get benefits at use sites. Usually this involves one of:</p> <ul class="simple"> <li>
<a class="reference internal" href="#ghc-flag-fspecialise-aggressively"><code>-fspecialise-aggressively</code></a> to force as much specialization as possible.</li> <li>
<code>{-# SPECIALIZE #-}</code> pragmas to ensure specialization to specific types.</li> <li>Use of the magic <code>inline</code> function to force inlining.</li> </ul> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fexpose-overloaded-unfoldings">
<code>-fexpose-overloaded-unfoldings</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>This experimental flag is a slightly less heavy weight alternative to <a class="reference internal" href="#ghc-flag-fexpose-all-unfoldings"><code>-fexpose-all-unfoldings</code></a>.</p> <p>Instead of exposing all functions it only aims at exposing constrained functions. This is intended to be used for cases where specialization is considered crucial but <a class="reference internal" href="#ghc-flag-fexpose-all-unfoldings"><code>-fexpose-all-unfoldings</code></a> imposes too much compile time cost.</p> <p>Currently this won’t expose unfoldings where a type class is hidden under a newtype. That is for cases like:</p> <pre data-language="haskell">newtype NT a = NT (Integral a =&gt; a)

foo :: NT a -&gt; T1 -&gt; TR
</pre> <p>GHC won’t recognise <code>foo</code> as specialisable and won’t expose the unfolding even with <a class="reference internal" href="#ghc-flag-fexpose-overloaded-unfoldings"><code>-fexpose-overloaded-unfoldings</code></a> enabled.</p> <p>All the other caveats about <a class="reference internal" href="#ghc-flag-fexpose-overloaded-unfoldings"><code>-fexpose-overloaded-unfoldings</code></a> still apply, so please see there for more details.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-ffloat-in">
<code>-ffloat-in</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Float let-bindings inwards, nearer their binding site. See <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/">Let-floating: moving bindings to give faster programs (ICFP’96)</a>.</p> <p>This optimisation moves let bindings closer to their use site. The benefit here is that this may avoid unnecessary allocation if the branch the let is now on is never executed. It also enables other optimisation passes to work more effectively as they have more information locally.</p> <p>This optimisation isn’t always beneficial though (so GHC applies some heuristics to decide when to apply it). The details get complicated but a simple example is that it is often beneficial to move let bindings outwards so that multiple let bindings can be grouped into a larger single let binding, effectively batching their allocation and helping the garbage collector and allocator.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-ffull-laziness">
<code>-ffull-laziness</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Run the full laziness optimisation (also known as let-floating), which floats let-bindings outside enclosing lambdas, in the hope they will be thereby be computed less often. See <a class="reference external" href="https://research.microsoft.com/en-us/um/people/simonpj/papers/float.ps.gz">Let-floating: moving bindings to give faster programs (ICFP’96)</a>. Full laziness increases sharing, which can lead to increased memory residency.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>GHC doesn’t implement complete full laziness. Although GHC’s full-laziness optimisation does enable some transformations which would be performed by a fully lazy implementation (such as extracting repeated computations from loops), these transformations are not applied consistently, so don’t rely on them.</p> </div> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-ffun-to-thunk">
<code>-ffun-to-thunk</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Worker/wrapper removes unused arguments, but usually we do not remove them all, lest it turn a function closure into a thunk, thereby perhaps creating a space leak and/or disrupting inlining. This flag allows worker/wrapper to remove <em>all</em> value lambdas.</p> <p>This flag was ineffective in the presence of <a class="reference internal" href="#ghc-flag-ffull-laziness"><code>-ffull-laziness</code></a>, which would flout a thunk out of a constant worker function <em>even though</em> <a class="reference internal" href="#ghc-flag-ffun-to-thunk"><code>-ffun-to-thunk</code></a> was off.</p> <p>Hence use of this flag is deprecated since GHC 9.4.1 and we rather suggest to pass <code>-fno-full-laziness</code> instead. That implies there’s no way for worker/wrapper to turn a function into a thunk in the presence of <code>-fno-full-laziness</code>. If that is inconvenient for you, please leave a comment <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/-/issues/21204">on the issue tracker (#21204)</a>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fignore-asserts">
<code>-fignore-asserts</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Causes GHC to ignore uses of the function <code>Exception.assert</code> in source code (in other words, rewriting <code>Exception.assert p e</code> to <code>e</code> (see <a class="reference internal" href="exts/assert.html#assertions"><span class="std std-ref">Assertions</span></a>).</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fignore-interface-pragmas">
<code>-fignore-interface-pragmas</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>Implied by <a class="reference internal" href="#ghc-flag--O%E2%9F%A8n%E2%9F%A9"><code>-O0</code></a>, otherwise off.</p> </dd> </dl> <p>Tells GHC to ignore all inessential information when reading interface files. That is, even if <code>M.hi</code> contains unfolding or strictness information for a function, GHC will ignore that information.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fkeep-auto-rules">
<code>-fkeep-auto-rules</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.10.1</p> </dd> </dl> <p>The type-class specialiser and call-pattern specialisation both generate so-called “auto” RULES. These rules are usually exposed to importing modules in the interface file. But when an auto rule is the sole reason for keeping a function alive, both the rule and the function are discarded, by default. That reduces code bloat, but risks the same function being specialised again in an importing module.</p> <p>You can change this behaviour with <a class="reference internal" href="#ghc-flag-fkeep-auto-rules"><code>-fkeep-auto-rules</code></a>. Switching it on keeps all auto-generated rules.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-flate-dmd-anal">
<code>-flate-dmd-anal</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Run demand analysis again, at the end of the simplification pipeline. We found some opportunities for discovering strictness that were not visible earlier; and optimisations like <a class="reference internal" href="#ghc-flag-fspec-constr"><code>-fspec-constr</code></a> can create functions with unused arguments which are eliminated by late demand analysis. Improvements are modest, but so is the cost. See notes on the <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/wikis/late-dmd">wiki page</a>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fliberate-case">
<code>-fliberate-case</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O2"><code>-O2</code></a>.</p> </dd> </dl> <p>Turn on the liberate-case transformation. This unrolls recursive function once in its own RHS, to avoid repeated case analysis of free variables. It’s a bit like the call-pattern specialiser (<a class="reference internal" href="#ghc-flag-fspec-constr"><code>-fspec-constr</code></a>) but for free variables rather than arguments.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fliberate-case-threshold-n">
<code>-fliberate-case-threshold=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2000</p> </dd> </dl> <p>Set the size threshold for the liberate-case transformation.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-floopification">
<code>-floopification</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>When this optimisation is enabled the code generator will turn all self-recursive saturated tail calls into local jumps rather than function calls.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fllvm-pass-vectors-in-regs">
<code>-fllvm-pass-vectors-in-regs</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>This flag has no effect since GHC 8.8 - its behavior is always on. It used to instruct GHC to use the platform’s native vector registers to pass vector arguments during function calls.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-inline-alloc-size-n">
<code>-fmax-inline-alloc-size=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>128</p> </dd> </dl> <p>Set the maximum size of inline array allocations to n bytes. GHC will allocate non-pinned arrays of statically known size in the current nursery block if they’re no bigger than n bytes, ignoring GC overheap. This value should be quite a bit smaller than the block size (typically: 4096).</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-inline-memcpy-insns-n">
<code>-fmax-inline-memcpy-insns=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>32</p> </dd> </dl> <p>Inline <code>memcpy</code> calls if they would generate no more than ⟨n⟩ pseudo-instructions.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-inline-memset-insns-n">
<code>-fmax-inline-memset-insns=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>32</p> </dd> </dl> <p>Inline <code>memset</code> calls if they would generate no more than n pseudo instructions.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-relevant-binds-n">
<code>-fmax-relevant-binds=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>6</p> </dd> </dl> <p>The type checker sometimes displays a fragment of the type environment in error messages, but only up to some maximum number, set by this flag. Turning it off with <code>-fno-max-relevant-binds</code> gives an unlimited number. Syntactically top-level bindings are also usually excluded (since they may be numerous), but <code>-fno-max-relevant-binds</code> includes them too.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-uncovered-patterns-n">
<code>-fmax-uncovered-patterns=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>4</p> </dd> </dl> <p>Maximum number of unmatched patterns to be shown in warnings generated by <a class="reference internal" href="using-warnings.html#ghc-flag-Wincomplete-patterns"><code>-Wincomplete-patterns</code></a> and <a class="reference internal" href="using-warnings.html#ghc-flag-Wincomplete-uni-patterns"><code>-Wincomplete-uni-patterns</code></a>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-simplifier-iterations-n">
<code>-fmax-simplifier-iterations=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>4</p> </dd> </dl> <p>Sets the maximal number of iterations for the simplifier.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-flocal-float-out">
<code>-flocal-float-out</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>Enable local floating of bindings from the RHS of a let(rec) in the simplifier. For example</p> <pre data-language="haskell">let x = let y = rhs_y in rhs_x in blah
==&gt;
let y = rhs_y in let x = rhs_x in blah
</pre> <p>See the paper “Let-floating: moving bindings to give faster programs”, Partain, Santos, and Peyton Jones; ICFP 1996. <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/">https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/</a></p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This is distinct from the global floating pass which can be disabled with <a class="reference internal" href="#ghc-flag--ffull-laziness"><code>-fno-full-laziness</code></a>.</p> </div> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-flocal-float-out-top-level">
<code>-flocal-float-out-top-level</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>Enable local floating of top-level bindings from the RHS of a let(rec) in the simplifier. For example</p>  <p>x = let y = e in (a,b) ===&gt; y = e; x = (a,b)</p>  <p>See the paper “Let-floating: moving bindings to give faster programs”, Partain, Santos, and Peyton Jones; ICFP 1996. <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/">https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/</a></p> <p>Note that if <a class="reference internal" href="#ghc-flag--flocal-float-out"><code>-fno-local-float-out</code></a> is set, that will take precedence.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This is distinct from the global floating pass which can be disabled with <a class="reference internal" href="#ghc-flag--ffull-laziness"><code>-fno-full-laziness</code></a>.</p> </div> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-worker-args-n">
<code>-fmax-worker-args=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>10</p> </dd> </dl> <p>A function will not be split into worker and wrapper if the number of value arguments of the resulting worker exceeds both that of the original function and this setting.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fmax-forced-spec-args-n">
<code>-fmax-forced-spec-args=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>512</p> </dd> </dl> <p>When using <code>SPEC</code> from <code>GHC.Types</code> to force SpecConstr to fire on a function sometimes this can result in functions taking a ridicolously large number of arguments resulting a very large compile time hits for minor performance benefits.</p> <p>Since this is usually unintended we prevent SpecConstr from firing and generate a warning if the number of arguments in the resulting function would exceed the value given by <code>-fmax-forced-spec-args</code>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fno-opt-coercion">
<code>-fno-opt-coercion</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>coercion optimisation enabled.</p> </dd> </dl> <p>Turn off the coercion optimiser.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fno-pre-inlining">
<code>-fno-pre-inlining</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>pre-inlining enabled</p> </dd> </dl> <p>Turn off pre-inlining.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fno-state-hack">
<code>-fno-state-hack</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>state hack is enabled</p> </dd> </dl> <p>Turn off the “state hack” whereby any lambda with a <code>State#</code> token as argument is considered to be single-entry, hence it is considered okay to inline things inside it. This can improve performance of IO and ST monad code, but it runs the risk of reducing sharing.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fomit-interface-pragmas">
<code>-fomit-interface-pragmas</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>Implied by <a class="reference internal" href="#ghc-flag--O%E2%9F%A8n%E2%9F%A9"><code>-O0</code></a>, otherwise off.</p> </dd> </dl> <p>Tells GHC to omit all inessential information from the interface file generated for the module being compiled (say M). This means that a module importing M will see only the <em>types</em> of the functions that M exports, but not their unfoldings, strictness info, etc. Hence, for example, no function exported by M will be inlined into an importing module. The benefit is that modules that import M will need to be recompiled less often (only when M’s exports change their type, not when they change their implementation).</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fomit-yields">
<code>-fomit-yields</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on (yields are <em>not</em> inserted)</p> </dd> </dl> <p>Tells GHC to omit heap checks when no allocation is being performed. While this improves binary sizes by about 5%, it also means that threads run in tight non-allocating loops will not get preempted in a timely fashion. If it is important to always be able to interrupt such threads, you should turn this optimization off. Consider also recompiling all libraries with this optimization turned off, if you need to guarantee interruptibility.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fobject-determinism">
<code>-fobject-determinism</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>object determinism is disabled</p> </dd> </dl> <p>Tell GHC to produce fully deterministic object code. Producing deterministic objects requires an additional renaming pass before the Cmm pipeline that renames all Uniques deterministically. This may slightly regress compilation speed, but guarantees deterministic objects.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fpedantic-bottoms">
<code>-fpedantic-bottoms</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Make GHC be more precise about its treatment of bottom (but see also <a class="reference internal" href="#ghc-flag-fno-state-hack"><code>-fno-state-hack</code></a>). In particular, stop GHC eta-expanding through a case expression, which is good for performance, but bad if you are using <code>seq</code> on partial applications.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fregs-graph">
<code>-fregs-graph</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off due to a performance regression bug (<a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/7679">#7679</a>)</p> </dd> </dl> <p><em>Only applies in combination with the native code generator.</em> Use the graph colouring register allocator for register allocation in the native code generator. By default, GHC uses a simpler, faster linear register allocator. The downside being that the linear register allocator usually generates worse code.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fregs-iterative">
<code>-fregs-iterative</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p><em>Only applies in combination with the native code generator.</em> Use the iterative coalescing graph colouring register allocator for register allocation in the native code generator. This is the same register allocator as the <a class="reference internal" href="#ghc-flag-fregs-graph"><code>-fregs-graph</code></a> one but also enables iterative coalescing during register allocation.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fsimplifier-phases-n">
<code>-fsimplifier-phases=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2</p> </dd> </dl> <p>Set the number of phases for the simplifier. Ignored with <code>-O0</code>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fsimpl-tick-factor-n">
<code>-fsimpl-tick-factor=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>100</p> </dd> </dl> <p>GHC’s optimiser can diverge if you write rewrite rules (<a class="reference internal" href="exts/rewrite_rules.html#rewrite-rules"><span class="std std-ref">Rewrite rules</span></a>) that don’t terminate, or (less satisfactorily) if you code up recursion through data types (<a class="reference internal" href="bugs.html#bugs-ghc"><span class="std std-ref">Bugs in GHC</span></a>). To avoid making the compiler fall into an infinite loop, the optimiser carries a “tick count” and stops inlining and applying rewrite rules when this count is exceeded. The limit is set as a multiple of the program size, so bigger programs get more ticks. The <code>-fsimpl-tick-factor</code> flag lets you change the multiplier. The default is 100; numbers larger than 100 give more ticks, and numbers smaller than 100 give fewer.</p> <p>If the tick-count expires, GHC summarises what simplifier steps it has done; you can use <code>-fddump-simpl-stats</code> to generate a much more detailed list. Usually that identifies the loop quite accurately, because some numbers are very large.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fdmd-unbox-width-n">
<code>-fdmd-unbox-width=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>3</p> </dd> </dl> <p>Boxity analysis optimistically pretends that a function returning a record with at most <code>-fdmd-unbox-width</code> fields has only call sites that don’t need the box of the returned record. That may in turn allow more argument unboxing to happen. Set to 0 to be completely conservative (which guarantees that no reboxing will happen due to this mechanism).</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspec-constr">
<code>-fspec-constr</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O2"><code>-O2</code></a>.</p> </dd> </dl> <p>Turn on call-pattern specialisation; see <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/system-f-with-type-equality-coercions-2/">Call-pattern specialisation for Haskell programs</a>.</p> <p>This optimisation specializes recursive functions according to their argument “shapes”. This is best explained by example so consider:</p> <pre data-language="haskell">last :: [a] -&gt; a
last [] = error "last"
last (x : []) = x
last (x : xs) = last xs
</pre> <p>In this code, once we pass the initial check for an empty list we know that in the recursive case this pattern match is redundant. As such <code>-fspec-constr</code> will transform the above code to:</p> <pre data-language="haskell">last :: [a] -&gt; a
last []       = error "last"
last (x : xs) = last' x xs
    where
      last' x []       = x
      last' x (y : ys) = last' y ys
</pre> <p>As well avoid unnecessary pattern matching it also helps avoid unnecessary allocation. This applies when an argument is strict in the recursive call to itself but not on the initial entry. A strict recursive branch of the function is created similar to the above example.</p> <p>It is also possible for library writers to instruct GHC to perform call-pattern specialisation extremely aggressively. This is necessary for some highly optimized libraries, where we may want to specialize regardless of the number of specialisations, or the size of the code. As an example, consider a simplified use-case from the <code>vector</code> library:</p> <pre data-language="haskell">import GHC.Types (SPEC(..))

foldl :: (a -&gt; b -&gt; a) -&gt; a -&gt; Stream b -&gt; a
{-# INLINE foldl #-}
foldl f z (Stream step s _) = foldl_loop SPEC z s
  where
    foldl_loop !sPEC z s = case step s of
                            Yield x s' -&gt; foldl_loop sPEC (f z x) s'
                            Skip       -&gt; foldl_loop sPEC z s'
                            Done       -&gt; z
</pre> <p>Here, after GHC inlines the body of <code>foldl</code> to a call site, it will perform call-pattern specialisation very aggressively on <code>foldl_loop</code> due to the use of <code>SPEC</code> in the argument of the loop body. <code>SPEC</code> from <code>GHC.Types</code> is specifically recognised by the compiler.</p> <p>(NB: it is extremely important you use <code>seq</code> or a bang pattern on the <code>SPEC</code> argument!)</p> <p>In particular, after inlining this will expose <code>f</code> to the loop body directly, allowing heavy specialisation over the recursive cases.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspec-constr-keen">
<code>-fspec-constr-keen</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>If this flag is on, call-pattern specialisation will specialise a call <code>(f (Just x))</code> with an explicit constructor argument, even if the argument is not scrutinised in the body of the function. This is sometimes beneficial; e.g. the argument might be given to some other function that can itself be specialised.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspec-constr-count-n">
<code>-fspec-constr-count=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>3</p> </dd> </dl> <p>Set the maximum number of specialisations that will be created for any one function by the SpecConstr transformation.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspec-constr-threshold-n">
<code>-fspec-constr-threshold=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2000</p> </dd> </dl> <p>Set the size threshold for the SpecConstr transformation.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspecialise">
<code>-fspecialise</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Specialise each type-class-overloaded function defined in this module for the types at which it is called in this module. If <a class="reference internal" href="#ghc-flag-fcross-module-specialise"><code>-fcross-module-specialise</code></a> is set imported functions that have an INLINABLE pragma (<a class="reference internal" href="exts/pragmas.html#inlinable-pragma"><span class="std std-ref">INLINABLE pragma</span></a>) will be specialised as well.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspecialise-aggressively">
<code>-fspecialise-aggressively</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>This flag controls the specialisation of <em>imported</em> functions only. By default, an imported function is only specialised if it is marked <code>INLINEABLE</code> or <code>INLINE</code>. But with <a class="reference internal" href="#ghc-flag-fspecialise-aggressively"><code>-fspecialise-aggressively</code></a>, an imported function is specialised if its unfolding is available in the interface file. (Use <a class="reference internal" href="#ghc-flag-fexpose-all-unfoldings"><code>-fexpose-all-unfoldings</code></a> or <a class="reference internal" href="#ghc-flag-fexpose-overloaded-unfoldings"><code>-fexpose-overloaded-unfoldings</code></a> to ensure that the unfolding is put into the interface file.)</p> <p><a class="reference internal" href="#ghc-flag-fspecialise-aggressively"><code>-fspecialise-aggressively</code></a> is not included in any optimisation level as it can massively increase code size.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fcross-module-specialise">
<code>-fcross-module-specialise</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Specialise <code>INLINABLE</code> (<a class="reference internal" href="exts/pragmas.html#inlinable-pragma"><span class="std std-ref">INLINABLE pragma</span></a>) type-class-overloaded functions imported from other modules for the types at which they are called in this module. Note that specialisation must be enabled (by <code>-fspecialise</code>) for this to have any effect.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fpolymorphic-specialisation">
<code>-fpolymorphic-specialisation</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Warning, this feature is highly experimental and may lead to incorrect runtime results. Use at your own risk (<a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/23469">#23469</a>, <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/23109">#23109</a>, <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/21229">#21229</a>, <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/23445">#23445</a>).</p> <p>Enable specialisation of function calls to known dictionaries with free type variables. The created specialisation will abstract over the type variables free in the dictionary.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-flate-specialise">
<code>-flate-specialise</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Runs another specialisation pass towards the end of the optimisation pipeline. This can catch specialisation opportunities which arose from the previous specialisation pass or other inlining.</p> <p>You might want to use this if you are you have a type class method which returns a constrained type. For example, a type class where one of the methods implements a traversal.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fspecialise-incoherents">
<code>-fspecialise-incoherents</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>on</p> </dd> </dl> <p>Enable specialisation of overloaded functions in cases when the selected instance is incoherent. This makes the choice of instance non-deterministic, so it is only safe to do if there is no observable runtime behaviour difference between potentially unifying instances. Turning this flag off ensures the incoherent instance selection adheres to the algorithm described in <a class="reference internal" href="exts/instances.html#extension-IncoherentInstances"><code>IncoherentInstances</code></a> at the cost of optimisation opportunities arising from specialisation.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-finline-generics">
<code>-finline-generics</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.2.1</p> </dd> </dl> <p id="index-5">Annotate methods of derived Generic and Generic1 instances with INLINE[1] pragmas based on heuristics dependent on the size of the data type in question. Improves performance of generics-based algorithms as GHC is able to optimize away intermediate representation more often.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-finline-generics-aggressively">
<code>-finline-generics-aggressively</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.2.1</p> </dd> </dl> <p id="index-6">Annotate methods of all derived Generic and Generic1 instances with INLINE[1] pragmas.</p> <p>This flag should only be used in modules deriving Generic instances that weren’t considered appropriate for INLINE[1] annotations by heuristics of <a class="reference internal" href="#ghc-flag-finline-generics"><code>-finline-generics</code></a>, yet you know that doing so would be beneficial.</p> <p>When enabled globally it will most likely lead to worse compile times and code size blowup without runtime performance gains.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fsolve-constant-dicts">
<code>-fsolve-constant-dicts</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>When solving constraints, try to eagerly solve super classes using available dictionaries.</p> <p>For example:</p> <pre data-language="haskell">class M a b where m :: a -&gt; b

type C a b = (Num a, M a b)

f :: C Int b =&gt; b -&gt; Int -&gt; Int
f _ x = x + 1
</pre> <p>The body of <code>f</code> requires a <code>Num Int</code> instance. We could solve this constraint from the context because we have <code>C Int b</code> and that provides us a solution for <code>Num Int</code>. However, we can often produce much better code by directly solving for an available <code>Num Int</code> dictionary we might have at hand. This removes potentially many layers of indirection and crucially allows other optimisations to fire as the dictionary will be statically known and selector functions can be inlined.</p> <p>The optimisation also works for GADTs which bind dictionaries. If we statically know which class dictionary we need then we will solve it directly rather than indirectly using the one passed in at run time.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstatic-argument-transformation">
<code>-fstatic-argument-transformation</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Turn on the static argument transformation, which turns a recursive function into a non-recursive one with a local recursive loop. See Chapter 7 of <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/compilation-transformation-non-strict-functional-languages/">Andre Santos’s PhD thesis</a>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstg-lift-lams">
<code>-fstg-lift-lams</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O2"><code>-O2</code></a>.</p> </dd> </dl> <p>Enables the late lambda lifting optimisation on the STG intermediate language. This selectively lifts local functions to top-level by converting free variables into function parameters.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstg-lift-lams-known">
<code>-fstg-lift-lams-known</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p>Allow turning known into unknown calls while performing late lambda lifting. This is deemed non-beneficial, so it’s off by default.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstg-lift-lams-non-rec-args">
<code>-fstg-lift-lams-non-rec-args</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>5</p> </dd> </dl> <p>Create top-level non-recursive functions with at most &lt;n&gt; parameters while performing late lambda lifting. The default is 5, the number of available parameter registers on x86_64.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstg-lift-lams-rec-args">
<code>-fstg-lift-lams-rec-args</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>5</p> </dd> </dl> <p>Create top-level recursive functions with at most &lt;n&gt; parameters while performing late lambda lifting. The default is 5, the number of available parameter registers on x86_64.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstrictness">
<code>-fstrictness</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Turn on demand analysis.</p> <p>A <em>Demand</em> describes an evaluation context of an expression. <em>Demand analysis</em> tries to find out what demands a function puts on its arguments when called: If an argument is scrutinised on every code path, the function is strict in that argument and GHC is free to use the more efficient call-by-value calling convention, as well as pass parameters unboxed.</p> <p>Apart from <em>strictness analysis</em>, demand analysis also performs <em>usage analysis</em>: Where <em>strict</em> translates to “evaluated at least once”, usage analysis asks whether arguments and bindings are “evaluated at most once” or not at all (“evaluated at most zero times”), e.g. <em>absent</em>. For the former, GHC may use call-by-name instead of call-by-need, effectively turning thunks into non-memoised functions. For the latter, no code needs to be generated at all: An absent argument can simply be replaced by a dummy value at the call site or omitted altogether.</p> <p>The worker/wrapper transformation (<a class="reference internal" href="#ghc-flag-fworker-wrapper"><code>-fworker-wrapper</code></a>) is responsible for exploiting unboxing opportunities and replacing absent arguments by dummies. For arguments that can’t be unboxed, opportunities for call-by-value and call-by-name are exploited in CorePrep when translating to STG.</p> <p>It’s not only interesting to look at how often a binding is <em>evaluated</em>, but also how often a function <em>is called</em>. If a function is called at most once, we may freely eta-expand it, even if doing so destroys shared work if the function was called multiple times. This information translates into <code>OneShotInfo</code> annotations that the Simplifier acts on.</p> <p><strong>Notation</strong></p> <p>So demand analysis is about conservatively inferring lower and upper bounds about how many times something is evaluated/called. We call the “how many times” part a <em>cardinality</em>. In the compiler and debug output we differentiate the following cardinality intervals as approximations to cardinality:</p> <table class="docutils align-default"> <thead> <tr>
<th class="head"><p>Interval</p></th> <th class="head"><p>Set of denoted cardinalities</p></th> <th class="head"><p>Syntax</p></th> <th class="head"><p>Explanation tying syntax to semantics</p></th> </tr> </thead>  <tr>
<td><p>[1,0]</p></td> <td><p>{}</p></td> <td><p><code>B</code></p></td> <td><p>Bottom element</p></td> </tr> <tr>
<td><p>[0,0]</p></td> <td><p>{0}</p></td> <td><p><code>A</code></p></td> <td><p>Absent</p></td> </tr> <tr>
<td><p>[0,1]</p></td> <td><p>{0,1}</p></td> <td><p><code>M</code></p></td> <td><p>Used at most once (“Maybe”)</p></td> </tr> <tr>
<td><p>[0,ω]</p></td> <td><p>{0,1,ω}</p></td> <td><p><code>L</code></p></td> <td><p>Lazy. Top element, no information, used at least 0, at most many times</p></td> </tr> <tr>
<td><p>[1,1]</p></td> <td><p>{1}</p></td> <td><p><code>1</code></p></td> <td><p>Strict, used exactly once</p></td> </tr> <tr>
<td><p>[1,ω]</p></td> <td><p>{1,ω}</p></td> <td><p><code>S</code></p></td> <td><p>Strict, used possibly many times</p></td> </tr>  </table> <p>Note that it’s never interesting to differentiate between a cardinality of 2 and 3, or even 4232123. We just approximate the &gt;1 case with ω, standing for “many times”.</p> <p>Apart from the cardinality describing <em>how often</em> an argument is evaluated, a demand also carries a <em>sub-demand</em>, describing <em>how deep</em> something is evaluated beyond a simple <code>seq</code>-like evaluation.</p> <p>This is the full syntax for cardinalities, demands and sub-demands in BNF:</p> <pre data-language="none">card ::= B | A | M | L | 1 | S    semantics as in the table above

d    ::= card sd                  card = how often, sd = how deep
      |  card                     abbreviation: Same as "card card"

sd   ::= card                     polymorphic sub-demand, card at every level
      |  P(d,d,..)                product sub-demand
      |  C(card,sd)               call sub-demand
</pre> <p>For example, <code>fst</code> is strict in its argument, and also in the first component of the argument. It will not evaluate the argument’s second component. That is expressed by the demand <code>1P(1L,A)</code>. The <code>P</code> is for “product sub-demand”, which has a <em>demand</em> for each product field. The notation <code>1L</code> just says “evaluated strictly (<code>1</code>), with everything nested inside evaluated according to <code>L</code>” – e.g., no information, because that would depend on the evaluation context of the call site of <code>fst</code>. The role of <code>L</code> in <code>1L</code> is that of a <em>polymorphic</em> sub-demand, being semantically equivalent to the sub-demand <code>P(LP(..))</code>, which we simply abbreviate by the (consequently overloaded) cardinality notation <code>L</code>.</p> <p>For another example, the expression <code>x + 1</code> evaluates <code>x</code> according to demand <code>1P(L)</code>. We have seen single letters stand for cardinalities and polymorphic sub-demands, but what does the single letter <code>L</code> mean for a <em>demand</em>? Such a single letter demand simply expands to a cardinality and a polymorphic sub-demand of the same letter: E.g. <code>L</code> is equivalent to <code>LL</code> by expansion of the single letter demand, which is equivalent to <code>LP(LP(..))</code>, so <code>L</code>s all the way down. It is always clear from context whether we talk about about a cardinality, sub-demand or demand.</p> <p><strong>Demand signatures</strong></p> <p>We summarise a function’s demand properties in its <em>demand signature</em>. This is the general syntax:</p> <pre data-language="none">{x-&gt;dx,y-&gt;dy,z-&gt;dz...}&lt;d1&gt;&lt;d2&gt;&lt;d3&gt;...&lt;dn&gt;div
        ^              ^   ^   ^      ^   ^
        |              |   |   |      |   |
        |              \---+---+------/   |
        |                  |              |
   demand on free        demand on      divergence
     variables           arguments      information
 (omitted if empty)                     (omitted if
                                      no information)
</pre> <p>We summarise <code>fst</code>’s demand properties in its <em>demand signature</em> <code>&lt;1P(1L,A)&gt;</code>, which just says “If <code>fst</code> is applied to one argument, that argument is evaluated according to <code>1P(1L,A)</code>”. For another example, the demand signature of <code>seq</code> would be <code>&lt;1A&gt;&lt;1L&gt;</code> and that of <code>+</code> would be <code>&lt;1P(L)&gt;&lt;1P(L)&gt;</code>.</p> <p>If not omitted, the divergence information can be <code>b</code> (surely diverges) or <code>x</code> (surely diverges or throws a precise exception). For example, <code>error</code> has demand signature <code>&lt;S&gt;b</code> and <code>throwIO</code> (which is the only way to throw precise exceptions) has demand signature <code>&lt;_&gt;&lt;L&gt;&lt;L&gt;x</code> (leaving out the complicated demand on the <code>Exception</code> dictionary).</p> <p><strong>Call sub-demands</strong></p> <p>Consider <code>maybe</code>:</p> <pre data-language="haskell">maybe :: b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
maybe n _ Nothing  = n
maybe _ s (Just a) = s a
</pre> <p>We give it demand signature <code>&lt;L&gt;&lt;MC(M,L)&gt;&lt;1L&gt;</code>. The <code>C(M,L)</code> is a <em>call sub-demand</em> that says “Called at most once, where the result is used according to <code>L</code>”. The expression <code>f `seq` f 1</code> puts <code>f</code> under demand <code>SC(1,L)</code> and serves as an example where the upper bound on evaluation cardinality doesn’t coincide with that of the call cardinality.</p> <p>Cardinality is always relative to the enclosing call cardinality, so <code>g 1 2 + g 3 4</code> puts <code>g</code> under demand <code>SC(S,C(1,L))</code>, which says “called multiple times (<code>S</code>), but every time it is called with one argument, it is applied exactly once to another argument (<code>1</code>)”.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fstrictness-before-n">
<code>-fstrictness-before=⟨n⟩</code> </dt> <dd>
<p>Run an additional demand analysis before simplifier phase ⟨n⟩.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funbox-small-strict-fields">
<code>-funbox-small-strict-fields</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p id="index-7">This option causes all constructor fields which are marked strict (i.e. “!”) and which representation is smaller or equal to the size of a pointer to be unpacked, if possible. It is equivalent to adding an <code>UNPACK</code> pragma (see <a class="reference internal" href="exts/pragmas.html#unpack-pragma"><span class="std std-ref">UNPACK pragma</span></a>) to every strict constructor field that fulfils the size restriction.</p> <p>For example, the constructor fields in the following data types</p> <pre data-language="haskell">data A = A !Int
data B = B !A
newtype C = C B
data D = D !C
</pre> <p>would all be represented by a single <code>Int#</code> (see <a class="reference internal" href="exts/primitives.html#primitives"><span class="std std-ref">Unboxed types and primitive operations</span></a>) value with <code>-funbox-small-strict-fields</code> enabled.</p> <p>This option is less of a sledgehammer than <code>-funbox-strict-fields</code>: it should rarely make things worse. If you use <code>-funbox-small-strict-fields</code> to turn on unboxing by default you can disable it for certain constructor fields using the <code>NOUNPACK</code> pragma (see <a class="reference internal" href="exts/pragmas.html#nounpack-pragma"><span class="std std-ref">NOUNPACK pragma</span></a>).</p> <p>Note that for consistency constructor fields are unpacked on 32-bit platforms as if it we were compiling for a 64-bit target even if fields are larger than a pointer on those platforms.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funbox-strict-fields">
<code>-funbox-strict-fields</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off</p> </dd> </dl> <p id="index-8">This option causes all constructor fields which are marked strict (i.e. <code>!</code>) to be unpacked if possible. It is equivalent to adding an <code>UNPACK</code> pragma to every strict constructor field (see <a class="reference internal" href="exts/pragmas.html#unpack-pragma"><span class="std std-ref">UNPACK pragma</span></a>).</p> <p>This option is a bit of a sledgehammer: it might sometimes make things worse. Selectively unboxing fields by using <code>UNPACK</code> pragmas might be better. An alternative is to use <code>-funbox-strict-fields</code> to turn on unboxing by default but disable it for certain constructor fields using the <code>NOUNPACK</code> pragma (see <a class="reference internal" href="exts/pragmas.html#nounpack-pragma"><span class="std std-ref">NOUNPACK pragma</span></a>).</p> <p>Alternatively you can use <a class="reference internal" href="#ghc-flag-funbox-small-strict-fields"><code>-funbox-small-strict-fields</code></a> to only unbox strict fields which are “small”.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-creation-threshold-n">
<code>-funfolding-creation-threshold=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>750</p> </dd> </dl> <p id="index-9">Governs the maximum size that GHC will allow a function unfolding to be. (An unfolding has a “size” that reflects the cost in terms of “code bloat” of expanding (aka inlining) that unfolding at a call site. A bigger function would be assigned a bigger cost.)</p> <p>Consequences:</p> <ol class="loweralpha simple"> <li>nothing larger than this will be inlined (unless it has an <code>INLINE</code> pragma)</li> <li>nothing larger than this will be spewed into an interface file.</li> </ol> <p>Increasing this figure is more likely to result in longer compile times than faster code. The <a class="reference internal" href="#ghc-flag-funfolding-use-threshold-n"><code>-funfolding-use-threshold=⟨n⟩</code></a> is more useful.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-dict-discount-n">
<code>-funfolding-dict-discount=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>30</p> </dd> </dl> <p id="index-10">How eager should the compiler be to inline dictionaries?</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-fun-discount-n">
<code>-funfolding-fun-discount=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>60</p> </dd> </dl> <p id="index-11">How eager should the compiler be to inline functions?</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-keeness-factor-n">
<code>-funfolding-keeness-factor=⟨n⟩</code> </dt> <dd>
<p>This factor was deprecated in GHC 9.0.1. See <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/15304">#15304</a> for details. Users who need to control inlining should rather consider <a class="reference internal" href="#ghc-flag-funfolding-use-threshold-n"><code>-funfolding-use-threshold=⟨n⟩</code></a>.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-use-threshold-n">
<code>-funfolding-use-threshold=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>80</p> </dd> </dl> <p id="index-12">This is the magic cut-off figure for unfolding (aka inlining): below this size, a function definition will be unfolded at the call-site, any bigger and it won’t. The size computed for a function depends on two things: the actual size of the expression minus any discounts that apply depending on the context into which the expression is to be inlined.</p> <p>The difference between this and <a class="reference internal" href="#ghc-flag-funfolding-creation-threshold-n"><code>-funfolding-creation-threshold=⟨n⟩</code></a> is that this one determines if a function definition will be inlined <em>at a call site</em>. The other option determines if a function definition will be kept around at all for potential inlining.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-case-threshold-n">
<code>-funfolding-case-threshold=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2</p> </dd> </dl> <p id="index-13">GHC is in general quite eager to inline small functions. However sometimes these functions will be expanded by more inlining after inlining. Since they are now applied to “interesting” arguments. Even worse, their expanded form might reference again a small function, which will be inlined and expanded afterwards. This can repeat often and lead to explosive growth of programs.</p> <p>As it happened in #18730.</p> <p>Starting with GHC 9.0 we will be less eager to inline deep into nested cases. We achieve this by applying a inlining penalty that increases as the nesting gets deeper. However sometimes a specific (maybe quite high!) threshold of nesting is to be expected.</p> <p>In such cases this flag can be used to ignore the first ⟨n⟩ levels of nesting when computing the penalty.</p> <p>This flag in combination with <a class="reference internal" href="#ghc-flag-funfolding-case-scaling-n"><code>-funfolding-case-scaling=⟨n⟩</code></a> can be used to break inlining loops without disabling inlining completely. For this purpose a smaller value is more likely to break such loops although often adjusting the scaling is enough and preferably.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-funfolding-case-scaling-n">
<code>-funfolding-case-scaling=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>30</p> </dd> </dl> <p id="index-14">GHC is in general quite eager to inline small functions. However sometimes these functions will be expanded by more inlining after inlining. Since they are now applied to “interesting” arguments. Even worse, their expanded form might reference again a small function, which will be inlined and expanded afterwards. This can repeat often and lead to explosive growth of programs.</p> <p>As it happened in #18730.</p> <p>Starting with GHC 9.0 we will be less eager to inline deep into nested cases. We achieve this by applying a inlining penalty that increases as the nesting gets deeper. However sometimes we are ok with inlining a lot in the name of performance.</p> <p>In such cases this flag can be used to tune how hard we penalize inlining into deeply nested cases beyond the threshold set by <a class="reference internal" href="#ghc-flag-funfolding-case-threshold-n"><code>-funfolding-case-threshold=⟨n⟩</code></a>. Cases are only counted against the nesting level if they have more than one alternative.</p> <p>We use 1/n to scale the penalty. That is a higher value gives a lower penalty.</p> <p>This can be used to break inlining loops. For this purpose a lower value is recommended. Values in the range 10 &lt;= n &lt;= 20 allow some inlining to take place while still allowing GHC to compile modules containing such inlining loops.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fworker-wrapper">
<code>-fworker-wrapper</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>off but enabled by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>.</p> </dd> </dl> <p>Enable the worker/wrapper transformation after a demand analysis pass.</p> <p>Exploits strictness and absence information by unboxing strict arguments and replacing absent fields by dummy values in a wrapper function that will inline in all relevant scenarios and thus expose a specialised, unboxed calling convention of the worker function.</p> <p>Implied by <a class="reference internal" href="#ghc-flag-O"><code>-O</code></a>, and by <a class="reference internal" href="#ghc-flag-fstrictness"><code>-fstrictness</code></a>. Disabled by <a class="reference internal" href="#ghc-flag--fstrictness"><code>-fno-strictness</code></a>. Enabling <a class="reference internal" href="#ghc-flag-fworker-wrapper"><code>-fworker-wrapper</code></a> while demand analysis is disabled (by <a class="reference internal" href="#ghc-flag--fstrictness"><code>-fno-strictness</code></a>) has no effect.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fworker-wrapper-cbv">
<code>-fworker-wrapper-cbv</code> </dt> <dd>
<p>Disabling this flag prevents a W/W split if the only benefit would be call-by-value for some arguments.</p> <p>Otherwise this exploits strictness information by passing strict value arguments call-by-value to the functions worker. Even for functions who would otherwise not get a worker.</p> <p>This avoids (potentially repeated) checks for evaluatedness of arguments in the rhs of the worker by pushing this check to the call site. If the argument is statically visible to be a value at the call site the overhead for the check disappears completely.</p> <p>This can cause slight codesize increases. It will also cause many more functions to get a worker/wrapper split which can play badly with rules (see <a class="reference external" href="https://gitlab.haskell.org/ghc/ghc/issues/20364">#20364</a>) which is why it’s currently disabled by default. In particular if you depend on rules firing on functions marked as NOINLINE without marking use sites of these functions as INLINE or INLINEABLE then things will break unless this flag is disabled.</p> <p>While WorkerWrapper is disabled this has no effect.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fbinary-blob-threshold-n">
<code>-fbinary-blob-threshold=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>500000</p> </dd> </dl> <p>The native code-generator can either dump binary blobs (e.g. string literals) into the assembly file (by using “.asciz” or “.string” assembler directives) or it can dump them as binary data into a temporary file which is then included by the assembler (using the “.incbin” assembler directive).</p> <p>This flag sets the size (in bytes) threshold above which the second approach is used. You can disable the second approach entirely by setting the threshold to 0.</p> </dd>
</dl> <dl class="std ghc-flag"> <dt class="sig sig-object std" id="ghc-flag-fwrite-if-compression-n">
<code>-fwrite-if-compression=⟨n⟩</code> </dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Default<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>2</p> </dd> <dt class="field-even">Since<span class="colon">:</span>
</dt> <dd class="field-even">
<p>9.12.1</p> </dd> </dl> <p>This flag defines the level of compression of interface files when writing to disk. The higher the flag, the more we deduplicate the interface file, at the cost of a higher compilation time. Deduplication (when applied to <a class="reference internal" href="using.html#ghc-flag-make"><code>--make</code></a> mode and <a class="reference internal" href="using.html#ghc-flag-interactive"><code>--interactive</code></a> mode) decreases the size of interface files as well as reducing the overall memory usage of GHC.</p> <p>Compression cannot be fully turned off, GHC always compresses interface files to a certain degree. Currently, we support values of <code>1</code>, <code>2</code> and <code>3</code>. Lower or higher values are clamped to <code>1</code> and <code>3</code> respectively.</p> <ul class="simple"> <li>
<code>1</code>: Compress as little as possible. No run-time impact, at the cost of interface file size and memory usage.</li> <li>
<code>2</code>: Apply compression with minimal run-time overhead, reducing the interface file size and memory usage.</li> <li>
<code>3</code>: Apply all possible compressions, minimal interface file sizes and memory usage, at the cost of run-time overhead.</li> </ul> </dd>
</dl> </section> </section> </div> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2002&ndash;2007 The University Court of the University of Glasgow. All rights reserved.<br>Licensed under the Glasgow Haskell Compiler License.<br>
    <a href="https://downloads.haskell.org/~ghc/9.12.1/docs/users_guide/using-optimisation.html" class="_attribution-link">https://downloads.haskell.org/~ghc/9.12.1/docs/users_guide/using-optimisation.html</a>
  </p>
</div>
