<devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip>    <h1 id="tensorflow::ops::sparseapplyadagradda" data-text="tensorflow::ops::SparseApplyAdagradDA" tabindex="-1">tensorflow::ops::SparseApplyAdagradDA</h1> <p><code translate="no" dir="ltr">#include &lt;training_ops.h&gt;</code></p> <p>Update entries in '*var' and '*accum' according to the proximal adagrad scheme. </p> <h2 id="summary" data-text="Summary" tabindex="-1">Summary</h2> <p>Args:</p>
<ul> <li>scope: A <a href="../scope.html#classtensorflow_1_1_scope">Scope</a> object</li> <li>var: Should be from a Variable().</li> <li>gradient_accumulator: Should be from a Variable().</li> <li>gradient_squared_accumulator: Should be from a Variable().</li> <li>grad: The gradient.</li> <li>indices: A vector of indices into the first dimension of var and accum.</li> <li>lr: Learning rate. Must be a scalar.</li> <li>l1: L1 regularization. Must be a scalar.</li> <li>l2: L2 regularization. Must be a scalar.</li> <li>global_step: Training step number. Must be a scalar.</li> </ul> <p>Optional attributes (see <code translate="no" dir="ltr"><a href="../../../struct/tensorflow/ops/sparse-apply-adagrad-d-a/attrs.html#structtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1_1_attrs">Attrs</a></code>):</p>
<ul> <li>use_locking: If True, updating of the var and accum tensors will be protected by a lock; otherwise the behavior is undefined, but may exhibit less contention.</li> </ul> <p>Returns:</p>
<ul> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code>: Same as "var". </li> </ul> <table class="constructors responsive"> <tr> <th colspan="2"> Constructors and Destructors </th> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1afb1971e3dbb0f4a487a6069c9fdb15ee">SparseApplyAdagradDA</a>(const ::<a href="../scope.html#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> var, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> gradient_accumulator, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> gradient_squared_accumulator, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> grad, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> indices, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> lr, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> l1, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> l2, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> global_step)</code> <br> </td> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a61642fb9a5da48aa72a60bc248dd3e03">SparseApplyAdagradDA</a>(const ::<a href="../scope.html#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> var, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> gradient_accumulator, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> gradient_squared_accumulator, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> grad, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> indices, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> lr, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> l1, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> l2, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> global_step, const <a href="../../../struct/tensorflow/ops/sparse-apply-adagrad-d-a/attrs.html#structtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1_1_attrs">SparseApplyAdagradDA::Attrs</a> &amp; attrs)</code> <br> </td> </tr> </table> <table class="properties responsive"> <tr> <th colspan="2"> Public attributes </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a79d811cc083567eda56a62699a3a737c">operation</a></code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../operation.html#classtensorflow_1_1_operation">Operation</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1ae2d982a56df04499e51fd2bcd4d2eaf1">out</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> </table> <table class="methods responsive"> <tr> <th colspan="2"> Public functions </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1ade2e4f81a3f15e8fcf846c76a6755f95">node</a>() const </code> </td> <td> <div> <code translate="no" dir="ltr">::tensorflow::Node *</code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a9eca1ddc2bc2bfeb6b52f0381ded7681">operator::tensorflow::Input</a>() const </code> </td> <td>  </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a2294c61087c20e5f137686b036811953">operator::tensorflow::Output</a>() const </code> </td> <td>  </td> </tr> </table> <table class="methods responsive"> <tr> <th colspan="2"> Public static functions </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a4c35b958f9150ddc168dc9c52e2b743e">UseLocking</a>(bool x)</code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../../../struct/tensorflow/ops/sparse-apply-adagrad-d-a/attrs.html#structtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1_1_attrs">Attrs</a></code> </div> </td> </tr> </table> <table class="constants responsive"> <tr> <th colspan="2"> Structs </th> </tr> <tr> <td> <a href="../../../struct/tensorflow/ops/sparse-apply-adagrad-d-a/attrs.html">tensorflow::ops::SparseApplyAdagradDA::Attrs</a> </td> <td> <p>Optional attribute setters for <a href="sparse-apply-adagrad-d-a.html#classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a">SparseApplyAdagradDA</a>. </p> </td> </tr> </table> <h2 id="public-attributes_1" data-text="Public attributes" tabindex="-1">Public attributes</h2> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a79d811cc083567eda56a62699a3a737c"> <h3 id="operation" data-text="operation" tabindex="-1">operation</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Text only" data-language="cpp">Operation operation</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1ae2d982a56df04499e51fd2bcd4d2eaf1"> <h3 id="out" data-text="out" tabindex="-1">out</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Text only" data-language="cpp">::tensorflow::Output out</pre></devsite-code>  </div> <h2 id="public-functions_1" data-text="Public functions" tabindex="-1">Public functions</h2> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1afb1971e3dbb0f4a487a6069c9fdb15ee"> <h3 id="sparseapplyadagradda" data-text="SparseApplyAdagradDA" tabindex="-1">SparseApplyAdagradDA</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp"> SparseApplyAdagradDA(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input var,
  ::tensorflow::Input gradient_accumulator,
  ::tensorflow::Input gradient_squared_accumulator,
  ::tensorflow::Input grad,
  ::tensorflow::Input indices,
  ::tensorflow::Input lr,
  ::tensorflow::Input l1,
  ::tensorflow::Input l2,
  ::tensorflow::Input global_step
)</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a61642fb9a5da48aa72a60bc248dd3e03"> <h3 id="sparseapplyadagradda_1" data-text="SparseApplyAdagradDA" tabindex="-1">SparseApplyAdagradDA</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp"> SparseApplyAdagradDA(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input var,
  ::tensorflow::Input gradient_accumulator,
  ::tensorflow::Input gradient_squared_accumulator,
  ::tensorflow::Input grad,
  ::tensorflow::Input indices,
  ::tensorflow::Input lr,
  ::tensorflow::Input l1,
  ::tensorflow::Input l2,
  ::tensorflow::Input global_step,
  const SparseApplyAdagradDA::Attrs &amp; attrs
)</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1ade2e4f81a3f15e8fcf846c76a6755f95"> <h3 id="node" data-text="node" tabindex="-1">node</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp">::tensorflow::Node * node() const </pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a9eca1ddc2bc2bfeb6b52f0381ded7681"> <h3 id="operator::tensorflow::input" data-text="operator::tensorflow::Input" tabindex="-1">operator::tensorflow::Input</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp">operator::tensorflow::Input() const </pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a2294c61087c20e5f137686b036811953"> <h3 id="operator::tensorflow::output" data-text="operator::tensorflow::Output" tabindex="-1">operator::tensorflow::Output</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp">operator::tensorflow::Output() const </pre></devsite-code>  </div> <h2 id="public-static-functions_1" data-text="Public static functions" tabindex="-1">Public static functions</h2> <div id="classtensorflow_1_1ops_1_1_sparse_apply_adagrad_d_a_1a4c35b958f9150ddc168dc9c52e2b743e"> <h3 id="uselocking" data-text="UseLocking" tabindex="-1">UseLocking</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Text only" data-language="cpp">Attrs UseLocking(
  bool x
)</pre></devsite-code>  </div>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/sparse-apply-adagrad-d-a" class="_attribution-link">https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/sparse-apply-adagrad-d-a</a>
  </p>
</div>
