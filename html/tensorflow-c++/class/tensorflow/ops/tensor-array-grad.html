<devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip>    <h1 id="tensorflow::ops::tensorarraygrad" data-text="tensorflow::ops::TensorArrayGrad" tabindex="-1">tensorflow::ops::TensorArrayGrad</h1> <p><code translate="no" dir="ltr">#include &lt;data_flow_ops.h&gt;</code></p> <p>Creates a <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> for storing the gradients of values in the given handle. </p> <h2 id="summary" data-text="Summary" tabindex="-1">Summary</h2> <p>If the given <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient already exists, returns a reference to it.</p> <p>Locks the size of the original <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> by disabling its dynamic size flag.</p> <p> <b>A note about the input flow_in:</b> </p> <p>The handle flow_in forces the execution of the gradient lookup to occur only after certain other operations have occurred. For example, when the forward <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is dynamically sized, writes to this <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> may resize the object. The gradient <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is statically sized based on the size of the forward <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> when this operation executes. Furthermore, the size of the forward <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is frozen by this call. As a result, the flow is used to ensure that the call to generate the gradient <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> only happens after all writes are executed.</p> <p>In the case of dynamically sized TensorArrays, gradient computation should only be performed on read operations that have themselves been chained via flow to occur only after all writes have executed. That way the final size of the forward <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is known when this operation is called.</p> <p> <b>A note about the source attribute:</b> </p> <p><a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient calls use an accumulator <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> object. If multiple gradients are calculated and run in the same session, the multiple gradient nodes may accidentally flow through the same accumulator <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a>. This double counts and generally breaks the <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient flow.</p> <p>The solution is to identify which gradient call this particular <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient is being called in. This is performed by identifying a unique string (e.g. "gradients", "gradients_1", ...) from the input gradient <a href="../tensor.html#classtensorflow_1_1_tensor">Tensor</a>'s name. This string is used as a suffix when creating the <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient object here (the attribute <code translate="no" dir="ltr">source</code>).</p> <p>The attribute <code translate="no" dir="ltr">source</code> is added as a suffix to the forward <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a>'s name when performing the creation / lookup, so that each separate gradient calculation gets its own <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> accumulator.</p> <p>Args:</p>
<ul> <li>scope: A <a href="../scope.html#classtensorflow_1_1_scope">Scope</a> object</li> <li>handle: The handle to the forward <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a>.</li> <li>flow_in: A float scalar that enforces proper chaining of operations.</li> <li>source: The gradient source string, used to decide which gradient <a href="tensor-array.html#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> to return.</li> </ul> <p>Returns:</p>
<ul> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code> grad_handle</li> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code> flow_out </li> </ul> <table class="constructors responsive"> <tr> <th colspan="2"> Constructors and Destructors </th> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1a6240f50f9c7efdcf3bf8d48c4218d27b">TensorArrayGrad</a>(const ::<a href="../scope.html#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> handle, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> flow_in, StringPiece source)</code> <br> </td> </tr> </table> <table class="properties responsive"> <tr> <th colspan="2"> Public attributes </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1a2499ef8bb9c633df24389a51f37654da">flow_out</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1ab5be040d777eb52f767d58a83a3a345d">grad_handle</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1ae7c0b0022fc4a44d321bf759c55413c2">operation</a></code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../operation.html#classtensorflow_1_1_operation">Operation</a></code> </div> </td> </tr> </table> <h2 id="public-attributes_1" data-text="Public attributes" tabindex="-1">Public attributes</h2> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1a2499ef8bb9c633df24389a51f37654da"> <h3 id="flow_out" data-text="flow_out" tabindex="-1">flow_out</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="scdoc" data-language="cpp">::tensorflow::Output flow_out</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1ab5be040d777eb52f767d58a83a3a345d"> <h3 id="grad_handle" data-text="grad_handle" tabindex="-1">grad_handle</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="scdoc" data-language="cpp">::tensorflow::Output grad_handle</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1ae7c0b0022fc4a44d321bf759c55413c2"> <h3 id="operation" data-text="operation" tabindex="-1">operation</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Text only" data-language="cpp">Operation operation</pre></devsite-code>  </div> <h2 id="public-functions" data-text="Public functions" tabindex="-1">Public functions</h2> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1a6240f50f9c7efdcf3bf8d48c4218d27b"> <h3 id="tensorarraygrad" data-text="TensorArrayGrad" tabindex="-1">TensorArrayGrad</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp"> TensorArrayGrad(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input handle,
  ::tensorflow::Input flow_in,
  StringPiece source
)</pre></devsite-code>  </div>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/tensor-array-grad" class="_attribution-link">https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/tensor-array-grad</a>
  </p>
</div>
