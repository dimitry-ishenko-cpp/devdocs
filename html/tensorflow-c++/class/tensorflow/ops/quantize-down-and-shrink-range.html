<devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip>    <h1 id="tensorflow::ops::quantizedownandshrinkrange" data-text="tensorflow::ops::QuantizeDownAndShrinkRange" tabindex="-1">tensorflow::ops::QuantizeDownAndShrinkRange</h1> <p><code translate="no" dir="ltr">#include &lt;math_ops.h&gt;</code></p> <p>Convert the quantized 'input' tensor into a lower-precision 'output', using the. </p> <h2 id="summary" data-text="Summary" tabindex="-1">Summary</h2> <p>actual distribution of the values to maximize the usage of the lower bit depth and adjusting the output min and max ranges accordingly.</p> <p>[input_min, input_max] are scalar floats that specify the range for the float interpretation of the 'input' data. For example, if input_min is -1.0f and input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0 value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.</p> <p>This operator tries to squeeze as much precision as possible into an output with a lower bit depth by calculating the actual min and max values found in the data. For example, maybe that quint16 input has no values lower than 16,384 and none higher than 49,152. That means only half the range is actually needed, all the float interpretations are between -0.5f and 0.5f, so if we want to compress the data into a quint8 output, we can use that range rather than the theoretical -1.0f to 1.0f that is suggested by the input min and max.</p> <p>In practice, this is most useful for taking output from operations like <a href="quantized-mat-mul.html#classtensorflow_1_1ops_1_1_quantized_mat_mul">QuantizedMatMul</a> that can produce higher bit-depth outputs than their inputs and may have large potential output ranges, but in practice have a distribution of input values that only uses a small fraction of the possible range. By feeding that output into this operator, we can reduce it from 32 bits down to 8 with minimal loss of accuracy.</p> <p>Args:</p>
<ul> <li>scope: A <a href="../scope.html#classtensorflow_1_1_scope">Scope</a> object</li> <li>input_min: The float value that the minimum quantized input value represents.</li> <li>input_max: The float value that the maximum quantized input value represents.</li> <li>out_type: The type of the output. Should be a lower bit depth than Tinput.</li> </ul> <p>Returns:</p>
<ul> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code> output</li> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code> output_min: The float value that the minimum quantized output value represents.</li> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code> output_max: The float value that the maximum quantized output value represents. </li> </ul> <table class="constructors responsive"> <tr> <th colspan="2"> Constructors and Destructors </th> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a19ee578c7b888e9aca48d291a1a0d5da">QuantizeDownAndShrinkRange</a>(const ::<a href="../scope.html#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> input, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> input_min, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> input_max, DataType out_type)</code> <br> </td> </tr> </table> <table class="properties responsive"> <tr> <th colspan="2"> Public attributes </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a3ab13cf6f6f7814f990022d1a49b3a99">operation</a></code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../operation.html#classtensorflow_1_1_operation">Operation</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a02ce18813489b86884040f42ddcfca87">output</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a3c2857dfc27b8777dc82845ec0a4919a">output_max</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1aa8dddbbd62576e4961029ce5ed846677">output_min</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> </table> <h2 id="public-attributes_1" data-text="Public attributes" tabindex="-1">Public attributes</h2> <div id="classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a3ab13cf6f6f7814f990022d1a49b3a99"> <h3 id="operation" data-text="operation" tabindex="-1">operation</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Text only" data-language="cpp">Operation operation</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a02ce18813489b86884040f42ddcfca87"> <h3 id="output" data-text="output" tabindex="-1">output</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Text only" data-language="cpp">::tensorflow::Output output</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a3c2857dfc27b8777dc82845ec0a4919a"> <h3 id="output_max" data-text="output_max" tabindex="-1">output_max</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="scdoc" data-language="cpp">::tensorflow::Output output_max</pre></devsite-code>  </div> <div id="classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1aa8dddbbd62576e4961029ce5ed846677"> <h3 id="output_min" data-text="output_min" tabindex="-1">output_min</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="scdoc" data-language="cpp">::tensorflow::Output output_min</pre></devsite-code>  </div> <h2 id="public-functions" data-text="Public functions" tabindex="-1">Public functions</h2> <div id="classtensorflow_1_1ops_1_1_quantize_down_and_shrink_range_1a19ee578c7b888e9aca48d291a1a0d5da"> <h3 id="quantizedownandshrinkrange" data-text="QuantizeDownAndShrinkRange" tabindex="-1">QuantizeDownAndShrinkRange</h3> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="GDScript" data-language="cpp"> QuantizeDownAndShrinkRange(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input input,
  ::tensorflow::Input input_min,
  ::tensorflow::Input input_max,
  DataType out_type
)</pre></devsite-code>  </div>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/quantize-down-and-shrink-range" class="_attribution-link">https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/quantize-down-and-shrink-range</a>
  </p>
</div>
