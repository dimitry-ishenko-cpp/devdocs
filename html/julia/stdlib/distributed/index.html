<h1 id="man-distributed">Distributed Computing</h1>
<h3 id="Distributed">
<code>Distributed</code><span class="docstring-category">Module</span>
</h3>
<section><p>Tools for distributed parallel processing.</p></section><h3 id="Distributed.addprocs">
<code>Distributed.addprocs</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">addprocs(manager::ClusterManager; kwargs...) -&gt; List of process identifiers</pre>
<p>Launches worker processes via the specified cluster manager.</p>
<p>For example, Beowulf clusters are supported via a custom cluster manager implemented in the package <code>ClusterManagers.jl</code>.</p>
<p>The number of seconds a newly launched worker waits for connection establishment from the master can be specified via variable <code>JULIA_WORKER_TIMEOUT</code> in the worker process's environment. Relevant only when using TCP/IP as transport.</p>
<p>To launch workers without blocking the REPL, or the containing function if launching workers programmatically, execute <code>addprocs</code> in its own task.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia"># On busy clusters, call `addprocs` asynchronously
t = @async addprocs(...)</pre>
<pre data-language="julia"># Utilize workers as and when they come online
if nprocs() &gt; 1   # Ensure at least one new worker is available
   ....   # perform distributed execution
end</pre>
<pre data-language="julia"># Retrieve newly launched worker IDs, or any error messages
if istaskdone(t)   # Check if `addprocs` has completed to ensure `fetch` doesn't block
    if nworkers() == N
        new_pids = fetch(t)
    else
        fetch(t)
    end
end</pre></section><section><pre data-language="julia">addprocs(machines; tunnel=false, sshflags=``, max_parallel=10, kwargs...) -&gt; List of process identifiers</pre>
<p>Add worker processes on remote machines via SSH. Configuration is done with keyword arguments (see below). In particular, the <code>exename</code> keyword can be used to specify the path to the <code>julia</code> binary on the remote machine(s).</p>
<p><code>machines</code> is a vector of "machine specifications" which are given as strings of the form <code>[user@]host[:port] [bind_addr[:port]]</code>. <code>user</code> defaults to current user and <code>port</code> to the standard SSH port. If <code>[bind_addr[:port]]</code> is specified, other workers will connect to this worker at the specified <code>bind_addr</code> and <code>port</code>.</p>
<p>It is possible to launch multiple processes on a remote host by using a tuple in the <code>machines</code> vector or the form <code>(machine_spec, count)</code>, where <code>count</code> is the number of workers to be launched on the specified host. Passing <code>:auto</code> as the worker count will launch as many workers as the number of CPU threads on the remote host.</p>
<p><strong>Examples</strong>:</p>
<pre data-language="julia">addprocs([
    "remote1",               # one worker on 'remote1' logging in with the current username
    "user@remote2",          # one worker on 'remote2' logging in with the 'user' username
    "user@remote3:2222",     # specifying SSH port to '2222' for 'remote3'
    ("user@remote4", 4),     # launch 4 workers on 'remote4'
    ("user@remote5", :auto), # launch as many workers as CPU threads on 'remote5'
])</pre>
<p><strong>Keyword arguments</strong>:</p>
<ul>
<li><p><code>tunnel</code>: if <code>true</code> then SSH tunneling will be used to connect to the worker from the master process. Default is <code>false</code>.</p></li>
<li><p><code>multiplex</code>: if <code>true</code> then SSH multiplexing is used for SSH tunneling. Default is <code>false</code>.</p></li>
<li><p><code>ssh</code>: the name or path of the SSH client executable used to start the workers. Default is <code>"ssh"</code>.</p></li>
<li><p><code>sshflags</code>: specifies additional ssh options, e.g. <code>sshflags=`-i /home/foo/bar.pem`</code></p></li>
<li><p><code>max_parallel</code>: specifies the maximum number of workers connected to in parallel at a host. Defaults to 10.</p></li>
<li>
<p><code>shell</code>: specifies the type of shell to which ssh connects on the workers.</p>
<ul>
<li><p><code>shell=:posix</code>: a POSIX-compatible Unix/Linux shell (sh, ksh, bash, dash, zsh, etc.). The default.</p></li>
<li><p><code>shell=:csh</code>: a Unix C shell (csh, tcsh).</p></li>
<li><p><code>shell=:wincmd</code>: Microsoft Windows <code>cmd.exe</code>.</p></li>
</ul>
</li>
<li><p><code>dir</code>: specifies the working directory on the workers. Defaults to the host's current directory (as found by <code>pwd()</code>)</p></li>
<li><p><code>enable_threaded_blas</code>: if <code>true</code> then BLAS will run on multiple threads in added processes. Default is <code>false</code>.</p></li>
<li><p><code>exename</code>: name of the <code>julia</code> executable. Defaults to <code>"$(Sys.BINDIR)/julia"</code> or <code>"$(Sys.BINDIR)/julia-debug"</code> as the case may be. It is recommended that a common Julia version is used on all remote machines because serialization and code distribution might fail otherwise.</p></li>
<li><p><code>exeflags</code>: additional flags passed to the worker processes.</p></li>
<li>
<p><code>topology</code>: Specifies how the workers connect to each other. Sending a message between unconnected workers results in an error.</p>
<ul>
<li><p><code>topology=:all_to_all</code>: All processes are connected to each other. The default.</p></li>
<li><p><code>topology=:master_worker</code>: Only the driver process, i.e. <code>pid</code> 1 connects to the workers. The workers do not connect to each other.</p></li>
<li><p><code>topology=:custom</code>: The <code>launch</code> method of the cluster manager specifies the connection topology via fields <code>ident</code> and <code>connect_idents</code> in <code>WorkerConfig</code>. A worker with a cluster manager identity <code>ident</code> will connect to all workers specified in <code>connect_idents</code>.</p></li>
</ul>
</li>
<li><p><code>lazy</code>: Applicable only with <code>topology=:all_to_all</code>. If <code>true</code>, worker-worker connections are setup lazily, i.e. they are setup at the first instance of a remote call between workers. Default is true.</p></li>
<li><p><code>env</code>: provide an array of string pairs such as <code>env=["JULIA_DEPOT_PATH"=&gt;"/depot"]</code> to request that environment variables are set on the remote machine. By default only the environment variable <code>JULIA_WORKER_TIMEOUT</code> is passed automatically from the local to the remote environment.</p></li>
<li><p><code>cmdline_cookie</code>: pass the authentication cookie via the <code>--worker</code> commandline option. The (more secure) default behaviour of passing the cookie via ssh stdio may hang with Windows workers that use older (pre-ConPTY) Julia or Windows versions, in which case <code>cmdline_cookie=true</code> offers a work-around.</p></li>
</ul>
<div class="admonition is-compat">

<div class="admonition-body"><p>The keyword arguments <code>ssh</code>, <code>shell</code>, <code>env</code> and <code>cmdline_cookie</code> were added in Julia 1.6.</p></div>
</div>
<p>Environment variables:</p>
<p>If the master process fails to establish a connection with a newly launched worker within 60.0 seconds, the worker treats it as a fatal situation and terminates. This timeout can be controlled via environment variable <code>JULIA_WORKER_TIMEOUT</code>. The value of <code>JULIA_WORKER_TIMEOUT</code> on the master process specifies the number of seconds a newly launched worker waits for connection establishment.</p></section><section><pre data-language="julia">addprocs(np::Integer=Sys.CPU_THREADS; restrict=true, kwargs...) -&gt; List of process identifiers</pre>
<p>Launch <code>np</code> workers on the local host using the in-built <code>LocalManager</code>.</p>
<p>Local workers inherit the current package environment (i.e., active project, <a href="../../base/constants/index.html#Base.LOAD_PATH"><code>LOAD_PATH</code></a>, and <a href="../../base/constants/index.html#Base.DEPOT_PATH"><code>DEPOT_PATH</code></a>) from the main process.</p>
<div class="admonition is-warning">

<div class="admonition-body"><p>Note that workers do not run a <code>~/.julia/config/startup.jl</code> startup script, nor do they synchronize their global state (such as command-line switches, global variables, new method definitions, and loaded modules) with any of the other running processes.</p></div>
</div>
<p><strong>Keyword arguments</strong>:</p>
<ul>
<li>
<code>restrict::Bool</code>: if <code>true</code> (default) binding is restricted to <code>127.0.0.1</code>.</li>
<li>
<code>dir</code>, <code>exename</code>, <code>exeflags</code>, <code>env</code>, <code>topology</code>, <code>lazy</code>, <code>enable_threaded_blas</code>: same effect as for <code>SSHManager</code>, see documentation for <a href="#Distributed.addprocs"><code>addprocs(machines::AbstractVector)</code></a>.</li>
</ul>
<div class="admonition is-compat">

<div class="admonition-body"><p>The inheriting of the package environment and the <code>env</code> keyword argument were added in Julia 1.9.</p></div>
</div></section><h3 id="Distributed.nprocs">
<code>Distributed.nprocs</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">nprocs()</pre>
<p>Get the number of available processes.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">julia&gt; nprocs()
3

julia&gt; workers()
2-element Array{Int64,1}:
 2
 3</pre></section><h3 id="Distributed.nworkers">
<code>Distributed.nworkers</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">nworkers()</pre>
<p>Get the number of available worker processes. This is one less than <a href="#Distributed.nprocs"><code>nprocs()</code></a>. Equal to <code>nprocs()</code> if <code>nprocs() == 1</code>.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 2

julia&gt; nprocs()
3

julia&gt; nworkers()
2</pre></section><h3 id="Distributed.procs-Tuple{}">
<code>Distributed.procs</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">procs()</pre>
<p>Return a list of all process identifiers, including pid 1 (which is not included by <a href="#Distributed.workers"><code>workers()</code></a>).</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 2

julia&gt; procs()
3-element Array{Int64,1}:
 1
 2
 3</pre></section><h3 id="Distributed.procs-Tuple{Integer}">
<code>Distributed.procs</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">procs(pid::Integer)</pre>
<p>Return a list of all process identifiers on the same physical node. Specifically all workers bound to the same ip-address as <code>pid</code> are returned.</p></section><h3 id="Distributed.workers">
<code>Distributed.workers</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">workers()</pre>
<p>Return a list of all worker process identifiers.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 2

julia&gt; workers()
2-element Array{Int64,1}:
 2
 3</pre></section><h3 id="Distributed.rmprocs">
<code>Distributed.rmprocs</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">rmprocs(pids...; waitfor=typemax(Int))</pre>
<p>Remove the specified workers. Note that only process 1 can add or remove workers.</p>
<p>Argument <code>waitfor</code> specifies how long to wait for the workers to shut down:</p>
<ul>
<li>If unspecified, <code>rmprocs</code> will wait until all requested <code>pids</code> are removed.</li>
<li>An <a href="../../base/base/index.html#Core.ErrorException"><code>ErrorException</code></a> is raised if all workers cannot be terminated before the requested <code>waitfor</code> seconds.</li>
<li>With a <code>waitfor</code> value of 0, the call returns immediately with the workers scheduled for removal in a different task. The scheduled <a href="../../base/parallel/index.html#Core.Task"><code>Task</code></a> object is returned. The user should call <a href="../../base/parallel/index.html#Base.wait"><code>wait</code></a> on the task before invoking any other parallel calls.</li>
</ul>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 5

julia&gt; t = rmprocs(2, 3, waitfor=0)
Task (runnable) @0x0000000107c718d0

julia&gt; wait(t)

julia&gt; workers()
3-element Array{Int64,1}:
 4
 5
 6</pre></section><h3 id="Distributed.interrupt">
<code>Distributed.interrupt</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">interrupt(pids::Integer...)</pre>
<p>Interrupt the current executing task on the specified workers. This is equivalent to pressing Ctrl-C on the local machine. If no arguments are given, all workers are interrupted.</p></section><section><pre data-language="julia">interrupt(pids::AbstractVector=workers())</pre>
<p>Interrupt the current executing task on the specified workers. This is equivalent to pressing Ctrl-C on the local machine. If no arguments are given, all workers are interrupted.</p></section><h3 id="Distributed.myid">
<code>Distributed.myid</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">myid()</pre>
<p>Get the id of the current process.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">julia&gt; myid()
1

julia&gt; remotecall_fetch(() -&gt; myid(), 4)
4</pre></section><h3 id="Distributed.pmap">
<code>Distributed.pmap</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">pmap(f, [::AbstractWorkerPool], c...; distributed=true, batch_size=1, on_error=nothing, retry_delays=[], retry_check=nothing) -&gt; collection</pre>
<p>Transform collection <code>c</code> by applying <code>f</code> to each element using available workers and tasks.</p>
<p>For multiple collection arguments, apply <code>f</code> elementwise.</p>
<p>Note that <code>f</code> must be made available to all worker processes; see <a href="../../manual/distributed-computing/index.html#code-availability">Code Availability and Loading Packages</a> for details.</p>
<p>If a worker pool is not specified all available workers will be used via a <a href="#Distributed.CachingPool"><code>CachingPool</code></a>.</p>
<p>By default, <code>pmap</code> distributes the computation over all specified workers. To use only the local process and distribute over tasks, specify <code>distributed=false</code>. This is equivalent to using <a href="../../base/parallel/index.html#Base.asyncmap"><code>asyncmap</code></a>. For example, <code>pmap(f, c; distributed=false)</code> is equivalent to <code>asyncmap(f,c; ntasks=()-&gt;nworkers())</code></p>
<p><code>pmap</code> can also use a mix of processes and tasks via the <code>batch_size</code> argument. For batch sizes greater than 1, the collection is processed in multiple batches, each of length <code>batch_size</code> or less. A batch is sent as a single request to a free worker, where a local <a href="../../base/parallel/index.html#Base.asyncmap"><code>asyncmap</code></a> processes elements from the batch using multiple concurrent tasks.</p>
<p>Any error stops <code>pmap</code> from processing the remainder of the collection. To override this behavior you can specify an error handling function via argument <code>on_error</code> which takes in a single argument, i.e., the exception. The function can stop the processing by rethrowing the error, or, to continue, return any value which is then returned inline with the results to the caller.</p>
<p>Consider the following two examples. The first one returns the exception object inline, the second a 0 in place of any exception:</p>
<pre data-language="julia">julia&gt; pmap(x-&gt;iseven(x) ? error("foo") : x, 1:4; on_error=identity)
4-element Array{Any,1}:
 1
  ErrorException("foo")
 3
  ErrorException("foo")

julia&gt; pmap(x-&gt;iseven(x) ? error("foo") : x, 1:4; on_error=ex-&gt;0)
4-element Array{Int64,1}:
 1
 0
 3
 0</pre>
<p>Errors can also be handled by retrying failed computations. Keyword arguments <code>retry_delays</code> and <code>retry_check</code> are passed through to <a href="../../base/base/index.html#Base.retry"><code>retry</code></a> as keyword arguments <code>delays</code> and <code>check</code> respectively. If batching is specified, and an entire batch fails, all items in the batch are retried.</p>
<p>Note that if both <code>on_error</code> and <code>retry_delays</code> are specified, the <code>on_error</code> hook is called before retrying. If <code>on_error</code> does not throw (or rethrow) an exception, the element will not be retried.</p>
<p>Example: On errors, retry <code>f</code> on an element a maximum of 3 times without any delay between retries.</p>
<pre data-language="julia">pmap(f, c; retry_delays = zeros(3))</pre>
<p>Example: Retry <code>f</code> only if the exception is not of type <a href="../../base/base/index.html#Core.InexactError"><code>InexactError</code></a>, with exponentially increasing delays up to 3 times. Return a <code>NaN</code> in place for all <code>InexactError</code> occurrences.</p>
<pre data-language="julia">pmap(f, c; on_error = e-&gt;(isa(e, InexactError) ? NaN : rethrow()), retry_delays = ExponentialBackOff(n = 3))</pre></section><h3 id="Distributed.RemoteException">
<code>Distributed.RemoteException</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">RemoteException(captured)</pre>
<p>Exceptions on remote computations are captured and rethrown locally. A <code>RemoteException</code> wraps the <code>pid</code> of the worker and a captured exception. A <code>CapturedException</code> captures the remote exception and a serializable form of the call stack when the exception was raised.</p></section><h3 id="Distributed.ProcessExitedException">
<code>Distributed.ProcessExitedException</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">ProcessExitedException(worker_id::Int)</pre>
<p>After a client Julia process has exited, further attempts to reference the dead child will throw this exception.</p></section><h3 id="Distributed.Future">
<code>Distributed.Future</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">Future(w::Int, rrid::RRID, v::Union{Some, Nothing}=nothing)</pre>
<p>A <code>Future</code> is a placeholder for a single computation of unknown termination status and time. For multiple potential computations, see <code>RemoteChannel</code>. See <code>remoteref_id</code> for identifying an <code>AbstractRemoteRef</code>.</p></section><h3 id="Distributed.RemoteChannel">
<code>Distributed.RemoteChannel</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">RemoteChannel(pid::Integer=myid())</pre>
<p>Make a reference to a <code>Channel{Any}(1)</code> on process <code>pid</code>. The default <code>pid</code> is the current process.</p>
<pre data-language="julia">RemoteChannel(f::Function, pid::Integer=myid())</pre>
<p>Create references to remote channels of a specific size and type. <code>f</code> is a function that when executed on <code>pid</code> must return an implementation of an <code>AbstractChannel</code>.</p>
<p>For example, <code>RemoteChannel(()-&gt;Channel{Int}(10), pid)</code>, will return a reference to a channel of type <code>Int</code> and size 10 on <code>pid</code>.</p>
<p>The default <code>pid</code> is the current process.</p></section><h3 id="Base.fetch-Tuple{Distributed.Future}">
<code>Base.fetch</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">fetch(x::Future)</pre>
<p>Wait for and get the value of a <a href="../future/index.html#Future"><code>Future</code></a>. The fetched value is cached locally. Further calls to <code>fetch</code> on the same reference return the cached value. If the remote value is an exception, throws a <a href="#Distributed.RemoteException"><code>RemoteException</code></a> which captures the remote exception and backtrace.</p></section><h3 id="Base.fetch-Tuple{RemoteChannel}">
<code>Base.fetch</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">fetch(c::RemoteChannel)</pre>
<p>Wait for and get a value from a <a href="#Distributed.RemoteChannel"><code>RemoteChannel</code></a>. Exceptions raised are the same as for a <a href="../future/index.html#Future"><code>Future</code></a>. Does not remove the item fetched.</p></section><section><pre data-language="julia">fetch(x::Any)</pre>
<p>Return <code>x</code>.</p>
<a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/5e9a32e7af2837e677e60543d4a15faa8d3a7297/base/task.jl#L375-L379">source</a></section><h3 id="Distributed.remotecall-Tuple{Any, Integer, Vararg{Any}}">
<code>Distributed.remotecall</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remotecall(f, id::Integer, args...; kwargs...) -&gt; Future</pre>
<p>Call a function <code>f</code> asynchronously on the given arguments on the specified process. Return a <a href="../future/index.html#Future"><code>Future</code></a>. Keyword arguments, if any, are passed through to <code>f</code>.</p></section><h3 id="Distributed.remotecall_wait-Tuple{Any, Integer, Vararg{Any}}">
<code>Distributed.remotecall_wait</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remotecall_wait(f, id::Integer, args...; kwargs...)</pre>
<p>Perform a faster <code>wait(remotecall(...))</code> in one message on the <code>Worker</code> specified by worker id <code>id</code>. Keyword arguments, if any, are passed through to <code>f</code>.</p>
<p>See also <a href="../../base/parallel/index.html#Base.wait"><code>wait</code></a> and <a href="#Distributed.remotecall-Tuple{Any,%20Integer,%20Vararg{Any}}"><code>remotecall</code></a>.</p></section><h3 id="Distributed.remotecall_fetch-Tuple{Any, Integer, Vararg{Any}}">
<code>Distributed.remotecall_fetch</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remotecall_fetch(f, id::Integer, args...; kwargs...)</pre>
<p>Perform <code>fetch(remotecall(...))</code> in one message. Keyword arguments, if any, are passed through to <code>f</code>. Any remote exceptions are captured in a <a href="#Distributed.RemoteException"><code>RemoteException</code></a> and thrown.</p>
<p>See also <a href="#"><code>fetch</code></a> and <a href="#Distributed.remotecall-Tuple{Any,%20Integer,%20Vararg{Any}}"><code>remotecall</code></a>.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 2

julia&gt; remotecall_fetch(sqrt, 2, 4)
2.0

julia&gt; remotecall_fetch(sqrt, 2, -4)
ERROR: On worker 2:
DomainError with -4.0:
sqrt was called with a negative real argument but will only return a complex result if called with a complex argument. Try sqrt(Complex(x)).
...</pre></section><h3 id="Distributed.remote_do-Tuple{Any, Integer, Vararg{Any}}">
<code>Distributed.remote_do</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remote_do(f, id::Integer, args...; kwargs...) -&gt; nothing</pre>
<p>Executes <code>f</code> on worker <code>id</code> asynchronously. Unlike <a href="#Distributed.remotecall-Tuple{Any,%20Integer,%20Vararg{Any}}"><code>remotecall</code></a>, it does not store the result of computation, nor is there a way to wait for its completion.</p>
<p>A successful invocation indicates that the request has been accepted for execution on the remote node.</p>
<p>While consecutive <code>remotecall</code>s to the same worker are serialized in the order they are invoked, the order of executions on the remote worker is undetermined. For example, <code>remote_do(f1, 2); remotecall(f2, 2); remote_do(f3, 2)</code> will serialize the call to <code>f1</code>, followed by <code>f2</code> and <code>f3</code> in that order. However, it is not guaranteed that <code>f1</code> is executed before <code>f3</code> on worker 2.</p>
<p>Any exceptions thrown by <code>f</code> are printed to <a href="../../base/io-network/index.html#Base.stderr"><code>stderr</code></a> on the remote worker.</p>
<p>Keyword arguments, if any, are passed through to <code>f</code>.</p></section><h3 id="Base.put!-Tuple{RemoteChannel, Vararg{Any}}">
<code>Base.put!</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">put!(rr::RemoteChannel, args...)</pre>
<p>Store a set of values to the <a href="#Distributed.RemoteChannel"><code>RemoteChannel</code></a>. If the channel is full, blocks until space is available. Return the first argument.</p></section><h3 id="Base.put!-Tuple{Distributed.Future, Any}">
<code>Base.put!</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">put!(rr::Future, v)</pre>
<p>Store a value to a <a href="../future/index.html#Future"><code>Future</code></a> <code>rr</code>. <code>Future</code>s are write-once remote references. A <code>put!</code> on an already set <code>Future</code> throws an <code>Exception</code>. All asynchronous remote calls return <code>Future</code>s and set the value to the return value of the call upon completion.</p></section><h3 id="Base.take!-Tuple{RemoteChannel, Vararg{Any}}">
<code>Base.take!</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">take!(rr::RemoteChannel, args...)</pre>
<p>Fetch value(s) from a <a href="#Distributed.RemoteChannel"><code>RemoteChannel</code></a> <code>rr</code>, removing the value(s) in the process.</p></section><h3 id="Base.isready-Tuple{RemoteChannel, Vararg{Any}}">
<code>Base.isready</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">isready(rr::RemoteChannel, args...)</pre>
<p>Determine whether a <a href="#Distributed.RemoteChannel"><code>RemoteChannel</code></a> has a value stored to it. Note that this function can cause race conditions, since by the time you receive its result it may no longer be true. However, it can be safely used on a <a href="../future/index.html#Future"><code>Future</code></a> since they are assigned only once.</p></section><h3 id="Base.isready-Tuple{Distributed.Future}">
<code>Base.isready</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">isready(rr::Future)</pre>
<p>Determine whether a <a href="../future/index.html#Future"><code>Future</code></a> has a value stored to it.</p>
<p>If the argument <code>Future</code> is owned by a different node, this call will block to wait for the answer. It is recommended to wait for <code>rr</code> in a separate task instead or to use a local <a href="../../base/parallel/index.html#Base.Channel"><code>Channel</code></a> as a proxy:</p>
<pre data-language="julia">p = 1
f = Future(p)
errormonitor(@async put!(f, remotecall_fetch(long_computation, p)))
isready(f)  # will not block</pre></section><h3 id="Distributed.AbstractWorkerPool">
<code>Distributed.AbstractWorkerPool</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">AbstractWorkerPool</pre>
<p>Supertype for worker pools such as <a href="#Distributed.WorkerPool"><code>WorkerPool</code></a> and <a href="#Distributed.CachingPool"><code>CachingPool</code></a>. An <code>AbstractWorkerPool</code> should implement:</p>
<ul>
<li>
<a href="../../base/collections/index.html#Base.push!"><code>push!</code></a> - add a new worker to the overall pool (available + busy)</li>
<li>
<a href="#"><code>put!</code></a> - put back a worker to the available pool</li>
<li>
<a href="#"><code>take!</code></a> - take a worker from the available pool (to be used for remote function execution)</li>
<li>
<a href="../../base/collections/index.html#Base.length"><code>length</code></a> - number of workers available in the overall pool</li>
<li>
<a href="#"><code>isready</code></a> - return false if a <code>take!</code> on the pool would block, else true</li>
</ul>
<p>The default implementations of the above (on a <code>AbstractWorkerPool</code>) require fields</p>
<ul>
<li><code>channel::Channel{Int}</code></li>
<li><code>workers::Set{Int}</code></li>
</ul>
<p>where <code>channel</code> contains free worker pids and <code>workers</code> is the set of all workers associated with this pool.</p></section><h3 id="Distributed.WorkerPool">
<code>Distributed.WorkerPool</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">WorkerPool(workers::Union{Vector{Int},AbstractRange{Int}})</pre>
<p>Create a <code>WorkerPool</code> from a vector or range of worker ids.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 3

julia&gt; WorkerPool([2, 3])
WorkerPool(Channel{Int64}(sz_max:9223372036854775807,sz_curr:2), Set([2, 3]), RemoteChannel{Channel{Any}}(1, 1, 6))

julia&gt; WorkerPool(2:4)
WorkerPool(Channel{Int64}(sz_max:9223372036854775807,sz_curr:2), Set([4, 2, 3]), RemoteChannel{Channel{Any}}(1, 1, 7))</pre></section><h3 id="Distributed.CachingPool">
<code>Distributed.CachingPool</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">CachingPool(workers::Vector{Int})</pre>
<p>An implementation of an <code>AbstractWorkerPool</code>. <a href="#Distributed.remote"><code>remote</code></a>, <a href="#Distributed.remotecall_fetch-Tuple{Any,%20Integer,%20Vararg{Any}}"><code>remotecall_fetch</code></a>, <a href="#Distributed.pmap"><code>pmap</code></a> (and other remote calls which execute functions remotely) benefit from caching the serialized/deserialized functions on the worker nodes, especially closures (which may capture large amounts of data).</p>
<p>The remote cache is maintained for the lifetime of the returned <code>CachingPool</code> object. To clear the cache earlier, use <code>clear!(pool)</code>.</p>
<p>For global variables, only the bindings are captured in a closure, not the data. <code>let</code> blocks can be used to capture global data.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">const foo = rand(10^8);
wp = CachingPool(workers())
let foo = foo
    pmap(i -&gt; sum(foo) + i, wp, 1:100);
end</pre>
<p>The above would transfer <code>foo</code> only once to each worker.</p></section><h3 id="Distributed.default_worker_pool">
<code>Distributed.default_worker_pool</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">default_worker_pool()</pre>
<p><a href="#Distributed.AbstractWorkerPool"><code>AbstractWorkerPool</code></a> containing idle <a href="#Distributed.workers"><code>workers</code></a> - used by <code>remote(f)</code> and <a href="#Distributed.pmap"><code>pmap</code></a> (by default). Unless one is explicitly set via <code>default_worker_pool!(pool)</code>, the default worker pool is initialized to a <a href="#Distributed.WorkerPool"><code>WorkerPool</code></a>.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 3

julia&gt; default_worker_pool()
WorkerPool(Channel{Int64}(sz_max:9223372036854775807,sz_curr:3), Set([4, 2, 3]), RemoteChannel{Channel{Any}}(1, 1, 4))</pre></section><h3 id="Distributed.clear!">
<code>Distributed.clear!</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">clear!(syms, pids=workers(); mod=Main)</pre>
<p>Clears global bindings in modules by initializing them to <code>nothing</code>. <code>syms</code> should be of type <a href="../../base/base/index.html#Core.Symbol"><code>Symbol</code></a> or a collection of <code>Symbol</code>s . <code>pids</code> and <code>mod</code> identify the processes and the module in which global variables are to be reinitialized. Only those names found to be defined under <code>mod</code> are cleared.</p>
<p>An exception is raised if a global constant is requested to be cleared.</p></section><section><pre data-language="julia">clear!(pool::CachingPool) -&gt; pool</pre>
<p>Removes all cached functions from all participating workers.</p></section><h3 id="Distributed.remote">
<code>Distributed.remote</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">remote([p::AbstractWorkerPool], f) -&gt; Function</pre>
<p>Return an anonymous function that executes function <code>f</code> on an available worker (drawn from <a href="#Distributed.WorkerPool"><code>WorkerPool</code></a> <code>p</code> if provided) using <a href="#Distributed.remotecall_fetch-Tuple{Any,%20Integer,%20Vararg{Any}}"><code>remotecall_fetch</code></a>.</p></section><h3 id="Distributed.remotecall-Tuple{Any, AbstractWorkerPool, Vararg{Any}}">
<code>Distributed.remotecall</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remotecall(f, pool::AbstractWorkerPool, args...; kwargs...) -&gt; Future</pre>
<p><a href="#Distributed.WorkerPool"><code>WorkerPool</code></a> variant of <code>remotecall(f, pid, ....)</code>. Wait for and take a free worker from <code>pool</code> and perform a <code>remotecall</code> on it.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 3

julia&gt; wp = WorkerPool([2, 3]);

julia&gt; A = rand(3000);

julia&gt; f = remotecall(maximum, wp, A)
Future(2, 1, 6, nothing)</pre>
<p>In this example, the task ran on pid 2, called from pid 1.</p></section><h3 id="Distributed.remotecall_wait-Tuple{Any, AbstractWorkerPool, Vararg{Any}}">
<code>Distributed.remotecall_wait</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remotecall_wait(f, pool::AbstractWorkerPool, args...; kwargs...) -&gt; Future</pre>
<p><a href="#Distributed.WorkerPool"><code>WorkerPool</code></a> variant of <code>remotecall_wait(f, pid, ....)</code>. Wait for and take a free worker from <code>pool</code> and perform a <code>remotecall_wait</code> on it.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 3

julia&gt; wp = WorkerPool([2, 3]);

julia&gt; A = rand(3000);

julia&gt; f = remotecall_wait(maximum, wp, A)
Future(3, 1, 9, nothing)

julia&gt; fetch(f)
0.9995177101692958</pre></section><h3 id="Distributed.remotecall_fetch-Tuple{Any, AbstractWorkerPool, Vararg{Any}}">
<code>Distributed.remotecall_fetch</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remotecall_fetch(f, pool::AbstractWorkerPool, args...; kwargs...) -&gt; result</pre>
<p><a href="#Distributed.WorkerPool"><code>WorkerPool</code></a> variant of <code>remotecall_fetch(f, pid, ....)</code>. Waits for and takes a free worker from <code>pool</code> and performs a <code>remotecall_fetch</code> on it.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">$ julia -p 3

julia&gt; wp = WorkerPool([2, 3]);

julia&gt; A = rand(3000);

julia&gt; remotecall_fetch(maximum, wp, A)
0.9995177101692958</pre></section><h3 id="Distributed.remote_do-Tuple{Any, AbstractWorkerPool, Vararg{Any}}">
<code>Distributed.remote_do</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">remote_do(f, pool::AbstractWorkerPool, args...; kwargs...) -&gt; nothing</pre>
<p><a href="#Distributed.WorkerPool"><code>WorkerPool</code></a> variant of <code>remote_do(f, pid, ....)</code>. Wait for and take a free worker from <code>pool</code> and perform a <code>remote_do</code> on it.</p></section><h3 id="Distributed.@spawn">
<code>Distributed.@spawn</code><span class="docstring-category">Macro</span>
</h3>
<section><pre data-language="julia">@spawn expr</pre>
<p>Create a closure around an expression and run it on an automatically-chosen process, returning a <a href="../future/index.html#Future"><code>Future</code></a> to the result. This macro is deprecated; <code>@spawnat :any expr</code> should be used instead.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">julia&gt; addprocs(3);

julia&gt; f = @spawn myid()
Future(2, 1, 5, nothing)

julia&gt; fetch(f)
2

julia&gt; f = @spawn myid()
Future(3, 1, 7, nothing)

julia&gt; fetch(f)
3</pre>
<div class="admonition is-compat">

<div class="admonition-body"><p>As of Julia 1.3 this macro is deprecated. Use <code>@spawnat :any</code> instead.</p></div>
</div></section><h3 id="Distributed.@spawnat">
<code>Distributed.@spawnat</code><span class="docstring-category">Macro</span>
</h3>
<section><pre data-language="julia">@spawnat p expr</pre>
<p>Create a closure around an expression and run the closure asynchronously on process <code>p</code>. Return a <a href="../future/index.html#Future"><code>Future</code></a> to the result. If <code>p</code> is the quoted literal symbol <code>:any</code>, then the system will pick a processor to use automatically.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">julia&gt; addprocs(3);

julia&gt; f = @spawnat 2 myid()
Future(2, 1, 3, nothing)

julia&gt; fetch(f)
2

julia&gt; f = @spawnat :any myid()
Future(3, 1, 7, nothing)

julia&gt; fetch(f)
3</pre>
<div class="admonition is-compat">

<div class="admonition-body"><p>The <code>:any</code> argument is available as of Julia 1.3.</p></div>
</div></section><h3 id="Distributed.@fetch">
<code>Distributed.@fetch</code><span class="docstring-category">Macro</span>
</h3>
<section><pre data-language="julia">@fetch expr</pre>
<p>Equivalent to <code>fetch(@spawnat :any expr)</code>. See <a href="#"><code>fetch</code></a> and <a href="#Distributed.@spawnat"><code>@spawnat</code></a>.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">julia&gt; addprocs(3);

julia&gt; @fetch myid()
2

julia&gt; @fetch myid()
3

julia&gt; @fetch myid()
4

julia&gt; @fetch myid()
2</pre></section><h3 id="Distributed.@fetchfrom">
<code>Distributed.@fetchfrom</code><span class="docstring-category">Macro</span>
</h3>
<section><pre data-language="julia">@fetchfrom</pre>
<p>Equivalent to <code>fetch(@spawnat p expr)</code>. See <a href="#"><code>fetch</code></a> and <a href="#Distributed.@spawnat"><code>@spawnat</code></a>.</p>
<p><strong>Examples</strong></p>
<pre data-language="julia">julia&gt; addprocs(3);

julia&gt; @fetchfrom 2 myid()
2

julia&gt; @fetchfrom 4 myid()
4</pre></section><h3 id="Distributed.@distributed">
<code>Distributed.@distributed</code><span class="docstring-category">Macro</span>
</h3>
<section><pre data-language="julia">@distributed</pre>
<p>A distributed memory, parallel for loop of the form :</p>
<pre data-language="julia">@distributed [reducer] for var = range
    body
end</pre>
<p>The specified range is partitioned and locally executed across all workers. In case an optional reducer function is specified, <code>@distributed</code> performs local reductions on each worker with a final reduction on the calling process.</p>
<p>Note that without a reducer function, <code>@distributed</code> executes asynchronously, i.e. it spawns independent tasks on all available workers and returns immediately without waiting for completion. To wait for completion, prefix the call with <a href="../../base/parallel/index.html#Base.@sync"><code>@sync</code></a>, like :</p>
<pre data-language="julia">@sync @distributed for var = range
    body
end</pre></section><h3 id="Distributed.@everywhere">
<code>Distributed.@everywhere</code><span class="docstring-category">Macro</span>
</h3>
<section><pre data-language="julia">@everywhere [procs()] expr</pre>
<p>Execute an expression under <code>Main</code> on all <code>procs</code>. Errors on any of the processes are collected into a <a href="../../base/base/index.html#Base.CompositeException"><code>CompositeException</code></a> and thrown. For example:</p>
<pre data-language="julia">@everywhere bar = 1</pre>
<p>will define <code>Main.bar</code> on all current processes. Any processes added later (say with <a href="#Distributed.addprocs"><code>addprocs()</code></a>) will not have the expression defined.</p>
<p>Unlike <a href="#Distributed.@spawnat"><code>@spawnat</code></a>, <code>@everywhere</code> does not capture any local variables. Instead, local variables can be broadcast using interpolation:</p>
<pre data-language="julia">foo = 1
@everywhere bar = $foo</pre>
<p>The optional argument <code>procs</code> allows specifying a subset of all processes to have execute the expression.</p>
<p>Similar to calling <code>remotecall_eval(Main, procs, expr)</code>, but with two extra features:</p>
<pre data-language="julia">- `using` and `import` statements run on the calling process first, to ensure
  packages are precompiled.
- The current source file path used by `include` is propagated to other processes.</pre></section><h3 id="Distributed.remoteref_id">
<code>Distributed.remoteref_id</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">remoteref_id(r::AbstractRemoteRef) -&gt; RRID</pre>
<p><code>Future</code>s and <code>RemoteChannel</code>s are identified by fields:</p>
<ul>
<li><p><code>where</code> - refers to the node where the underlying object/storage referred to by the reference actually exists.</p></li>
<li><p><code>whence</code> - refers to the node the remote reference was created from. Note that this is different from the node where the underlying object referred to actually exists. For example calling <code>RemoteChannel(2)</code> from the master process would result in a <code>where</code> value of 2 and a <code>whence</code> value of 1.</p></li>
<li><p><code>id</code> is unique across all references created from the worker specified by <code>whence</code>.</p></li>
</ul>
<p>Taken together, <code>whence</code> and <code>id</code> uniquely identify a reference across all workers.</p>
<p><code>remoteref_id</code> is a low-level API which returns a <code>RRID</code> object that wraps <code>whence</code> and <code>id</code> values of a remote reference.</p></section><h3 id="Distributed.channel_from_id">
<code>Distributed.channel_from_id</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">channel_from_id(id) -&gt; c</pre>
<p>A low-level API which returns the backing <code>AbstractChannel</code> for an <code>id</code> returned by <a href="#Distributed.remoteref_id"><code>remoteref_id</code></a>. The call is valid only on the node where the backing channel exists.</p></section><h3 id="Distributed.worker_id_from_socket">
<code>Distributed.worker_id_from_socket</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">worker_id_from_socket(s) -&gt; pid</pre>
<p>A low-level API which, given a <code>IO</code> connection or a <code>Worker</code>, returns the <code>pid</code> of the worker it is connected to. This is useful when writing custom <a href="../serialization/index.html#Serialization.serialize"><code>serialize</code></a> methods for a type, which optimizes the data written out depending on the receiving process id.</p></section><h3 id="Distributed.cluster_cookie-Tuple{}">
<code>Distributed.cluster_cookie</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">cluster_cookie() -&gt; cookie</pre>
<p>Return the cluster cookie.</p></section><h3 id="Distributed.cluster_cookie-Tuple{Any}">
<code>Distributed.cluster_cookie</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">cluster_cookie(cookie) -&gt; cookie</pre>
<p>Set the passed cookie as the cluster cookie, then returns it.</p></section><h2 id="Cluster-Manager-Interface">
<a class="docs-heading-anchor" href="#Cluster-Manager-Interface">Cluster Manager Interface</a>
</h2>
<p>This interface provides a mechanism to launch and manage Julia workers on different cluster environments. There are two types of managers present in Base: <code>LocalManager</code>, for launching additional workers on the same host, and <code>SSHManager</code>, for launching on remote hosts via <code>ssh</code>. TCP/IP sockets are used to connect and transport messages between processes. It is possible for Cluster Managers to provide a different transport.</p>
<h3 id="Distributed.ClusterManager">
<code>Distributed.ClusterManager</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">ClusterManager</pre>
<p>Supertype for cluster managers, which control workers processes as a cluster. Cluster managers implement how workers can be added, removed and communicated with. <code>SSHManager</code> and <code>LocalManager</code> are subtypes of this.</p></section><h3 id="Distributed.WorkerConfig">
<code>Distributed.WorkerConfig</code><span class="docstring-category">Type</span>
</h3>
<section><pre data-language="julia">WorkerConfig</pre>
<p>Type used by <a href="#Distributed.ClusterManager"><code>ClusterManager</code></a>s to control workers added to their clusters. Some fields are used by all cluster managers to access a host:</p>
<ul>
<li>
<code>io</code> – the connection used to access the worker (a subtype of <code>IO</code> or <code>Nothing</code>)</li>
<li>
<code>host</code> – the host address (either a <code>String</code> or <code>Nothing</code>)</li>
<li>
<code>port</code> – the port on the host used to connect to the worker (either an <code>Int</code> or <code>Nothing</code>)</li>
</ul>
<p>Some are used by the cluster manager to add workers to an already-initialized host:</p>
<ul>
<li>
<code>count</code> – the number of workers to be launched on the host</li>
<li>
<code>exename</code> – the path to the Julia executable on the host, defaults to <code>"$(Sys.BINDIR)/julia"</code> or <code>"$(Sys.BINDIR)/julia-debug"</code>
</li>
<li>
<code>exeflags</code> – flags to use when launching Julia remotely</li>
</ul>
<p>The <code>userdata</code> field is used to store information for each worker by external managers.</p>
<p>Some fields are used by <code>SSHManager</code> and similar managers:</p>
<ul>
<li>
<code>tunnel</code> – <code>true</code> (use tunneling), <code>false</code> (do not use tunneling), or <a href="../../base/constants/index.html#Core.nothing"><code>nothing</code></a> (use default for the manager)</li>
<li>
<code>multiplex</code> – <code>true</code> (use SSH multiplexing for tunneling) or <code>false</code>
</li>
<li>
<code>forward</code> – the forwarding option used for <code>-L</code> option of ssh</li>
<li>
<code>bind_addr</code> – the address on the remote host to bind to</li>
<li>
<code>sshflags</code> – flags to use in establishing the SSH connection</li>
<li>
<code>max_parallel</code> – the maximum number of workers to connect to in parallel on the host</li>
</ul>
<p>Some fields are used by both <code>LocalManager</code>s and <code>SSHManager</code>s:</p>
<ul>
<li>
<code>connect_at</code> – determines whether this is a worker-to-worker or driver-to-worker setup call</li>
<li>
<code>process</code> – the process which will be connected (usually the manager will assign this during <a href="#Distributed.addprocs"><code>addprocs</code></a>)</li>
<li>
<code>ospid</code> – the process ID according to the host OS, used to interrupt worker processes</li>
<li>
<code>environ</code> – private dictionary used to store temporary information by Local/SSH managers</li>
<li>
<code>ident</code> – worker as identified by the <a href="#Distributed.ClusterManager"><code>ClusterManager</code></a>
</li>
<li>
<code>connect_idents</code> – list of worker ids the worker must connect to if using a custom topology</li>
<li>
<code>enable_threaded_blas</code> – <code>true</code>, <code>false</code>, or <code>nothing</code>, whether to use threaded BLAS or not on the workers</li>
</ul></section><h3 id="Distributed.launch">
<code>Distributed.launch</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">launch(manager::ClusterManager, params::Dict, launched::Array, launch_ntfy::Condition)</pre>
<p>Implemented by cluster managers. For every Julia worker launched by this function, it should append a <code>WorkerConfig</code> entry to <code>launched</code> and notify <code>launch_ntfy</code>. The function MUST exit once all workers, requested by <code>manager</code> have been launched. <code>params</code> is a dictionary of all keyword arguments <a href="#Distributed.addprocs"><code>addprocs</code></a> was called with.</p></section><h3 id="Distributed.manage">
<code>Distributed.manage</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">manage(manager::ClusterManager, id::Integer, config::WorkerConfig. op::Symbol)</pre>
<p>Implemented by cluster managers. It is called on the master process, during a worker's lifetime, with appropriate <code>op</code> values:</p>
<ul>
<li>with <code>:register</code>/<code>:deregister</code> when a worker is added / removed from the Julia worker pool.</li>
<li>with <code>:interrupt</code> when <code>interrupt(workers)</code> is called. The <code>ClusterManager</code> should signal the appropriate worker with an interrupt signal.</li>
<li>with <code>:finalize</code> for cleanup purposes.</li>
</ul></section><h3 id="Base.kill-Tuple{ClusterManager, Int64, WorkerConfig}">
<code>Base.kill</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">kill(manager::ClusterManager, pid::Int, config::WorkerConfig)</pre>
<p>Implemented by cluster managers. It is called on the master process, by <a href="#Distributed.rmprocs"><code>rmprocs</code></a>. It should cause the remote worker specified by <code>pid</code> to exit. <code>kill(manager::ClusterManager.....)</code> executes a remote <code>exit()</code> on <code>pid</code>.</p></section><h3 id="Sockets.connect-Tuple{ClusterManager, Int64, WorkerConfig}">
<code>Sockets.connect</code><span class="docstring-category">Method</span>
</h3>
<section><pre data-language="julia">connect(manager::ClusterManager, pid::Int, config::WorkerConfig) -&gt; (instrm::IO, outstrm::IO)</pre>
<p>Implemented by cluster managers using custom transports. It should establish a logical connection to worker with id <code>pid</code>, specified by <code>config</code> and return a pair of <code>IO</code> objects. Messages from <code>pid</code> to current process will be read off <code>instrm</code>, while messages to be sent to <code>pid</code> will be written to <code>outstrm</code>. The custom transport implementation must ensure that messages are delivered and received completely and in order. <code>connect(manager::ClusterManager.....)</code> sets up TCP/IP socket connections in-between workers.</p></section><h3 id="Distributed.init_worker">
<code>Distributed.init_worker</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">init_worker(cookie::AbstractString, manager::ClusterManager=DefaultClusterManager())</pre>
<p>Called by cluster managers implementing custom transports. It initializes a newly launched process as a worker. Command line argument <code>--worker[=&lt;cookie&gt;]</code> has the effect of initializing a process as a worker using TCP/IP sockets for transport. <code>cookie</code> is a <a href="#Distributed.cluster_cookie-Tuple{}"><code>cluster_cookie</code></a>.</p></section><h3 id="Distributed.start_worker">
<code>Distributed.start_worker</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">start_worker([out::IO=stdout], cookie::AbstractString=readline(stdin); close_stdin::Bool=true, stderr_to_stdout::Bool=true)</pre>
<p><code>start_worker</code> is an internal function which is the default entry point for worker processes connecting via TCP/IP. It sets up the process as a Julia cluster worker.</p>
<p>host:port information is written to stream <code>out</code> (defaults to stdout).</p>
<p>The function reads the cookie from stdin if required, and listens on a free port (or if specified, the port in the <code>--bind-to</code> command line option) and schedules tasks to process incoming TCP connections and requests. It also (optionally) closes stdin and redirects stderr to stdout.</p>
<p>It does not return.</p></section><h3 id="Distributed.process_messages">
<code>Distributed.process_messages</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">process_messages(r_stream::IO, w_stream::IO, incoming::Bool=true)</pre>
<p>Called by cluster managers using custom transports. It should be called when the custom transport implementation receives the first message from a remote worker. The custom transport must manage a logical connection to the remote worker and provide two <code>IO</code> objects, one for incoming messages and the other for messages addressed to the remote worker. If <code>incoming</code> is <code>true</code>, the remote peer initiated the connection. Whichever of the pair initiates the connection sends the cluster cookie and its Julia version number to perform the authentication handshake.</p>
<p>See also <a href="#Distributed.cluster_cookie-Tuple{}"><code>cluster_cookie</code></a>.</p></section><h3 id="Distributed.default_addprocs_params">
<code>Distributed.default_addprocs_params</code><span class="docstring-category">Function</span>
</h3>
<section><pre data-language="julia">default_addprocs_params(mgr::ClusterManager) -&gt; Dict{Symbol, Any}</pre>
<p>Implemented by cluster managers. The default keyword parameters passed when calling <code>addprocs(mgr)</code>. The minimal set of options is available by calling <code>default_addprocs_params()</code></p></section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2009&ndash;2024 Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and other contributors<br>Licensed under the MIT License.<br>
    <a href="https://docs.julialang.org/en/v1.11/stdlib/Distributed/" class="_attribution-link">https://docs.julialang.org/en/v1.11/stdlib/Distributed/</a>
  </p>
</div>
