<h1 id="man-multithreading">Multi-Threading</h1>
<p>Visit this <a href="https://julialang.org/blog/2019/07/multithreading/">blog post</a> for a presentation of Julia multi-threading features.</p>
<h2 id="Starting-Julia-with-multiple-threads">
<a class="docs-heading-anchor" href="#Starting-Julia-with-multiple-threads">Starting Julia with multiple threads</a>
</h2>
<p>By default, Julia starts up with a single thread of execution. This can be verified by using the command <a href="../../base/multi-threading/index.html#Base.Threads.nthreads"><code>Threads.nthreads()</code></a>:</p>
<pre data-language="julia">julia&gt; Threads.nthreads()
1</pre>
<p>The number of execution threads is controlled either by using the <code>-t</code>/<code>--threads</code> command line argument or by using the <a href="../environment-variables/index.html#JULIA_NUM_THREADS"><code>JULIA_NUM_THREADS</code></a> environment variable. When both are specified, then <code>-t</code>/<code>--threads</code> takes precedence.</p>
<p>The number of threads can either be specified as an integer (<code>--threads=4</code>) or as <code>auto</code> (<code>--threads=auto</code>), where <code>auto</code> tries to infer a useful default number of threads to use (see <a href="../command-line-interface/index.html#command-line-interface">Command-line Options</a> for more details).</p>
<div class="admonition is-compat">

<div class="admonition-body"><p>The <code>-t</code>/<code>--threads</code> command line argument requires at least Julia 1.5. In older versions you must use the environment variable instead.</p></div>
</div>
<div class="admonition is-compat">

<div class="admonition-body"><p>Using <code>auto</code> as value of the environment variable <code>JULIA_NUM_THREADS</code> requires at least Julia 1.7. In older versions, this value is ignored.</p></div>
</div>
<p>Lets start Julia with 4 threads:</p>
<pre data-language="julia">$ julia --threads 4</pre>
<p>Let's verify there are 4 threads at our disposal.</p>
<pre data-language="julia">julia&gt; Threads.nthreads()
4</pre>
<p>But we are currently on the master thread. To check, we use the function <a href="../../base/multi-threading/index.html#Base.Threads.threadid"><code>Threads.threadid</code></a></p>
<pre data-language="julia">julia&gt; Threads.threadid()
1</pre>
<div class="admonition is-info">

<div class="admonition-body">
<p>If you prefer to use the environment variable you can set it as follows in Bash (Linux/macOS):</p>
<pre data-language="julia">export JULIA_NUM_THREADS=4</pre>
<p>C shell on Linux/macOS, CMD on Windows:</p>
<pre data-language="julia">set JULIA_NUM_THREADS=4</pre>
<p>Powershell on Windows:</p>
<pre data-language="julia">$env:JULIA_NUM_THREADS=4</pre>
<p>Note that this must be done <em>before</em> starting Julia.</p>
</div>
</div>
<div class="admonition is-info">

<div class="admonition-body"><p>The number of threads specified with <code>-t</code>/<code>--threads</code> is propagated to worker processes that are spawned using the <code>-p</code>/<code>--procs</code> or <code>--machine-file</code> command line options. For example, <code>julia -p2 -t2</code> spawns 1 main process with 2 worker processes, and all three processes have 2 threads enabled. For more fine grained control over worker threads use <a href="../../stdlib/distributed/index.html#Distributed.addprocs"><code>addprocs</code></a> and pass <code>-t</code>/<code>--threads</code> as <code>exeflags</code>.</p></div>
</div>
<h3 id="Multiple-GC-Threads">
<a class="docs-heading-anchor" href="#Multiple-GC-Threads">Multiple GC Threads</a>
</h3>
<p>The Garbage Collector (GC) can use multiple threads. The amount used is either half the number of compute worker threads or configured by either the <code>--gcthreads</code> command line argument or by using the <a href="../environment-variables/index.html#env-gc-threads"><code>JULIA_NUM_GC_THREADS</code></a> environment variable.</p>
<div class="admonition is-compat">

<div class="admonition-body"><p>The <code>--gcthreads</code> command line argument requires at least Julia 1.10.</p></div>
</div>
<h2 id="man-threadpools">
<a class="docs-heading-anchor" href="#man-threadpools">Threadpools</a>
</h2>
<p>When a program's threads are busy with many tasks to run, tasks may experience delays which may negatively affect the responsiveness and interactivity of the program. To address this, you can specify that a task is interactive when you <a href="../../base/multi-threading/index.html#Base.Threads.@spawn"><code>Threads.@spawn</code></a> it:</p>
<pre data-language="julia">using Base.Threads
@spawn :interactive f()</pre>
<p>Interactive tasks should avoid performing high latency operations, and if they are long duration tasks, should yield frequently.</p>
<p>Julia may be started with one or more threads reserved to run interactive tasks:</p>
<pre data-language="julia">$ julia --threads 3,1</pre>
<p>The environment variable <code>JULIA_NUM_THREADS</code> can also be used similarly:</p>
<pre data-language="julia">export JULIA_NUM_THREADS=3,1</pre>
<p>This starts Julia with 3 threads in the <code>:default</code> threadpool and 1 thread in the <code>:interactive</code> threadpool:</p>
<pre data-language="julia">julia&gt; using Base.Threads

julia&gt; nthreadpools()
2

julia&gt; threadpool()
:default

julia&gt; nthreads(:default)
3

julia&gt; nthreads(:interactive)
1

julia&gt; nthreads()
3</pre>
<div class="admonition is-info">

<div class="admonition-body"><p>The zero-argument version of <code>nthreads</code> returns the number of threads in the default pool.</p></div>
</div>
<p>Either or both numbers can be replaced with the word <code>auto</code>, which causes Julia to choose a reasonable default.</p>
<h2 id="Communication-and-synchronization">
<a class="docs-heading-anchor" href="#Communication-and-synchronization">Communication and synchronization</a>
</h2>
<p>Although Julia's threads can communicate through shared memory, it is notoriously difficult to write correct and data-race free multi-threaded code. Julia's <a href="../../base/parallel/index.html#Base.Channel"><code>Channel</code></a>s are thread-safe and may be used to communicate safely.</p>
<h3 id="Data-race-freedom">
<a class="docs-heading-anchor" href="#Data-race-freedom">Data-race freedom</a>
</h3>
<p>You are entirely responsible for ensuring that your program is data-race free, and nothing promised here can be assumed if you do not observe that requirement. The observed results may be highly unintuitive.</p>
<p>The best way to ensure this is to acquire a lock around any access to data that can be observed from multiple threads. For example, in most cases you should use the following code pattern:</p>
<pre data-language="julia">julia&gt; lock(lk) do
           use(a)
       end

julia&gt; begin
           lock(lk)
           try
               use(a)
           finally
               unlock(lk)
           end
       end</pre>
<p>where <code>lk</code> is a lock (e.g. <code>ReentrantLock()</code>) and <code>a</code> data.</p>
<p>Additionally, Julia is not memory safe in the presence of a data race. Be very careful about reading <em>any</em> data if another thread might write to it! Instead, always use the lock pattern above when changing data (such as assigning to a global or closure variable) accessed by other threads.</p>
<pre data-language="julia">Thread 1:
global b = false
global a = rand()
global b = true

Thread 2:
while !b; end
bad_read1(a) # it is NOT safe to access `a` here!

Thread 3:
while !@isdefined(a); end
bad_read2(a) # it is NOT safe to access `a` here</pre>
<h2 id="The-@threads-Macro">
<a class="docs-heading-anchor" href="#The-@threads-Macro">The <code>@threads</code> Macro</a>
</h2>
<p>Let's work a simple example using our native threads. Let us create an array of zeros:</p>
<pre data-language="julia">julia&gt; a = zeros(10)
10-element Vector{Float64}:
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0</pre>
<p>Let us operate on this array simultaneously using 4 threads. We'll have each thread write its thread ID into each location.</p>
<p>Julia supports parallel loops using the <a href="../../base/multi-threading/index.html#Base.Threads.@threads"><code>Threads.@threads</code></a> macro. This macro is affixed in front of a <code>for</code> loop to indicate to Julia that the loop is a multi-threaded region:</p>
<pre data-language="julia">julia&gt; Threads.@threads for i = 1:10
           a[i] = Threads.threadid()
       end</pre>
<p>The iteration space is split among the threads, after which each thread writes its thread ID to its assigned locations:</p>
<pre data-language="julia">julia&gt; a
10-element Vector{Float64}:
 1.0
 1.0
 1.0
 2.0
 2.0
 2.0
 3.0
 3.0
 4.0
 4.0</pre>
<p>Note that <a href="../../base/multi-threading/index.html#Base.Threads.@threads"><code>Threads.@threads</code></a> does not have an optional reduction parameter like <a href="../../stdlib/distributed/index.html#Distributed.@distributed"><code>@distributed</code></a>.</p>
<h3 id="Using-@threads-without-data-races">
<a class="docs-heading-anchor" href="#Using-@threads-without-data-races">Using <code>@threads</code> without data races</a>
</h3>
<p>Taking the example of a naive sum</p>
<pre data-language="julia">julia&gt; function sum_single(a)
           s = 0
           for i in a
               s += i
           end
           s
       end
sum_single (generic function with 1 method)

julia&gt; sum_single(1:1_000_000)
500000500000</pre>
<p>Simply adding <code>@threads</code> exposes a data race with multiple threads reading and writing <code>s</code> at the same time.</p>
<pre data-language="julia">julia&gt; function sum_multi_bad(a)
           s = 0
           Threads.@threads for i in a
               s += i
           end
           s
       end
sum_multi_bad (generic function with 1 method)

julia&gt; sum_multi_bad(1:1_000_000)
70140554652</pre>
<p>Note that the result is not <code>500000500000</code> as it should be, and will most likely change each evaluation.</p>
<p>To fix this, buffers that are specific to the task may be used to segment the sum into chunks that are race-free. Here <code>sum_single</code> is reused, with its own internal buffer <code>s</code>, and vector <code>a</code> is split into <code>nthreads()</code> chunks for parallel work via <code>nthreads()</code> <code>@spawn</code>-ed tasks.</p>
<pre data-language="julia">julia&gt; function sum_multi_good(a)
           chunks = Iterators.partition(a, length(a) รท Threads.nthreads())
           tasks = map(chunks) do chunk
               Threads.@spawn sum_single(chunk)
           end
           chunk_sums = fetch.(tasks)
           return sum_single(chunk_sums)
       end
sum_multi_good (generic function with 1 method)

julia&gt; sum_multi_good(1:1_000_000)
500000500000</pre>
<div class="admonition is-info">

<div class="admonition-body"><p>Buffers should not be managed based on <code>threadid()</code> i.e. <code>buffers = zeros(Threads.nthreads())</code> because concurrent tasks can yield, meaning multiple concurrent tasks may use the same buffer on a given thread, introducing risk of data races. Further, when more than one thread is available tasks may change thread at yield points, which is known as <a href="#man-task-migration">task migration</a>.</p></div>
</div>
<p>Another option is the use of atomic operations on variables shared across tasks/threads, which may be more performant depending on the characteristics of the operations.</p>
<h2 id="Atomic-Operations">
<a class="docs-heading-anchor" href="#Atomic-Operations">Atomic Operations</a>
</h2>
<p>Julia supports accessing and modifying values <em>atomically</em>, that is, in a thread-safe way to avoid <a href="https://en.wikipedia.org/wiki/Race_condition">race conditions</a>. A value (which must be of a primitive type) can be wrapped as <a href="../../base/multi-threading/index.html#Base.Threads.Atomic"><code>Threads.Atomic</code></a> to indicate it must be accessed in this way. Here we can see an example:</p>
<pre data-language="julia">julia&gt; i = Threads.Atomic{Int}(0);

julia&gt; ids = zeros(4);

julia&gt; old_is = zeros(4);

julia&gt; Threads.@threads for id in 1:4
           old_is[id] = Threads.atomic_add!(i, id)
           ids[id] = id
       end

julia&gt; old_is
4-element Vector{Float64}:
 0.0
 1.0
 7.0
 3.0

julia&gt; i[]
 10

julia&gt; ids
4-element Vector{Float64}:
 1.0
 2.0
 3.0
 4.0</pre>
<p>Had we tried to do the addition without the atomic tag, we might have gotten the wrong answer due to a race condition. An example of what would happen if we didn't avoid the race:</p>
<pre data-language="julia">julia&gt; using Base.Threads

julia&gt; Threads.nthreads()
4

julia&gt; acc = Ref(0)
Base.RefValue{Int64}(0)

julia&gt; @threads for i in 1:1000
          acc[] += 1
       end

julia&gt; acc[]
926

julia&gt; acc = Atomic{Int64}(0)
Atomic{Int64}(0)

julia&gt; @threads for i in 1:1000
          atomic_add!(acc, 1)
       end

julia&gt; acc[]
1000</pre>
<h2 id="man-atomics">
<a class="docs-heading-anchor" href="#man-atomics">Per-field atomics</a>
</h2>
<p>We can also use atomics on a more granular level using the <a href="../../base/multi-threading/index.html#Base.@atomic"><code>@atomic</code></a>, <a href="../../base/multi-threading/index.html#Base.@atomicswap"><code>@atomicswap</code></a>, and <a href="../../base/multi-threading/index.html#Base.@atomicreplace"><code>@atomicreplace</code></a> macros.</p>
<p>Specific details of the memory model and other details of the design are written in the <a href="https://gist.github.com/vtjnash/11b0031f2e2a66c9c24d33e810b34ec0">Julia Atomics Manifesto</a>, which will later be published formally.</p>
<p>Any field in a struct declaration can be decorated with <code>@atomic</code>, and then any write must be marked with <code>@atomic</code> also, and must use one of the defined atomic orderings (<code>:monotonic</code>, <code>:acquire</code>, <code>:release</code>, <code>:acquire_release</code>, or <code>:sequentially_consistent</code>). Any read of an atomic field can also be annotated with an atomic ordering constraint, or will be done with monotonic (relaxed) ordering if unspecified.</p>
<div class="admonition is-compat">

<div class="admonition-body"><p>Per-field atomics requires at least Julia 1.7.</p></div>
</div>
<h2 id="Side-effects-and-mutable-function-arguments">
<a class="docs-heading-anchor" href="#Side-effects-and-mutable-function-arguments">Side effects and mutable function arguments</a>
</h2>
<p>When using multi-threading we have to be careful when using functions that are not <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> as we might get a wrong answer. For instance functions that have a <a href="../style-guide/index.html#bang-convention">name ending with <code>!</code></a> by convention modify their arguments and thus are not pure.</p>
<h2 id="@threadcall">
<a class="docs-heading-anchor" href="#@threadcall">@threadcall</a>
</h2>
<p>External libraries, such as those called via <a href="../../base/c/index.html#ccall"><code>ccall</code></a>, pose a problem for Julia's task-based I/O mechanism. If a C library performs a blocking operation, that prevents the Julia scheduler from executing any other tasks until the call returns. (Exceptions are calls into custom C code that call back into Julia, which may then yield, or C code that calls <code>jl_yield()</code>, the C equivalent of <a href="../../base/parallel/index.html#Base.yield"><code>yield</code></a>.)</p>
<p>The <a href="../../base/multi-threading/index.html#Base.@threadcall"><code>@threadcall</code></a> macro provides a way to avoid stalling execution in such a scenario. It schedules a C function for execution in a separate thread. A threadpool with a default size of 4 is used for this. The size of the threadpool is controlled via environment variable <code>UV_THREADPOOL_SIZE</code>. While waiting for a free thread, and during function execution once a thread is available, the requesting task (on the main Julia event loop) yields to other tasks. Note that <code>@threadcall</code> does not return until the execution is complete. From a user point of view, it is therefore a blocking call like other Julia APIs.</p>
<p>It is very important that the called function does not call back into Julia, as it will segfault.</p>
<p><code>@threadcall</code> may be removed/changed in future versions of Julia.</p>
<h2 id="Caveats">
<a class="docs-heading-anchor" href="#Caveats">Caveats</a>
</h2>
<p>At this time, most operations in the Julia runtime and standard libraries can be used in a thread-safe manner, if the user code is data-race free. However, in some areas work on stabilizing thread support is ongoing. Multi-threaded programming has many inherent difficulties, and if a program using threads exhibits unusual or undesirable behavior (e.g. crashes or mysterious results), thread interactions should typically be suspected first.</p>
<p>There are a few specific limitations and warnings to be aware of when using threads in Julia:</p>
<ul>
<li>Base collection types require manual locking if used simultaneously by multiple threads where at least one thread modifies the collection (common examples include <code>push!</code> on arrays, or inserting items into a <code>Dict</code>).</li>
<li>The schedule used by <code>@spawn</code> is nondeterministic and should not be relied on.</li>
<li>Compute-bound, non-memory-allocating tasks can prevent garbage collection from running in other threads that are allocating memory. In these cases it may be necessary to insert a manual call to <code>GC.safepoint()</code> to allow GC to run. This limitation will be removed in the future.</li>
<li>Avoid running top-level operations, e.g. <code>include</code>, or <code>eval</code> of type, method, and module definitions in parallel.</li>
<li>Be aware that finalizers registered by a library may break if threads are enabled. This may require some transitional work across the ecosystem before threading can be widely adopted with confidence. See the next section for further details.</li>
</ul>
<h2 id="man-task-migration">
<a class="docs-heading-anchor" href="#man-task-migration">Task Migration</a>
</h2>
<p>After a task starts running on a certain thread it may move to a different thread if the task yields.</p>
<p>Such tasks may have been started with <a href="../../base/multi-threading/index.html#Base.Threads.@spawn"><code>@spawn</code></a> or <a href="../../base/multi-threading/index.html#Base.Threads.@threads"><code>@threads</code></a>, although the <code>:static</code> schedule option for <code>@threads</code> does freeze the threadid.</p>
<p>This means that in most cases <a href="../../base/multi-threading/index.html#Base.Threads.threadid"><code>threadid()</code></a> should not be treated as constant within a task, and therefore should not be used to index into a vector of buffers or stateful objects.</p>
<div class="admonition is-compat">

<div class="admonition-body"><p>Task migration was introduced in Julia 1.7. Before this tasks always remained on the same thread that they were started on.</p></div>
</div>
<h2 id="Safe-use-of-Finalizers">
<a class="docs-heading-anchor" href="#Safe-use-of-Finalizers">Safe use of Finalizers</a>
</h2>
<p>Because finalizers can interrupt any code, they must be very careful in how they interact with any global state. Unfortunately, the main reason that finalizers are used is to update global state (a pure function is generally rather pointless as a finalizer). This leads us to a bit of a conundrum. There are a few approaches to dealing with this problem:</p>
<ol>
<li><p>When single-threaded, code could call the internal <code>jl_gc_enable_finalizers</code> C function to prevent finalizers from being scheduled inside a critical region. Internally, this is used inside some functions (such as our C locks) to prevent recursion when doing certain operations (incremental package loading, codegen, etc.). The combination of a lock and this flag can be used to make finalizers safe.</p></li>
<li>
<p>A second strategy, employed by Base in a couple places, is to explicitly delay a finalizer until it may be able to acquire its lock non-recursively. The following example demonstrates how this strategy could be applied to <code>Distributed.finalize_ref</code>:</p>
<pre data-language="julia">function finalize_ref(r::AbstractRemoteRef)
    if r.where &gt; 0 # Check if the finalizer is already run
        if islocked(client_refs) || !trylock(client_refs)
            # delay finalizer for later if we aren't free to acquire the lock
            finalizer(finalize_ref, r)
            return nothing
        end
        try # `lock` should always be followed by `try`
            if r.where &gt; 0 # Must check again here
                # Do actual cleanup here
                r.where = 0
            end
        finally
            unlock(client_refs)
        end
    end
    nothing
end</pre>
</li>
<li><p>A related third strategy is to use a yield-free queue. We don't currently have a lock-free queue implemented in Base, but <code>Base.IntrusiveLinkedListSynchronized{T}</code> is suitable. This can frequently be a good strategy to use for code with event loops. For example, this strategy is employed by <code>Gtk.jl</code> to manage lifetime ref-counting. In this approach, we don't do any explicit work inside the <code>finalizer</code>, and instead add it to a queue to run at a safer time. In fact, Julia's task scheduler already uses this, so defining the finalizer as <code>x -&gt; @spawn do_cleanup(x)</code> is one example of this approach. Note however that this doesn't control which thread <code>do_cleanup</code> runs on, so <code>do_cleanup</code> would still need to acquire a lock. That doesn't need to be true if you implement your own queue, as you can explicitly only drain that queue from your thread.</p></li>
</ol><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2009&ndash;2023 Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and other contributors<br>Licensed under the MIT License.<br>
    <a href="https://docs.julialang.org/en/v1.10/manual/multi-threading/" class="_attribution-link">https://docs.julialang.org/en/v1.10/manual/multi-threading/</a>
  </p>
</div>
