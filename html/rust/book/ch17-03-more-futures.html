<h1 id="working-with-any-number-of-futures">Working with Any Number of Futures</h1> <p>When we switched from using two futures to three in the previous section, we also had to switch from using <code>join</code> to using <code>join3</code>. It would be annoying to have to call a different function every time we changed the number of futures we wanted to join. Happily, we have a macro form of <code>join</code> to which we can pass an arbitrary number of arguments. It also handles awaiting the futures itself. Thus, we could rewrite the code from Listing 17-13 to use <code>join!</code> instead of <code>join3</code>, as in Listing 17-14.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = async move {
            let vals = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("received '{value}'");
            }
        };

        let tx_fut = async move {
            let vals = vec![
                String::from("more"),
                String::from("messages"),
                String::from("for"),
                String::from("you"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        trpl::join!(tx1_fut, tx_fut, rx_fut);
    });
}</pre> <figcaption>Listing 17-14: Using <code>join!</code> to wait for multiple futures</figcaption> </figure> <p>This is definitely an improvement over swapping between <code>join</code> and <code>join3</code> and <code>join4</code> and so on! However, even this macro form only works when we know the number of futures ahead of time. In real-world Rust, though, pushing futures into a collection and then waiting on some or all the futures of them to complete is a common pattern.</p> <p>To check all the futures in some collection, we’ll need to iterate over and join on <em>all</em> of them. The <code>trpl::join_all</code> function accepts any type that implements the <code>Iterator</code> trait, which you learned about back in <a href="ch13-02-iterators.html#the-iterator-trait-and-the-next-method">The Iterator Trait and the <code>next</code> Method</a> Chapter 13, so it seems like just the ticket. Let’s try putting our futures in a vector and replacing <code>join!</code> with <code>join_all</code> as show in Listing 17-15.</p> <figure class="listing"> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = async move {
            let vals = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("received '{value}'");
            }
        };

        let tx_fut = async move {
            let vals = vec![
                String::from("more"),
                String::from("messages"),
                String::from("for"),
                String::from("you"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let futures = vec![tx1_fut, rx_fut, tx_fut];

        trpl::join_all(futures).await;
    });
}</pre> <figcaption>Listing 17-15: Storing anonymous futures in a vector and calling <code>join_all</code></figcaption> </figure> <p>Unfortunately, this code doesn’t compile. Instead, we get this error:</p>  <pre>error[E0308]: mismatched types
  --&gt; src/main.rs:45:37
   |
10 |         let tx1_fut = async move {
   |                       ---------- the expected `async` block
...
24 |         let rx_fut = async {
   |                      ----- the found `async` block
...
45 |         let futures = vec![tx1_fut, rx_fut, tx_fut];
   |                                     ^^^^^^ expected `async` block, found a 
different `async` block
   |
   = note: expected `async` block `{async block@src/main.rs:10:23: 10:33}`
              found `async` block `{async block@src/main.rs:24:22: 24:27}`
   = note: no two async blocks, even if identical, have the same type
   = help: consider pinning your async block and casting it to a trait object
</pre> <p>This might be surprising. After all, none of the async blocks returns anything, so each one produces a <code>Future&lt;Output = ()&gt;</code>. Remember that <code>Future</code> is a trait, though, and that the compiler creates a unique enum for each async block. You can’t put two different hand-written structs in a <code>Vec</code>, and the same rule applies to the different enums generated by the compiler.</p> <p>To make this work, we need to use <em>trait objects</em>, just as we did in <a href="ch12-03-improving-error-handling-and-modularity.html">“Returning Errors from the run function”</a> in Chapter 12. (We’ll cover trait objects in detail in Chapter 18.) Using trait objects lets us treat each of the anonymous futures produced by these types as the same type, because all of them implement the <code>Future</code> trait.</p> <section class="note" aria-role="note"> <p>Note: In the Chapter 8 section <a href="ch12-03-improving-error-handling-and-modularity.html#returning-errors-from-the-run-function">Using an Enum to Store Multiple Values</a>, we discussed another way to include multiple types in a <code>Vec</code>: using an enum to represent each type that can appear in the vector. We can’t do that here, though. For one thing, we have no way to name the different types, because they are anonymous. For another, the reason we reached for a vector and <code>join_all</code> in the first place was to be able to work with a dynamic collection of futures where we only care that they have the same output type.</p> </section> <p>We start by wrapping each future in the <code>vec!</code> in a <code>Box::new</code>, as shown in Listing 17-16.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = async move {
            let vals = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("received '{value}'");
            }
        };

        let tx_fut = async move {
            let vals = vec![
                String::from("more"),
                String::from("messages"),
                String::from("for"),
                String::from("you"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let futures =
            vec![Box::new(tx1_fut), Box::new(rx_fut), Box::new(tx_fut)];

        trpl::join_all(futures).await;
    });
}</pre> <figcaption>Listing 17-16: Using <code>Box::new</code> to align the types of the futures in a <code>Vec</code></figcaption> </figure> <p>Unfortunately, this code still doesn’t compile. In fact, we get the same basic error we got before for both the second and third <code>Box::new</code> calls, as well as new errors referring to the <code>Unpin</code> trait. We’ll come back to the <code>Unpin</code> errors in a moment. First, let’s fix the type errors on the <code>Box::new</code> calls by explicitly annotating the type of the <code>futures</code> variable (see Listing 17-17).</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{future::Future, time::Duration};

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = async move {
            let vals = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("received '{value}'");
            }
        };

        let tx_fut = async move {
            let vals = vec![
                String::from("more"),
                String::from("messages"),
                String::from("for"),
                String::from("you"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        };

        let futures: Vec&lt;Box&lt;dyn Future&lt;Output = ()&gt;&gt;&gt; =
            vec![Box::new(tx1_fut), Box::new(rx_fut), Box::new(tx_fut)];

        trpl::join_all(futures).await;
    });
}</pre> <figcaption>Listing 17-17: Fixing the rest of the type mismatch errors by using an explicit type declaration</figcaption> </figure> <p>This type declaration is a little involved, so let’s walk through it:</p> <ol> <li>The innermost type is the future itself. We note explicitly that the output of the future is the unit type <code>()</code> by writing <code>Future&lt;Output = ()&gt;</code>.</li> <li>Then we annotate the trait with <code>dyn</code> to mark it as dynamic.</li> <li>The entire trait reference is wrapped in a <code>Box</code>.</li> <li>Finally, we state explicitly that <code>futures</code> is a <code>Vec</code> containing these items.</li> </ol> <p>That already made a big difference. Now when we run the compiler, we get only the errors mentioning <code>Unpin</code>. Although there are three of them, their contents are very similar.</p>  <pre>error[E0308]: mismatched types
   --&gt; src/main.rs:46:46
    |
10  |         let tx1_fut = async move {
    |                       ---------- the expected `async` block
...
24  |         let rx_fut = async {
    |                      ----- the found `async` block
...
46  |             vec![Box::new(tx1_fut), Box::new(rx_fut), Box::new(tx_fut)];
    |                                     -------- ^^^^^^ expected `async` block, found a different `async` block
    |                                     |
    |                                     arguments to this function are incorrect
    |
    = note: expected `async` block `{async block@src/main.rs:10:23: 10:33}`
               found `async` block `{async block@src/main.rs:24:22: 24:27}`
    = note: no two async blocks, even if identical, have the same type
    = help: consider pinning your async block and casting it to a trait object
note: associated function defined here
   --&gt; file:///home/.rustup/toolchains/1.82/lib/rustlib/src/rust/library/alloc/src/boxed.rs:255:12
    |
255 |     pub fn new(x: T) -&gt; Self {
    |            ^^^

error[E0308]: mismatched types
   --&gt; src/main.rs:46:64
    |
10  |         let tx1_fut = async move {
    |                       ---------- the expected `async` block
...
30  |         let tx_fut = async move {
    |                      ---------- the found `async` block
...
46  |             vec![Box::new(tx1_fut), Box::new(rx_fut), Box::new(tx_fut)];
    |                                                       -------- ^^^^^^ expected `async` block, found a different `async` block
    |                                                       |
    |                                                       arguments to this function are incorrect
    |
    = note: expected `async` block `{async block@src/main.rs:10:23: 10:33}`
               found `async` block `{async block@src/main.rs:30:22: 30:32}`
    = note: no two async blocks, even if identical, have the same type
    = help: consider pinning your async block and casting it to a trait object
note: associated function defined here
   --&gt; file:///home/.rustup/toolchains/1.82/lib/rustlib/src/rust/library/alloc/src/boxed.rs:255:12
    |
255 |     pub fn new(x: T) -&gt; Self {
    |            ^^^

error[E0277]: `{async block@src/main.rs:10:23: 10:33}` cannot be unpinned
   --&gt; src/main.rs:48:24
    |
48  |         trpl::join_all(futures).await;
    |         -------------- ^^^^^^^ the trait `Unpin` is not implemented for `{async block@src/main.rs:10:23: 10:33}`, which is required by `Box&lt;{async block@src/main.rs:10:23: 10:33}&gt;: Future`
    |         |
    |         required by a bound introduced by this call
    |
    = note: consider using the `pin!` macro
            consider using `Box::pin` if you need to access the pinned value outside of the current scope
    = note: required for `Box&lt;{async block@src/main.rs:10:23: 10:33}&gt;` to implement `Future`
note: required by a bound in `join_all`
   --&gt; file:///home/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/future/join_all.rs:105:14
    |
102 | pub fn join_all&lt;I&gt;(iter: I) -&gt; JoinAll&lt;I::Item&gt;
    |        -------- required by a bound in this function
...
105 |     I::Item: Future,
    |              ^^^^^^ required by this bound in `join_all`

error[E0277]: `{async block@src/main.rs:10:23: 10:33}` cannot be unpinned
  --&gt; src/main.rs:48:9
   |
48 |         trpl::join_all(futures).await;
   |         ^^^^^^^^^^^^^^^^^^^^^^^ the trait `Unpin` is not implemented for `{async block@src/main.rs:10:23: 10:33}`, which is required by `Box&lt;{async block@src/main.rs:10:23: 10:33}&gt;: Future`
   |
   = note: consider using the `pin!` macro
           consider using `Box::pin` if you need to access the pinned value outside of the current scope
   = note: required for `Box&lt;{async block@src/main.rs:10:23: 10:33}&gt;` to implement `Future`
note: required by a bound in `futures_util::future::join_all::JoinAll`
  --&gt; file:///home/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/future/join_all.rs:29:8
   |
27 | pub struct JoinAll&lt;F&gt;
   |            ------- required by a bound in this struct
28 | where
29 |     F: Future,
   |        ^^^^^^ required by this bound in `JoinAll`

error[E0277]: `{async block@src/main.rs:10:23: 10:33}` cannot be unpinned
  --&gt; src/main.rs:48:33
   |
48 |         trpl::join_all(futures).await;
   |                                 ^^^^^ the trait `Unpin` is not implemented for `{async block@src/main.rs:10:23: 10:33}`, which is required by `Box&lt;{async block@src/main.rs:10:23: 10:33}&gt;: Future`
   |
   = note: consider using the `pin!` macro
           consider using `Box::pin` if you need to access the pinned value outside of the current scope
   = note: required for `Box&lt;{async block@src/main.rs:10:23: 10:33}&gt;` to implement `Future`
note: required by a bound in `futures_util::future::join_all::JoinAll`
  --&gt; file:///home/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/future/join_all.rs:29:8
   |
27 | pub struct JoinAll&lt;F&gt;
   |            ------- required by a bound in this struct
28 | where
29 |     F: Future,
   |        ^^^^^^ required by this bound in `JoinAll`
</pre> <p>That is a <em>lot</em> to digest, so let’s pull it apart. The first part of the message tell us that the first async block (<code>src/main.rs:8:23: 20:10</code>) does not implement the <code>Unpin</code> trait and suggests using <code>pin!</code> or <code>Box::pin</code> to resolve it. Later in the chapter, we’ll dig into a few more details about <code>Pin</code> and <code>Unpin</code>. For the moment, though, we can just follow the compiler’s advice to get unstuck. In Listing 17-18, we start by updating the type annotation for <code>futures</code>, with a <code>Pin</code> wrapping each <code>Box</code>. Second, we use <code>Box::pin</code> to pin the futures themselves.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{
    future::Future,
    pin::{pin, Pin},
    time::Duration,
};

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = pin!(async move {
            let vals = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        });

        let rx_fut = pin!(async {
            while let Some(value) = rx.recv().await {
                println!("received '{value}'");
            }
        });

        let tx_fut = pin!(async move {
            let vals = vec![
                String::from("more"),
                String::from("messages"),
                String::from("for"),
                String::from("you"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        });

        let futures: Vec&lt;Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt;&gt;&gt;&gt; =
            vec![Box::pin(tx1_fut), Box::pin(rx_fut), Box::pin(tx_fut)];

        trpl::join_all(futures).await;
    });
}</pre> <figcaption>Listing 17-18: Using <code>Pin</code> and <code>Box::pin</code> to make the <code>Vec</code> type check</figcaption> </figure> <p>If we compile and run this, we finally get the output we hoped for:</p>  <pre>received 'hi'
received 'more'
received 'from'
received 'messages'
received 'the'
received 'for'
received 'future'
received 'you'
</pre> <p>Phew!</p> <p>There’s a bit more to explore here. For one thing, using <code>Pin&lt;Box&lt;T&gt;&gt;</code> adds a small amount of overhead from putting these futures on the heap with <code>Box</code>—and we’re only doing that to get the types to line up. We don’t actually <em>need</em> the heap allocation, after all: these futures are local to this particular function. As noted before, <code>Pin</code> is itself a wrapper type, so we can get the benefit of having a single type in the <code>Vec</code>—the original reason we reached for <code>Box</code>—without doing a heap allocation. We can use <code>Pin</code> directly with each future, using the <code>std::pin::pin</code> macro.</p> <p>However, we must still be explicit about the type of the pinned reference; otherwise, Rust will still not know to interpret these as dynamic trait objects, which is what we need them to be in the <code>Vec</code>. We therefore <code>pin!</code> each future when we define it, and define <code>futures</code> as a <code>Vec</code> containing pinned mutable references to the dynamic future type, as in Listing 17-19.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{
    future::Future,
    pin::{pin, Pin},
    time::Duration,
};

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = pin!(async move {
            // --snip--
            let vals = vec![
                String::from("hi"),
                String::from("from"),
                String::from("the"),
                String::from("future"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        });

        let rx_fut = pin!(async {
            // --snip--
            while let Some(value) = rx.recv().await {
                println!("received '{value}'");
            }
        });

        let tx_fut = pin!(async move {
            // --snip--
            let vals = vec![
                String::from("more"),
                String::from("messages"),
                String::from("for"),
                String::from("you"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_secs(1)).await;
            }
        });

        let futures: Vec&lt;Pin&lt;&amp;mut dyn Future&lt;Output = ()&gt;&gt;&gt; =
            vec![tx1_fut, rx_fut, tx_fut];

        trpl::join_all(futures).await;
    });
}</pre> <figcaption>Listing 17-19: Using <code>Pin</code> directly with the <code>pin!</code> macro to avoid unnecessary heap allocations</figcaption> </figure> <p>We got this far by ignoring the fact that we might have different <code>Output</code> types. For example, in Listing 17-20, the anonymous future for <code>a</code> implements <code>Future&lt;Output = u32&gt;</code>, the anonymous future for <code>b</code> implements <code>Future&lt;Output = &amp;str&gt;</code>, and the anonymous future for <code>c</code> implements <code>Future&lt;Output = bool&gt;</code>.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

fn main() {
    trpl::run(async {
        let a = async { 1u32 };
        let b = async { "Hello!" };
        let c = async { true };

        let (a_result, b_result, c_result) = trpl::join!(a, b, c);
        println!("{a_result}, {b_result}, {c_result}");
    });
}</pre> <figcaption>Listing 17-20: Three futures with distinct types</figcaption> </figure> <p>We can use <code>trpl::join!</code> to await them, because it allows us to pass in multiple future types and produces a tuple of those types. We <em>cannot</em> use <code>trpl::join_all</code>, because it requires all of the futures passed in to have the same type. Remember, that error is what got us started on this adventure with <code>Pin</code>!</p> <p>This is a fundamental tradeoff: we can either deal with a dynamic number of futures with <code>join_all</code>, as long as they all have the same type, or we can deal with a set number of futures with the <code>join</code> functions or the <code>join!</code> macro, even if they have different types. This is the same scenario we’d face when working with any other types in Rust. Futures are not special, even though we have some nice syntax for working with them, and that’s a good thing.</p> <h3 id="racing-futures">Racing Futures</h3> <p>When we “join” futures with the <code>join</code> family of functions and macros, we require <em>all</em> of them to finish before we move on. Sometimes, though, we only need <em>some</em> future from a set to finish before we move on—kind of similar to racing one future against another.</p> <p>In Listing 17-21, we once again use <code>trpl::race</code> to run two futures, <code>slow</code> and <code>fast</code>, against each other.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let slow = async {
            println!("'slow' started.");
            trpl::sleep(Duration::from_millis(100)).await;
            println!("'slow' finished.");
        };

        let fast = async {
            println!("'fast' started.");
            trpl::sleep(Duration::from_millis(50)).await;
            println!("'fast' finished.");
        };

        trpl::race(slow, fast).await;
    });
}</pre> <figcaption>Listing 17-21: Using <code>race</code> to get the result of whichever future finishes first</figcaption> </figure> <p>Each future prints a message when it starts running, pauses for some amount of time by calling and awaiting <code>sleep</code>, and then prints another message when it finishes. Then we pass both <code>slow</code> and <code>fast</code> to <code>trpl::race</code> and wait for one of them to finish. (The outcome here isn’t too surprising: <code>fast</code> wins.) Unlike when we used <code>race</code> back in <a href="ch17-01-futures-and-syntax.html#our-first-async-program">“Our First Async Program”</a>, we just ignore the <code>Either</code> instance it returns here, because all of the interesting behavior happens in the body of the async blocks.</p> <p>Notice that if you flip the order of the arguments to <code>race</code>, the order of the “started” messages changes, even though the <code>fast</code> future always completes first. That’s because the implementation of this particular <code>race</code> function is not fair. It always runs the futures passed in as arguments in the order in which they’re passed. Other implementations <em>are</em> fair and will randomly choose which future to poll first. Regardless of whether the implementation of race we’re using is fair, though, <em>one</em> of the futures will run up to the first <code>await</code> in its body before another task can start.</p> <p>Recall from <a href="ch17-01-futures-and-syntax.html#our-first-async-program">Our First Async Program</a> that at each await point, Rust gives a runtime a chance to pause the task and switch to another one if the future being awaited isn’t ready. The inverse is also true: Rust <em>only</em> pauses async blocks and hands control back to a runtime at an await point. Everything between await points is synchronous.</p> <p>That means if you do a bunch of work in an async block without an await point, that future will block any other futures from making progress. You may sometimes hear this referred to as one future <em>starving</em> other futures. In some cases, that may not be a big deal. However, if you are doing some kind of expensive setup or long-running work, or if you have a future that will keep doing some particular task indefinitely, you’ll need to think about when and where to hand control back to the runtime.</p> <p>By the same token, if you have long-running blocking operations, async can be a useful tool for providing ways for different parts of the program to relate to each other.</p> <p>But <em>how</em> would you hand control back to the runtime in those cases?</p>   <h3 id="yielding-control-to-the-runtime">Yielding Control to the Runtime</h3> <p>Let’s simulate a long-running operation. Listing 17-22 introduces a <code>slow</code> function.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{thread, time::Duration};

fn main() {
    trpl::run(async {
        // We will call `slow` here later
    });
}

fn slow(name: &amp;str, ms: u64) {
    thread::sleep(Duration::from_millis(ms));
    println!("'{name}' ran for {ms}ms");
}</pre> <figcaption>Listing 17-22: Using <code>thread::sleep</code> to simulate slow operations</figcaption> </figure> <p>This code uses <code>std::thread::sleep</code> instead of <code>trpl::sleep</code> so that calling <code>slow</code> will block the current thread for some number of milliseconds. We can use <code>slow</code> to stand in for real-world operations that are both long-running and blocking.</p> <p>In Listing 17-23, we use <code>slow</code> to emulate doing this kind of CPU-bound work in a pair of futures.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{thread, time::Duration};

fn main() {
    trpl::run(async {
        let a = async {
            println!("'a' started.");
            slow("a", 30);
            slow("a", 10);
            slow("a", 20);
            trpl::sleep(Duration::from_millis(50)).await;
            println!("'a' finished.");
        };

        let b = async {
            println!("'b' started.");
            slow("b", 75);
            slow("b", 10);
            slow("b", 15);
            slow("b", 350);
            trpl::sleep(Duration::from_millis(50)).await;
            println!("'b' finished.");
        };

        trpl::race(a, b).await;
    });
}

fn slow(name: &amp;str, ms: u64) {
    thread::sleep(Duration::from_millis(ms));
    println!("'{name}' ran for {ms}ms");
}</pre> <figcaption>Listing 17-23: Using <code>thread::sleep</code> to simulate slow operations</figcaption> </figure> <p>To begin, each future only hands control back to the runtime <em>after</em> carrying out a bunch of slow operations. If you run this code, you will see this output:</p>  <pre>'a' started.
'a' ran for 30ms
'a' ran for 10ms
'a' ran for 20ms
'b' started.
'b' ran for 75ms
'b' ran for 10ms
'b' ran for 15ms
'b' ran for 350ms
'a' finished.
</pre> <p>As with our earlier example, <code>race</code> still finishes as soon as <code>a</code> is done. There’s no interleaving between the two futures, though. The <code>a</code> future does all of its work until the <code>trpl::sleep</code> call is awaited, then the <code>b</code> future does all of its work until its own <code>trpl::sleep</code> call is awaited, and finally the <code>a</code> future completes. To allow both futures to make progress between their slow tasks, we need await points so we can hand control back to the runtime. That means we need something we can await!</p> <p>We can already see this kind of handoff happening in Listing 17-23: if we removed the <code>trpl::sleep</code> at the end of the <code>a</code> future, it would complete without the <code>b</code> future running <em>at all</em>. Let’s try using the <code>sleep</code> function as a starting point for letting operations switch off making progress, as shown in Listing 17-24.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{thread, time::Duration};

fn main() {
    trpl::run(async {
        let one_ms = Duration::from_millis(1);

        let a = async {
            println!("'a' started.");
            slow("a", 30);
            trpl::sleep(one_ms).await;
            slow("a", 10);
            trpl::sleep(one_ms).await;
            slow("a", 20);
            trpl::sleep(one_ms).await;
            println!("'a' finished.");
        };

        let b = async {
            println!("'b' started.");
            slow("b", 75);
            trpl::sleep(one_ms).await;
            slow("b", 10);
            trpl::sleep(one_ms).await;
            slow("b", 15);
            trpl::sleep(one_ms).await;
            slow("b", 35);
            trpl::sleep(one_ms).await;
            println!("'b' finished.");
        };

        trpl::race(a, b).await;
    });
}

fn slow(name: &amp;str, ms: u64) {
    thread::sleep(Duration::from_millis(ms));
    println!("'{name}' ran for {ms}ms");
}</pre> <figcaption>Listing 17-24: Using <code>sleep</code> to let operations switch off making progress</figcaption> </figure> <p>In Listing 17-24, we add <code>trpl::sleep</code> calls with await points between each call to <code>slow</code>. Now the two futures’ work is interleaved:</p>  <pre>'a' started.
'a' ran for 30ms
'b' started.
'b' ran for 75ms
'a' ran for 10ms
'b' ran for 10ms
'a' ran for 20ms
'b' ran for 15ms
'a' finished.
</pre> <p>The <code>a</code> future still runs for a bit before handing off control to <code>b</code>, because it calls <code>slow</code> before ever calling <code>trpl::sleep</code>, but after that the futures swap back and forth each time one of them hits an await point. In this case, we have done that after every call to <code>slow</code>, but we could break up the work in whatever way makes the most sense to us.</p> <p>We don’t really want to <em>sleep</em> here, though: we want to make progress as fast as we can. We just need to hand back control to the runtime. We can do that directly, using the <code>yield_now</code> function. In Listing 17-25, we replace all those <code>sleep</code> calls with <code>yield_now</code>.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{thread, time::Duration};

fn main() {
    trpl::run(async {
        let a = async {
            println!("'a' started.");
            slow("a", 30);
            trpl::yield_now().await;
            slow("a", 10);
            trpl::yield_now().await;
            slow("a", 20);
            trpl::yield_now().await;
            println!("'a' finished.");
        };

        let b = async {
            println!("'b' started.");
            slow("b", 75);
            trpl::yield_now().await;
            slow("b", 10);
            trpl::yield_now().await;
            slow("b", 15);
            trpl::yield_now().await;
            slow("b", 35);
            trpl::yield_now().await;
            println!("'b' finished.");
        };

        trpl::race(a, b).await;
    });
}

fn slow(name: &amp;str, ms: u64) {
    thread::sleep(Duration::from_millis(ms));
    println!("'{name}' ran for {ms}ms");
}</pre> <figcaption>Listing 17-25: Using <code>yield_now</code> to let operations switch off making progress</figcaption> </figure> <p>This code is both clearer about the actual intent and can be significantly faster than using <code>sleep</code>, because timers such as the one used by <code>sleep</code> often have limits on how granular they can be. The version of <code>sleep</code> we are using, for example, will always sleep for at least a millisecond, even if we pass it a <code>Duration</code> of one nanosecond. Again, modern computers are <em>fast</em>: they can do a lot in one millisecond!</p> <p>You can see this for yourself by setting up a little benchmark, such as the one in Listing 17-26. (This isn’t an especially rigorous way to do performance testing, but it suffices to show the difference here.)</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::time::{Duration, Instant};

fn main() {
    trpl::run(async {
        let one_ns = Duration::from_nanos(1);
        let start = Instant::now();
        async {
            for _ in 1..1000 {
                trpl::sleep(one_ns).await;
            }
        }
        .await;
        let time = Instant::now() - start;
        println!(
            "'sleep' version finished after {} seconds.",
            time.as_secs_f32()
        );

        let start = Instant::now();
        async {
            for _ in 1..1000 {
                trpl::yield_now().await;
            }
        }
        .await;
        let time = Instant::now() - start;
        println!(
            "'yield' version finished after {} seconds.",
            time.as_secs_f32()
        );
    });
}</pre> <figcaption>Listing 17-26: Comparing the performance of <code>sleep</code> and <code>yield_now</code></figcaption> </figure> <p>Here, we skip all the status printing, pass a one-nanosecond <code>Duration</code> to <code>trpl::sleep</code>, and let each future run by itself, with no switching between the futures. Then we run for 1,000 iterations and see how long the future using <code>trpl::sleep</code> takes compared to the future using <code>trpl::yield_now</code>.</p> <p>The version with <code>yield_now</code> is <em>way</em> faster!</p> <p>This means that async can be useful even for compute-bound tasks, depending on what else your program is doing, because it provides a useful tool for structuring the relationships between different parts of the program. This is a form of <em>cooperative multitasking</em>, where each future has the power to determine when it hands over control via await points. Each future therefore also has the responsibility to avoid blocking for too long. In some Rust-based embedded operating systems, this is the <em>only</em> kind of multitasking!</p> <p>In real-world code, you won’t usually be alternating function calls with await points on every single line, of course. While yielding control in this way is relatively inexpensive, it’s not free. In many cases, trying to break up a compute-bound task might make it significantly slower, so sometimes it’s better for <em>overall</em> performance to let an operation block briefly. Always measure to see what your code’s actual performance bottlenecks are. The underlying dynamic is important to keep in mind, though, if you <em>are</em> seeing a lot of work happening in serial that you expected to happen concurrently!</p> <h3 id="building-our-own-async-abstractions">Building Our Own Async Abstractions</h3> <p>We can also compose futures together to create new patterns. For example, we can build a <code>timeout</code> function with async building blocks we already have. When we’re done, the result will be another building block we could use to create still more async abstractions.</p> <p>Listing 17-27 shows how we would expect this <code>timeout</code> to work with a slow future.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let slow = async {
            trpl::sleep(Duration::from_millis(100)).await;
            "I finished!"
        };

        match timeout(slow, Duration::from_millis(10)).await {
            Ok(message) =&gt; println!("Succeeded with '{message}'"),
            Err(duration) =&gt; {
                println!("Failed after {} seconds", duration.as_secs())
            }
        }
    });
}</pre> <figcaption>Listing 17-27: Using our imagined <code>timeout</code> to run a slow operation with a time limit</figcaption> </figure> <p>Let’s implement this! To begin, let’s think about the API for <code>timeout</code>:</p> <ul> <li>It needs to be an async function itself so we can await it.</li> <li>Its first parameter should be a future to run. We can make it generic to allow it to work with any future.</li> <li>Its second parameter will be the maximum time to wait. If we use a <code>Duration</code>, that will make it easy to pass along to <code>trpl::sleep</code>.</li> <li>It should return a <code>Result</code>. If the future completes successfully, the <code>Result</code> will be <code>Ok</code> with the value produced by the future. If the timeout elapses first, the <code>Result</code> will be <code>Err</code> with the duration that the timeout waited for.</li> </ul> <p>Listing 17-28 shows this declaration.</p>  <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{future::Future, time::Duration};

fn main() {
    trpl::run(async {
        let slow = async {
            trpl::sleep(Duration::from_secs(5)).await;
            "Finally finished"
        };

        match timeout(slow, Duration::from_millis(10)).await {
            Ok(message) =&gt; println!("Succeeded with '{message}'"),
            Err(duration) =&gt; {
                println!("Failed after {} seconds", duration.as_secs())
            }
        }
    });
}

async fn timeout&lt;F: Future&gt;(
    future_to_try: F,
    max_time: Duration,
) -&gt; Result&lt;F::Output, Duration&gt; {
    // Here is where our implementation will go!
}</pre> <figcaption>Listing 17-28: Defining the signature of <code>timeout</code></figcaption> </figure> <p>That satisfies our goals for the types. Now let’s think about the <em>behavior</em> we need: we want to race the future passed in against the duration. We can use <code>trpl::sleep</code> to make a timer future from the duration, and use <code>trpl::race</code> to run that timer with the future the caller passes in.</p> <p>We also know that <code>race</code> is not fair, polling arguments in the order in which they are passed. Thus, we pass <code>future_to_try</code> to <code>race</code> first so it gets a chance to complete even if <code>max_time</code> is a very short duration. If <code>future_to_try</code> finishes first, <code>race</code> will return <code>Left</code> with the output from <code>future_to_try</code>. If <code>timer</code> finishes first, <code>race</code> will return <code>Right</code> with the timer’s output of <code>()</code>.</p> <p>In Listing 17-29, we match on the result of awaiting <code>trpl::race</code>.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">extern crate trpl; // required for mdbook test

use std::{future::Future, time::Duration};

use trpl::Either;

// --snip--

fn main() {
    trpl::run(async {
        let slow = async {
            trpl::sleep(Duration::from_secs(5)).await;
            "Finally finished"
        };

        match timeout(slow, Duration::from_secs(2)).await {
            Ok(message) =&gt; println!("Succeeded with '{message}'"),
            Err(duration) =&gt; {
                println!("Failed after {} seconds", duration.as_secs())
            }
        }
    });
}

async fn timeout&lt;F: Future&gt;(
    future_to_try: F,
    max_time: Duration,
) -&gt; Result&lt;F::Output, Duration&gt; {
    match trpl::race(future_to_try, trpl::sleep(max_time)).await {
        Either::Left(output) =&gt; Ok(output),
        Either::Right(_) =&gt; Err(max_time),
    }
}</pre> <figcaption>Listing 17-29: Defining <code>timeout</code> with <code>race</code> and <code>sleep</code></figcaption> </figure> <p>If the <code>future_to_try</code> succeeds and we get a <code>Left(output)</code>, we return <code>Ok(output)</code>. If the sleep timer elapses instead and we get a <code>Right(())</code>, we ignore the <code>()</code> with <code>_</code> and return <code>Err(max_time)</code> instead.</p> <p>With that, we have a working <code>timeout</code> built out of two other async helpers. If we run our code, it will print the failure mode after the timeout:</p> <pre>Failed after 2 seconds
</pre> <p>Because futures compose with other futures, you can build really powerful tools using smaller async building blocks. For example, you can use this same approach to combine timeouts with retries, and in turn use those with operations such as network calls (one of the examples from the beginning of the chapter).</p> <p>In practice, you’ll usually work directly with <code>async</code> and <code>await</code>, and secondarily with functions and macros such as <code>join</code>, <code>join_all</code>, <code>race</code>, and so on. You’ll only need to reach for <code>pin</code> now and again to use futures with those APIs.</p> <p>We’ve now seen a number of ways to work with multiple futures at the same time. Up next, we’ll look at how we can work with multiple futures in a sequence over time with <em>streams</em>. Here are a couple more things you might want to consider first, though:</p> <ul> <li> <p>We used a <code>Vec</code> with <code>join_all</code> to wait for all of the futures in some group to finish. How could you use a <code>Vec</code> to process a group of futures in sequence instead? What are the tradeoffs of doing that?</p> </li> <li> <p>Take a look at the <code>futures::stream::FuturesUnordered</code> type from the <code>futures</code> crate. How would using it be different from using a <code>Vec</code>? (Don’t worry about the fact that it’s from the <code>stream</code> part of the crate; it works just fine with any collection of futures.)</p> </li> </ul><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2010 The Rust Project Developers<br>Licensed under the Apache License, Version 2.0 or the MIT license, at your option.<br>
    <a href="https://doc.rust-lang.org/book/ch17-03-more-futures.html" class="_attribution-link">https://doc.rust-lang.org/book/ch17-03-more-futures.html</a>
  </p>
</div>
