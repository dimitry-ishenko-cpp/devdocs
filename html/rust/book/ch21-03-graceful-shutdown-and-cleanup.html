<h1 id="graceful-shutdown-and-cleanup">Graceful Shutdown and Cleanup</h1> <p>The code in Listing 21-20 is responding to requests asynchronously through the use of a thread pool, as we intended. We get some warnings about the <code>workers</code>, <code>id</code>, and <code>thread</code> fields that we’re not using in a direct way that reminds us we’re not cleaning up anything. When we use the less elegant <kbd>ctrl</kbd>-<kbd>c</kbd> method to halt the main thread, all other threads are stopped immediately as well, even if they’re in the middle of serving a request.</p> <p>Next, then, we’ll implement the <code>Drop</code> trait to call <code>join</code> on each of the threads in the pool so they can finish the requests they’re working on before closing. Then we’ll implement a way to tell the threads they should stop accepting new requests and shut down. To see this code in action, we’ll modify our server to accept only two requests before gracefully shutting down its thread pool.</p> <p>One thing to notice as we go: none of this affects the parts of the code that handle executing the closures, so everything here would be just the same if we were using a thread pool for an async runtime.</p> <h3 id="implementing-the-drop-trait-on-threadpool">Implementing the <code id="">Drop</code> Trait on <code>ThreadPool</code>
</h3> <p>Let’s start with implementing <code>Drop</code> on our thread pool. When the pool is dropped, our threads should all join to make sure they finish their work. Listing 21-22 shows a first attempt at a <code>Drop</code> implementation; this code won’t quite work yet.</p> <figure class="listing"> <span class="file-name">Filename: src/lib.rs</span> <pre data-language="rust">use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: mpsc::Sender&lt;Job&gt;,
}

type Job = Box&lt;dyn FnOnce() + Send + 'static&gt;;

impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -&gt; ThreadPool {
        assert!(size &gt; 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&amp;receiver)));
        }

        ThreadPool { workers, sender }
    }

    pub fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&amp;mut self) {
        for worker in &amp;mut self.workers {
            println!("Shutting down worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle&lt;()&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;) -&gt; Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} got a job; executing.");

            job();
        });

        Worker { id, thread }
    }
}</pre> <figcaption>Listing 21-22: Joining each thread when the thread pool goes out of scope</figcaption> </figure> <p>First, we loop through each of the thread pool <code>workers</code>. We use <code>&amp;mut</code> for this because <code>self</code> is a mutable reference, and we also need to be able to mutate <code>worker</code>. For each worker, we print a message saying that this particular worker is shutting down, and then we call <code>join</code> on that worker’s thread. If the call to <code>join</code> fails, we use <code>unwrap</code> to make Rust panic and go into an ungraceful shutdown.</p> <p>Here is the error we get when we compile this code:</p> <pre>$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0507]: cannot move out of `worker.thread` which is behind a mutable reference
    --&gt; src/lib.rs:52:13
     |
52   |             worker.thread.join().unwrap();
     |             ^^^^^^^^^^^^^ ------ `worker.thread` moved due to this method call
     |             |
     |             move occurs because `worker.thread` has type `JoinHandle&lt;()&gt;`, which does not implement the `Copy` trait
     |
note: `JoinHandle::&lt;T&gt;::join` takes ownership of the receiver `self`, which moves `worker.thread`
    --&gt; file:///home/.rustup/toolchains/1.82/lib/rustlib/src/rust/library/std/src/thread/mod.rs:1763:17
     |
1763 |     pub fn join(self) -&gt; Result&lt;T&gt; {
     |                 ^^^^

For more information about this error, try `rustc --explain E0507`.
error: could not compile `hello` (lib) due to 1 previous error
</pre> <p>The error tells us we can’t call <code>join</code> because we only have a mutable borrow of each <code>worker</code> and <code>join</code> takes ownership of its argument. To solve this issue, we need to move the thread out of the <code>Worker</code> instance that owns <code>thread</code> so <code>join</code> can consume the thread. One way to do this is by taking the same approach we did in Listing 18-15. If <code>Worker</code> held an <code>Option&lt;thread::JoinHandle&lt;()&gt;&gt;</code>, we could call the <code>take</code> method on the <code>Option</code> to move the value out of the <code>Some</code> variant and leave a <code>None</code> variant in its place. In other words, a <code>Worker</code> that is running would have a <code>Some</code> variant in <code>thread</code>, and when we wanted to clean up a <code>Worker</code>, we would replace <code>Some</code> with <code>None</code> so the <code>Worker</code> doesn’t have a thread to run.</p> <p>However, the <em>only</em> time this would come up would be when dropping the <code>Worker</code>. In exchange, we would have to deal with an <code>Option&lt;thread::JoinHandle&lt;()&gt;&gt;</code> everywhere we access <code>worker.thread</code>. Idiomatic Rust uses <code>Option</code> quite a bit, but when you find yourself wrapping something in <code>Option</code> as a workaround even though you know the item will always be present, it is a good idea to look for alternative approaches. They can make your code cleaner and less error-prone.</p> <p>In this case, there is a better alternative: the <code>Vec::drain</code> method. It accepts a range parameter to specify which items to remove from the <code>Vec</code>, and returns an iterator of those items. Passing the <code>..</code> range syntax will remove <em>every</em> value from the <code>Vec</code>.</p> <p>So we need to update the <code>ThreadPool</code> <code>drop</code> implementation like this:</p> <figure class="listing"> <span class="file-name">Filename: src/lib.rs</span> <pre data-language="rust">#![allow(unused)]
fn main() {
use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: mpsc::Sender&lt;Job&gt;,
}

type Job = Box&lt;dyn FnOnce() + Send + 'static&gt;;

impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -&gt; ThreadPool {
        assert!(size &gt; 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&amp;receiver)));
        }

        ThreadPool { workers, sender }
    }

    pub fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&amp;mut self) {
        for worker in self.workers.drain(..) {
            println!("Shutting down worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle&lt;()&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;) -&gt; Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} got a job; executing.");

            job();
        });

        Worker { id, thread }
    }
}
}</pre> </figure> <p>This resolves the compiler error and does not require any other changes to our code.</p> <h3 id="signaling-to-the-threads-to-stop-listening-for-jobs">Signaling to the Threads to Stop Listening for Jobs</h3> <p>With all the changes we’ve made, our code compiles without any warnings. However, the bad news is this code doesn’t function the way we want it to yet. The key is the logic in the closures run by the threads of the <code>Worker</code> instances: at the moment, we call <code>join</code>, but that won’t shut down the threads because they <code>loop</code> forever looking for jobs. If we try to drop our <code>ThreadPool</code> with our current implementation of <code>drop</code>, the main thread will block forever waiting for the first thread to finish.</p> <p>To fix this problem, we’ll need a change in the <code>ThreadPool</code> <code>drop</code> implementation and then a change in the <code>Worker</code> loop.</p> <p>First, we’ll change the <code>ThreadPool</code> <code>drop</code> implementation to explicitly drop the <code>sender</code> before waiting for the threads to finish. Listing 21-23 shows the changes to <code>ThreadPool</code> to explicitly drop <code>sender</code>. Unlike with the <code>workers</code>, here we <em>do</em> need to use an <code>Option</code> to be able to move <code>sender</code> out of <code>ThreadPool</code> with <code>Option::take</code>.</p> <figure class="listing"> <span class="file-name">Filename: src/lib.rs</span> <pre data-language="rust">use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: Option&lt;mpsc::Sender&lt;Job&gt;&gt;,
}
// --snip--

type Job = Box&lt;dyn FnOnce() + Send + 'static&gt;;

impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -&gt; ThreadPool {
        // --snip--

        assert!(size &gt; 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&amp;receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&amp;mut self) {
        drop(self.sender.take());

        for worker in self.workers.drain(..) {
            println!("Shutting down worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle&lt;()&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;) -&gt; Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} got a job; executing.");

            job();
        });

        Worker { id, thread }
    }
}</pre> <figcaption>Listing 21-23: Explicitly drop <code>sender</code> before joining the worker threads</figcaption> </figure> <p>Dropping <code>sender</code> closes the channel, which indicates no more messages will be sent. When that happens, all the calls to <code>recv</code> that the workers do in the infinite loop will return an error. In Listing 21-24, we change the <code>Worker</code> loop to gracefully exit the loop in that case, which means the threads will finish when the <code>ThreadPool</code> <code>drop</code> implementation calls <code>join</code> on them.</p> <figure class="listing"> <span class="file-name">Filename: src/lib.rs</span> <pre data-language="rust">use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: Option&lt;mpsc::Sender&lt;Job&gt;&gt;,
}

type Job = Box&lt;dyn FnOnce() + Send + 'static&gt;;

impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -&gt; ThreadPool {
        assert!(size &gt; 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&amp;receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&amp;mut self) {
        drop(self.sender.take());

        for worker in self.workers.drain(..) {
            println!("Shutting down worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle&lt;()&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;) -&gt; Worker {
        let thread = thread::spawn(move || loop {
            let message = receiver.lock().unwrap().recv();

            match message {
                Ok(job) =&gt; {
                    println!("Worker {id} got a job; executing.");

                    job();
                }
                Err(_) =&gt; {
                    println!("Worker {id} disconnected; shutting down.");
                    break;
                }
            }
        });

        Worker { id, thread }
    }
}</pre> <figcaption>Listing 21-24: Explicitly break out of the loop when <code>recv</code> returns an error</figcaption> </figure> <p>To see this code in action, let’s modify <code>main</code> to accept only two requests before gracefully shutting down the server, as shown in Listing 21-25.</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">use hello::ThreadPool;
use std::{
    fs,
    io::{prelude::*, BufReader},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};

fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("Shutting down.");
}

fn handle_connection(mut stream: TcpStream) {
    let buf_reader = BufReader::new(&amp;stream);
    let request_line = buf_reader.lines().next().unwrap().unwrap();

    let (status_line, filename) = match &amp;request_line[..] {
        "GET / HTTP/1.1" =&gt; ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" =&gt; {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ =&gt; ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    let contents = fs::read_to_string(filename).unwrap();
    let length = contents.len();

    let response =
        format!("{status_line}\r\nContent-Length: {length}\r\n\r\n{contents}");

    stream.write_all(response.as_bytes()).unwrap();
}</pre> <figcaption>Listing 21-25: Shut down the server after serving two requests by exiting the loop</figcaption> </figure> <p>You wouldn’t want a real-world web server to shut down after serving only two requests. This code just demonstrates that the graceful shutdown and cleanup is in working order.</p> <p>The <code>take</code> method is defined in the <code>Iterator</code> trait and limits the iteration to the first two items at most. The <code>ThreadPool</code> will go out of scope at the end of <code>main</code>, and the <code>drop</code> implementation will run.</p> <p>Start the server with <code>cargo run</code>, and make three requests. The third request should error, and in your terminal you should see output similar to this:</p>  <pre>$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.41s
     Running `target/debug/hello`
Worker 0 got a job; executing.
Shutting down.
Shutting down worker 0
Worker 3 got a job; executing.
Worker 1 disconnected; shutting down.
Worker 2 disconnected; shutting down.
Worker 3 disconnected; shutting down.
Worker 0 disconnected; shutting down.
Shutting down worker 1
Shutting down worker 2
Shutting down worker 3
</pre> <p>You might see a different ordering of workers and messages printed. We can see how this code works from the messages: workers 0 and 3 got the first two requests. The server stopped accepting connections after the second connection, and the <code>Drop</code> implementation on <code>ThreadPool</code> starts executing before worker 3 even starts its job. Dropping the <code>sender</code> disconnects all the workers and tells them to shut down. The workers each print a message when they disconnect, and then the thread pool calls <code>join</code> to wait for each worker thread to finish.</p> <p>Notice one interesting aspect of this particular execution: the <code>ThreadPool</code> dropped the <code>sender</code>, and before any worker received an error, we tried to join worker 0. Worker 0 had not yet gotten an error from <code>recv</code>, so the main thread blocked waiting for worker 0 to finish. In the meantime, worker 3 received a job and then all threads received an error. When worker 0 finished, the main thread waited for the rest of the workers to finish. At that point, they had all exited their loops and stopped.</p> <p>Congrats! We’ve now completed our project; we have a basic web server that uses a thread pool to respond asynchronously. We’re able to perform a graceful shutdown of the server, which cleans up all the threads in the pool.</p> <p>Here’s the full code for reference:</p> <figure class="listing"> <span class="file-name">Filename: src/main.rs</span> <pre data-language="rust">use hello::ThreadPool;
use std::{
    fs,
    io::{prelude::*, BufReader},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};

fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("Shutting down.");
}

fn handle_connection(mut stream: TcpStream) {
    let buf_reader = BufReader::new(&amp;stream);
    let request_line = buf_reader.lines().next().unwrap().unwrap();

    let (status_line, filename) = match &amp;request_line[..] {
        "GET / HTTP/1.1" =&gt; ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" =&gt; {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ =&gt; ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    let contents = fs::read_to_string(filename).unwrap();
    let length = contents.len();

    let response =
        format!("{status_line}\r\nContent-Length: {length}\r\n\r\n{contents}");

    stream.write_all(response.as_bytes()).unwrap();
}</pre> </figure> <figure class="listing"> <span class="file-name">Filename: src/lib.rs</span> <pre data-language="rust">use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: Option&lt;mpsc::Sender&lt;Job&gt;&gt;,
}

type Job = Box&lt;dyn FnOnce() + Send + 'static&gt;;

impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -&gt; ThreadPool {
        assert!(size &gt; 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&amp;receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&amp;mut self) {
        drop(self.sender.take());

        for worker in &amp;mut self.workers {
            println!("Shutting down worker {}", worker.id);

            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}

struct Worker {
    id: usize,
    thread: Option&lt;thread::JoinHandle&lt;()&gt;&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;) -&gt; Worker {
        let thread = thread::spawn(move || loop {
            let message = receiver.lock().unwrap().recv();

            match message {
                Ok(job) =&gt; {
                    println!("Worker {id} got a job; executing.");

                    job();
                }
                Err(_) =&gt; {
                    println!("Worker {id} disconnected; shutting down.");
                    break;
                }
            }
        });

        Worker {
            id,
            thread: Some(thread),
        }
    }
}</pre> </figure> <p>We could do more here! If you want to continue enhancing this project, here are some ideas:</p> <ul> <li>Add more documentation to <code>ThreadPool</code> and its public methods.</li> <li>Add tests of the library’s functionality.</li> <li>Change calls to <code>unwrap</code> to more robust error handling.</li> <li>Use <code>ThreadPool</code> to perform some task other than serving web requests.</li> <li>Find a thread pool crate on <a href="https://crates.io/">crates.io</a> and implement a similar web server using the crate instead. Then compare its API and robustness to the thread pool we implemented.</li> </ul> <h2 id="summary">Summary</h2> <p>Well done! You’ve made it to the end of the book! We want to thank you for joining us on this tour of Rust. You’re now ready to implement your own Rust projects and help with other peoples’ projects. Keep in mind that there is a welcoming community of other Rustaceans who would love to help you with any challenges you encounter on your Rust journey.</p><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2010 The Rust Project Developers<br>Licensed under the Apache License, Version 2.0 or the MIT license, at your option.<br>
    <a href="https://doc.rust-lang.org/book/ch21-03-graceful-shutdown-and-cleanup.html" class="_attribution-link">https://doc.rust-lang.org/book/ch21-03-graceful-shutdown-and-cleanup.html</a>
  </p>
</div>
