<h1 class="devsite-page-title">Module: tf.compat.v1</h1> <devsite-bookmark></devsite-bookmark>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>   <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/_api/v2/compat/v1/__init__.py">  View source on GitHub </a> </td> </table> <p>Bring in all of the public TensorFlow interface into this module.</p> <h2 id="modules" data-text="Modules">Modules</h2> <p><a href="v1/app.html"><code translate="no" dir="ltr">app</code></a> module: Generic entry point script.</p> <p><a href="v1/audio.html"><code translate="no" dir="ltr">audio</code></a> module: Public API for tf.audio namespace.</p> <p><a href="v1/autograph.html"><code translate="no" dir="ltr">autograph</code></a> module: Conversion of eager-style Python into TensorFlow graph code.</p> <p><a href="v1/bitwise.html"><code translate="no" dir="ltr">bitwise</code></a> module: Operations for manipulating the binary representations of integers.</p> <p><a href="v1/compat.html"><code translate="no" dir="ltr">compat</code></a> module: Compatibility functions.</p> <p><a href="v1/config.html"><code translate="no" dir="ltr">config</code></a> module: Public API for tf.config namespace.</p> <p><a href="v1/data.html"><code translate="no" dir="ltr">data</code></a> module: <a href="../data/dataset.html"><code translate="no" dir="ltr">tf.data.Dataset</code></a> API for input pipelines.</p> <p><a href="v1/debugging.html"><code translate="no" dir="ltr">debugging</code></a> module: Public API for tf.debugging namespace.</p> <p><a href="v1/distribute.html"><code translate="no" dir="ltr">distribute</code></a> module: Library for running a computation across multiple devices.</p> <p><a href="v1/distributions.html"><code translate="no" dir="ltr">distributions</code></a> module: Core module for TensorFlow distribution objects and helpers.</p> <p><a href="v1/dtypes.html"><code translate="no" dir="ltr">dtypes</code></a> module: Public API for tf.dtypes namespace.</p> <p><a href="v1/errors.html"><code translate="no" dir="ltr">errors</code></a> module: Exception types for TensorFlow errors.</p> <p><a href="v1/estimator.html"><code translate="no" dir="ltr">estimator</code></a> module: Estimator: High level tools for working with models.</p> <p><a href="v1/experimental.html"><code translate="no" dir="ltr">experimental</code></a> module: Public API for tf.experimental namespace.</p> <p><a href="v1/feature_column.html"><code translate="no" dir="ltr">feature_column</code></a> module: Public API for tf.feature_column namespace.</p> <p><a href="v1/flags.html"><code translate="no" dir="ltr">flags</code></a> module: Import router for absl.flags. See <a href="https://github.com/abseil/abseil-py">https://github.com/abseil/abseil-py</a></p> <p><a href="v1/gfile.html"><code translate="no" dir="ltr">gfile</code></a> module: Import router for file_io.</p> <p><a href="v1/graph_util.html"><code translate="no" dir="ltr">graph_util</code></a> module: Helpers to manipulate a tensor graph in python.</p> <p><a href="v1/image.html"><code translate="no" dir="ltr">image</code></a> module: Image ops.</p> <p><a href="v1/initializers.html"><code translate="no" dir="ltr">initializers</code></a> module: Public API for tf.initializers namespace.</p> <p><a href="v1/io.html"><code translate="no" dir="ltr">io</code></a> module: Public API for tf.io namespace.</p> <p><a href="v1/keras.html"><code translate="no" dir="ltr">keras</code></a> module: Implementation of the Keras API, the high-level API of TensorFlow.</p> <p><a href="v1/layers.html"><code translate="no" dir="ltr">layers</code></a> module: Public API for tf.keras.<strong>internal</strong>.legacy.layers namespace.</p> <p><a href="v1/linalg.html"><code translate="no" dir="ltr">linalg</code></a> module: Operations for linear algebra.</p> <p><a href="v1/lite.html"><code translate="no" dir="ltr">lite</code></a> module: Public API for tf.lite namespace.</p> <p><a href="v1/logging.html"><code translate="no" dir="ltr">logging</code></a> module: Logging and Summary Operations.</p> <p><a href="v1/lookup.html"><code translate="no" dir="ltr">lookup</code></a> module: Public API for tf.lookup namespace.</p> <p><a href="v1/losses.html"><code translate="no" dir="ltr">losses</code></a> module: Loss operations for use in neural networks.</p> <p><a href="v1/manip.html"><code translate="no" dir="ltr">manip</code></a> module: Operators for manipulating tensors.</p> <p><a href="v1/math.html"><code translate="no" dir="ltr">math</code></a> module: Math Operations.</p> <p><a href="v1/metrics.html"><code translate="no" dir="ltr">metrics</code></a> module: Evaluation-related metrics.</p> <p><a href="v1/mixed_precision.html"><code translate="no" dir="ltr">mixed_precision</code></a> module: Public API for tf.mixed_precision namespace.</p> <p><a href="v1/mlir.html"><code translate="no" dir="ltr">mlir</code></a> module: Public API for tf.mlir namespace.</p> <p><a href="v1/nest.html"><code translate="no" dir="ltr">nest</code></a> module: Functions that work with structures.</p> <p><a href="v1/nn.html"><code translate="no" dir="ltr">nn</code></a> module: Primitive Neural Net (NN) Operations.</p> <p><a href="v1/profiler.html"><code translate="no" dir="ltr">profiler</code></a> module: Public API for tf.profiler namespace.</p> <p><a href="v1/python_io.html"><code translate="no" dir="ltr">python_io</code></a> module: Python functions for directly manipulating TFRecord-formatted files.</p> <p><a href="v1/quantization.html"><code translate="no" dir="ltr">quantization</code></a> module: Public API for tf.quantization namespace.</p> <p><a href="v1/queue.html"><code translate="no" dir="ltr">queue</code></a> module: Public API for tf.queue namespace.</p> <p><a href="v1/ragged.html"><code translate="no" dir="ltr">ragged</code></a> module: Ragged Tensors.</p> <p><a href="v1/random.html"><code translate="no" dir="ltr">random</code></a> module: Public API for tf.random namespace.</p> <p><a href="v1/raw_ops.html"><code translate="no" dir="ltr">raw_ops</code></a> module: Public API for tf.raw_ops namespace.</p> <p><a href="v1/resource_loader.html"><code translate="no" dir="ltr">resource_loader</code></a> module: Resource management library.</p> <p><a href="v1/saved_model.html"><code translate="no" dir="ltr">saved_model</code></a> module: Public API for tf.saved_model namespace.</p> <p><a href="v1/sets.html"><code translate="no" dir="ltr">sets</code></a> module: Tensorflow set operations.</p> <p><a href="v1/signal.html"><code translate="no" dir="ltr">signal</code></a> module: Signal processing operations.</p> <p><a href="v1/sparse.html"><code translate="no" dir="ltr">sparse</code></a> module: Sparse Tensor Representation.</p> <p><a href="v1/spectral.html"><code translate="no" dir="ltr">spectral</code></a> module: Public API for tf.spectral namespace.</p> <p><a href="v1/strings.html"><code translate="no" dir="ltr">strings</code></a> module: Operations for working with string Tensors.</p> <p><a href="v1/summary.html"><code translate="no" dir="ltr">summary</code></a> module: Operations for writing summary data, for use in analysis and visualization.</p> <p><a href="v1/sysconfig.html"><code translate="no" dir="ltr">sysconfig</code></a> module: System configuration library.</p> <p><a href="v1/test.html"><code translate="no" dir="ltr">test</code></a> module: Testing.</p> <p><a href="v1/tpu.html"><code translate="no" dir="ltr">tpu</code></a> module: Ops related to Tensor Processing Units.</p> <p><a href="v1/train.html"><code translate="no" dir="ltr">train</code></a> module: Support for training models.</p> <p><a href="v1/types.html"><code translate="no" dir="ltr">types</code></a> module: Public TensorFlow type definitions.</p> <p><a href="v1/user_ops.html"><code translate="no" dir="ltr">user_ops</code></a> module: Public API for tf.user_ops namespace.</p> <p><a href="v1/version.html"><code translate="no" dir="ltr">version</code></a> module: Public API for tf.version namespace.</p> <p><a href="v1/xla.html"><code translate="no" dir="ltr">xla</code></a> module: Public API for tf.xla namespace.</p> <h2 id="classes" data-text="Classes">Classes</h2> <p><a href="../aggregationmethod.html"><code translate="no" dir="ltr">class AggregationMethod</code></a>: A class listing aggregation methods used to combine gradients.</p> <p><a href="v1/attrvalue.html"><code translate="no" dir="ltr">class AttrValue</code></a>: A ProtocolMessage</p> <p><a href="v1/conditionalaccumulator.html"><code translate="no" dir="ltr">class ConditionalAccumulator</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="v1/conditionalaccumulatorbase.html"><code translate="no" dir="ltr">class ConditionalAccumulatorBase</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="v1/configproto.html"><code translate="no" dir="ltr">class ConfigProto</code></a>: A ProtocolMessage</p> <p><a href="../criticalsection.html"><code translate="no" dir="ltr">class CriticalSection</code></a>: Critical section.</p> <p><a href="../dtypes/dtype.html"><code translate="no" dir="ltr">class DType</code></a>: Represents the type of the elements in a <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="v1/devicespec.html"><code translate="no" dir="ltr">class DeviceSpec</code></a>: Represents a (possibly partial) specification for a TensorFlow device.</p> <p><a href="v1/dimension.html"><code translate="no" dir="ltr">class Dimension</code></a>: Represents the value of one dimension in a TensorShape.</p> <p><a href="v1/event.html"><code translate="no" dir="ltr">class Event</code></a>: A ProtocolMessage</p> <p><a href="../queue/fifoqueue.html"><code translate="no" dir="ltr">class FIFOQueue</code></a>: A queue implementation that dequeues elements in first-in first-out order.</p> <p><a href="../io/fixedlenfeature.html"><code translate="no" dir="ltr">class FixedLenFeature</code></a>: Configuration for parsing a fixed-length input feature.</p> <p><a href="../io/fixedlensequencefeature.html"><code translate="no" dir="ltr">class FixedLenSequenceFeature</code></a>: Configuration for parsing a variable-length input feature into a <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="v1/fixedlengthrecordreader.html"><code translate="no" dir="ltr">class FixedLengthRecordReader</code></a>: A Reader that outputs fixed-length records from a file.</p> <p><a href="v1/gpuoptions.html"><code translate="no" dir="ltr">class GPUOptions</code></a>: A ProtocolMessage</p> <p><a href="../gradienttape.html"><code translate="no" dir="ltr">class GradientTape</code></a>: Record operations for automatic differentiation.</p> <p><a href="../graph.html"><code translate="no" dir="ltr">class Graph</code></a>: A TensorFlow computation, represented as a dataflow graph.</p> <p><a href="v1/graphdef.html"><code translate="no" dir="ltr">class GraphDef</code></a>: A protobuf containing the graph of operations.</p> <p><a href="v1/graphkeys.html"><code translate="no" dir="ltr">class GraphKeys</code></a>: Standard names to use for graph collections.</p> <p><a href="v1/graphoptions.html"><code translate="no" dir="ltr">class GraphOptions</code></a>: A ProtocolMessage</p> <p><a href="v1/histogramproto.html"><code translate="no" dir="ltr">class HistogramProto</code></a>: A ProtocolMessage</p> <p><a href="v1/identityreader.html"><code translate="no" dir="ltr">class IdentityReader</code></a>: A Reader that outputs the queued work as both the key and value.</p> <p><a href="../indexedslices.html"><code translate="no" dir="ltr">class IndexedSlices</code></a>: A sparse representation of a set of tensor slices at given indices.</p> <p><a href="../indexedslicesspec.html"><code translate="no" dir="ltr">class IndexedSlicesSpec</code></a>: Type specification for a <a href="../indexedslices.html"><code translate="no" dir="ltr">tf.IndexedSlices</code></a>.</p> <p><a href="v1/interactivesession.html"><code translate="no" dir="ltr">class InteractiveSession</code></a>: A TensorFlow <code translate="no" dir="ltr">Session</code> for use in interactive contexts, such as a shell.</p> <p><a href="v1/lmdbreader.html"><code translate="no" dir="ltr">class LMDBReader</code></a>: A Reader that outputs the records from a LMDB file.</p> <p><a href="v1/logmessage.html"><code translate="no" dir="ltr">class LogMessage</code></a>: A ProtocolMessage</p> <p><a href="v1/metagraphdef.html"><code translate="no" dir="ltr">class MetaGraphDef</code></a>: A ProtocolMessage</p> <p><a href="../module.html"><code translate="no" dir="ltr">class Module</code></a>: Base neural network module class.</p> <p><a href="v1/nameattrlist.html"><code translate="no" dir="ltr">class NameAttrList</code></a>: A ProtocolMessage</p> <p><a href="v1/nodedef.html"><code translate="no" dir="ltr">class NodeDef</code></a>: A ProtocolMessage</p> <p><a href="../errors/operror.html"><code translate="no" dir="ltr">class OpError</code></a>: The base class for TensorFlow exceptions.</p> <p><a href="../operation.html"><code translate="no" dir="ltr">class Operation</code></a>: Represents a graph node that performs computation on tensors.</p> <p><a href="v1/optimizeroptions.html"><code translate="no" dir="ltr">class OptimizerOptions</code></a>: A ProtocolMessage</p> <p><a href="../optionalspec.html"><code translate="no" dir="ltr">class OptionalSpec</code></a>: Type specification for <a href="../experimental/optional.html"><code translate="no" dir="ltr">tf.experimental.Optional</code></a>.</p> <p><a href="../queue/paddingfifoqueue.html"><code translate="no" dir="ltr">class PaddingFIFOQueue</code></a>: A FIFOQueue that supports batching variable-sized tensors by padding.</p> <p><a href="../queue/priorityqueue.html"><code translate="no" dir="ltr">class PriorityQueue</code></a>: A queue implementation that dequeues elements in prioritized order.</p> <p><a href="../queue/queuebase.html"><code translate="no" dir="ltr">class QueueBase</code></a>: Base class for queue implementations.</p> <p><a href="../raggedtensor.html"><code translate="no" dir="ltr">class RaggedTensor</code></a>: Represents a ragged tensor.</p> <p><a href="../raggedtensorspec.html"><code translate="no" dir="ltr">class RaggedTensorSpec</code></a>: Type specification for a <a href="../raggedtensor.html"><code translate="no" dir="ltr">tf.RaggedTensor</code></a>.</p> <p><a href="../queue/randomshufflequeue.html"><code translate="no" dir="ltr">class RandomShuffleQueue</code></a>: A queue implementation that dequeues elements in a random order.</p> <p><a href="v1/readerbase.html"><code translate="no" dir="ltr">class ReaderBase</code></a>: Base class for different Reader types, that produce a record every step.</p> <p><a href="../registergradient.html"><code translate="no" dir="ltr">class RegisterGradient</code></a>: A decorator for registering the gradient function for an op type.</p> <p><a href="v1/runmetadata.html"><code translate="no" dir="ltr">class RunMetadata</code></a>: A ProtocolMessage</p> <p><a href="v1/runoptions.html"><code translate="no" dir="ltr">class RunOptions</code></a>: A ProtocolMessage</p> <p><a href="v1/session.html"><code translate="no" dir="ltr">class Session</code></a>: A class for running TensorFlow operations.</p> <p><a href="v1/sessionlog.html"><code translate="no" dir="ltr">class SessionLog</code></a>: A ProtocolMessage</p> <p><a href="v1/sparseconditionalaccumulator.html"><code translate="no" dir="ltr">class SparseConditionalAccumulator</code></a>: A conditional accumulator for aggregating sparse gradients.</p> <p><a href="../io/sparsefeature.html"><code translate="no" dir="ltr">class SparseFeature</code></a>: Configuration for parsing a sparse input feature from an <code translate="no" dir="ltr">Example</code>.</p> <p><a href="../sparse/sparsetensor.html"><code translate="no" dir="ltr">class SparseTensor</code></a>: Represents a sparse tensor.</p> <p><a href="../sparsetensorspec.html"><code translate="no" dir="ltr">class SparseTensorSpec</code></a>: Type specification for a <a href="../sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a>.</p> <p><a href="v1/sparsetensorvalue.html"><code translate="no" dir="ltr">class SparseTensorValue</code></a>: SparseTensorValue(indices, values, dense_shape)</p> <p><a href="v1/summary.html"><code translate="no" dir="ltr">class Summary</code></a>: A ProtocolMessage</p> <p><a href="v1/summarymetadata.html"><code translate="no" dir="ltr">class SummaryMetadata</code></a>: A ProtocolMessage</p> <p><a href="v1/tfrecordreader.html"><code translate="no" dir="ltr">class TFRecordReader</code></a>: A Reader that outputs the records from a TFRecords file.</p> <p><a href="../tensor.html"><code translate="no" dir="ltr">class Tensor</code></a>: A <a href="../tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> represents a multidimensional array of elements.</p> <p><a href="../tensorarray.html"><code translate="no" dir="ltr">class TensorArray</code></a>: Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.</p> <p><a href="../tensorarrayspec.html"><code translate="no" dir="ltr">class TensorArraySpec</code></a>: Type specification for a <a href="../tensorarray.html"><code translate="no" dir="ltr">tf.TensorArray</code></a>.</p> <p><a href="v1/tensorinfo.html"><code translate="no" dir="ltr">class TensorInfo</code></a>: A ProtocolMessage</p> <p><a href="../tensorshape.html"><code translate="no" dir="ltr">class TensorShape</code></a>: Represents the shape of a <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="../tensorspec.html"><code translate="no" dir="ltr">class TensorSpec</code></a>: Describes a tf.Tensor.</p> <p><a href="v1/textlinereader.html"><code translate="no" dir="ltr">class TextLineReader</code></a>: A Reader that outputs the lines of a file delimited by newlines.</p> <p><a href="../typespec.html"><code translate="no" dir="ltr">class TypeSpec</code></a>: Specifies a TensorFlow value type.</p> <p><a href="../unconnectedgradients.html"><code translate="no" dir="ltr">class UnconnectedGradients</code></a>: Controls how gradient computation behaves when y does not depend on x.</p> <p><a href="../io/varlenfeature.html"><code translate="no" dir="ltr">class VarLenFeature</code></a>: Configuration for parsing a variable-length input feature.</p> <p><a href="v1/variable.html"><code translate="no" dir="ltr">class Variable</code></a>: See the <a href="https://tensorflow.org/guide/variables">Variables Guide</a>.</p> <p><a href="v1/variableaggregation.html"><code translate="no" dir="ltr">class VariableAggregation</code></a>: Indicates how a distributed variable will be aggregated.</p> <p><a href="v1/variablescope.html"><code translate="no" dir="ltr">class VariableScope</code></a>: Variable scope object to carry defaults to provide to <code translate="no" dir="ltr">get_variable</code>.</p> <p><a href="../variablesynchronization.html"><code translate="no" dir="ltr">class VariableSynchronization</code></a>: Indicates when a distributed variable will be synced.</p> <p><a href="v1/wholefilereader.html"><code translate="no" dir="ltr">class WholeFileReader</code></a>: A Reader that outputs the entire contents of a file as a value.</p> <p><a href="v1/keras/initializers/constant.html"><code translate="no" dir="ltr">class constant_initializer</code></a>: Initializer that generates tensors with constant values.</p> <p><a href="v1/keras/initializers/glorot_normal.html"><code translate="no" dir="ltr">class glorot_normal_initializer</code></a>: The Glorot normal initializer, also called Xavier normal initializer.</p> <p><a href="v1/keras/initializers/glorot_uniform.html"><code translate="no" dir="ltr">class glorot_uniform_initializer</code></a>: The Glorot uniform initializer, also called Xavier uniform initializer.</p> <p><a href="v1/keras/backend/name_scope.html"><code translate="no" dir="ltr">class name_scope</code></a>: A context manager for use when defining a Python op.</p> <p><a href="v1/keras/initializers/ones.html"><code translate="no" dir="ltr">class ones_initializer</code></a>: Initializer that generates tensors initialized to 1.</p> <p><a href="v1/keras/initializers/orthogonal.html"><code translate="no" dir="ltr">class orthogonal_initializer</code></a>: Initializer that generates an orthogonal matrix.</p> <p><a href="v1/random_normal_initializer.html"><code translate="no" dir="ltr">class random_normal_initializer</code></a>: Initializer that generates tensors with a normal distribution.</p> <p><a href="v1/random_uniform_initializer.html"><code translate="no" dir="ltr">class random_uniform_initializer</code></a>: Initializer that generates tensors with a uniform distribution.</p> <p><a href="v1/truncated_normal_initializer.html"><code translate="no" dir="ltr">class truncated_normal_initializer</code></a>: Initializer that generates a truncated normal distribution.</p> <p><a href="v1/uniform_unit_scaling_initializer.html"><code translate="no" dir="ltr">class uniform_unit_scaling_initializer</code></a>: Initializer that generates tensors without scaling variance.</p> <p><a href="v1/variable_scope.html"><code translate="no" dir="ltr">class variable_scope</code></a>: A context manager for defining ops that creates variables (layers).</p> <p><a href="v1/keras/initializers/variancescaling.html"><code translate="no" dir="ltr">class variance_scaling_initializer</code></a>: Initializer capable of adapting its scale to the shape of weights tensors.</p> <p><a href="v1/keras/initializers/zeros.html"><code translate="no" dir="ltr">class zeros_initializer</code></a>: Initializer that generates tensors initialized to 0.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="../debugging/assert.html"><code translate="no" dir="ltr">Assert(...)</code></a>: Asserts that the given condition is true.</p> <p><a href="../no_gradient.html"><code translate="no" dir="ltr">NoGradient(...)</code></a>: Specifies that ops of type <code translate="no" dir="ltr">op_type</code> is not differentiable.</p> <p><a href="../no_gradient.html"><code translate="no" dir="ltr">NotDifferentiable(...)</code></a>: Specifies that ops of type <code translate="no" dir="ltr">op_type</code> is not differentiable.</p> <p><a href="v1/print.html"><code translate="no" dir="ltr">Print(...)</code></a>: Prints a list of tensors. (deprecated)</p> <p><a href="../math/abs.html"><code translate="no" dir="ltr">abs(...)</code></a>: Computes the absolute value of a tensor.</p> <p><a href="../math/accumulate_n.html"><code translate="no" dir="ltr">accumulate_n(...)</code></a>: Returns the element-wise sum of a list of tensors.</p> <p><a href="../math/acos.html"><code translate="no" dir="ltr">acos(...)</code></a>: Computes acos of x element-wise.</p> <p><a href="../math/acosh.html"><code translate="no" dir="ltr">acosh(...)</code></a>: Computes inverse hyperbolic cosine of x element-wise.</p> <p><a href="../math/add.html"><code translate="no" dir="ltr">add(...)</code></a>: Returns x + y element-wise.</p> <p><a href="v1/add_check_numerics_ops.html"><code translate="no" dir="ltr">add_check_numerics_ops(...)</code></a>: Connect a <a href="../debugging/check_numerics.html"><code translate="no" dir="ltr">tf.debugging.check_numerics</code></a> to every floating point tensor.</p> <p><a href="../math/add_n.html"><code translate="no" dir="ltr">add_n(...)</code></a>: Adds all input tensors element-wise.</p> <p><a href="v1/add_to_collection.html"><code translate="no" dir="ltr">add_to_collection(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#add_to_collection"><code translate="no" dir="ltr">Graph.add_to_collection()</code></a> using the default graph.</p> <p><a href="v1/add_to_collections.html"><code translate="no" dir="ltr">add_to_collections(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#add_to_collections"><code translate="no" dir="ltr">Graph.add_to_collections()</code></a> using the default graph.</p> <p><a href="v1/all_variables.html"><code translate="no" dir="ltr">all_variables(...)</code></a>: Use <a href="v1/global_variables.html"><code translate="no" dir="ltr">tf.compat.v1.global_variables</code></a> instead. (deprecated)</p> <p><a href="../math/angle.html"><code translate="no" dir="ltr">angle(...)</code></a>: Returns the element-wise argument of a complex (or real) tensor.</p> <p><a href="v1/arg_max.html"><code translate="no" dir="ltr">arg_max(...)</code></a>: Returns the index with the largest value across dimensions of a tensor.</p> <p><a href="v1/arg_min.html"><code translate="no" dir="ltr">arg_min(...)</code></a>: Returns the index with the smallest value across dimensions of a tensor.</p> <p><a href="v1/argmax.html"><code translate="no" dir="ltr">argmax(...)</code></a>: Returns the index with the largest value across axes of a tensor. (deprecated arguments)</p> <p><a href="v1/argmin.html"><code translate="no" dir="ltr">argmin(...)</code></a>: Returns the index with the smallest value across axes of a tensor. (deprecated arguments)</p> <p><a href="../argsort.html"><code translate="no" dir="ltr">argsort(...)</code></a>: Returns the indices of a tensor that give its sorted order along an axis.</p> <p><a href="../dtypes/as_dtype.html"><code translate="no" dir="ltr">as_dtype(...)</code></a>: Converts the given <code translate="no" dir="ltr">type_value</code> to a <code translate="no" dir="ltr">DType</code>.</p> <p><a href="../strings/as_string.html"><code translate="no" dir="ltr">as_string(...)</code></a>: Converts each entry in the given tensor to strings.</p> <p><a href="../math/asin.html"><code translate="no" dir="ltr">asin(...)</code></a>: Computes the trignometric inverse sine of x element-wise.</p> <p><a href="../math/asinh.html"><code translate="no" dir="ltr">asinh(...)</code></a>: Computes inverse hyperbolic sine of x element-wise.</p> <p><a href="v1/assert_equal.html"><code translate="no" dir="ltr">assert_equal(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x == y</code> holds element-wise.</p> <p><a href="v1/assert_greater.html"><code translate="no" dir="ltr">assert_greater(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &gt; y</code> holds element-wise.</p> <p><a href="v1/assert_greater_equal.html"><code translate="no" dir="ltr">assert_greater_equal(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &gt;= y</code> holds element-wise.</p> <p><a href="v1/assert_integer.html"><code translate="no" dir="ltr">assert_integer(...)</code></a>: Assert that <code translate="no" dir="ltr">x</code> is of integer dtype.</p> <p><a href="v1/assert_less.html"><code translate="no" dir="ltr">assert_less(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &lt; y</code> holds element-wise.</p> <p><a href="v1/assert_less_equal.html"><code translate="no" dir="ltr">assert_less_equal(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &lt;= y</code> holds element-wise.</p> <p><a href="v1/assert_near.html"><code translate="no" dir="ltr">assert_near(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are close element-wise.</p> <p><a href="v1/assert_negative.html"><code translate="no" dir="ltr">assert_negative(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &lt; 0</code> holds element-wise.</p> <p><a href="v1/assert_non_negative.html"><code translate="no" dir="ltr">assert_non_negative(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &gt;= 0</code> holds element-wise.</p> <p><a href="v1/assert_non_positive.html"><code translate="no" dir="ltr">assert_non_positive(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &lt;= 0</code> holds element-wise.</p> <p><a href="v1/assert_none_equal.html"><code translate="no" dir="ltr">assert_none_equal(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x != y</code> holds element-wise.</p> <p><a href="v1/assert_positive.html"><code translate="no" dir="ltr">assert_positive(...)</code></a>: Assert the condition <code translate="no" dir="ltr">x &gt; 0</code> holds element-wise.</p> <p><a href="../debugging/assert_proper_iterable.html"><code translate="no" dir="ltr">assert_proper_iterable(...)</code></a>: Static assert that values is a "proper" iterable.</p> <p><a href="v1/assert_rank.html"><code translate="no" dir="ltr">assert_rank(...)</code></a>: Assert <code translate="no" dir="ltr">x</code> has rank equal to <code translate="no" dir="ltr">rank</code>.</p> <p><a href="v1/assert_rank_at_least.html"><code translate="no" dir="ltr">assert_rank_at_least(...)</code></a>: Assert <code translate="no" dir="ltr">x</code> has rank equal to <code translate="no" dir="ltr">rank</code> or higher.</p> <p><a href="v1/assert_rank_in.html"><code translate="no" dir="ltr">assert_rank_in(...)</code></a>: Assert <code translate="no" dir="ltr">x</code> has rank in <code translate="no" dir="ltr">ranks</code>.</p> <p><a href="../debugging/assert_same_float_dtype.html"><code translate="no" dir="ltr">assert_same_float_dtype(...)</code></a>: Validate and return float type based on <code translate="no" dir="ltr">tensors</code> and <code translate="no" dir="ltr">dtype</code>.</p> <p><a href="v1/assert_scalar.html"><code translate="no" dir="ltr">assert_scalar(...)</code></a>: Asserts that the given <code translate="no" dir="ltr">tensor</code> is a scalar (i.e. zero-dimensional).</p> <p><a href="v1/assert_type.html"><code translate="no" dir="ltr">assert_type(...)</code></a>: Statically asserts that the given <code translate="no" dir="ltr">Tensor</code> is of the specified type.</p> <p><a href="v1/assert_variables_initialized.html"><code translate="no" dir="ltr">assert_variables_initialized(...)</code></a>: Returns an Op to check if variables are initialized.</p> <p><a href="v1/assign.html"><code translate="no" dir="ltr">assign(...)</code></a>: Update <code translate="no" dir="ltr">ref</code> by assigning <code translate="no" dir="ltr">value</code> to it.</p> <p><a href="v1/assign_add.html"><code translate="no" dir="ltr">assign_add(...)</code></a>: Update <code translate="no" dir="ltr">ref</code> by adding <code translate="no" dir="ltr">value</code> to it.</p> <p><a href="v1/assign_sub.html"><code translate="no" dir="ltr">assign_sub(...)</code></a>: Update <code translate="no" dir="ltr">ref</code> by subtracting <code translate="no" dir="ltr">value</code> from it.</p> <p><a href="../math/atan.html"><code translate="no" dir="ltr">atan(...)</code></a>: Computes the trignometric inverse tangent of x element-wise.</p> <p><a href="../math/atan2.html"><code translate="no" dir="ltr">atan2(...)</code></a>: Computes arctangent of <code translate="no" dir="ltr">y/x</code> element-wise, respecting signs of the arguments.</p> <p><a href="../math/atanh.html"><code translate="no" dir="ltr">atanh(...)</code></a>: Computes inverse hyperbolic tangent of x element-wise.</p> <p><a href="v1/batch_gather.html"><code translate="no" dir="ltr">batch_gather(...)</code></a>: Gather slices from params according to indices with leading batch dims. (deprecated)</p> <p><a href="v1/batch_scatter_update.html"><code translate="no" dir="ltr">batch_scatter_update(...)</code></a>: Generalization of <a href="v1/scatter_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> to axis different than 0. (deprecated)</p> <p><a href="v1/batch_to_space.html"><code translate="no" dir="ltr">batch_to_space(...)</code></a>: BatchToSpace for 4-D tensors of type T.</p> <p><a href="v1/batch_to_space_nd.html"><code translate="no" dir="ltr">batch_to_space_nd(...)</code></a>: BatchToSpace for N-D tensors of type T.</p> <p><a href="../math/betainc.html"><code translate="no" dir="ltr">betainc(...)</code></a>: Compute the regularized incomplete beta integral \(I_x(a, b)\).</p> <p><a href="v1/bincount.html"><code translate="no" dir="ltr">bincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../bitcast.html"><code translate="no" dir="ltr">bitcast(...)</code></a>: Bitcasts a tensor from one type to another without copying data.</p> <p><a href="v1/boolean_mask.html"><code translate="no" dir="ltr">boolean_mask(...)</code></a>: Apply boolean mask to tensor.</p> <p><a href="../broadcast_dynamic_shape.html"><code translate="no" dir="ltr">broadcast_dynamic_shape(...)</code></a>: Computes the shape of a broadcast given symbolic shapes.</p> <p><a href="../broadcast_static_shape.html"><code translate="no" dir="ltr">broadcast_static_shape(...)</code></a>: Computes the shape of a broadcast given known shapes.</p> <p><a href="../broadcast_to.html"><code translate="no" dir="ltr">broadcast_to(...)</code></a>: Broadcast an array for a compatible shape.</p> <p><a href="v1/case.html"><code translate="no" dir="ltr">case(...)</code></a>: Create a case operation.</p> <p><a href="../cast.html"><code translate="no" dir="ltr">cast(...)</code></a>: Casts a tensor to a new type.</p> <p><a href="../math/ceil.html"><code translate="no" dir="ltr">ceil(...)</code></a>: Return the ceiling of the input, element-wise.</p> <p><a href="../debugging/check_numerics.html"><code translate="no" dir="ltr">check_numerics(...)</code></a>: Checks a tensor for NaN and Inf values.</p> <p><a href="../linalg/cholesky.html"><code translate="no" dir="ltr">cholesky(...)</code></a>: Computes the Cholesky decomposition of one or more square matrices.</p> <p><a href="../linalg/cholesky_solve.html"><code translate="no" dir="ltr">cholesky_solve(...)</code></a>: Solves systems of linear eqns <code translate="no" dir="ltr">A X = RHS</code>, given Cholesky factorizations.</p> <p><a href="v1/clip_by_average_norm.html"><code translate="no" dir="ltr">clip_by_average_norm(...)</code></a>: Clips tensor values to a maximum average L2-norm. (deprecated)</p> <p><a href="../clip_by_global_norm.html"><code translate="no" dir="ltr">clip_by_global_norm(...)</code></a>: Clips values of multiple tensors by the ratio of the sum of their norms.</p> <p><a href="../clip_by_norm.html"><code translate="no" dir="ltr">clip_by_norm(...)</code></a>: Clips tensor values to a maximum L2-norm.</p> <p><a href="../clip_by_value.html"><code translate="no" dir="ltr">clip_by_value(...)</code></a>: Clips tensor values to a specified min and max.</p> <p><a href="v1/colocate_with.html"><code translate="no" dir="ltr">colocate_with(...)</code></a>: DEPRECATED FUNCTION</p> <p><a href="../dtypes/complex.html"><code translate="no" dir="ltr">complex(...)</code></a>: Converts two real numbers to a complex number.</p> <p><a href="../concat.html"><code translate="no" dir="ltr">concat(...)</code></a>: Concatenates tensors along one dimension.</p> <p><a href="v1/cond.html"><code translate="no" dir="ltr">cond(...)</code></a>: Return <code translate="no" dir="ltr">true_fn()</code> if the predicate <code translate="no" dir="ltr">pred</code> is true else <code translate="no" dir="ltr">false_fn()</code>. (deprecated arguments)</p> <p><a href="v1/confusion_matrix.html"><code translate="no" dir="ltr">confusion_matrix(...)</code></a>: Computes the confusion matrix from predictions and labels.</p> <p><a href="../math/conj.html"><code translate="no" dir="ltr">conj(...)</code></a>: Returns the complex conjugate of a complex number.</p> <p><a href="v1/constant.html"><code translate="no" dir="ltr">constant(...)</code></a>: Creates a constant tensor.</p> <p><a href="v1/container.html"><code translate="no" dir="ltr">container(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#container"><code translate="no" dir="ltr">Graph.container()</code></a> using the default graph.</p> <p><a href="../control_dependencies.html"><code translate="no" dir="ltr">control_dependencies(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#control_dependencies"><code translate="no" dir="ltr">Graph.control_dependencies()</code></a> using the default graph.</p> <p><a href="v1/control_flow_v2_enabled.html"><code translate="no" dir="ltr">control_flow_v2_enabled(...)</code></a>: Returns <code translate="no" dir="ltr">True</code> if v2 control flow is enabled.</p> <p><a href="v1/convert_to_tensor.html"><code translate="no" dir="ltr">convert_to_tensor(...)</code></a>: Converts the given <code translate="no" dir="ltr">value</code> to a <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="v1/convert_to_tensor_or_indexed_slices.html"><code translate="no" dir="ltr">convert_to_tensor_or_indexed_slices(...)</code></a>: Converts the given object to a <code translate="no" dir="ltr">Tensor</code> or an <code translate="no" dir="ltr">IndexedSlices</code>.</p> <p><a href="v1/convert_to_tensor_or_sparse_tensor.html"><code translate="no" dir="ltr">convert_to_tensor_or_sparse_tensor(...)</code></a>: Converts value to a <code translate="no" dir="ltr">SparseTensor</code> or <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="../math/cos.html"><code translate="no" dir="ltr">cos(...)</code></a>: Computes cos of x element-wise.</p> <p><a href="../math/cosh.html"><code translate="no" dir="ltr">cosh(...)</code></a>: Computes hyperbolic cosine of x element-wise.</p> <p><a href="v1/count_nonzero.html"><code translate="no" dir="ltr">count_nonzero(...)</code></a>: Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)</p> <p><a href="v1/count_up_to.html"><code translate="no" dir="ltr">count_up_to(...)</code></a>: Increments 'ref' until it reaches 'limit'. (deprecated)</p> <p><a href="v1/create_partitioned_variables.html"><code translate="no" dir="ltr">create_partitioned_variables(...)</code></a>: Create a list of partitioned variables according to the given <code translate="no" dir="ltr">slicing</code>. (deprecated)</p> <p><a href="../linalg/cross.html"><code translate="no" dir="ltr">cross(...)</code></a>: Compute the pairwise cross product.</p> <p><a href="../math/cumprod.html"><code translate="no" dir="ltr">cumprod(...)</code></a>: Compute the cumulative product of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../math/cumsum.html"><code translate="no" dir="ltr">cumsum(...)</code></a>: Compute the cumulative sum of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../custom_gradient.html"><code translate="no" dir="ltr">custom_gradient(...)</code></a>: Decorator to define a function with a custom gradient.</p> <p><a href="../io/decode_base64.html"><code translate="no" dir="ltr">decode_base64(...)</code></a>: Decode web-safe base64-encoded strings.</p> <p><a href="../io/decode_compressed.html"><code translate="no" dir="ltr">decode_compressed(...)</code></a>: Decompress strings.</p> <p><a href="v1/decode_csv.html"><code translate="no" dir="ltr">decode_csv(...)</code></a>: Convert CSV records to tensors. Each column maps to one tensor.</p> <p><a href="../io/decode_json_example.html"><code translate="no" dir="ltr">decode_json_example(...)</code></a>: Convert JSON-encoded Example records to binary protocol buffer strings.</p> <p><a href="v1/decode_raw.html"><code translate="no" dir="ltr">decode_raw(...)</code></a>: Convert raw byte strings into tensors. (deprecated arguments)</p> <p><a href="v1/delete_session_tensor.html"><code translate="no" dir="ltr">delete_session_tensor(...)</code></a>: Delete the tensor for the given tensor handle.</p> <p><a href="v1/depth_to_space.html"><code translate="no" dir="ltr">depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="../quantization/dequantize.html"><code translate="no" dir="ltr">dequantize(...)</code></a>: Dequantize the 'input' tensor into a float or bfloat16 Tensor.</p> <p><a href="../io/deserialize_many_sparse.html"><code translate="no" dir="ltr">deserialize_many_sparse(...)</code></a>: Deserialize and concatenate <code translate="no" dir="ltr">SparseTensors</code> from a serialized minibatch.</p> <p><a href="v1/device.html"><code translate="no" dir="ltr">device(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#device"><code translate="no" dir="ltr">Graph.device()</code></a> using the default graph.</p> <p><a href="../linalg/tensor_diag.html"><code translate="no" dir="ltr">diag(...)</code></a>: Returns a diagonal tensor with a given diagonal values.</p> <p><a href="../linalg/tensor_diag_part.html"><code translate="no" dir="ltr">diag_part(...)</code></a>: Returns the diagonal part of the tensor.</p> <p><a href="../math/digamma.html"><code translate="no" dir="ltr">digamma(...)</code></a>: Computes Psi, the derivative of Lgamma (the log of the absolute value of</p> <p><a href="dimension_at_index.html"><code translate="no" dir="ltr">dimension_at_index(...)</code></a>: Compatibility utility required to allow for both V1 and V2 behavior in TF.</p> <p><a href="dimension_value.html"><code translate="no" dir="ltr">dimension_value(...)</code></a>: Compatibility utility required to allow for both V1 and V2 behavior in TF.</p> <p><a href="v1/disable_control_flow_v2.html"><code translate="no" dir="ltr">disable_control_flow_v2(...)</code></a>: Opts out of control flow v2.</p> <p><a href="v1/disable_eager_execution.html"><code translate="no" dir="ltr">disable_eager_execution(...)</code></a>: Disables eager execution.</p> <p><a href="v1/disable_resource_variables.html"><code translate="no" dir="ltr">disable_resource_variables(...)</code></a>: Opts out of resource variables. (deprecated)</p> <p><a href="v1/disable_tensor_equality.html"><code translate="no" dir="ltr">disable_tensor_equality(...)</code></a>: Compare Tensors by their id and be hashable.</p> <p><a href="v1/disable_v2_behavior.html"><code translate="no" dir="ltr">disable_v2_behavior(...)</code></a>: Disables TensorFlow 2.x behaviors.</p> <p><a href="v1/disable_v2_tensorshape.html"><code translate="no" dir="ltr">disable_v2_tensorshape(...)</code></a>: Disables the V2 TensorShape behavior and reverts to V1 behavior.</p> <p><a href="v1/div.html"><code translate="no" dir="ltr">div(...)</code></a>: Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <p><a href="../math/divide_no_nan.html"><code translate="no" dir="ltr">div_no_nan(...)</code></a>: Computes a safe divide which returns 0 if <code translate="no" dir="ltr">y</code> (denominator) is zero.</p> <p><a href="../math/divide.html"><code translate="no" dir="ltr">divide(...)</code></a>: Computes Python style division of <code translate="no" dir="ltr">x</code> by <code translate="no" dir="ltr">y</code>.</p> <p><a href="../dynamic_partition.html"><code translate="no" dir="ltr">dynamic_partition(...)</code></a>: Partitions <code translate="no" dir="ltr">data</code> into <code translate="no" dir="ltr">num_partitions</code> tensors using indices from <code translate="no" dir="ltr">partitions</code>.</p> <p><a href="../dynamic_stitch.html"><code translate="no" dir="ltr">dynamic_stitch(...)</code></a>: Interleave the values from the <code translate="no" dir="ltr">data</code> tensors into a single tensor.</p> <p><a href="../edit_distance.html"><code translate="no" dir="ltr">edit_distance(...)</code></a>: Computes the Levenshtein distance between sequences.</p> <p><a href="../einsum.html"><code translate="no" dir="ltr">einsum(...)</code></a>: Tensor contraction over specified indices and outer product.</p> <p><a href="v1/enable_control_flow_v2.html"><code translate="no" dir="ltr">enable_control_flow_v2(...)</code></a>: Use control flow v2.</p> <p><a href="v1/enable_eager_execution.html"><code translate="no" dir="ltr">enable_eager_execution(...)</code></a>: Enables eager execution for the lifetime of this program.</p> <p><a href="v1/enable_resource_variables.html"><code translate="no" dir="ltr">enable_resource_variables(...)</code></a>: Creates resource variables by default.</p> <p><a href="v1/enable_tensor_equality.html"><code translate="no" dir="ltr">enable_tensor_equality(...)</code></a>: Compare Tensors with element-wise comparison and thus be unhashable.</p> <p><a href="v1/enable_v2_behavior.html"><code translate="no" dir="ltr">enable_v2_behavior(...)</code></a>: Enables TensorFlow 2.x behaviors.</p> <p><a href="v1/enable_v2_tensorshape.html"><code translate="no" dir="ltr">enable_v2_tensorshape(...)</code></a>: In TensorFlow 2.0, iterating over a TensorShape instance returns values.</p> <p><a href="../io/encode_base64.html"><code translate="no" dir="ltr">encode_base64(...)</code></a>: Encode strings into web-safe base64 format.</p> <p><a href="../ensure_shape.html"><code translate="no" dir="ltr">ensure_shape(...)</code></a>: Updates the shape of a tensor and checks at runtime that the shape holds.</p> <p><a href="../math/equal.html"><code translate="no" dir="ltr">equal(...)</code></a>: Returns the truth value of (x == y) element-wise.</p> <p><a href="../math/erf.html"><code translate="no" dir="ltr">erf(...)</code></a>: Computes the <a href="https://en.wikipedia.org/wiki/Error_function">Gauss error function</a> of <code translate="no" dir="ltr">x</code> element-wise. In statistics, for non-negative values of \(x\), the error function has the following interpretation: for a random variable \(Y\) that is normally distributed with mean 0 and variance \(1/\sqrt{2}\), \(erf(x)\) is the probability that \(Y\) falls in the range \([−x, x]\).</p> <p><a href="../math/erfc.html"><code translate="no" dir="ltr">erfc(...)</code></a>: Computes the complementary error function of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="v1/executing_eagerly.html"><code translate="no" dir="ltr">executing_eagerly(...)</code></a>: Checks whether the current thread has eager execution enabled.</p> <p><a href="v1/executing_eagerly_outside_functions.html"><code translate="no" dir="ltr">executing_eagerly_outside_functions(...)</code></a>: Returns True if executing eagerly, even if inside a graph function.</p> <p><a href="../math/exp.html"><code translate="no" dir="ltr">exp(...)</code></a>: Computes exponential of x element-wise. \(y = e^x\).</p> <p><a href="v1/expand_dims.html"><code translate="no" dir="ltr">expand_dims(...)</code></a>: Returns a tensor with a length 1 axis inserted at index <code translate="no" dir="ltr">axis</code>. (deprecated arguments)</p> <p><a href="../math/expm1.html"><code translate="no" dir="ltr">expm1(...)</code></a>: Computes <code translate="no" dir="ltr">exp(x) - 1</code> element-wise.</p> <p><a href="v1/extract_image_patches.html"><code translate="no" dir="ltr">extract_image_patches(...)</code></a>: Extract <code translate="no" dir="ltr">patches</code> from <code translate="no" dir="ltr">images</code> and put them in the "depth" output dimension.</p> <p><a href="../extract_volume_patches.html"><code translate="no" dir="ltr">extract_volume_patches(...)</code></a>: Extract <code translate="no" dir="ltr">patches</code> from <code translate="no" dir="ltr">input</code> and put them in the <code translate="no" dir="ltr">"depth"</code> output dimension. 3D extension of <code translate="no" dir="ltr">extract_image_patches</code>.</p> <p><a href="../eye.html"><code translate="no" dir="ltr">eye(...)</code></a>: Construct an identity matrix, or a batch of matrices.</p> <p><a href="../quantization/fake_quant_with_min_max_args.html"><code translate="no" dir="ltr">fake_quant_with_min_max_args(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.</p> <p><a href="../quantization/fake_quant_with_min_max_args_gradient.html"><code translate="no" dir="ltr">fake_quant_with_min_max_args_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p> <p><a href="../quantization/fake_quant_with_min_max_vars.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars</p> <p><a href="../quantization/fake_quant_with_min_max_vars_gradient.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p> <p><a href="../quantization/fake_quant_with_min_max_vars_per_channel.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_per_channel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via per-channel floats</p> <p><a href="../quantization/fake_quant_with_min_max_vars_per_channel_gradient.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_per_channel_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p> <p><a href="../signal/fft.html"><code translate="no" dir="ltr">fft(...)</code></a>: Fast Fourier transform.</p> <p><a href="../signal/fft2d.html"><code translate="no" dir="ltr">fft2d(...)</code></a>: 2D fast Fourier transform.</p> <p><a href="../signal/fft3d.html"><code translate="no" dir="ltr">fft3d(...)</code></a>: 3D fast Fourier transform.</p> <p><a href="../fill.html"><code translate="no" dir="ltr">fill(...)</code></a>: Creates a tensor filled with a scalar value.</p> <p><a href="../fingerprint.html"><code translate="no" dir="ltr">fingerprint(...)</code></a>: Generates fingerprint values.</p> <p><a href="v1/fixed_size_partitioner.html"><code translate="no" dir="ltr">fixed_size_partitioner(...)</code></a>: Partitioner to specify a fixed number of shards along given axis.</p> <p><a href="../math/floor.html"><code translate="no" dir="ltr">floor(...)</code></a>: Returns element-wise largest integer not greater than x.</p> <p><a href="v1/floor_div.html"><code translate="no" dir="ltr">floor_div(...)</code></a>: Returns x // y element-wise.</p> <p><a href="../math/floordiv.html"><code translate="no" dir="ltr">floordiv(...)</code></a>: Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p><a href="../math/floormod.html"><code translate="no" dir="ltr">floormod(...)</code></a>: Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p><a href="v1/foldl.html"><code translate="no" dir="ltr">foldl(...)</code></a>: foldl on the list of tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0.</p> <p><a href="v1/foldr.html"><code translate="no" dir="ltr">foldr(...)</code></a>: foldr on the list of tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0.</p> <p><a href="../function.html"><code translate="no" dir="ltr">function(...)</code></a>: Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments)</p> <p><a href="v1/gather.html"><code translate="no" dir="ltr">gather(...)</code></a>: Gather slices from params axis <code translate="no" dir="ltr">axis</code> according to indices. (deprecated arguments)</p> <p><a href="v1/gather_nd.html"><code translate="no" dir="ltr">gather_nd(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> into a Tensor with shape specified by <code translate="no" dir="ltr">indices</code>.</p> <p><a href="v1/get_collection.html"><code translate="no" dir="ltr">get_collection(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#get_collection"><code translate="no" dir="ltr">Graph.get_collection()</code></a> using the default graph.</p> <p><a href="v1/get_collection_ref.html"><code translate="no" dir="ltr">get_collection_ref(...)</code></a>: Wrapper for <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#get_collection_ref"><code translate="no" dir="ltr">Graph.get_collection_ref()</code></a> using the default graph.</p> <p><a href="v1/get_default_graph.html"><code translate="no" dir="ltr">get_default_graph(...)</code></a>: Returns the default graph for the current thread.</p> <p><a href="v1/get_default_session.html"><code translate="no" dir="ltr">get_default_session(...)</code></a>: Returns the default session for the current thread.</p> <p><a href="v1/get_local_variable.html"><code translate="no" dir="ltr">get_local_variable(...)</code></a>: Gets an existing <em>local</em> variable or creates a new one.</p> <p><a href="../get_logger.html"><code translate="no" dir="ltr">get_logger(...)</code></a>: Return TF logger instance.</p> <p><a href="v1/get_seed.html"><code translate="no" dir="ltr">get_seed(...)</code></a>: Returns the local seeds an operation should use given an op-specific seed.</p> <p><a href="v1/get_session_handle.html"><code translate="no" dir="ltr">get_session_handle(...)</code></a>: Return the handle of <code translate="no" dir="ltr">data</code>.</p> <p><a href="v1/get_session_tensor.html"><code translate="no" dir="ltr">get_session_tensor(...)</code></a>: Get the tensor of type <code translate="no" dir="ltr">dtype</code> by feeding a tensor handle.</p> <p><a href="../get_static_value.html"><code translate="no" dir="ltr">get_static_value(...)</code></a>: Returns the constant value of the given tensor, if efficiently calculable.</p> <p><a href="v1/get_variable.html"><code translate="no" dir="ltr">get_variable(...)</code></a>: Gets an existing variable with these parameters or create a new one.</p> <p><a href="v1/get_variable_scope.html"><code translate="no" dir="ltr">get_variable_scope(...)</code></a>: Returns the current variable scope.</p> <p><a href="../linalg/global_norm.html"><code translate="no" dir="ltr">global_norm(...)</code></a>: Computes the global norm of multiple tensors.</p> <p><a href="v1/global_variables.html"><code translate="no" dir="ltr">global_variables(...)</code></a>: Returns global variables.</p> <p><a href="v1/global_variables_initializer.html"><code translate="no" dir="ltr">global_variables_initializer(...)</code></a>: Returns an Op that initializes global variables.</p> <p><a href="../grad_pass_through.html"><code translate="no" dir="ltr">grad_pass_through(...)</code></a>: Creates a grad-pass-through op with the forward behavior provided in f.</p> <p><a href="v1/gradients.html"><code translate="no" dir="ltr">gradients(...)</code></a>: Constructs symbolic derivatives of sum of <code translate="no" dir="ltr">ys</code> w.r.t. x in <code translate="no" dir="ltr">xs</code>.</p> <p><a href="../math/greater.html"><code translate="no" dir="ltr">greater(...)</code></a>: Returns the truth value of (x &gt; y) element-wise.</p> <p><a href="../math/greater_equal.html"><code translate="no" dir="ltr">greater_equal(...)</code></a>: Returns the truth value of (x &gt;= y) element-wise.</p> <p><a href="../group.html"><code translate="no" dir="ltr">group(...)</code></a>: Create an op that groups multiple operations.</p> <p><a href="../guarantee_const.html"><code translate="no" dir="ltr">guarantee_const(...)</code></a>: Promise to the TF runtime that the input tensor is a constant. (deprecated)</p> <p><a href="v1/hessians.html"><code translate="no" dir="ltr">hessians(...)</code></a>: Constructs the Hessian of sum of <code translate="no" dir="ltr">ys</code> with respect to <code translate="no" dir="ltr">x</code> in <code translate="no" dir="ltr">xs</code>.</p> <p><a href="../histogram_fixed_width.html"><code translate="no" dir="ltr">histogram_fixed_width(...)</code></a>: Return histogram of values.</p> <p><a href="../histogram_fixed_width_bins.html"><code translate="no" dir="ltr">histogram_fixed_width_bins(...)</code></a>: Bins the given values for use in a histogram.</p> <p><a href="../identity.html"><code translate="no" dir="ltr">identity(...)</code></a>: Return a Tensor with the same shape and contents as input.</p> <p><a href="../identity_n.html"><code translate="no" dir="ltr">identity_n(...)</code></a>: Returns a list of tensors with the same shapes and contents as the input</p> <p><a href="../signal/ifft.html"><code translate="no" dir="ltr">ifft(...)</code></a>: Inverse fast Fourier transform.</p> <p><a href="../signal/ifft2d.html"><code translate="no" dir="ltr">ifft2d(...)</code></a>: Inverse 2D fast Fourier transform.</p> <p><a href="../signal/ifft3d.html"><code translate="no" dir="ltr">ifft3d(...)</code></a>: Inverse 3D fast Fourier transform.</p> <p><a href="../math/igamma.html"><code translate="no" dir="ltr">igamma(...)</code></a>: Compute the lower regularized incomplete Gamma function <code translate="no" dir="ltr">P(a, x)</code>.</p> <p><a href="../math/igammac.html"><code translate="no" dir="ltr">igammac(...)</code></a>: Compute the upper regularized incomplete Gamma function <code translate="no" dir="ltr">Q(a, x)</code>.</p> <p><a href="../math/imag.html"><code translate="no" dir="ltr">imag(...)</code></a>: Returns the imaginary part of a complex (or real) tensor.</p> <p><a href="../graph_util/import_graph_def.html"><code translate="no" dir="ltr">import_graph_def(...)</code></a>: Imports the graph from <code translate="no" dir="ltr">graph_def</code> into the current default <code translate="no" dir="ltr">Graph</code>. (deprecated arguments)</p> <p><a href="../init_scope.html"><code translate="no" dir="ltr">init_scope(...)</code></a>: A context manager that lifts ops out of control-flow scopes and function-building graphs.</p> <p><a href="v1/initialize_all_tables.html"><code translate="no" dir="ltr">initialize_all_tables(...)</code></a>: Returns an Op that initializes all tables of the default graph. (deprecated)</p> <p><a href="v1/initialize_all_variables.html"><code translate="no" dir="ltr">initialize_all_variables(...)</code></a>: See <a href="v1/global_variables_initializer.html"><code translate="no" dir="ltr">tf.compat.v1.global_variables_initializer</code></a>. (deprecated)</p> <p><a href="v1/initialize_local_variables.html"><code translate="no" dir="ltr">initialize_local_variables(...)</code></a>: See <a href="v1/local_variables_initializer.html"><code translate="no" dir="ltr">tf.compat.v1.local_variables_initializer</code></a>. (deprecated)</p> <p><a href="v1/initialize_variables.html"><code translate="no" dir="ltr">initialize_variables(...)</code></a>: See <a href="v1/variables_initializer.html"><code translate="no" dir="ltr">tf.compat.v1.variables_initializer</code></a>. (deprecated)</p> <p><a href="../math/invert_permutation.html"><code translate="no" dir="ltr">invert_permutation(...)</code></a>: Computes the inverse permutation of a tensor.</p> <p><a href="../math/is_finite.html"><code translate="no" dir="ltr">is_finite(...)</code></a>: Returns which elements of x are finite.</p> <p><a href="../math/is_inf.html"><code translate="no" dir="ltr">is_inf(...)</code></a>: Returns which elements of x are Inf.</p> <p><a href="../math/is_nan.html"><code translate="no" dir="ltr">is_nan(...)</code></a>: Returns which elements of x are NaN.</p> <p><a href="../math/is_non_decreasing.html"><code translate="no" dir="ltr">is_non_decreasing(...)</code></a>: Returns <code translate="no" dir="ltr">True</code> if <code translate="no" dir="ltr">x</code> is non-decreasing.</p> <p><a href="../debugging/is_numeric_tensor.html"><code translate="no" dir="ltr">is_numeric_tensor(...)</code></a>: Returns <code translate="no" dir="ltr">True</code> if the elements of <code translate="no" dir="ltr">tensor</code> are numbers.</p> <p><a href="../math/is_strictly_increasing.html"><code translate="no" dir="ltr">is_strictly_increasing(...)</code></a>: Returns <code translate="no" dir="ltr">True</code> if <code translate="no" dir="ltr">x</code> is strictly increasing.</p> <p><a href="../is_tensor.html"><code translate="no" dir="ltr">is_tensor(...)</code></a>: Checks whether <code translate="no" dir="ltr">x</code> is a TF-native type that can be passed to many TF ops.</p> <p><a href="v1/is_variable_initialized.html"><code translate="no" dir="ltr">is_variable_initialized(...)</code></a>: Tests if a variable has been initialized.</p> <p><a href="../math/lbeta.html"><code translate="no" dir="ltr">lbeta(...)</code></a>: Computes \(ln(|Beta(x)|)\), reducing along the last dimension.</p> <p><a href="../math/less.html"><code translate="no" dir="ltr">less(...)</code></a>: Returns the truth value of (x &lt; y) element-wise.</p> <p><a href="../math/less_equal.html"><code translate="no" dir="ltr">less_equal(...)</code></a>: Returns the truth value of (x &lt;= y) element-wise.</p> <p><a href="../math/lgamma.html"><code translate="no" dir="ltr">lgamma(...)</code></a>: Computes the log of the absolute value of <code translate="no" dir="ltr">Gamma(x)</code> element-wise.</p> <p><a href="../linspace.html"><code translate="no" dir="ltr">lin_space(...)</code></a>: Generates evenly-spaced values in an interval along a given axis.</p> <p><a href="../linspace.html"><code translate="no" dir="ltr">linspace(...)</code></a>: Generates evenly-spaced values in an interval along a given axis.</p> <p><a href="v1/load_file_system_library.html"><code translate="no" dir="ltr">load_file_system_library(...)</code></a>: Loads a TensorFlow plugin, containing file system implementation. (deprecated)</p> <p><a href="../load_library.html"><code translate="no" dir="ltr">load_library(...)</code></a>: Loads a TensorFlow plugin.</p> <p><a href="../load_op_library.html"><code translate="no" dir="ltr">load_op_library(...)</code></a>: Loads a TensorFlow plugin, containing custom ops and kernels.</p> <p><a href="v1/local_variables.html"><code translate="no" dir="ltr">local_variables(...)</code></a>: Returns local variables.</p> <p><a href="v1/local_variables_initializer.html"><code translate="no" dir="ltr">local_variables_initializer(...)</code></a>: Returns an Op that initializes all local variables.</p> <p><a href="../math/log.html"><code translate="no" dir="ltr">log(...)</code></a>: Computes natural logarithm of x element-wise.</p> <p><a href="../math/log1p.html"><code translate="no" dir="ltr">log1p(...)</code></a>: Computes natural logarithm of (1 + x) element-wise.</p> <p><a href="../math/log_sigmoid.html"><code translate="no" dir="ltr">log_sigmoid(...)</code></a>: Computes log sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../math/logical_and.html"><code translate="no" dir="ltr">logical_and(...)</code></a>: Returns the truth value of x AND y element-wise.</p> <p><a href="../math/logical_not.html"><code translate="no" dir="ltr">logical_not(...)</code></a>: Returns the truth value of <code translate="no" dir="ltr">NOT x</code> element-wise.</p> <p><a href="../math/logical_or.html"><code translate="no" dir="ltr">logical_or(...)</code></a>: Returns the truth value of x OR y element-wise.</p> <p><a href="../math/logical_xor.html"><code translate="no" dir="ltr">logical_xor(...)</code></a>: Logical XOR function.</p> <p><a href="../make_ndarray.html"><code translate="no" dir="ltr">make_ndarray(...)</code></a>: Create a numpy ndarray from a tensor.</p> <p><a href="v1/make_template.html"><code translate="no" dir="ltr">make_template(...)</code></a>: Given an arbitrary function, wrap it so that it does variable sharing.</p> <p><a href="../make_tensor_proto.html"><code translate="no" dir="ltr">make_tensor_proto(...)</code></a>: Create a TensorProto.</p> <p><a href="v1/map_fn.html"><code translate="no" dir="ltr">map_fn(...)</code></a>: Transforms <code translate="no" dir="ltr">elems</code> by applying <code translate="no" dir="ltr">fn</code> to each element unstacked on axis 0. (deprecated arguments)</p> <p><a href="../io/matching_files.html"><code translate="no" dir="ltr">matching_files(...)</code></a>: Returns the set of files matching one or more glob patterns.</p> <p><a href="../linalg/matmul.html"><code translate="no" dir="ltr">matmul(...)</code></a>: Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p><a href="../linalg/band_part.html"><code translate="no" dir="ltr">matrix_band_part(...)</code></a>: Copy a tensor setting everything outside a central band in each innermost matrix to zero.</p> <p><a href="../linalg/det.html"><code translate="no" dir="ltr">matrix_determinant(...)</code></a>: Computes the determinant of one or more square matrices.</p> <p><a href="../linalg/diag.html"><code translate="no" dir="ltr">matrix_diag(...)</code></a>: Returns a batched diagonal tensor with given batched diagonal values.</p> <p><a href="../linalg/diag_part.html"><code translate="no" dir="ltr">matrix_diag_part(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../linalg/inv.html"><code translate="no" dir="ltr">matrix_inverse(...)</code></a>: Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).</p> <p><a href="../linalg/set_diag.html"><code translate="no" dir="ltr">matrix_set_diag(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../linalg/solve.html"><code translate="no" dir="ltr">matrix_solve(...)</code></a>: Solves systems of linear equations.</p> <p><a href="../linalg/lstsq.html"><code translate="no" dir="ltr">matrix_solve_ls(...)</code></a>: Solves one or more linear least-squares problems.</p> <p><a href="../linalg/sqrtm.html"><code translate="no" dir="ltr">matrix_square_root(...)</code></a>: Computes the matrix square root of one or more square matrices:</p> <p><a href="../linalg/matrix_transpose.html"><code translate="no" dir="ltr">matrix_transpose(...)</code></a>: Transposes last two dimensions of tensor <code translate="no" dir="ltr">a</code>.</p> <p><a href="../linalg/triangular_solve.html"><code translate="no" dir="ltr">matrix_triangular_solve(...)</code></a>: Solve systems of linear equations with upper or lower triangular matrices.</p> <p><a href="../math/maximum.html"><code translate="no" dir="ltr">maximum(...)</code></a>: Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise.</p> <p><a href="../meshgrid.html"><code translate="no" dir="ltr">meshgrid(...)</code></a>: Broadcasts parameters for evaluation on an N-D grid.</p> <p><a href="v1/min_max_variable_partitioner.html"><code translate="no" dir="ltr">min_max_variable_partitioner(...)</code></a>: Partitioner to allocate minimum size per slice.</p> <p><a href="../math/minimum.html"><code translate="no" dir="ltr">minimum(...)</code></a>: Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.</p> <p><a href="../math/floormod.html"><code translate="no" dir="ltr">mod(...)</code></a>: Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p><a href="v1/model_variables.html"><code translate="no" dir="ltr">model_variables(...)</code></a>: Returns all variables in the MODEL_VARIABLES collection.</p> <p><a href="v1/moving_average_variables.html"><code translate="no" dir="ltr">moving_average_variables(...)</code></a>: Returns all variables that maintain their moving averages.</p> <p><a href="v1/multinomial.html"><code translate="no" dir="ltr">multinomial(...)</code></a>: Draws samples from a multinomial distribution. (deprecated)</p> <p><a href="../math/multiply.html"><code translate="no" dir="ltr">multiply(...)</code></a>: Returns an element-wise x * y.</p> <p><a href="../math/negative.html"><code translate="no" dir="ltr">negative(...)</code></a>: Computes numerical negative value element-wise.</p> <p><a href="../no_gradient.html"><code translate="no" dir="ltr">no_gradient(...)</code></a>: Specifies that ops of type <code translate="no" dir="ltr">op_type</code> is not differentiable.</p> <p><a href="../no_op.html"><code translate="no" dir="ltr">no_op(...)</code></a>: Does nothing. Only useful as a placeholder for control edges.</p> <p><a href="v1/no_regularizer.html"><code translate="no" dir="ltr">no_regularizer(...)</code></a>: Use this function to prevent regularization of variables.</p> <p><a href="../nondifferentiable_batch_function.html"><code translate="no" dir="ltr">nondifferentiable_batch_function(...)</code></a>: Batches the computation done by the decorated function.</p> <p><a href="v1/norm.html"><code translate="no" dir="ltr">norm(...)</code></a>: Computes the norm of vectors, matrices, and tensors. (deprecated arguments)</p> <p><a href="../math/not_equal.html"><code translate="no" dir="ltr">not_equal(...)</code></a>: Returns the truth value of (x != y) element-wise.</p> <p><a href="../numpy_function.html"><code translate="no" dir="ltr">numpy_function(...)</code></a>: Wraps a python function and uses it as a TensorFlow op.</p> <p><a href="../one_hot.html"><code translate="no" dir="ltr">one_hot(...)</code></a>: Returns a one-hot tensor.</p> <p><a href="../ones.html"><code translate="no" dir="ltr">ones(...)</code></a>: Creates a tensor with all elements set to one (1).</p> <p><a href="v1/ones_like.html"><code translate="no" dir="ltr">ones_like(...)</code></a>: Creates a tensor with all elements set to 1.</p> <p><a href="v1/op_scope.html"><code translate="no" dir="ltr">op_scope(...)</code></a>: DEPRECATED. Same as name_scope above, just different argument order.</p> <p><a href="v1/pad.html"><code translate="no" dir="ltr">pad(...)</code></a>: Pads a tensor.</p> <p><a href="../parallel_stack.html"><code translate="no" dir="ltr">parallel_stack(...)</code></a>: Stacks a list of rank-<code translate="no" dir="ltr">R</code> tensors into one rank-<code translate="no" dir="ltr">(R+1)</code> tensor in parallel.</p> <p><a href="v1/parse_example.html"><code translate="no" dir="ltr">parse_example(...)</code></a>: Parses <code translate="no" dir="ltr">Example</code> protos into a <code translate="no" dir="ltr">dict</code> of tensors.</p> <p><a href="v1/parse_single_example.html"><code translate="no" dir="ltr">parse_single_example(...)</code></a>: Parses a single <code translate="no" dir="ltr">Example</code> proto.</p> <p><a href="../io/parse_single_sequence_example.html"><code translate="no" dir="ltr">parse_single_sequence_example(...)</code></a>: Parses a single <code translate="no" dir="ltr">SequenceExample</code> proto.</p> <p><a href="../io/parse_tensor.html"><code translate="no" dir="ltr">parse_tensor(...)</code></a>: Transforms a serialized tensorflow.TensorProto proto into a Tensor.</p> <p><a href="v1/placeholder.html"><code translate="no" dir="ltr">placeholder(...)</code></a>: Inserts a placeholder for a tensor that will be always fed.</p> <p><a href="v1/placeholder_with_default.html"><code translate="no" dir="ltr">placeholder_with_default(...)</code></a>: A placeholder op that passes through <code translate="no" dir="ltr">input</code> when its output is not fed.</p> <p><a href="../math/polygamma.html"><code translate="no" dir="ltr">polygamma(...)</code></a>: Compute the polygamma function \(\psi^{(n)}(x)\).</p> <p><a href="../math/pow.html"><code translate="no" dir="ltr">pow(...)</code></a>: Computes the power of one value to another.</p> <p><a href="../print.html"><code translate="no" dir="ltr">print(...)</code></a>: Print the specified inputs.</p> <p><a href="v1/py_func.html"><code translate="no" dir="ltr">py_func(...)</code></a>: Wraps a python function and uses it as a TensorFlow op.</p> <p><a href="../py_function.html"><code translate="no" dir="ltr">py_function(...)</code></a>: Wraps a python function into a TensorFlow op that executes it eagerly.</p> <p><a href="../linalg/qr.html"><code translate="no" dir="ltr">qr(...)</code></a>: Computes the QR decompositions of one or more matrices.</p> <p><a href="../quantization/quantize.html"><code translate="no" dir="ltr">quantize(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <p><a href="v1/quantize_v2.html"><code translate="no" dir="ltr">quantize_v2(...)</code></a>: Please use <a href="../quantization/quantize.html"><code translate="no" dir="ltr">tf.quantization.quantize</code></a> instead.</p> <p><a href="../quantization/quantized_concat.html"><code translate="no" dir="ltr">quantized_concat(...)</code></a>: Concatenates quantized tensors along one dimension.</p> <p><a href="../image/random_crop.html"><code translate="no" dir="ltr">random_crop(...)</code></a>: Randomly crops a tensor to a given size.</p> <p><a href="../random/gamma.html"><code translate="no" dir="ltr">random_gamma(...)</code></a>: Draws <code translate="no" dir="ltr">shape</code> samples from each of the given Gamma distribution(s).</p> <p><a href="../random_index_shuffle.html"><code translate="no" dir="ltr">random_index_shuffle(...)</code></a>: Outputs the position of <code translate="no" dir="ltr">value</code> in a permutation of [0, ..., max_index].</p> <p><a href="../random/normal.html"><code translate="no" dir="ltr">random_normal(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="v1/random_poisson.html"><code translate="no" dir="ltr">random_poisson(...)</code></a>: Draws <code translate="no" dir="ltr">shape</code> samples from each of the given Poisson distribution(s).</p> <p><a href="../random/shuffle.html"><code translate="no" dir="ltr">random_shuffle(...)</code></a>: Randomly shuffles a tensor along its first dimension.</p> <p><a href="../random/uniform.html"><code translate="no" dir="ltr">random_uniform(...)</code></a>: Outputs random values from a uniform distribution.</p> <p><a href="../range.html"><code translate="no" dir="ltr">range(...)</code></a>: Creates a sequence of numbers.</p> <p><a href="../rank.html"><code translate="no" dir="ltr">rank(...)</code></a>: Returns the rank of a tensor.</p> <p><a href="../io/read_file.html"><code translate="no" dir="ltr">read_file(...)</code></a>: Reads the contents of file.</p> <p><a href="../math/real.html"><code translate="no" dir="ltr">real(...)</code></a>: Returns the real part of a complex (or real) tensor.</p> <p><a href="../realdiv.html"><code translate="no" dir="ltr">realdiv(...)</code></a>: Returns x / y element-wise for real types.</p> <p><a href="../math/reciprocal.html"><code translate="no" dir="ltr">reciprocal(...)</code></a>: Computes the reciprocal of x element-wise.</p> <p><a href="../recompute_grad.html"><code translate="no" dir="ltr">recompute_grad(...)</code></a>: Defines a function as a recompute-checkpoint for the tape auto-diff.</p> <p><a href="v1/reduce_all.html"><code translate="no" dir="ltr">reduce_all(...)</code></a>: Computes <a href="../math/logical_and.html"><code translate="no" dir="ltr">tf.math.logical_and</code></a> of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="v1/reduce_any.html"><code translate="no" dir="ltr">reduce_any(...)</code></a>: Computes <a href="../math/logical_or.html"><code translate="no" dir="ltr">tf.math.logical_or</code></a> of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="v1/reduce_join.html"><code translate="no" dir="ltr">reduce_join(...)</code></a>: Joins all strings into a single string, or joins along an axis.</p> <p><a href="v1/reduce_logsumexp.html"><code translate="no" dir="ltr">reduce_logsumexp(...)</code></a>: Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)</p> <p><a href="v1/reduce_max.html"><code translate="no" dir="ltr">reduce_max(...)</code></a>: Computes <a href="../math/maximum.html"><code translate="no" dir="ltr">tf.math.maximum</code></a> of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="v1/reduce_mean.html"><code translate="no" dir="ltr">reduce_mean(...)</code></a>: Computes the mean of elements across dimensions of a tensor.</p> <p><a href="v1/reduce_min.html"><code translate="no" dir="ltr">reduce_min(...)</code></a>: Computes the <a href="../math/minimum.html"><code translate="no" dir="ltr">tf.math.minimum</code></a> of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="v1/reduce_prod.html"><code translate="no" dir="ltr">reduce_prod(...)</code></a>: Computes <a href="../math/multiply.html"><code translate="no" dir="ltr">tf.math.multiply</code></a> of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="v1/reduce_sum.html"><code translate="no" dir="ltr">reduce_sum(...)</code></a>: Computes the sum of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="../strings/regex_replace.html"><code translate="no" dir="ltr">regex_replace(...)</code></a>: Replace elements of <code translate="no" dir="ltr">input</code> matching regex <code translate="no" dir="ltr">pattern</code> with <code translate="no" dir="ltr">rewrite</code>.</p> <p><a href="../register_tensor_conversion_function.html"><code translate="no" dir="ltr">register_tensor_conversion_function(...)</code></a>: Registers a function for converting objects of <code translate="no" dir="ltr">base_type</code> to <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="../repeat.html"><code translate="no" dir="ltr">repeat(...)</code></a>: Repeat elements of <code translate="no" dir="ltr">input</code>.</p> <p><a href="v1/report_uninitialized_variables.html"><code translate="no" dir="ltr">report_uninitialized_variables(...)</code></a>: Adds ops to list the names of uninitialized variables.</p> <p><a href="../required_space_to_batch_paddings.html"><code translate="no" dir="ltr">required_space_to_batch_paddings(...)</code></a>: Calculate padding required to make block_shape divide input_shape.</p> <p><a href="v1/reset_default_graph.html"><code translate="no" dir="ltr">reset_default_graph(...)</code></a>: Clears the default graph stack and resets the global default graph.</p> <p><a href="../reshape.html"><code translate="no" dir="ltr">reshape(...)</code></a>: Reshapes a tensor.</p> <p><a href="v1/resource_variables_enabled.html"><code translate="no" dir="ltr">resource_variables_enabled(...)</code></a>: Returns <code translate="no" dir="ltr">True</code> if resource variables are enabled.</p> <p><a href="../reverse.html"><code translate="no" dir="ltr">reverse(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="v1/reverse_sequence.html"><code translate="no" dir="ltr">reverse_sequence(...)</code></a>: Reverses variable length slices. (deprecated arguments) (deprecated arguments)</p> <p><a href="../reverse.html"><code translate="no" dir="ltr">reverse_v2(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="../math/rint.html"><code translate="no" dir="ltr">rint(...)</code></a>: Returns element-wise integer closest to x.</p> <p><a href="../roll.html"><code translate="no" dir="ltr">roll(...)</code></a>: Rolls the elements of a tensor along an axis.</p> <p><a href="../math/round.html"><code translate="no" dir="ltr">round(...)</code></a>: Rounds the values of a tensor to the nearest integer, element-wise.</p> <p><a href="../math/rsqrt.html"><code translate="no" dir="ltr">rsqrt(...)</code></a>: Computes reciprocal of square root of x element-wise.</p> <p><a href="../dtypes/saturate_cast.html"><code translate="no" dir="ltr">saturate_cast(...)</code></a>: Performs a safe saturating cast of <code translate="no" dir="ltr">value</code> to <code translate="no" dir="ltr">dtype</code>.</p> <p><a href="v1/scalar_mul.html"><code translate="no" dir="ltr">scalar_mul(...)</code></a>: Multiplies a scalar times a <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">IndexedSlices</code> object.</p> <p><a href="v1/scan.html"><code translate="no" dir="ltr">scan(...)</code></a>: scan on the list of tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0.</p> <p><a href="v1/scatter_add.html"><code translate="no" dir="ltr">scatter_add(...)</code></a>: Adds sparse updates to the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="v1/scatter_div.html"><code translate="no" dir="ltr">scatter_div(...)</code></a>: Divides a variable reference by sparse updates.</p> <p><a href="v1/scatter_max.html"><code translate="no" dir="ltr">scatter_max(...)</code></a>: Reduces sparse updates into a variable reference using the <code translate="no" dir="ltr">max</code> operation.</p> <p><a href="v1/scatter_min.html"><code translate="no" dir="ltr">scatter_min(...)</code></a>: Reduces sparse updates into a variable reference using the <code translate="no" dir="ltr">min</code> operation.</p> <p><a href="v1/scatter_mul.html"><code translate="no" dir="ltr">scatter_mul(...)</code></a>: Multiplies sparse updates into a variable reference.</p> <p><a href="../scatter_nd.html"><code translate="no" dir="ltr">scatter_nd(...)</code></a>: Scatters <code translate="no" dir="ltr">updates</code> into a tensor of shape <code translate="no" dir="ltr">shape</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="v1/scatter_nd_add.html"><code translate="no" dir="ltr">scatter_nd_add(...)</code></a>: Applies sparse addition to individual values or slices in a Variable.</p> <p><a href="v1/scatter_nd_sub.html"><code translate="no" dir="ltr">scatter_nd_sub(...)</code></a>: Applies sparse subtraction to individual values or slices in a Variable.</p> <p><a href="v1/scatter_nd_update.html"><code translate="no" dir="ltr">scatter_nd_update(...)</code></a>: Applies sparse <code translate="no" dir="ltr">updates</code> to individual values or slices in a Variable.</p> <p><a href="v1/scatter_sub.html"><code translate="no" dir="ltr">scatter_sub(...)</code></a>: Subtracts sparse updates to a variable reference.</p> <p><a href="v1/scatter_update.html"><code translate="no" dir="ltr">scatter_update(...)</code></a>: Applies sparse updates to a variable reference.</p> <p><a href="../searchsorted.html"><code translate="no" dir="ltr">searchsorted(...)</code></a>: Searches for where a value would go in a sorted sequence.</p> <p><a href="../math/segment_max.html"><code translate="no" dir="ltr">segment_max(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../math/segment_mean.html"><code translate="no" dir="ltr">segment_mean(...)</code></a>: Computes the mean along segments of a tensor.</p> <p><a href="../math/segment_min.html"><code translate="no" dir="ltr">segment_min(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../math/segment_prod.html"><code translate="no" dir="ltr">segment_prod(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../math/segment_sum.html"><code translate="no" dir="ltr">segment_sum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../linalg/eigh.html"><code translate="no" dir="ltr">self_adjoint_eig(...)</code></a>: Computes the eigen decomposition of a batch of self-adjoint matrices.</p> <p><a href="../linalg/eigvalsh.html"><code translate="no" dir="ltr">self_adjoint_eigvals(...)</code></a>: Computes the eigenvalues of one or more self-adjoint matrices.</p> <p><a href="../sequence_mask.html"><code translate="no" dir="ltr">sequence_mask(...)</code></a>: Returns a mask tensor representing the first N positions of each cell.</p> <p><a href="v1/serialize_many_sparse.html"><code translate="no" dir="ltr">serialize_many_sparse(...)</code></a>: Serialize <code translate="no" dir="ltr">N</code>-minibatch <code translate="no" dir="ltr">SparseTensor</code> into an <code translate="no" dir="ltr">[N, 3]</code> <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="v1/serialize_sparse.html"><code translate="no" dir="ltr">serialize_sparse(...)</code></a>: Serialize a <code translate="no" dir="ltr">SparseTensor</code> into a 3-vector (1-D <code translate="no" dir="ltr">Tensor</code>) object.</p> <p><a href="../io/serialize_tensor.html"><code translate="no" dir="ltr">serialize_tensor(...)</code></a>: Transforms a Tensor into a serialized TensorProto proto.</p> <p><a href="v1/set_random_seed.html"><code translate="no" dir="ltr">set_random_seed(...)</code></a>: Sets the graph-level random seed for the default graph.</p> <p><a href="v1/setdiff1d.html"><code translate="no" dir="ltr">setdiff1d(...)</code></a>: Computes the difference between two lists of numbers or strings.</p> <p><a href="v1/shape.html"><code translate="no" dir="ltr">shape(...)</code></a>: Returns the shape of a tensor.</p> <p><a href="../shape_n.html"><code translate="no" dir="ltr">shape_n(...)</code></a>: Returns shape of tensors.</p> <p><a href="../math/sigmoid.html"><code translate="no" dir="ltr">sigmoid(...)</code></a>: Computes sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../math/sign.html"><code translate="no" dir="ltr">sign(...)</code></a>: Returns an element-wise indication of the sign of a number.</p> <p><a href="../math/sin.html"><code translate="no" dir="ltr">sin(...)</code></a>: Computes sine of x element-wise.</p> <p><a href="../math/sinh.html"><code translate="no" dir="ltr">sinh(...)</code></a>: Computes hyperbolic sine of x element-wise.</p> <p><a href="v1/size.html"><code translate="no" dir="ltr">size(...)</code></a>: Returns the size of a tensor.</p> <p><a href="../slice.html"><code translate="no" dir="ltr">slice(...)</code></a>: Extracts a slice from a tensor.</p> <p><a href="../sort.html"><code translate="no" dir="ltr">sort(...)</code></a>: Sorts a tensor.</p> <p><a href="v1/space_to_batch.html"><code translate="no" dir="ltr">space_to_batch(...)</code></a>: SpaceToBatch for 4-D tensors of type T.</p> <p><a href="../space_to_batch_nd.html"><code translate="no" dir="ltr">space_to_batch_nd(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="v1/space_to_depth.html"><code translate="no" dir="ltr">space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="v1/sparse_add.html"><code translate="no" dir="ltr">sparse_add(...)</code></a>: Adds two tensors, at least one of each is a <code translate="no" dir="ltr">SparseTensor</code>. (deprecated arguments)</p> <p><a href="v1/sparse_concat.html"><code translate="no" dir="ltr">sparse_concat(...)</code></a>: Concatenates a list of <code translate="no" dir="ltr">SparseTensor</code> along the specified dimension. (deprecated arguments)</p> <p><a href="../sparse/fill_empty_rows.html"><code translate="no" dir="ltr">sparse_fill_empty_rows(...)</code></a>: Fills empty rows in the input 2-D <code translate="no" dir="ltr">SparseTensor</code> with a default value.</p> <p><a href="../sparse/mask.html"><code translate="no" dir="ltr">sparse_mask(...)</code></a>: Masks elements of <code translate="no" dir="ltr">IndexedSlices</code>.</p> <p><a href="v1/sparse_matmul.html"><code translate="no" dir="ltr">sparse_matmul(...)</code></a>: Multiply matrix "a" by matrix "b".</p> <p><a href="../sparse/maximum.html"><code translate="no" dir="ltr">sparse_maximum(...)</code></a>: Returns the element-wise max of two SparseTensors.</p> <p><a href="v1/sparse_merge.html"><code translate="no" dir="ltr">sparse_merge(...)</code></a>: Combines a batch of feature ids and values into a single <code translate="no" dir="ltr">SparseTensor</code>. (deprecated)</p> <p><a href="../sparse/minimum.html"><code translate="no" dir="ltr">sparse_minimum(...)</code></a>: Returns the element-wise min of two SparseTensors.</p> <p><a href="v1/sparse_placeholder.html"><code translate="no" dir="ltr">sparse_placeholder(...)</code></a>: Inserts a placeholder for a sparse tensor that will be always fed.</p> <p><a href="v1/sparse_reduce_max.html"><code translate="no" dir="ltr">sparse_reduce_max(...)</code></a>: Computes <a href="../sparse/maximum.html"><code translate="no" dir="ltr">tf.sparse.maximum</code></a> of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)</p> <p><a href="v1/sparse_reduce_max_sparse.html"><code translate="no" dir="ltr">sparse_reduce_max_sparse(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)</p> <p><a href="v1/sparse_reduce_sum.html"><code translate="no" dir="ltr">sparse_reduce_sum(...)</code></a>: Computes <a href="../sparse/add.html"><code translate="no" dir="ltr">tf.sparse.add</code></a> of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)</p> <p><a href="v1/sparse_reduce_sum_sparse.html"><code translate="no" dir="ltr">sparse_reduce_sum_sparse(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)</p> <p><a href="../sparse/reorder.html"><code translate="no" dir="ltr">sparse_reorder(...)</code></a>: Reorders a <code translate="no" dir="ltr">SparseTensor</code> into the canonical, row-major ordering.</p> <p><a href="../sparse/reset_shape.html"><code translate="no" dir="ltr">sparse_reset_shape(...)</code></a>: Resets the shape of a <code translate="no" dir="ltr">SparseTensor</code> with indices and values unchanged.</p> <p><a href="../sparse/reshape.html"><code translate="no" dir="ltr">sparse_reshape(...)</code></a>: Reshapes a <code translate="no" dir="ltr">SparseTensor</code> to represent values in a new dense shape.</p> <p><a href="../sparse/retain.html"><code translate="no" dir="ltr">sparse_retain(...)</code></a>: Retains specified non-empty values within a <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="v1/sparse_segment_mean.html"><code translate="no" dir="ltr">sparse_segment_mean(...)</code></a>: Computes the mean along sparse segments of a tensor.</p> <p><a href="v1/sparse_segment_sqrt_n.html"><code translate="no" dir="ltr">sparse_segment_sqrt_n(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt(N).</p> <p><a href="v1/sparse_segment_sum.html"><code translate="no" dir="ltr">sparse_segment_sum(...)</code></a>: Computes the sum along sparse segments of a tensor.</p> <p><a href="../sparse/slice.html"><code translate="no" dir="ltr">sparse_slice(...)</code></a>: Slice a <code translate="no" dir="ltr">SparseTensor</code> based on the <code translate="no" dir="ltr">start</code> and <code translate="no" dir="ltr">size</code>.</p> <p><a href="../sparse/softmax.html"><code translate="no" dir="ltr">sparse_softmax(...)</code></a>: Applies softmax to a batched N-D <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="v1/sparse_split.html"><code translate="no" dir="ltr">sparse_split(...)</code></a>: Split a <code translate="no" dir="ltr">SparseTensor</code> into <code translate="no" dir="ltr">num_split</code> tensors along <code translate="no" dir="ltr">axis</code>. (deprecated arguments)</p> <p><a href="../sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">sparse_tensor_dense_matmul(...)</code></a>: Multiply SparseTensor (or dense Matrix) (of rank 2) "A" by dense matrix</p> <p><a href="../sparse/to_dense.html"><code translate="no" dir="ltr">sparse_tensor_to_dense(...)</code></a>: Converts a <code translate="no" dir="ltr">SparseTensor</code> into a dense tensor.</p> <p><a href="v1/sparse_to_dense.html"><code translate="no" dir="ltr">sparse_to_dense(...)</code></a>: Converts a sparse representation into a dense tensor. (deprecated)</p> <p><a href="../sparse/to_indicator.html"><code translate="no" dir="ltr">sparse_to_indicator(...)</code></a>: Converts a <code translate="no" dir="ltr">SparseTensor</code> of ids into a dense bool indicator tensor.</p> <p><a href="../sparse/transpose.html"><code translate="no" dir="ltr">sparse_transpose(...)</code></a>: Transposes a <code translate="no" dir="ltr">SparseTensor</code></p> <p><a href="../split.html"><code translate="no" dir="ltr">split(...)</code></a>: Splits a tensor <code translate="no" dir="ltr">value</code> into a list of sub tensors.</p> <p><a href="../math/sqrt.html"><code translate="no" dir="ltr">sqrt(...)</code></a>: Computes element-wise square root of the input tensor.</p> <p><a href="../math/square.html"><code translate="no" dir="ltr">square(...)</code></a>: Computes square of x element-wise.</p> <p><a href="../math/squared_difference.html"><code translate="no" dir="ltr">squared_difference(...)</code></a>: Returns conj(x - y)(x - y) element-wise.</p> <p><a href="v1/squeeze.html"><code translate="no" dir="ltr">squeeze(...)</code></a>: Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)</p> <p><a href="../stack.html"><code translate="no" dir="ltr">stack(...)</code></a>: Stacks a list of rank-<code translate="no" dir="ltr">R</code> tensors into one rank-<code translate="no" dir="ltr">(R+1)</code> tensor.</p> <p><a href="../stop_gradient.html"><code translate="no" dir="ltr">stop_gradient(...)</code></a>: Stops gradient computation.</p> <p><a href="../strided_slice.html"><code translate="no" dir="ltr">strided_slice(...)</code></a>: Extracts a strided slice of a tensor (generalized Python array indexing).</p> <p><a href="../strings/join.html"><code translate="no" dir="ltr">string_join(...)</code></a>: Perform element-wise concatenation of a list of string tensors.</p> <p><a href="v1/string_split.html"><code translate="no" dir="ltr">string_split(...)</code></a>: Split elements of <code translate="no" dir="ltr">source</code> based on <code translate="no" dir="ltr">delimiter</code>. (deprecated arguments)</p> <p><a href="../strings/strip.html"><code translate="no" dir="ltr">string_strip(...)</code></a>: Strip leading and trailing whitespaces from the Tensor.</p> <p><a href="v1/string_to_hash_bucket.html"><code translate="no" dir="ltr">string_to_hash_bucket(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../strings/to_hash_bucket_fast.html"><code translate="no" dir="ltr">string_to_hash_bucket_fast(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../strings/to_hash_bucket_strong.html"><code translate="no" dir="ltr">string_to_hash_bucket_strong(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="v1/string_to_number.html"><code translate="no" dir="ltr">string_to_number(...)</code></a>: Converts each string in the input Tensor to the specified numeric type.</p> <p><a href="v1/substr.html"><code translate="no" dir="ltr">substr(...)</code></a>: Return substrings from <code translate="no" dir="ltr">Tensor</code> of strings.</p> <p><a href="../math/subtract.html"><code translate="no" dir="ltr">subtract(...)</code></a>: Returns x - y element-wise.</p> <p><a href="../linalg/svd.html"><code translate="no" dir="ltr">svd(...)</code></a>: Computes the singular value decompositions of one or more matrices.</p> <p><a href="../switch_case.html"><code translate="no" dir="ltr">switch_case(...)</code></a>: Create a switch/case operation, i.e. an integer-indexed conditional.</p> <p><a href="v1/tables_initializer.html"><code translate="no" dir="ltr">tables_initializer(...)</code></a>: Returns an Op that initializes all tables of the default graph.</p> <p><a href="../math/tan.html"><code translate="no" dir="ltr">tan(...)</code></a>: Computes tan of x element-wise.</p> <p><a href="../math/tanh.html"><code translate="no" dir="ltr">tanh(...)</code></a>: Computes hyperbolic tangent of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../tensor_scatter_nd_add.html"><code translate="no" dir="ltr">tensor_scatter_add(...)</code></a>: Adds sparse <code translate="no" dir="ltr">updates</code> to an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../tensor_scatter_nd_add.html"><code translate="no" dir="ltr">tensor_scatter_nd_add(...)</code></a>: Adds sparse <code translate="no" dir="ltr">updates</code> to an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../tensor_scatter_nd_max.html"><code translate="no" dir="ltr">tensor_scatter_nd_max(...)</code></a>: Apply a sparse update to a tensor taking the element-wise maximum.</p> <p><a href="../tensor_scatter_nd_min.html"><code translate="no" dir="ltr">tensor_scatter_nd_min(...)</code></a></p> <p><a href="../tensor_scatter_nd_sub.html"><code translate="no" dir="ltr">tensor_scatter_nd_sub(...)</code></a>: Subtracts sparse <code translate="no" dir="ltr">updates</code> from an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../tensor_scatter_nd_update.html"><code translate="no" dir="ltr">tensor_scatter_nd_update(...)</code></a>: Scatter <code translate="no" dir="ltr">updates</code> into an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../tensor_scatter_nd_sub.html"><code translate="no" dir="ltr">tensor_scatter_sub(...)</code></a>: Subtracts sparse <code translate="no" dir="ltr">updates</code> from an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../tensor_scatter_nd_update.html"><code translate="no" dir="ltr">tensor_scatter_update(...)</code></a>: Scatter <code translate="no" dir="ltr">updates</code> into an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../tensordot.html"><code translate="no" dir="ltr">tensordot(...)</code></a>: Tensor contraction of a and b along specified axes and outer product.</p> <p><a href="../tile.html"><code translate="no" dir="ltr">tile(...)</code></a>: Constructs a tensor by tiling a given tensor.</p> <p><a href="../timestamp.html"><code translate="no" dir="ltr">timestamp(...)</code></a>: Provides the time since epoch in seconds.</p> <p><a href="v1/to_bfloat16.html"><code translate="no" dir="ltr">to_bfloat16(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">bfloat16</code>. (deprecated)</p> <p><a href="v1/to_complex128.html"><code translate="no" dir="ltr">to_complex128(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">complex128</code>. (deprecated)</p> <p><a href="v1/to_complex64.html"><code translate="no" dir="ltr">to_complex64(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">complex64</code>. (deprecated)</p> <p><a href="v1/to_double.html"><code translate="no" dir="ltr">to_double(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">float64</code>. (deprecated)</p> <p><a href="v1/to_float.html"><code translate="no" dir="ltr">to_float(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">float32</code>. (deprecated)</p> <p><a href="v1/to_int32.html"><code translate="no" dir="ltr">to_int32(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">int32</code>. (deprecated)</p> <p><a href="v1/to_int64.html"><code translate="no" dir="ltr">to_int64(...)</code></a>: Casts a tensor to type <code translate="no" dir="ltr">int64</code>. (deprecated)</p> <p><a href="../linalg/trace.html"><code translate="no" dir="ltr">trace(...)</code></a>: Compute the trace of a tensor <code translate="no" dir="ltr">x</code>.</p> <p><a href="v1/trainable_variables.html"><code translate="no" dir="ltr">trainable_variables(...)</code></a>: Returns all variables created with <code translate="no" dir="ltr">trainable=True</code>.</p> <p><a href="v1/transpose.html"><code translate="no" dir="ltr">transpose(...)</code></a>: Transposes <code translate="no" dir="ltr">a</code>.</p> <p><a href="../math/truediv.html"><code translate="no" dir="ltr">truediv(...)</code></a>: Divides x / y elementwise (using Python 3 division operator semantics).</p> <p><a href="../random/truncated_normal.html"><code translate="no" dir="ltr">truncated_normal(...)</code></a>: Outputs random values from a truncated normal distribution.</p> <p><a href="../truncatediv.html"><code translate="no" dir="ltr">truncatediv(...)</code></a>: Returns x / y element-wise for integer types.</p> <p><a href="../truncatemod.html"><code translate="no" dir="ltr">truncatemod(...)</code></a>: Returns element-wise remainder of division. This emulates C semantics in that</p> <p><a href="v1/tuple.html"><code translate="no" dir="ltr">tuple(...)</code></a>: Group tensors together.</p> <p><a href="../type_spec_from_value.html"><code translate="no" dir="ltr">type_spec_from_value(...)</code></a>: Returns a <a href="../typespec.html"><code translate="no" dir="ltr">tf.TypeSpec</code></a> that represents the given <code translate="no" dir="ltr">value</code>.</p> <p><a href="../unique.html"><code translate="no" dir="ltr">unique(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="../unique_with_counts.html"><code translate="no" dir="ltr">unique_with_counts(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="../unravel_index.html"><code translate="no" dir="ltr">unravel_index(...)</code></a>: Converts an array of flat indices into a tuple of coordinate arrays.</p> <p><a href="../math/unsorted_segment_max.html"><code translate="no" dir="ltr">unsorted_segment_max(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../math/unsorted_segment_mean.html"><code translate="no" dir="ltr">unsorted_segment_mean(...)</code></a>: Computes the mean along segments of a tensor.</p> <p><a href="../math/unsorted_segment_min.html"><code translate="no" dir="ltr">unsorted_segment_min(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../math/unsorted_segment_prod.html"><code translate="no" dir="ltr">unsorted_segment_prod(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../math/unsorted_segment_sqrt_n.html"><code translate="no" dir="ltr">unsorted_segment_sqrt_n(...)</code></a>: Computes the sum along segments of a tensor divided by the sqrt(N).</p> <p><a href="../math/unsorted_segment_sum.html"><code translate="no" dir="ltr">unsorted_segment_sum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../unstack.html"><code translate="no" dir="ltr">unstack(...)</code></a>: Unpacks the given dimension of a rank-<code translate="no" dir="ltr">R</code> tensor into rank-<code translate="no" dir="ltr">(R-1)</code> tensors.</p> <p><a href="v1/variable_axis_size_partitioner.html"><code translate="no" dir="ltr">variable_axis_size_partitioner(...)</code></a>: Get a partitioner for VariableScope to keep shards below <code translate="no" dir="ltr">max_shard_bytes</code>.</p> <p><a href="v1/variable_creator_scope.html"><code translate="no" dir="ltr">variable_creator_scope(...)</code></a>: Scope which defines a variable creation function to be used by variable().</p> <p><a href="v1/variable_op_scope.html"><code translate="no" dir="ltr">variable_op_scope(...)</code></a>: Deprecated: context manager for defining an op that creates variables.</p> <p><a href="v1/variables_initializer.html"><code translate="no" dir="ltr">variables_initializer(...)</code></a>: Returns an Op that initializes a list of variables.</p> <p><a href="../vectorized_map.html"><code translate="no" dir="ltr">vectorized_map(...)</code></a>: Parallel map on the list of tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0.</p> <p><a href="v1/verify_tensor_all_finite.html"><code translate="no" dir="ltr">verify_tensor_all_finite(...)</code></a>: Assert that the tensor does not contain any NaN's or Inf's.</p> <p><a href="v1/where.html"><code translate="no" dir="ltr">where(...)</code></a>: Return the elements, either from <code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>, depending on the <code translate="no" dir="ltr">condition</code>.</p> <p><a href="../where.html"><code translate="no" dir="ltr">where_v2(...)</code></a>: Returns the indices of non-zero elements, or multiplexes <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="v1/while_loop.html"><code translate="no" dir="ltr">while_loop(...)</code></a>: Repeat <code translate="no" dir="ltr">body</code> while the condition <code translate="no" dir="ltr">cond</code> is true.</p> <p><a href="v1/wrap_function.html"><code translate="no" dir="ltr">wrap_function(...)</code></a>: Wraps the TF 1.x function fn into a graph function.</p> <p><a href="../io/write_file.html"><code translate="no" dir="ltr">write_file(...)</code></a>: Writes <code translate="no" dir="ltr">contents</code> to the file at input <code translate="no" dir="ltr">filename</code>.</p> <p><a href="../zeros.html"><code translate="no" dir="ltr">zeros(...)</code></a>: Creates a tensor with all elements set to zero.</p> <p><a href="v1/zeros_like.html"><code translate="no" dir="ltr">zeros_like(...)</code></a>: Creates a tensor with all elements set to zero.</p> <p><a href="../math/zeta.html"><code translate="no" dir="ltr">zeta(...)</code></a>: Compute the Hurwitz zeta function \(\zeta(x, q)\).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Other Members</th></tr> 
<tr> <td> AUTO_REUSE </td> <td> <code translate="no" dir="ltr">&lt;_ReuseMode.AUTO_REUSE: 1&gt;</code> <p>When passed in as the value for the <code translate="no" dir="ltr">reuse</code> flag, <code translate="no" dir="ltr">AUTO_REUSE</code> indicates that get_variable() should create the requested variable if it doesn't exist or, if it does exist, simply return it. </p>
</td> </tr>
<tr> <td> COMPILER_VERSION </td> <td> <code translate="no" dir="ltr">'9.3.1 20200408'</code> </td> </tr>
<tr> <td> CXX11_ABI_FLAG </td> <td> <code translate="no" dir="ltr">1</code> </td> </tr>
<tr> <td> GIT_VERSION </td> <td> <code translate="no" dir="ltr">'v2.9.0-rc2-42-g8a20d54a3c1'</code> </td> </tr>
<tr> <td> GRAPH_DEF_VERSION </td> <td> <code translate="no" dir="ltr">1087</code> </td> </tr>
<tr> <td> GRAPH_DEF_VERSION_MIN_CONSUMER </td> <td> <code translate="no" dir="ltr">0</code> </td> </tr>
<tr> <td> GRAPH_DEF_VERSION_MIN_PRODUCER </td> <td> <code translate="no" dir="ltr">0</code> </td> </tr>
<tr> <td> MONOLITHIC_BUILD </td> <td> <code translate="no" dir="ltr">0</code> </td> </tr>
<tr> <td> QUANTIZED_DTYPES </td> <td> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">{
 tf.qint16,
 tf.qint16_ref,
 tf.qint32,
 tf.qint32_ref,
 tf.qint8,
 tf.qint8_ref,
 tf.quint16,
 tf.quint16_ref,
 tf.quint8,
 tf.quint8_ref
}
</pre> 
</td> </tr>
<tr> <td> VERSION </td> <td> <code translate="no" dir="ltr">'2.9.0'</code> </td> </tr>
<tr> <td> <strong>version</strong> </td> <td> <code translate="no" dir="ltr">'2.9.0'</code> </td> </tr>
<tr> <td> bfloat16 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>16-bit bfloat (brain floating point). </p>
</td> </tr>
<tr> <td> bool </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Boolean. </p>
</td> </tr>
<tr> <td> complex128 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>128-bit complex. </p>
</td> </tr>
<tr> <td> complex64 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>64-bit complex. </p>
</td> </tr>
<tr> <td> double </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>64-bit (double precision) floating-point. </p>
</td> </tr>
<tr> <td> float16 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>16-bit (half precision) floating-point. </p>
</td> </tr>
<tr> <td> float32 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>32-bit (single precision) floating-point. </p>
</td> </tr>
<tr> <td> float64 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>64-bit (double precision) floating-point. </p>
</td> </tr>
<tr> <td> half </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>16-bit (half precision) floating-point. </p>
</td> </tr>
<tr> <td> int16 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Signed 16-bit integer. </p>
</td> </tr>
<tr> <td> int32 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Signed 32-bit integer. </p>
</td> </tr>
<tr> <td> int64 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Signed 64-bit integer. </p>
</td> </tr>
<tr> <td> int8 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Signed 8-bit integer. </p>
</td> </tr>
<tr> <td> newaxis </td> <td> <code translate="no" dir="ltr">None</code> </td> </tr>
<tr> <td> qint16 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Signed quantized 16-bit integer. </p>
</td> </tr>
<tr> <td> qint32 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>signed quantized 32-bit integer. </p>
</td> </tr>
<tr> <td> qint8 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Signed quantized 8-bit integer. </p>
</td> </tr>
<tr> <td> quint16 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Unsigned quantized 16-bit integer. </p>
</td> </tr>
<tr> <td> quint8 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Unsigned quantized 8-bit integer. </p>
</td> </tr>
<tr> <td> resource </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Handle to a mutable, dynamically allocated resource. </p>
</td> </tr>
<tr> <td> string </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Variable-length string, represented as byte array. </p>
</td> </tr>
<tr> <td> uint16 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Unsigned 16-bit (word) integer. </p>
</td> </tr>
<tr> <td> uint32 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Unsigned 32-bit (dword) integer. </p>
</td> </tr>
<tr> <td> uint64 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Unsigned 64-bit (qword) integer. </p>
</td> </tr>
<tr> <td> uint8 </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Unsigned 8-bit (byte) integer. </p>
</td> </tr>
<tr> <td> variant </td> <td> Instance of <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> <p>Data of arbitrary type (known at runtime). </p>
</td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1</a>
  </p>
</div>
