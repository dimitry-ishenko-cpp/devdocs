<h1 class="devsite-page-title" tabindex="-1"> tf.compat.v1.nn.static_rnn </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.nn.static_rnn"> <meta itemprop="path" content="Stable"> </div>   <p>Creates a recurrent neural network specified by RNNCell <code translate="no" dir="ltr">cell</code>. (deprecated)</p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.compat.v1.nn.static_rnn(
    cell,
    inputs,
    initial_state=None,
    dtype=None,
    sequence_length=None,
    scope=None
)
</pre></devsite-code>  <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use <a href="../../../keras/layers/rnn.html"><code translate="no" dir="ltr">keras.layers.RNN(cell, unroll=True)</code></a>, which is equivalent to this API</span></aside> <p>The simplest form of RNN network generated is:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">state = cell.zero_state(...)
outputs = []
for input_ in inputs:
  output, state = cell(input_, state)
  outputs.append(output)
return (outputs, state)
</pre></devsite-code> <p>However, a few other options are available:</p> <p>An initial state can be provided. If the sequence_length vector is provided, dynamic calculation is performed. This method of calculation does not compute the RNN steps past the maximum sequence length of the minibatch (thus saving computational time), and properly propagates the state at an example's sequence length to the final state output.</p> <p>The dynamic calculation performed is, at time <code translate="no" dir="ltr">t</code> for batch row <code translate="no" dir="ltr">b</code>,</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">(output, state)(b, t) =
  (t &gt;= sequence_length(b))
    ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))
    : cell(input(b, t), state(b, t - 1))
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">cell</code> </td> <td> An instance of RNNCell. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> A length T list of inputs, each a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[batch_size, input_size]</code>, or a nested tuple of such elements. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">initial_state</code> </td> <td> (optional) An initial state for the RNN. If <code translate="no" dir="ltr">cell.state_size</code> is an integer, this must be a <code translate="no" dir="ltr">Tensor</code> of appropriate type and shape <code translate="no" dir="ltr">[batch_size, cell.state_size]</code>. If <code translate="no" dir="ltr">cell.state_size</code> is a tuple, this should be a tuple of tensors having shapes <code translate="no" dir="ltr">[batch_size, s] for s in cell.state_size</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> (optional) The data type for the initial state and expected output. Required if initial_state is not provided or RNN state has a heterogeneous dtype. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sequence_length</code> </td> <td> Specifies the length of each sequence in inputs. An int32 or int64 vector (tensor) size <code translate="no" dir="ltr">[batch_size]</code>, values in <code translate="no" dir="ltr">[0, T)</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">scope</code> </td> <td> VariableScope for the created subgraph; defaults to "rnn". </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A pair (outputs, state) where: <ul> <li><p>outputs is a length T list of outputs (one for each input), or a nested tuple of such elements.</p></li> <li><p>state is the final state </p></li>
</ul>
</td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">cell</code> is not an instance of RNNCell. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">inputs</code> is <code translate="no" dir="ltr">None</code> or an empty list, or if the input depth (column size) cannot be inferred from inputs via shape inference. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/static_rnn" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/static_rnn</a>
  </p>
</div>
