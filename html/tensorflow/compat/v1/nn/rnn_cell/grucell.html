<h1 class="devsite-page-title">tf.compat.v1.nn.rnn_cell.GRUCell</h1> <devsite-bookmark></devsite-bookmark>       <p>Gated Recurrent Unit cell.</p> <p>Inherits From: <a href="rnncell.html"><code translate="no" dir="ltr">RNNCell</code></a>, <a href="../../layers/layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../../keras/layers/layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../../module.html"><code translate="no" dir="ltr">Module</code></a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.nn.rnn_cell.GRUCell(
    num_units,
    activation=None,
    reuse=None,
    kernel_initializer=None,
    bias_initializer=None,
    name=None,
    dtype=None,
    **kwargs
)
</pre>  <p>Note that this cell is not optimized for performance. Please use <code translate="no" dir="ltr">tf.contrib.cudnn_rnn.CudnnGRU</code> for better performance on GPU, or <code translate="no" dir="ltr">tf.contrib.rnn.GRUBlockCellV2</code> for better performance on CPU.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">num_units</code> </td> <td> int, The number of units in the GRU cell. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activation</code> </td> <td> Nonlinearity to use. Default: <code translate="no" dir="ltr">tanh</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reuse</code> </td> <td> (optional) Python boolean describing whether to reuse variables in an existing scope. If not <code translate="no" dir="ltr">True</code>, and the existing scope already has the given variables, an error is raised. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_initializer</code> </td> <td> (optional) The initializer to use for the weight and projection matrices. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_initializer</code> </td> <td> (optional) The initializer to use for the bias. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> String, the name of the layer. Layers with the same name will share weights, but to avoid mistakes we require reuse=True in such cases. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> Default dtype of the layer (default of <code translate="no" dir="ltr">None</code> means use the type of the first input). Required when <code translate="no" dir="ltr">build</code> is called before <code translate="no" dir="ltr">call</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Dict, keyword named properties for common layer attributes, like <code translate="no" dir="ltr">trainable</code> etc when constructing the cell from configs of get_config(). <p>References: Learning Phrase Representations using RNN Encoder Decoder for Statistical Machine Translation: <a href="https://aclanthology.coli.uni-saarland.de/papers/D14-1179/d14-1179">Cho et al., 2014</a> (<a href="http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf">pdf</a>) </p>
</td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">graph</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_size</code> </td> <td> Integer or TensorShape: size of outputs produced by this cell. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">scope_name</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">state_size</code> </td> <td> size(s) of state(s) used by this cell. <p>It can be represented by an Integer, a TensorShape or a tuple of Integers or TensorShapes. </p>
</td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="apply" data-text="apply"><code translate="no" dir="ltr">apply</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/legacy_tf_layers/base.py#L239-L240">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
apply(
    *args, **kwargs
)
</pre> <h3 id="get_initial_state" data-text="get_initial_state"><code translate="no" dir="ltr">get_initial_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/layers/rnn/legacy_cells.py#L239-L266">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_initial_state(
    inputs=None, batch_size=None, dtype=None
)
</pre> <h3 id="get_losses_for" data-text="get_losses_for"><code translate="no" dir="ltr">get_losses_for</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/engine/base_layer_v1.py#L1341-L1358">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_losses_for(
    inputs
)
</pre> <p>Retrieves losses relevant to a specific set of inputs.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> Input tensor or list/tuple of input tensors. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> List of loss tensors of the layer that depend on <code translate="no" dir="ltr">inputs</code>. </td> </tr> 
</table> <h3 id="get_updates_for" data-text="get_updates_for"><code translate="no" dir="ltr">get_updates_for</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/engine/base_layer_v1.py#L1322-L1339">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_updates_for(
    inputs
)
</pre> <p>Retrieves updates relevant to a specific set of inputs.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> Input tensor or list/tuple of input tensors. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> List of update ops of the layer that depend on <code translate="no" dir="ltr">inputs</code>. </td> </tr> 
</table> <h3 id="zero_state" data-text="zero_state"><code translate="no" dir="ltr">zero_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/layers/rnn/legacy_cells.py#L268-L297">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
zero_state(
    batch_size, dtype
)
</pre> <p>Return zero-filled state tensor(s).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> int, float, or unit Tensor representing the batch size. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> the data type to use for the state. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> If <code translate="no" dir="ltr">state_size</code> is an int or TensorShape, then the return value is a <code translate="no" dir="ltr">N-D</code> tensor of shape <code translate="no" dir="ltr">[batch_size, state_size]</code> filled with zeros. <p>If <code translate="no" dir="ltr">state_size</code> is a nested list or tuple, then the return value is a nested list or tuple (of the same structure) of <code translate="no" dir="ltr">2-D</code> tensors with the shapes <code translate="no" dir="ltr">[batch_size, s]</code> for each s in <code translate="no" dir="ltr">state_size</code>. </p>
</td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/nn/rnn_cell/GRUCell" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/nn/rnn_cell/GRUCell</a>
  </p>
</div>
