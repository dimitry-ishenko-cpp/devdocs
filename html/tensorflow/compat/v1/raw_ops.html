<h1 class="devsite-page-title" tabindex="-1"> Module: tf.compat.v1.raw_ops </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>  <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.raw_ops"> <meta itemprop="path" content="Stable"> </div>   <p>Public API for tf._api.v2.raw_ops namespace</p> <h2 id="functions" data-text="Functions" tabindex="-1">Functions</h2> <p><a href="../../raw_ops/abort.html"><code translate="no" dir="ltr">Abort(...)</code></a>: Raise a exception to abort the process when called.</p> <p><a href="../../raw_ops/abs.html"><code translate="no" dir="ltr">Abs(...)</code></a>: Computes the absolute value of a tensor.</p> <p><a href="../../raw_ops/accumulatenv2.html"><code translate="no" dir="ltr">AccumulateNV2(...)</code></a>: Returns the element-wise sum of a list of tensors.</p> <p><a href="../../raw_ops/accumulatorapplygradient.html"><code translate="no" dir="ltr">AccumulatorApplyGradient(...)</code></a>: Applies a gradient to a given accumulator.</p> <p><a href="../../raw_ops/accumulatornumaccumulated.html"><code translate="no" dir="ltr">AccumulatorNumAccumulated(...)</code></a>: Returns the number of gradients aggregated in the given accumulators.</p> <p><a href="../../raw_ops/accumulatorsetglobalstep.html"><code translate="no" dir="ltr">AccumulatorSetGlobalStep(...)</code></a>: Updates the accumulator with a new value for global_step.</p> <p><a href="../../raw_ops/accumulatortakegradient.html"><code translate="no" dir="ltr">AccumulatorTakeGradient(...)</code></a>: Extracts the average gradient in the given ConditionalAccumulator.</p> <p><a href="../../raw_ops/acos.html"><code translate="no" dir="ltr">Acos(...)</code></a>: Computes acos of x element-wise.</p> <p><a href="../../raw_ops/acosh.html"><code translate="no" dir="ltr">Acosh(...)</code></a>: Computes inverse hyperbolic cosine of x element-wise.</p> <p><a href="../../raw_ops/add.html"><code translate="no" dir="ltr">Add(...)</code></a>: Returns x + y element-wise.</p> <p><a href="../../raw_ops/addmanysparsetotensorsmap.html"><code translate="no" dir="ltr">AddManySparseToTensorsMap(...)</code></a>: Add an <code translate="no" dir="ltr">N</code>-minibatch <code translate="no" dir="ltr">SparseTensor</code> to a <code translate="no" dir="ltr">SparseTensorsMap</code>, return <code translate="no" dir="ltr">N</code> handles.</p> <p><a href="../../raw_ops/addn.html"><code translate="no" dir="ltr">AddN(...)</code></a>: Add all input tensors element wise.</p> <p><a href="../../raw_ops/addsparsetotensorsmap.html"><code translate="no" dir="ltr">AddSparseToTensorsMap(...)</code></a>: Add a <code translate="no" dir="ltr">SparseTensor</code> to a <code translate="no" dir="ltr">SparseTensorsMap</code> return its handle.</p> <p><a href="../../raw_ops/addv2.html"><code translate="no" dir="ltr">AddV2(...)</code></a>: Returns x + y element-wise.</p> <p><a href="../../raw_ops/adjustcontrast.html"><code translate="no" dir="ltr">AdjustContrast(...)</code></a>: Deprecated. Disallowed in GraphDef version &gt;= 2.</p> <p><a href="../../raw_ops/adjustcontrastv2.html"><code translate="no" dir="ltr">AdjustContrastv2(...)</code></a>: Adjust the contrast of one or more images.</p> <p><a href="../../raw_ops/adjusthue.html"><code translate="no" dir="ltr">AdjustHue(...)</code></a>: Adjust the hue of one or more images.</p> <p><a href="../../raw_ops/adjustsaturation.html"><code translate="no" dir="ltr">AdjustSaturation(...)</code></a>: Adjust the saturation of one or more images.</p> <p><a href="../../raw_ops/all.html"><code translate="no" dir="ltr">All(...)</code></a>: Computes the "logical and" of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/allcandidatesampler.html"><code translate="no" dir="ltr">AllCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/alltoall.html"><code translate="no" dir="ltr">AllToAll(...)</code></a>: An Op to exchange data across TPU replicas.</p> <p><a href="../../raw_ops/angle.html"><code translate="no" dir="ltr">Angle(...)</code></a>: Returns the argument of a complex number.</p> <p><a href="../../raw_ops/anonymoushashtable.html"><code translate="no" dir="ltr">AnonymousHashTable(...)</code></a>: Creates a uninitialized anonymous hash table.</p> <p><a href="../../raw_ops/anonymousiterator.html"><code translate="no" dir="ltr">AnonymousIterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/anonymousiteratorv2.html"><code translate="no" dir="ltr">AnonymousIteratorV2(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/anonymousiteratorv3.html"><code translate="no" dir="ltr">AnonymousIteratorV3(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/anonymousmemorycache.html"><code translate="no" dir="ltr">AnonymousMemoryCache(...)</code></a></p> <p><a href="../../raw_ops/anonymousmultideviceiterator.html"><code translate="no" dir="ltr">AnonymousMultiDeviceIterator(...)</code></a>: A container for a multi device iterator resource.</p> <p><a href="../../raw_ops/anonymousmultideviceiteratorv3.html"><code translate="no" dir="ltr">AnonymousMultiDeviceIteratorV3(...)</code></a>: A container for a multi device iterator resource.</p> <p><a href="../../raw_ops/anonymousmutabledensehashtable.html"><code translate="no" dir="ltr">AnonymousMutableDenseHashTable(...)</code></a>: Creates an empty anonymous mutable hash table that uses tensors as the backing store.</p> <p><a href="../../raw_ops/anonymousmutablehashtable.html"><code translate="no" dir="ltr">AnonymousMutableHashTable(...)</code></a>: Creates an empty anonymous mutable hash table.</p> <p><a href="../../raw_ops/anonymousmutablehashtableoftensors.html"><code translate="no" dir="ltr">AnonymousMutableHashTableOfTensors(...)</code></a>: Creates an empty anonymous mutable hash table of vector values.</p> <p><a href="../../raw_ops/anonymousrandomseedgenerator.html"><code translate="no" dir="ltr">AnonymousRandomSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/anonymousseedgenerator.html"><code translate="no" dir="ltr">AnonymousSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/any.html"><code translate="no" dir="ltr">Any(...)</code></a>: Computes the "logical or" of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/applyadamax.html"><code translate="no" dir="ltr">ApplyAdaMax(...)</code></a>: Update '*var' according to the AdaMax algorithm.</p> <p><a href="../../raw_ops/applyadadelta.html"><code translate="no" dir="ltr">ApplyAdadelta(...)</code></a>: Update '*var' according to the adadelta scheme.</p> <p><a href="../../raw_ops/applyadagrad.html"><code translate="no" dir="ltr">ApplyAdagrad(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/applyadagradda.html"><code translate="no" dir="ltr">ApplyAdagradDA(...)</code></a>: Update '*var' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/applyadagradv2.html"><code translate="no" dir="ltr">ApplyAdagradV2(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/applyadam.html"><code translate="no" dir="ltr">ApplyAdam(...)</code></a>: Update '*var' according to the Adam algorithm.</p> <p><a href="../../raw_ops/applyaddsign.html"><code translate="no" dir="ltr">ApplyAddSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/applycenteredrmsprop.html"><code translate="no" dir="ltr">ApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/applyftrl.html"><code translate="no" dir="ltr">ApplyFtrl(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/applyftrlv2.html"><code translate="no" dir="ltr">ApplyFtrlV2(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/applygradientdescent.html"><code translate="no" dir="ltr">ApplyGradientDescent(...)</code></a>: Update '*var' by subtracting 'alpha' * 'delta' from it.</p> <p><a href="../../raw_ops/applymomentum.html"><code translate="no" dir="ltr">ApplyMomentum(...)</code></a>: Update '*var' according to the momentum scheme.</p> <p><a href="../../raw_ops/applypowersign.html"><code translate="no" dir="ltr">ApplyPowerSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/applyproximaladagrad.html"><code translate="no" dir="ltr">ApplyProximalAdagrad(...)</code></a>: Update '<em>var' and '</em>accum' according to FOBOS with Adagrad learning rate.</p> <p><a href="../../raw_ops/applyproximalgradientdescent.html"><code translate="no" dir="ltr">ApplyProximalGradientDescent(...)</code></a>: Update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/applyrmsprop.html"><code translate="no" dir="ltr">ApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/approxtopk.html"><code translate="no" dir="ltr">ApproxTopK(...)</code></a>: Returns min/max k values and their indices of the input operand in an approximate manner.</p> <p><a href="../../raw_ops/approximateequal.html"><code translate="no" dir="ltr">ApproximateEqual(...)</code></a>: Returns the truth value of abs(x-y) &lt; tolerance element-wise.</p> <p><a href="../../raw_ops/argmax.html"><code translate="no" dir="ltr">ArgMax(...)</code></a>: Returns the index with the largest value across dimensions of a tensor.</p> <p><a href="../../raw_ops/argmin.html"><code translate="no" dir="ltr">ArgMin(...)</code></a>: Returns the index with the smallest value across dimensions of a tensor.</p> <p><a href="../../raw_ops/asstring.html"><code translate="no" dir="ltr">AsString(...)</code></a>: Converts each entry in the given tensor to strings.</p> <p><a href="../../raw_ops/asin.html"><code translate="no" dir="ltr">Asin(...)</code></a>: Computes the trignometric inverse sine of x element-wise.</p> <p><a href="../../raw_ops/asinh.html"><code translate="no" dir="ltr">Asinh(...)</code></a>: Computes inverse hyperbolic sine of x element-wise.</p> <p><a href="../../raw_ops/assert.html"><code translate="no" dir="ltr">Assert(...)</code></a>: Asserts that the given condition is true.</p> <p><a href="../../raw_ops/assertcardinalitydataset.html"><code translate="no" dir="ltr">AssertCardinalityDataset(...)</code></a></p> <p><a href="../../raw_ops/assertnextdataset.html"><code translate="no" dir="ltr">AssertNextDataset(...)</code></a>: A transformation that asserts which transformations happen next.</p> <p><a href="../../raw_ops/assertprevdataset.html"><code translate="no" dir="ltr">AssertPrevDataset(...)</code></a>: A transformation that asserts which transformations happened previously.</p> <p><a href="../../raw_ops/assign.html"><code translate="no" dir="ltr">Assign(...)</code></a>: Update 'ref' by assigning 'value' to it.</p> <p><a href="../../raw_ops/assignadd.html"><code translate="no" dir="ltr">AssignAdd(...)</code></a>: Update 'ref' by adding 'value' to it.</p> <p><a href="../../raw_ops/assignaddvariableop.html"><code translate="no" dir="ltr">AssignAddVariableOp(...)</code></a>: Adds a value to the current value of a variable.</p> <p><a href="../../raw_ops/assignsub.html"><code translate="no" dir="ltr">AssignSub(...)</code></a>: Update 'ref' by subtracting 'value' from it.</p> <p><a href="../../raw_ops/assignsubvariableop.html"><code translate="no" dir="ltr">AssignSubVariableOp(...)</code></a>: Subtracts a value from the current value of a variable.</p> <p><a href="../../raw_ops/assignvariableop.html"><code translate="no" dir="ltr">AssignVariableOp(...)</code></a>: Assigns a new value to a variable.</p> <p><a href="../../raw_ops/assignvariablexlaconcatnd.html"><code translate="no" dir="ltr">AssignVariableXlaConcatND(...)</code></a>: Concats input tensor across all dimensions.</p> <p><a href="../../raw_ops/atan.html"><code translate="no" dir="ltr">Atan(...)</code></a>: Computes the trignometric inverse tangent of x element-wise.</p> <p><a href="../../raw_ops/atan2.html"><code translate="no" dir="ltr">Atan2(...)</code></a>: Computes arctangent of <code translate="no" dir="ltr">y/x</code> element-wise, respecting signs of the arguments.</p> <p><a href="../../raw_ops/atanh.html"><code translate="no" dir="ltr">Atanh(...)</code></a>: Computes inverse hyperbolic tangent of x element-wise.</p> <p><a href="../../raw_ops/audiospectrogram.html"><code translate="no" dir="ltr">AudioSpectrogram(...)</code></a>: Produces a visualization of audio data over time.</p> <p><a href="../../raw_ops/audiosummary.html"><code translate="no" dir="ltr">AudioSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with audio.</p> <p><a href="../../raw_ops/audiosummaryv2.html"><code translate="no" dir="ltr">AudioSummaryV2(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with audio.</p> <p><a href="../../raw_ops/autosharddataset.html"><code translate="no" dir="ltr">AutoShardDataset(...)</code></a>: Creates a dataset that shards the input dataset.</p> <p><a href="../../raw_ops/avgpool.html"><code translate="no" dir="ltr">AvgPool(...)</code></a>: Performs average pooling on the input.</p> <p><a href="../../raw_ops/avgpool3d.html"><code translate="no" dir="ltr">AvgPool3D(...)</code></a>: Performs 3D average pooling on the input.</p> <p><a href="../../raw_ops/avgpool3dgrad.html"><code translate="no" dir="ltr">AvgPool3DGrad(...)</code></a>: Computes gradients of average pooling function.</p> <p><a href="../../raw_ops/avgpoolgrad.html"><code translate="no" dir="ltr">AvgPoolGrad(...)</code></a>: Computes gradients of the average pooling function.</p> <p><a href="../../raw_ops/bandedtriangularsolve.html"><code translate="no" dir="ltr">BandedTriangularSolve(...)</code></a></p> <p><a href="../../raw_ops/barrier.html"><code translate="no" dir="ltr">Barrier(...)</code></a>: Defines a barrier that persists across different graph executions.</p> <p><a href="../../raw_ops/barrierclose.html"><code translate="no" dir="ltr">BarrierClose(...)</code></a>: Closes the given barrier.</p> <p><a href="../../raw_ops/barrierincompletesize.html"><code translate="no" dir="ltr">BarrierIncompleteSize(...)</code></a>: Computes the number of incomplete elements in the given barrier.</p> <p><a href="../../raw_ops/barrierinsertmany.html"><code translate="no" dir="ltr">BarrierInsertMany(...)</code></a>: For each key, assigns the respective value to the specified component.</p> <p><a href="../../raw_ops/barrierreadysize.html"><code translate="no" dir="ltr">BarrierReadySize(...)</code></a>: Computes the number of complete elements in the given barrier.</p> <p><a href="../../raw_ops/barriertakemany.html"><code translate="no" dir="ltr">BarrierTakeMany(...)</code></a>: Takes the given number of completed elements from a barrier.</p> <p><a href="../../raw_ops/batch.html"><code translate="no" dir="ltr">Batch(...)</code></a>: Batches all input tensors nondeterministically.</p> <p><a href="../../raw_ops/batchcholesky.html"><code translate="no" dir="ltr">BatchCholesky(...)</code></a></p> <p><a href="../../raw_ops/batchcholeskygrad.html"><code translate="no" dir="ltr">BatchCholeskyGrad(...)</code></a></p> <p><a href="../../raw_ops/batchdataset.html"><code translate="no" dir="ltr">BatchDataset(...)</code></a>: Creates a dataset that batches <code translate="no" dir="ltr">batch_size</code> elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/batchdatasetv2.html"><code translate="no" dir="ltr">BatchDatasetV2(...)</code></a>: Creates a dataset that batches <code translate="no" dir="ltr">batch_size</code> elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/batchfft.html"><code translate="no" dir="ltr">BatchFFT(...)</code></a></p> <p><a href="../../raw_ops/batchfft2d.html"><code translate="no" dir="ltr">BatchFFT2D(...)</code></a></p> <p><a href="../../raw_ops/batchfft3d.html"><code translate="no" dir="ltr">BatchFFT3D(...)</code></a></p> <p><a href="../../raw_ops/batchfunction.html"><code translate="no" dir="ltr">BatchFunction(...)</code></a>: Batches all the inputs tensors to the computation done by the function.</p> <p><a href="../../raw_ops/batchifft.html"><code translate="no" dir="ltr">BatchIFFT(...)</code></a></p> <p><a href="../../raw_ops/batchifft2d.html"><code translate="no" dir="ltr">BatchIFFT2D(...)</code></a></p> <p><a href="../../raw_ops/batchifft3d.html"><code translate="no" dir="ltr">BatchIFFT3D(...)</code></a></p> <p><a href="../../raw_ops/batchmatmul.html"><code translate="no" dir="ltr">BatchMatMul(...)</code></a>: Multiplies slices of two tensors in batches.</p> <p><a href="../../raw_ops/batchmatmulv2.html"><code translate="no" dir="ltr">BatchMatMulV2(...)</code></a>: Multiplies slices of two tensors in batches.</p> <p><a href="../../raw_ops/batchmatmulv3.html"><code translate="no" dir="ltr">BatchMatMulV3(...)</code></a>: Multiplies slices of two tensors in batches.</p> <p><a href="../../raw_ops/batchmatrixbandpart.html"><code translate="no" dir="ltr">BatchMatrixBandPart(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixdeterminant.html"><code translate="no" dir="ltr">BatchMatrixDeterminant(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixdiag.html"><code translate="no" dir="ltr">BatchMatrixDiag(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixdiagpart.html"><code translate="no" dir="ltr">BatchMatrixDiagPart(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixinverse.html"><code translate="no" dir="ltr">BatchMatrixInverse(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixsetdiag.html"><code translate="no" dir="ltr">BatchMatrixSetDiag(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixsolve.html"><code translate="no" dir="ltr">BatchMatrixSolve(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixsolvels.html"><code translate="no" dir="ltr">BatchMatrixSolveLs(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixtriangularsolve.html"><code translate="no" dir="ltr">BatchMatrixTriangularSolve(...)</code></a></p> <p><a href="../../raw_ops/batchnormwithglobalnormalization.html"><code translate="no" dir="ltr">BatchNormWithGlobalNormalization(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/batchnormwithglobalnormalizationgrad.html"><code translate="no" dir="ltr">BatchNormWithGlobalNormalizationGrad(...)</code></a>: Gradients for batch normalization.</p> <p><a href="../../raw_ops/batchselfadjointeig.html"><code translate="no" dir="ltr">BatchSelfAdjointEig(...)</code></a></p> <p><a href="../../raw_ops/batchselfadjointeigv2.html"><code translate="no" dir="ltr">BatchSelfAdjointEigV2(...)</code></a></p> <p><a href="../../raw_ops/batchsvd.html"><code translate="no" dir="ltr">BatchSvd(...)</code></a></p> <p><a href="../../raw_ops/batchtospace.html"><code translate="no" dir="ltr">BatchToSpace(...)</code></a>: BatchToSpace for 4-D tensors of type T.</p> <p><a href="../../raw_ops/batchtospacend.html"><code translate="no" dir="ltr">BatchToSpaceND(...)</code></a>: BatchToSpace for N-D tensors of type T.</p> <p><a href="../../raw_ops/besseli0.html"><code translate="no" dir="ltr">BesselI0(...)</code></a></p> <p><a href="../../raw_ops/besseli0e.html"><code translate="no" dir="ltr">BesselI0e(...)</code></a></p> <p><a href="../../raw_ops/besseli1.html"><code translate="no" dir="ltr">BesselI1(...)</code></a></p> <p><a href="../../raw_ops/besseli1e.html"><code translate="no" dir="ltr">BesselI1e(...)</code></a></p> <p><a href="../../raw_ops/besselj0.html"><code translate="no" dir="ltr">BesselJ0(...)</code></a></p> <p><a href="../../raw_ops/besselj1.html"><code translate="no" dir="ltr">BesselJ1(...)</code></a></p> <p><a href="../../raw_ops/besselk0.html"><code translate="no" dir="ltr">BesselK0(...)</code></a></p> <p><a href="../../raw_ops/besselk0e.html"><code translate="no" dir="ltr">BesselK0e(...)</code></a></p> <p><a href="../../raw_ops/besselk1.html"><code translate="no" dir="ltr">BesselK1(...)</code></a></p> <p><a href="../../raw_ops/besselk1e.html"><code translate="no" dir="ltr">BesselK1e(...)</code></a></p> <p><a href="../../raw_ops/bessely0.html"><code translate="no" dir="ltr">BesselY0(...)</code></a></p> <p><a href="../../raw_ops/bessely1.html"><code translate="no" dir="ltr">BesselY1(...)</code></a></p> <p><a href="../../raw_ops/betainc.html"><code translate="no" dir="ltr">Betainc(...)</code></a>: Compute the regularized incomplete beta integral \(I_x(a, b)\).</p> <p><a href="../../raw_ops/biasadd.html"><code translate="no" dir="ltr">BiasAdd(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/biasaddgrad.html"><code translate="no" dir="ltr">BiasAddGrad(...)</code></a>: The backward operation for "BiasAdd" on the "bias" tensor.</p> <p><a href="../../raw_ops/biasaddv1.html"><code translate="no" dir="ltr">BiasAddV1(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/bincount.html"><code translate="no" dir="ltr">Bincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/bitcast.html"><code translate="no" dir="ltr">Bitcast(...)</code></a>: Bitcasts a tensor from one type to another without copying data.</p> <p><a href="../../raw_ops/bitwiseand.html"><code translate="no" dir="ltr">BitwiseAnd(...)</code></a>: Elementwise computes the bitwise AND of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/bitwiseor.html"><code translate="no" dir="ltr">BitwiseOr(...)</code></a>: Elementwise computes the bitwise OR of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/bitwisexor.html"><code translate="no" dir="ltr">BitwiseXor(...)</code></a>: Elementwise computes the bitwise XOR of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/blocklstm.html"><code translate="no" dir="ltr">BlockLSTM(...)</code></a>: Computes the LSTM cell forward propagation for all the time steps.</p> <p><a href="../../raw_ops/blocklstmgrad.html"><code translate="no" dir="ltr">BlockLSTMGrad(...)</code></a>: Computes the LSTM cell backward propagation for the entire time sequence.</p> <p><a href="../../raw_ops/blocklstmgradv2.html"><code translate="no" dir="ltr">BlockLSTMGradV2(...)</code></a>: Computes the LSTM cell backward propagation for the entire time sequence.</p> <p><a href="../../raw_ops/blocklstmv2.html"><code translate="no" dir="ltr">BlockLSTMV2(...)</code></a>: Computes the LSTM cell forward propagation for all the time steps.</p> <p><a href="../../raw_ops/boostedtreesaggregatestats.html"><code translate="no" dir="ltr">BoostedTreesAggregateStats(...)</code></a>: Aggregates the summary of accumulated stats for the batch.</p> <p><a href="../../raw_ops/boostedtreesbucketize.html"><code translate="no" dir="ltr">BoostedTreesBucketize(...)</code></a>: Bucketize each feature based on bucket boundaries.</p> <p><a href="../../raw_ops/boostedtreescalculatebestfeaturesplit.html"><code translate="no" dir="ltr">BoostedTreesCalculateBestFeatureSplit(...)</code></a>: Calculates gains for each feature and returns the best possible split information for the feature.</p> <p><a href="../../raw_ops/boostedtreescalculatebestfeaturesplitv2.html"><code translate="no" dir="ltr">BoostedTreesCalculateBestFeatureSplitV2(...)</code></a>: Calculates gains for each feature and returns the best possible split information for each node. However, if no split is found, then no split information is returned for that node.</p> <p><a href="../../raw_ops/boostedtreescalculatebestgainsperfeature.html"><code translate="no" dir="ltr">BoostedTreesCalculateBestGainsPerFeature(...)</code></a>: Calculates gains for each feature and returns the best possible split information for the feature.</p> <p><a href="../../raw_ops/boostedtreescenterbias.html"><code translate="no" dir="ltr">BoostedTreesCenterBias(...)</code></a>: Calculates the prior from the training data (the bias) and fills in the first node with the logits' prior. Returns a boolean indicating whether to continue centering.</p> <p><a href="../../raw_ops/boostedtreescreateensemble.html"><code translate="no" dir="ltr">BoostedTreesCreateEnsemble(...)</code></a>: Creates a tree ensemble model and returns a handle to it.</p> <p><a href="../../raw_ops/boostedtreescreatequantilestreamresource.html"><code translate="no" dir="ltr">BoostedTreesCreateQuantileStreamResource(...)</code></a>: Create the Resource for Quantile Streams.</p> <p><a href="../../raw_ops/boostedtreesdeserializeensemble.html"><code translate="no" dir="ltr">BoostedTreesDeserializeEnsemble(...)</code></a>: Deserializes a serialized tree ensemble config and replaces current tree</p> <p><a href="../../raw_ops/boostedtreesensembleresourcehandleop.html"><code translate="no" dir="ltr">BoostedTreesEnsembleResourceHandleOp(...)</code></a>: Creates a handle to a BoostedTreesEnsembleResource</p> <p><a href="../../raw_ops/boostedtreesexampledebugoutputs.html"><code translate="no" dir="ltr">BoostedTreesExampleDebugOutputs(...)</code></a>: Debugging/model interpretability outputs for each example.</p> <p><a href="../../raw_ops/boostedtreesflushquantilesummaries.html"><code translate="no" dir="ltr">BoostedTreesFlushQuantileSummaries(...)</code></a>: Flush the quantile summaries from each quantile stream resource.</p> <p><a href="../../raw_ops/boostedtreesgetensemblestates.html"><code translate="no" dir="ltr">BoostedTreesGetEnsembleStates(...)</code></a>: Retrieves the tree ensemble resource stamp token, number of trees and growing statistics.</p> <p><a href="../../raw_ops/boostedtreesmakequantilesummaries.html"><code translate="no" dir="ltr">BoostedTreesMakeQuantileSummaries(...)</code></a>: Makes the summary of quantiles for the batch.</p> <p><a href="../../raw_ops/boostedtreesmakestatssummary.html"><code translate="no" dir="ltr">BoostedTreesMakeStatsSummary(...)</code></a>: Makes the summary of accumulated stats for the batch.</p> <p><a href="../../raw_ops/boostedtreespredict.html"><code translate="no" dir="ltr">BoostedTreesPredict(...)</code></a>: Runs multiple additive regression ensemble predictors on input instances and</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourceaddsummaries.html"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceAddSummaries(...)</code></a>: Add the quantile summaries to each quantile stream resource.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourcedeserialize.html"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceDeserialize(...)</code></a>: Deserialize bucket boundaries and ready flag into current QuantileAccumulator.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourceflush.html"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceFlush(...)</code></a>: Flush the summaries for a quantile stream resource.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourcegetbucketboundaries.html"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceGetBucketBoundaries(...)</code></a>: Generate the bucket boundaries for each feature based on accumulated summaries.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourcehandleop.html"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceHandleOp(...)</code></a>: Creates a handle to a BoostedTreesQuantileStreamResource.</p> <p><a href="../../raw_ops/boostedtreesserializeensemble.html"><code translate="no" dir="ltr">BoostedTreesSerializeEnsemble(...)</code></a>: Serializes the tree ensemble to a proto.</p> <p><a href="../../raw_ops/boostedtreessparseaggregatestats.html"><code translate="no" dir="ltr">BoostedTreesSparseAggregateStats(...)</code></a>: Aggregates the summary of accumulated stats for the batch.</p> <p><a href="../../raw_ops/boostedtreessparsecalculatebestfeaturesplit.html"><code translate="no" dir="ltr">BoostedTreesSparseCalculateBestFeatureSplit(...)</code></a>: Calculates gains for each feature and returns the best possible split information for the feature.</p> <p><a href="../../raw_ops/boostedtreestrainingpredict.html"><code translate="no" dir="ltr">BoostedTreesTrainingPredict(...)</code></a>: Runs multiple additive regression ensemble predictors on input instances and</p> <p><a href="../../raw_ops/boostedtreesupdateensemble.html"><code translate="no" dir="ltr">BoostedTreesUpdateEnsemble(...)</code></a>: Updates the tree ensemble by either adding a layer to the last tree being grown</p> <p><a href="../../raw_ops/boostedtreesupdateensemblev2.html"><code translate="no" dir="ltr">BoostedTreesUpdateEnsembleV2(...)</code></a>: Updates the tree ensemble by adding a layer to the last tree being grown</p> <p><a href="../../raw_ops/broadcastargs.html"><code translate="no" dir="ltr">BroadcastArgs(...)</code></a>: Return the shape of s0 op s1 with broadcast.</p> <p><a href="../../raw_ops/broadcastgradientargs.html"><code translate="no" dir="ltr">BroadcastGradientArgs(...)</code></a>: Return the reduction indices for computing gradients of s0 op s1 with broadcast.</p> <p><a href="../../raw_ops/broadcastto.html"><code translate="no" dir="ltr">BroadcastTo(...)</code></a>: Broadcast an array for a compatible shape.</p> <p><a href="../../raw_ops/bucketize.html"><code translate="no" dir="ltr">Bucketize(...)</code></a>: Bucketizes 'input' based on 'boundaries'.</p> <p><a href="../../raw_ops/bytesproducedstatsdataset.html"><code translate="no" dir="ltr">BytesProducedStatsDataset(...)</code></a>: Records the bytes size of each element of <code translate="no" dir="ltr">input_dataset</code> in a StatsAggregator.</p> <p><a href="../../raw_ops/csrsparsematrixcomponents.html"><code translate="no" dir="ltr">CSRSparseMatrixComponents(...)</code></a>: Reads out the CSR components at batch <code translate="no" dir="ltr">index</code>.</p> <p><a href="../../raw_ops/csrsparsematrixtodense.html"><code translate="no" dir="ltr">CSRSparseMatrixToDense(...)</code></a>: Convert a (possibly batched) CSRSparseMatrix to dense.</p> <p><a href="../../raw_ops/csrsparsematrixtosparsetensor.html"><code translate="no" dir="ltr">CSRSparseMatrixToSparseTensor(...)</code></a>: Converts a (possibly batched) CSRSparesMatrix to a SparseTensor.</p> <p><a href="../../raw_ops/csvdataset.html"><code translate="no" dir="ltr">CSVDataset(...)</code></a></p> <p><a href="../../raw_ops/csvdatasetv2.html"><code translate="no" dir="ltr">CSVDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/ctcbeamsearchdecoder.html"><code translate="no" dir="ltr">CTCBeamSearchDecoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p> <p><a href="../../raw_ops/ctcgreedydecoder.html"><code translate="no" dir="ltr">CTCGreedyDecoder(...)</code></a>: Performs greedy decoding on the logits given in inputs.</p> <p><a href="../../raw_ops/ctcloss.html"><code translate="no" dir="ltr">CTCLoss(...)</code></a>: Calculates the CTC Loss (log probability) for each batch entry.</p> <p><a href="../../raw_ops/ctclossv2.html"><code translate="no" dir="ltr">CTCLossV2(...)</code></a>: Calculates the CTC Loss (log probability) for each batch entry.</p> <p><a href="../../raw_ops/cachedataset.html"><code translate="no" dir="ltr">CacheDataset(...)</code></a>: Creates a dataset that caches elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/cachedatasetv2.html"><code translate="no" dir="ltr">CacheDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/case.html"><code translate="no" dir="ltr">Case(...)</code></a>: An n-way switch statement which calls a single branch function.</p> <p><a href="../../raw_ops/cast.html"><code translate="no" dir="ltr">Cast(...)</code></a>: Cast x of type SrcT to y of DstT.</p> <p><a href="../../raw_ops/ceil.html"><code translate="no" dir="ltr">Ceil(...)</code></a>: Returns element-wise smallest integer not less than x.</p> <p><a href="../../raw_ops/checknumerics.html"><code translate="no" dir="ltr">CheckNumerics(...)</code></a>: Checks a tensor for NaN and Inf values.</p> <p><a href="../../raw_ops/checknumericsv2.html"><code translate="no" dir="ltr">CheckNumericsV2(...)</code></a>: Checks a tensor for NaN, -Inf and +Inf values.</p> <p><a href="../../raw_ops/cholesky.html"><code translate="no" dir="ltr">Cholesky(...)</code></a>: Computes the Cholesky decomposition of one or more square matrices.</p> <p><a href="../../raw_ops/choleskygrad.html"><code translate="no" dir="ltr">CholeskyGrad(...)</code></a>: Computes the reverse mode backpropagated gradient of the Cholesky algorithm.</p> <p><a href="../../raw_ops/choosefastestbranchdataset.html"><code translate="no" dir="ltr">ChooseFastestBranchDataset(...)</code></a></p> <p><a href="../../raw_ops/choosefastestdataset.html"><code translate="no" dir="ltr">ChooseFastestDataset(...)</code></a></p> <p><a href="../../raw_ops/clipbyvalue.html"><code translate="no" dir="ltr">ClipByValue(...)</code></a>: Clips tensor values to a specified min and max.</p> <p><a href="../../raw_ops/closesummarywriter.html"><code translate="no" dir="ltr">CloseSummaryWriter(...)</code></a></p> <p><a href="../../raw_ops/collectivealltoallv2.html"><code translate="no" dir="ltr">CollectiveAllToAllV2(...)</code></a>: Mutually exchanges multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivealltoallv3.html"><code translate="no" dir="ltr">CollectiveAllToAllV3(...)</code></a>: Mutually exchanges multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectiveassigngroupv2.html"><code translate="no" dir="ltr">CollectiveAssignGroupV2(...)</code></a>: Assign group keys based on group assignment.</p> <p><a href="../../raw_ops/collectivebcastrecv.html"><code translate="no" dir="ltr">CollectiveBcastRecv(...)</code></a>: Receives a tensor value broadcast from another device.</p> <p><a href="../../raw_ops/collectivebcastrecvv2.html"><code translate="no" dir="ltr">CollectiveBcastRecvV2(...)</code></a>: Receives a tensor value broadcast from another device.</p> <p><a href="../../raw_ops/collectivebcastsend.html"><code translate="no" dir="ltr">CollectiveBcastSend(...)</code></a>: Broadcasts a tensor value to one or more other devices.</p> <p><a href="../../raw_ops/collectivebcastsendv2.html"><code translate="no" dir="ltr">CollectiveBcastSendV2(...)</code></a>: Broadcasts a tensor value to one or more other devices.</p> <p><a href="../../raw_ops/collectivegather.html"><code translate="no" dir="ltr">CollectiveGather(...)</code></a>: Mutually accumulates multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivegatherv2.html"><code translate="no" dir="ltr">CollectiveGatherV2(...)</code></a>: Mutually accumulates multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectiveinitializecommunicator.html"><code translate="no" dir="ltr">CollectiveInitializeCommunicator(...)</code></a>: Initializes a group for collective operations.</p> <p><a href="../../raw_ops/collectivepermute.html"><code translate="no" dir="ltr">CollectivePermute(...)</code></a>: An Op to permute tensors across replicated TPU instances.</p> <p><a href="../../raw_ops/collectivereduce.html"><code translate="no" dir="ltr">CollectiveReduce(...)</code></a>: Mutually reduces multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivereducescatterv2.html"><code translate="no" dir="ltr">CollectiveReduceScatterV2(...)</code></a>: Mutually reduces multiple tensors of identical type and shape and scatters the result.</p> <p><a href="../../raw_ops/collectivereducev2.html"><code translate="no" dir="ltr">CollectiveReduceV2(...)</code></a>: Mutually reduces multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivereducev3.html"><code translate="no" dir="ltr">CollectiveReduceV3(...)</code></a>: Mutually reduces multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/combinednonmaxsuppression.html"><code translate="no" dir="ltr">CombinedNonMaxSuppression(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/complex.html"><code translate="no" dir="ltr">Complex(...)</code></a>: Converts two real numbers to a complex number.</p> <p><a href="../../raw_ops/complexabs.html"><code translate="no" dir="ltr">ComplexAbs(...)</code></a>: Computes the complex absolute value of a tensor.</p> <p><a href="../../raw_ops/compositetensorvariantfromcomponents.html"><code translate="no" dir="ltr">CompositeTensorVariantFromComponents(...)</code></a>: Encodes an <code translate="no" dir="ltr">ExtensionType</code> value into a <code translate="no" dir="ltr">variant</code> scalar Tensor.</p> <p><a href="../../raw_ops/compositetensorvarianttocomponents.html"><code translate="no" dir="ltr">CompositeTensorVariantToComponents(...)</code></a>: Decodes a <code translate="no" dir="ltr">variant</code> scalar Tensor into an <code translate="no" dir="ltr">ExtensionType</code> value.</p> <p><a href="../../raw_ops/compresselement.html"><code translate="no" dir="ltr">CompressElement(...)</code></a>: Compresses a dataset element.</p> <p><a href="../../raw_ops/computeaccidentalhits.html"><code translate="no" dir="ltr">ComputeAccidentalHits(...)</code></a>: Computes the ids of the positions in sampled_candidates that match true_labels.</p> <p><a href="../../raw_ops/computebatchsize.html"><code translate="no" dir="ltr">ComputeBatchSize(...)</code></a>: Computes the static batch size of a dataset sans partial batches.</p> <p><a href="../../raw_ops/concat.html"><code translate="no" dir="ltr">Concat(...)</code></a>: Concatenates tensors along one dimension.</p> <p><a href="../../raw_ops/concatoffset.html"><code translate="no" dir="ltr">ConcatOffset(...)</code></a>: Computes offsets of concat inputs within its output.</p> <p><a href="../../raw_ops/concatv2.html"><code translate="no" dir="ltr">ConcatV2(...)</code></a>: Concatenates tensors along one dimension.</p> <p><a href="../../raw_ops/concatenatedataset.html"><code translate="no" dir="ltr">ConcatenateDataset(...)</code></a>: Creates a dataset that concatenates <code translate="no" dir="ltr">input_dataset</code> with <code translate="no" dir="ltr">another_dataset</code>.</p> <p><a href="../../raw_ops/conditionalaccumulator.html"><code translate="no" dir="ltr">ConditionalAccumulator(...)</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="../../raw_ops/configuredistributedtpu.html"><code translate="no" dir="ltr">ConfigureDistributedTPU(...)</code></a>: Sets up the centralized structures for a distributed TPU system.</p> <p><a href="../../raw_ops/configuretpuembedding.html"><code translate="no" dir="ltr">ConfigureTPUEmbedding(...)</code></a>: Sets up TPUEmbedding in a distributed TPU system.</p> <p><a href="../../raw_ops/conj.html"><code translate="no" dir="ltr">Conj(...)</code></a>: Returns the complex conjugate of a complex number.</p> <p><a href="../../raw_ops/conjugatetranspose.html"><code translate="no" dir="ltr">ConjugateTranspose(...)</code></a>: Shuffle dimensions of x according to a permutation and conjugate the result.</p> <p><a href="../../raw_ops/const.html"><code translate="no" dir="ltr">Const(...)</code></a>: Returns a constant tensor.</p> <p><a href="../../raw_ops/consumemutexlock.html"><code translate="no" dir="ltr">ConsumeMutexLock(...)</code></a>: This op consumes a lock created by <code translate="no" dir="ltr">MutexLock</code>.</p> <p><a href="../../raw_ops/controltrigger.html"><code translate="no" dir="ltr">ControlTrigger(...)</code></a>: Does nothing. Serves as a control trigger for scheduling.</p> <p><a href="../../raw_ops/conv.html"><code translate="no" dir="ltr">Conv(...)</code></a>: Computes a N-D convolution given (N+1+batch_dims)-D <code translate="no" dir="ltr">input</code> and (N+2)-D <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/conv2d.html"><code translate="no" dir="ltr">Conv2D(...)</code></a>: Computes a 2-D convolution given 4-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/conv2dbackpropfilter.html"><code translate="no" dir="ltr">Conv2DBackpropFilter(...)</code></a>: Computes the gradients of convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv2dbackpropfilterv2.html"><code translate="no" dir="ltr">Conv2DBackpropFilterV2(...)</code></a>: Computes the gradients of convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv2dbackpropinput.html"><code translate="no" dir="ltr">Conv2DBackpropInput(...)</code></a>: Computes the gradients of convolution with respect to the input.</p> <p><a href="../../raw_ops/conv2dbackpropinputv2.html"><code translate="no" dir="ltr">Conv2DBackpropInputV2(...)</code></a>: Computes the gradients of convolution with respect to the input.</p> <p><a href="../../raw_ops/conv3d.html"><code translate="no" dir="ltr">Conv3D(...)</code></a>: Computes a 3-D convolution given 5-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/conv3dbackpropfilter.html"><code translate="no" dir="ltr">Conv3DBackpropFilter(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv3dbackpropfilterv2.html"><code translate="no" dir="ltr">Conv3DBackpropFilterV2(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv3dbackpropinput.html"><code translate="no" dir="ltr">Conv3DBackpropInput(...)</code></a>: Computes the gradients of 3-D convolution with respect to the input.</p> <p><a href="../../raw_ops/conv3dbackpropinputv2.html"><code translate="no" dir="ltr">Conv3DBackpropInputV2(...)</code></a>: Computes the gradients of 3-D convolution with respect to the input.</p> <p><a href="../../raw_ops/converttocootensor.html"><code translate="no" dir="ltr">ConvertToCooTensor(...)</code></a></p> <p><a href="../../raw_ops/copy.html"><code translate="no" dir="ltr">Copy(...)</code></a>: Copy a tensor from CPU-to-CPU or GPU-to-GPU.</p> <p><a href="../../raw_ops/copyhost.html"><code translate="no" dir="ltr">CopyHost(...)</code></a>: Copy a tensor to host.</p> <p><a href="../../raw_ops/cos.html"><code translate="no" dir="ltr">Cos(...)</code></a>: Computes cos of x element-wise.</p> <p><a href="../../raw_ops/cosh.html"><code translate="no" dir="ltr">Cosh(...)</code></a>: Computes hyperbolic cosine of x element-wise.</p> <p><a href="../../raw_ops/countupto.html"><code translate="no" dir="ltr">CountUpTo(...)</code></a>: Increments 'ref' until it reaches 'limit'.</p> <p><a href="../../raw_ops/createsummarydbwriter.html"><code translate="no" dir="ltr">CreateSummaryDbWriter(...)</code></a></p> <p><a href="../../raw_ops/createsummaryfilewriter.html"><code translate="no" dir="ltr">CreateSummaryFileWriter(...)</code></a></p> <p><a href="../../raw_ops/cropandresize.html"><code translate="no" dir="ltr">CropAndResize(...)</code></a>: Extracts crops from the input image tensor and resizes them.</p> <p><a href="../../raw_ops/cropandresizegradboxes.html"><code translate="no" dir="ltr">CropAndResizeGradBoxes(...)</code></a>: Computes the gradient of the crop_and_resize op wrt the input boxes tensor.</p> <p><a href="../../raw_ops/cropandresizegradimage.html"><code translate="no" dir="ltr">CropAndResizeGradImage(...)</code></a>: Computes the gradient of the crop_and_resize op wrt the input image tensor.</p> <p><a href="../../raw_ops/cross.html"><code translate="no" dir="ltr">Cross(...)</code></a>: Compute the pairwise cross product.</p> <p><a href="../../raw_ops/crossreplicasum.html"><code translate="no" dir="ltr">CrossReplicaSum(...)</code></a>: An Op to sum inputs across replicated TPU instances.</p> <p><a href="../../raw_ops/cudnnrnn.html"><code translate="no" dir="ltr">CudnnRNN(...)</code></a>: A RNN backed by cuDNN.</p> <p><a href="../../raw_ops/cudnnrnnbackprop.html"><code translate="no" dir="ltr">CudnnRNNBackprop(...)</code></a>: Backprop step of CudnnRNN.</p> <p><a href="../../raw_ops/cudnnrnnbackpropv2.html"><code translate="no" dir="ltr">CudnnRNNBackpropV2(...)</code></a>: Backprop step of CudnnRNN.</p> <p><a href="../../raw_ops/cudnnrnnbackpropv3.html"><code translate="no" dir="ltr">CudnnRNNBackpropV3(...)</code></a>: Backprop step of CudnnRNNV3.</p> <p><a href="../../raw_ops/cudnnrnncanonicaltoparams.html"><code translate="no" dir="ltr">CudnnRNNCanonicalToParams(...)</code></a>: Converts CudnnRNN params from canonical form to usable form.</p> <p><a href="../../raw_ops/cudnnrnncanonicaltoparamsv2.html"><code translate="no" dir="ltr">CudnnRNNCanonicalToParamsV2(...)</code></a>: Converts CudnnRNN params from canonical form to usable form. It supports the projection in LSTM.</p> <p><a href="../../raw_ops/cudnnrnnparamssize.html"><code translate="no" dir="ltr">CudnnRNNParamsSize(...)</code></a>: Computes size of weights that can be used by a Cudnn RNN model.</p> <p><a href="../../raw_ops/cudnnrnnparamstocanonical.html"><code translate="no" dir="ltr">CudnnRNNParamsToCanonical(...)</code></a>: Retrieves CudnnRNN params in canonical form.</p> <p><a href="../../raw_ops/cudnnrnnparamstocanonicalv2.html"><code translate="no" dir="ltr">CudnnRNNParamsToCanonicalV2(...)</code></a>: Retrieves CudnnRNN params in canonical form. It supports the projection in LSTM.</p> <p><a href="../../raw_ops/cudnnrnnv2.html"><code translate="no" dir="ltr">CudnnRNNV2(...)</code></a>: A RNN backed by cuDNN.</p> <p><a href="../../raw_ops/cudnnrnnv3.html"><code translate="no" dir="ltr">CudnnRNNV3(...)</code></a>: A RNN backed by cuDNN.</p> <p><a href="../../raw_ops/cumprod.html"><code translate="no" dir="ltr">Cumprod(...)</code></a>: Compute the cumulative product of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../../raw_ops/cumsum.html"><code translate="no" dir="ltr">Cumsum(...)</code></a>: Compute the cumulative sum of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../../raw_ops/cumulativelogsumexp.html"><code translate="no" dir="ltr">CumulativeLogsumexp(...)</code></a>: Compute the cumulative product of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../../raw_ops/dataformatdimmap.html"><code translate="no" dir="ltr">DataFormatDimMap(...)</code></a>: Returns the dimension index in the destination data format given the one in</p> <p><a href="../../raw_ops/dataformatvecpermute.html"><code translate="no" dir="ltr">DataFormatVecPermute(...)</code></a>: Permute input tensor from <code translate="no" dir="ltr">src_format</code> to <code translate="no" dir="ltr">dst_format</code>.</p> <p><a href="../../raw_ops/dataservicedataset.html"><code translate="no" dir="ltr">DataServiceDataset(...)</code></a>: Creates a dataset that reads data from the tf.data service.</p> <p><a href="../../raw_ops/dataservicedatasetv2.html"><code translate="no" dir="ltr">DataServiceDatasetV2(...)</code></a>: Creates a dataset that reads data from the tf.data service.</p> <p><a href="../../raw_ops/dataservicedatasetv3.html"><code translate="no" dir="ltr">DataServiceDatasetV3(...)</code></a>: Creates a dataset that reads data from the tf.data service.</p> <p><a href="../../raw_ops/dataservicedatasetv4.html"><code translate="no" dir="ltr">DataServiceDatasetV4(...)</code></a>: Creates a dataset that reads data from the tf.data service.</p> <p><a href="../../raw_ops/datasetcardinality.html"><code translate="no" dir="ltr">DatasetCardinality(...)</code></a>: Returns the cardinality of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasetfingerprint.html"><code translate="no" dir="ltr">DatasetFingerprint(...)</code></a>: Returns the fingerprint of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasetfromgraph.html"><code translate="no" dir="ltr">DatasetFromGraph(...)</code></a>: Creates a dataset from the given <code translate="no" dir="ltr">graph_def</code>.</p> <p><a href="../../raw_ops/datasettograph.html"><code translate="no" dir="ltr">DatasetToGraph(...)</code></a>: Returns a serialized GraphDef representing <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasettographv2.html"><code translate="no" dir="ltr">DatasetToGraphV2(...)</code></a>: Returns a serialized GraphDef representing <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasettosingleelement.html"><code translate="no" dir="ltr">DatasetToSingleElement(...)</code></a>: Outputs the single element from the given dataset.</p> <p><a href="../../raw_ops/datasettotfrecord.html"><code translate="no" dir="ltr">DatasetToTFRecord(...)</code></a>: Writes the given dataset to the given file using the TFRecord format.</p> <p><a href="../../raw_ops/dawsn.html"><code translate="no" dir="ltr">Dawsn(...)</code></a></p> <p><a href="../../raw_ops/debuggradientidentity.html"><code translate="no" dir="ltr">DebugGradientIdentity(...)</code></a>: Identity op for gradient debugging.</p> <p><a href="../../raw_ops/debuggradientrefidentity.html"><code translate="no" dir="ltr">DebugGradientRefIdentity(...)</code></a>: Identity op for gradient debugging.</p> <p><a href="../../raw_ops/debugidentity.html"><code translate="no" dir="ltr">DebugIdentity(...)</code></a>: Provides an identity mapping of the non-Ref type input tensor for debugging.</p> <p><a href="../../raw_ops/debugidentityv2.html"><code translate="no" dir="ltr">DebugIdentityV2(...)</code></a>: Debug Identity V2 Op.</p> <p><a href="../../raw_ops/debugidentityv3.html"><code translate="no" dir="ltr">DebugIdentityV3(...)</code></a>: Provides an identity mapping of the non-Ref type input tensor for debugging.</p> <p><a href="../../raw_ops/debugnancount.html"><code translate="no" dir="ltr">DebugNanCount(...)</code></a>: Debug NaN Value Counter Op.</p> <p><a href="../../raw_ops/debugnumericsummary.html"><code translate="no" dir="ltr">DebugNumericSummary(...)</code></a>: Debug Numeric Summary Op.</p> <p><a href="../../raw_ops/debugnumericsummaryv2.html"><code translate="no" dir="ltr">DebugNumericSummaryV2(...)</code></a>: Debug Numeric Summary V2 Op.</p> <p><a href="../../raw_ops/decodeandcropjpeg.html"><code translate="no" dir="ltr">DecodeAndCropJpeg(...)</code></a>: Decode and Crop a JPEG-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodebase64.html"><code translate="no" dir="ltr">DecodeBase64(...)</code></a>: Decode web-safe base64-encoded strings.</p> <p><a href="../../raw_ops/decodebmp.html"><code translate="no" dir="ltr">DecodeBmp(...)</code></a>: Decode the first frame of a BMP-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodecsv.html"><code translate="no" dir="ltr">DecodeCSV(...)</code></a>: Convert CSV records to tensors. Each column maps to one tensor.</p> <p><a href="../../raw_ops/decodecompressed.html"><code translate="no" dir="ltr">DecodeCompressed(...)</code></a>: Decompress strings.</p> <p><a href="../../raw_ops/decodegif.html"><code translate="no" dir="ltr">DecodeGif(...)</code></a>: Decode the frame(s) of a GIF-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodeimage.html"><code translate="no" dir="ltr">DecodeImage(...)</code></a>: Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.</p> <p><a href="../../raw_ops/decodejsonexample.html"><code translate="no" dir="ltr">DecodeJSONExample(...)</code></a>: Convert JSON-encoded Example records to binary protocol buffer strings.</p> <p><a href="../../raw_ops/decodejpeg.html"><code translate="no" dir="ltr">DecodeJpeg(...)</code></a>: Decode a JPEG-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodepaddedraw.html"><code translate="no" dir="ltr">DecodePaddedRaw(...)</code></a>: Reinterpret the bytes of a string as a vector of numbers.</p> <p><a href="../../raw_ops/decodepng.html"><code translate="no" dir="ltr">DecodePng(...)</code></a>: Decode a PNG-encoded image to a uint8 or uint16 tensor.</p> <p><a href="../../raw_ops/decodeprotov2.html"><code translate="no" dir="ltr">DecodeProtoV2(...)</code></a>: The op extracts fields from a serialized protocol buffers message into tensors.</p> <p><a href="../../raw_ops/decoderaw.html"><code translate="no" dir="ltr">DecodeRaw(...)</code></a>: Reinterpret the bytes of a string as a vector of numbers.</p> <p><a href="../../raw_ops/decodewav.html"><code translate="no" dir="ltr">DecodeWav(...)</code></a>: Decode a 16-bit PCM WAV file to a float tensor.</p> <p><a href="../../raw_ops/deepcopy.html"><code translate="no" dir="ltr">DeepCopy(...)</code></a>: Makes a copy of <code translate="no" dir="ltr">x</code>.</p> <p><a href="../../raw_ops/deleteiterator.html"><code translate="no" dir="ltr">DeleteIterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/deletememorycache.html"><code translate="no" dir="ltr">DeleteMemoryCache(...)</code></a></p> <p><a href="../../raw_ops/deletemultideviceiterator.html"><code translate="no" dir="ltr">DeleteMultiDeviceIterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/deleterandomseedgenerator.html"><code translate="no" dir="ltr">DeleteRandomSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/deleteseedgenerator.html"><code translate="no" dir="ltr">DeleteSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/deletesessiontensor.html"><code translate="no" dir="ltr">DeleteSessionTensor(...)</code></a>: Delete the tensor specified by its handle in the session.</p> <p><a href="../../raw_ops/densebincount.html"><code translate="no" dir="ltr">DenseBincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/densecountsparseoutput.html"><code translate="no" dir="ltr">DenseCountSparseOutput(...)</code></a>: Performs sparse-output bin counting for a tf.tensor input.</p> <p><a href="../../raw_ops/densetocsrsparsematrix.html"><code translate="no" dir="ltr">DenseToCSRSparseMatrix(...)</code></a>: Converts a dense tensor to a (possibly batched) CSRSparseMatrix.</p> <p><a href="../../raw_ops/densetodensesetoperation.html"><code translate="no" dir="ltr">DenseToDenseSetOperation(...)</code></a>: Applies set operation along last dimension of 2 <code translate="no" dir="ltr">Tensor</code> inputs.</p> <p><a href="../../raw_ops/densetosparsebatchdataset.html"><code translate="no" dir="ltr">DenseToSparseBatchDataset(...)</code></a>: Creates a dataset that batches input elements into a SparseTensor.</p> <p><a href="../../raw_ops/densetosparsesetoperation.html"><code translate="no" dir="ltr">DenseToSparseSetOperation(...)</code></a>: Applies set operation along last dimension of <code translate="no" dir="ltr">Tensor</code> and <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/depthtospace.html"><code translate="no" dir="ltr">DepthToSpace(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="../../raw_ops/depthwiseconv2dnative.html"><code translate="no" dir="ltr">DepthwiseConv2dNative(...)</code></a>: Computes a 2-D depthwise convolution given 4-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/depthwiseconv2dnativebackpropfilter.html"><code translate="no" dir="ltr">DepthwiseConv2dNativeBackpropFilter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p> <p><a href="../../raw_ops/depthwiseconv2dnativebackpropinput.html"><code translate="no" dir="ltr">DepthwiseConv2dNativeBackpropInput(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p> <p><a href="../../raw_ops/dequantize.html"><code translate="no" dir="ltr">Dequantize(...)</code></a>: Dequantize the 'input' tensor into a float or bfloat16 Tensor.</p> <p><a href="../../raw_ops/deserializeiterator.html"><code translate="no" dir="ltr">DeserializeIterator(...)</code></a>: Converts the given variant tensor to an iterator and stores it in the given resource.</p> <p><a href="../../raw_ops/deserializemanysparse.html"><code translate="no" dir="ltr">DeserializeManySparse(...)</code></a>: Deserialize and concatenate <code translate="no" dir="ltr">SparseTensors</code> from a serialized minibatch.</p> <p><a href="../../raw_ops/deserializesparse.html"><code translate="no" dir="ltr">DeserializeSparse(...)</code></a>: Deserialize <code translate="no" dir="ltr">SparseTensor</code> objects.</p> <p><a href="../../raw_ops/destroyresourceop.html"><code translate="no" dir="ltr">DestroyResourceOp(...)</code></a>: Deletes the resource specified by the handle.</p> <p><a href="../../raw_ops/destroytemporaryvariable.html"><code translate="no" dir="ltr">DestroyTemporaryVariable(...)</code></a>: Destroys the temporary variable and returns its final value.</p> <p><a href="../../raw_ops/deviceindex.html"><code translate="no" dir="ltr">DeviceIndex(...)</code></a>: Return the index of device the op runs.</p> <p><a href="../../raw_ops/diag.html"><code translate="no" dir="ltr">Diag(...)</code></a>: Returns a diagonal tensor with a given diagonal values.</p> <p><a href="../../raw_ops/diagpart.html"><code translate="no" dir="ltr">DiagPart(...)</code></a>: Returns the diagonal part of the tensor.</p> <p><a href="../../raw_ops/digamma.html"><code translate="no" dir="ltr">Digamma(...)</code></a>: Computes Psi, the derivative of Lgamma (the log of the absolute value of</p> <p><a href="../../raw_ops/dilation2d.html"><code translate="no" dir="ltr">Dilation2D(...)</code></a>: Computes the grayscale dilation of 4-D <code translate="no" dir="ltr">input</code> and 3-D <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/dilation2dbackpropfilter.html"><code translate="no" dir="ltr">Dilation2DBackpropFilter(...)</code></a>: Computes the gradient of morphological 2-D dilation with respect to the filter.</p> <p><a href="../../raw_ops/dilation2dbackpropinput.html"><code translate="no" dir="ltr">Dilation2DBackpropInput(...)</code></a>: Computes the gradient of morphological 2-D dilation with respect to the input.</p> <p><a href="../../raw_ops/directedinterleavedataset.html"><code translate="no" dir="ltr">DirectedInterleaveDataset(...)</code></a>: A substitute for <code translate="no" dir="ltr">InterleaveDataset</code> on a fixed list of <code translate="no" dir="ltr">N</code> datasets.</p> <p><a href="../../raw_ops/disablecopyonread.html"><code translate="no" dir="ltr">DisableCopyOnRead(...)</code></a>: Turns off the copy-on-read mode.</p> <p><a href="../../raw_ops/distributedsave.html"><code translate="no" dir="ltr">DistributedSave(...)</code></a></p> <p><a href="../../raw_ops/div.html"><code translate="no" dir="ltr">Div(...)</code></a>: Returns x / y element-wise.</p> <p><a href="../../raw_ops/divnonan.html"><code translate="no" dir="ltr">DivNoNan(...)</code></a>: Returns 0 if the denominator is zero.</p> <p><a href="../../raw_ops/drawboundingboxes.html"><code translate="no" dir="ltr">DrawBoundingBoxes(...)</code></a>: Draw bounding boxes on a batch of images.</p> <p><a href="../../raw_ops/drawboundingboxesv2.html"><code translate="no" dir="ltr">DrawBoundingBoxesV2(...)</code></a>: Draw bounding boxes on a batch of images.</p> <p><a href="../../raw_ops/dummyiterationcounter.html"><code translate="no" dir="ltr">DummyIterationCounter(...)</code></a></p> <p><a href="../../raw_ops/dummymemorycache.html"><code translate="no" dir="ltr">DummyMemoryCache(...)</code></a></p> <p><a href="../../raw_ops/dummyseedgenerator.html"><code translate="no" dir="ltr">DummySeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/dynamicenqueuetpuembeddingarbitrarytensorbatch.html"><code translate="no" dir="ltr">DynamicEnqueueTPUEmbeddingArbitraryTensorBatch(...)</code></a>: Eases the porting of code that uses tf.nn.embedding_lookup_sparse().</p> <p><a href="../../raw_ops/dynamicenqueuetpuembeddingraggedtensorbatch.html"><code translate="no" dir="ltr">DynamicEnqueueTPUEmbeddingRaggedTensorBatch(...)</code></a></p> <p><a href="../../raw_ops/dynamicpartition.html"><code translate="no" dir="ltr">DynamicPartition(...)</code></a>: Partitions <code translate="no" dir="ltr">data</code> into <code translate="no" dir="ltr">num_partitions</code> tensors using indices from <code translate="no" dir="ltr">partitions</code>.</p> <p><a href="../../raw_ops/dynamicstitch.html"><code translate="no" dir="ltr">DynamicStitch(...)</code></a>: Interleave the values from the <code translate="no" dir="ltr">data</code> tensors into a single tensor.</p> <p><a href="../../raw_ops/eagerpyfunc.html"><code translate="no" dir="ltr">EagerPyFunc(...)</code></a>: Eagerly executes a python function to compute func(input)-&gt;output.</p> <p><a href="../../raw_ops/editdistance.html"><code translate="no" dir="ltr">EditDistance(...)</code></a>: Computes the (possibly normalized) Levenshtein Edit Distance.</p> <p><a href="../../raw_ops/eig.html"><code translate="no" dir="ltr">Eig(...)</code></a>: Computes the eigen decomposition of one or more square matrices.</p> <p><a href="../../raw_ops/einsum.html"><code translate="no" dir="ltr">Einsum(...)</code></a>: Tensor contraction according to Einstein summation convention.</p> <p><a href="../../raw_ops/elu.html"><code translate="no" dir="ltr">Elu(...)</code></a>: Computes the exponential linear function.</p> <p><a href="../../raw_ops/elugrad.html"><code translate="no" dir="ltr">EluGrad(...)</code></a>: Computes gradients for the exponential linear (Elu) operation.</p> <p><a href="../../raw_ops/empty.html"><code translate="no" dir="ltr">Empty(...)</code></a>: Creates a tensor with the given shape.</p> <p><a href="../../raw_ops/emptytensorlist.html"><code translate="no" dir="ltr">EmptyTensorList(...)</code></a>: Creates and returns an empty tensor list.</p> <p><a href="../../raw_ops/emptytensormap.html"><code translate="no" dir="ltr">EmptyTensorMap(...)</code></a>: Creates and returns an empty tensor map.</p> <p><a href="../../raw_ops/encodebase64.html"><code translate="no" dir="ltr">EncodeBase64(...)</code></a>: Encode strings into web-safe base64 format.</p> <p><a href="../../raw_ops/encodejpeg.html"><code translate="no" dir="ltr">EncodeJpeg(...)</code></a>: JPEG-encode an image.</p> <p><a href="../../raw_ops/encodejpegvariablequality.html"><code translate="no" dir="ltr">EncodeJpegVariableQuality(...)</code></a>: JPEG encode input image with provided compression quality.</p> <p><a href="../../raw_ops/encodepng.html"><code translate="no" dir="ltr">EncodePng(...)</code></a>: PNG-encode an image.</p> <p><a href="../../raw_ops/encodeproto.html"><code translate="no" dir="ltr">EncodeProto(...)</code></a>: The op serializes protobuf messages provided in the input tensors.</p> <p><a href="../../raw_ops/encodewav.html"><code translate="no" dir="ltr">EncodeWav(...)</code></a>: Encode audio data using the WAV file format.</p> <p><a href="../../raw_ops/enqueuetpuembeddingarbitrarytensorbatch.html"><code translate="no" dir="ltr">EnqueueTPUEmbeddingArbitraryTensorBatch(...)</code></a>: Eases the porting of code that uses tf.nn.embedding_lookup_sparse().</p> <p><a href="../../raw_ops/enqueuetpuembeddingintegerbatch.html"><code translate="no" dir="ltr">EnqueueTPUEmbeddingIntegerBatch(...)</code></a>: An op that enqueues a list of input batch tensors to TPUEmbedding.</p> <p><a href="../../raw_ops/enqueuetpuembeddingraggedtensorbatch.html"><code translate="no" dir="ltr">EnqueueTPUEmbeddingRaggedTensorBatch(...)</code></a>: Eases the porting of code that uses tf.nn.embedding_lookup().</p> <p><a href="../../raw_ops/enqueuetpuembeddingsparsebatch.html"><code translate="no" dir="ltr">EnqueueTPUEmbeddingSparseBatch(...)</code></a>: An op that enqueues TPUEmbedding input indices from a SparseTensor.</p> <p><a href="../../raw_ops/enqueuetpuembeddingsparsetensorbatch.html"><code translate="no" dir="ltr">EnqueueTPUEmbeddingSparseTensorBatch(...)</code></a>: Eases the porting of code that uses tf.nn.embedding_lookup_sparse().</p> <p><a href="../../raw_ops/ensureshape.html"><code translate="no" dir="ltr">EnsureShape(...)</code></a>: Ensures that the tensor's shape matches the expected shape.</p> <p><a href="../../raw_ops/enter.html"><code translate="no" dir="ltr">Enter(...)</code></a>: Creates or finds a child frame, and makes <code translate="no" dir="ltr">data</code> available to the child frame.</p> <p><a href="../../raw_ops/equal.html"><code translate="no" dir="ltr">Equal(...)</code></a>: Returns the truth value of (x == y) element-wise.</p> <p><a href="../../raw_ops/erf.html"><code translate="no" dir="ltr">Erf(...)</code></a>: Computes the <a href="https://en.wikipedia.org/wiki/Error_function">Gauss error function</a> of <code translate="no" dir="ltr">x</code> element-wise. In statistics, for non-negative values of \(x\), the error function has the following interpretation: for a random variable \(Y\) that is normally distributed with mean 0 and variance \(1/\sqrt{2}\), \(erf(x)\) is the probability that \(Y\) falls in the range \([x, x]\).</p> <p><a href="../../raw_ops/erfc.html"><code translate="no" dir="ltr">Erfc(...)</code></a>: Computes the complementary error function of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/erfinv.html"><code translate="no" dir="ltr">Erfinv(...)</code></a></p> <p><a href="../../raw_ops/euclideannorm.html"><code translate="no" dir="ltr">EuclideanNorm(...)</code></a>: Computes the euclidean norm of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/exit.html"><code translate="no" dir="ltr">Exit(...)</code></a>: Exits the current frame to its parent frame.</p> <p><a href="../../raw_ops/exp.html"><code translate="no" dir="ltr">Exp(...)</code></a>: Computes exponential of x element-wise. \(y = e^x\).</p> <p><a href="../../raw_ops/expanddims.html"><code translate="no" dir="ltr">ExpandDims(...)</code></a>: Inserts a dimension of 1 into a tensor's shape.</p> <p><a href="../../raw_ops/experimentalassertnextdataset.html"><code translate="no" dir="ltr">ExperimentalAssertNextDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalautosharddataset.html"><code translate="no" dir="ltr">ExperimentalAutoShardDataset(...)</code></a>: Creates a dataset that shards the input dataset.</p> <p><a href="../../raw_ops/experimentalbytesproducedstatsdataset.html"><code translate="no" dir="ltr">ExperimentalBytesProducedStatsDataset(...)</code></a>: Records the bytes size of each element of <code translate="no" dir="ltr">input_dataset</code> in a StatsAggregator.</p> <p><a href="../../raw_ops/experimentalcsvdataset.html"><code translate="no" dir="ltr">ExperimentalCSVDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalchoosefastestdataset.html"><code translate="no" dir="ltr">ExperimentalChooseFastestDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentaldatasetcardinality.html"><code translate="no" dir="ltr">ExperimentalDatasetCardinality(...)</code></a>: Returns the cardinality of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentaldatasettotfrecord.html"><code translate="no" dir="ltr">ExperimentalDatasetToTFRecord(...)</code></a>: Writes the given dataset to the given file using the TFRecord format.</p> <p><a href="../../raw_ops/experimentaldensetosparsebatchdataset.html"><code translate="no" dir="ltr">ExperimentalDenseToSparseBatchDataset(...)</code></a>: Creates a dataset that batches input elements into a SparseTensor.</p> <p><a href="../../raw_ops/experimentaldirectedinterleavedataset.html"><code translate="no" dir="ltr">ExperimentalDirectedInterleaveDataset(...)</code></a>: A substitute for <code translate="no" dir="ltr">InterleaveDataset</code> on a fixed list of <code translate="no" dir="ltr">N</code> datasets.</p> <p><a href="../../raw_ops/experimentalgroupbyreducerdataset.html"><code translate="no" dir="ltr">ExperimentalGroupByReducerDataset(...)</code></a>: Creates a dataset that computes a group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalgroupbywindowdataset.html"><code translate="no" dir="ltr">ExperimentalGroupByWindowDataset(...)</code></a>: Creates a dataset that computes a windowed group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalignoreerrorsdataset.html"><code translate="no" dir="ltr">ExperimentalIgnoreErrorsDataset(...)</code></a>: Creates a dataset that contains the elements of <code translate="no" dir="ltr">input_dataset</code> ignoring errors.</p> <p><a href="../../raw_ops/experimentaliteratorgetdevice.html"><code translate="no" dir="ltr">ExperimentalIteratorGetDevice(...)</code></a>: Returns the name of the device on which <code translate="no" dir="ltr">resource</code> has been placed.</p> <p><a href="../../raw_ops/experimentallmdbdataset.html"><code translate="no" dir="ltr">ExperimentalLMDBDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentallatencystatsdataset.html"><code translate="no" dir="ltr">ExperimentalLatencyStatsDataset(...)</code></a>: Records the latency of producing <code translate="no" dir="ltr">input_dataset</code> elements in a StatsAggregator.</p> <p><a href="../../raw_ops/experimentalmapandbatchdataset.html"><code translate="no" dir="ltr">ExperimentalMapAndBatchDataset(...)</code></a>: Creates a dataset that fuses mapping with batching.</p> <p><a href="../../raw_ops/experimentalmapdataset.html"><code translate="no" dir="ltr">ExperimentalMapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalmatchingfilesdataset.html"><code translate="no" dir="ltr">ExperimentalMatchingFilesDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalmaxintraopparallelismdataset.html"><code translate="no" dir="ltr">ExperimentalMaxIntraOpParallelismDataset(...)</code></a>: Creates a dataset that overrides the maximum intra-op parallelism.</p> <p><a href="../../raw_ops/experimentalnonserializabledataset.html"><code translate="no" dir="ltr">ExperimentalNonSerializableDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalparallelinterleavedataset.html"><code translate="no" dir="ltr">ExperimentalParallelInterleaveDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalparseexampledataset.html"><code translate="no" dir="ltr">ExperimentalParseExampleDataset(...)</code></a>: Transforms <code translate="no" dir="ltr">input_dataset</code> containing <code translate="no" dir="ltr">Example</code> protos as vectors of DT_STRING into a dataset of <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects representing the parsed features.</p> <p><a href="../../raw_ops/experimentalprivatethreadpooldataset.html"><code translate="no" dir="ltr">ExperimentalPrivateThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalrandomdataset.html"><code translate="no" dir="ltr">ExperimentalRandomDataset(...)</code></a>: Creates a Dataset that returns pseudorandom numbers.</p> <p><a href="../../raw_ops/experimentalrebatchdataset.html"><code translate="no" dir="ltr">ExperimentalRebatchDataset(...)</code></a>: Creates a dataset that changes the batch size.</p> <p><a href="../../raw_ops/experimentalscandataset.html"><code translate="no" dir="ltr">ExperimentalScanDataset(...)</code></a>: Creates a dataset successively reduces <code translate="no" dir="ltr">f</code> over the elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalsetstatsaggregatordataset.html"><code translate="no" dir="ltr">ExperimentalSetStatsAggregatorDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalsleepdataset.html"><code translate="no" dir="ltr">ExperimentalSleepDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalslidingwindowdataset.html"><code translate="no" dir="ltr">ExperimentalSlidingWindowDataset(...)</code></a>: Creates a dataset that passes a sliding window over <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalsqldataset.html"><code translate="no" dir="ltr">ExperimentalSqlDataset(...)</code></a>: Creates a dataset that executes a SQL query and emits rows of the result set.</p> <p><a href="../../raw_ops/experimentalstatsaggregatorhandle.html"><code translate="no" dir="ltr">ExperimentalStatsAggregatorHandle(...)</code></a>: Creates a statistics manager resource.</p> <p><a href="../../raw_ops/experimentalstatsaggregatorsummary.html"><code translate="no" dir="ltr">ExperimentalStatsAggregatorSummary(...)</code></a>: Produces a summary of any statistics recorded by the given statistics manager.</p> <p><a href="../../raw_ops/experimentaltakewhiledataset.html"><code translate="no" dir="ltr">ExperimentalTakeWhileDataset(...)</code></a>: Creates a dataset that stops iteration when predicate` is false.</p> <p><a href="../../raw_ops/experimentalthreadpooldataset.html"><code translate="no" dir="ltr">ExperimentalThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalthreadpoolhandle.html"><code translate="no" dir="ltr">ExperimentalThreadPoolHandle(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalunbatchdataset.html"><code translate="no" dir="ltr">ExperimentalUnbatchDataset(...)</code></a>: A dataset that splits the elements of its input into multiple elements.</p> <p><a href="../../raw_ops/experimentaluniquedataset.html"><code translate="no" dir="ltr">ExperimentalUniqueDataset(...)</code></a>: Creates a dataset that contains the unique elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/expint.html"><code translate="no" dir="ltr">Expint(...)</code></a></p> <p><a href="../../raw_ops/expm1.html"><code translate="no" dir="ltr">Expm1(...)</code></a>: Computes <code translate="no" dir="ltr">exp(x) - 1</code> element-wise.</p> <p><a href="../../raw_ops/extractglimpse.html"><code translate="no" dir="ltr">ExtractGlimpse(...)</code></a>: Extracts a glimpse from the input tensor.</p> <p><a href="../../raw_ops/extractglimpsev2.html"><code translate="no" dir="ltr">ExtractGlimpseV2(...)</code></a>: Extracts a glimpse from the input tensor.</p> <p><a href="../../raw_ops/extractimagepatches.html"><code translate="no" dir="ltr">ExtractImagePatches(...)</code></a>: Extract <code translate="no" dir="ltr">patches</code> from <code translate="no" dir="ltr">images</code> and put them in the "depth" output dimension.</p> <p><a href="../../raw_ops/extractjpegshape.html"><code translate="no" dir="ltr">ExtractJpegShape(...)</code></a>: Extract the shape information of a JPEG-encoded image.</p> <p><a href="../../raw_ops/extractvolumepatches.html"><code translate="no" dir="ltr">ExtractVolumePatches(...)</code></a>: Extract <code translate="no" dir="ltr">patches</code> from <code translate="no" dir="ltr">input</code> and put them in the <code translate="no" dir="ltr">"depth"</code> output dimension. 3D extension of <code translate="no" dir="ltr">extract_image_patches</code>.</p> <p><a href="../../raw_ops/fft.html"><code translate="no" dir="ltr">FFT(...)</code></a>: Fast Fourier transform.</p> <p><a href="../../raw_ops/fft2d.html"><code translate="no" dir="ltr">FFT2D(...)</code></a>: 2D fast Fourier transform.</p> <p><a href="../../raw_ops/fft3d.html"><code translate="no" dir="ltr">FFT3D(...)</code></a>: 3D fast Fourier transform.</p> <p><a href="../../raw_ops/fftnd.html"><code translate="no" dir="ltr">FFTND(...)</code></a>: ND fast Fourier transform.</p> <p><a href="../../raw_ops/fifoqueue.html"><code translate="no" dir="ltr">FIFOQueue(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/fifoqueuev2.html"><code translate="no" dir="ltr">FIFOQueueV2(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/fact.html"><code translate="no" dir="ltr">Fact(...)</code></a>: Output a fact about factorials.</p> <p><a href="../../raw_ops/fakeparam.html"><code translate="no" dir="ltr">FakeParam(...)</code></a>: This op is used as a placeholder in If branch functions.</p> <p><a href="../../raw_ops/fakequantwithminmaxargs.html"><code translate="no" dir="ltr">FakeQuantWithMinMaxArgs(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same shape and type.</p> <p><a href="../../raw_ops/fakequantwithminmaxargsgradient.html"><code translate="no" dir="ltr">FakeQuantWithMinMaxArgsGradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p> <p><a href="../../raw_ops/fakequantwithminmaxvars.html"><code translate="no" dir="ltr">FakeQuantWithMinMaxVars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars</p> <p><a href="../../raw_ops/fakequantwithminmaxvarsgradient.html"><code translate="no" dir="ltr">FakeQuantWithMinMaxVarsGradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p> <p><a href="../../raw_ops/fakequantwithminmaxvarsperchannel.html"><code translate="no" dir="ltr">FakeQuantWithMinMaxVarsPerChannel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via per-channel floats</p> <p><a href="../../raw_ops/fakequantwithminmaxvarsperchannelgradient.html"><code translate="no" dir="ltr">FakeQuantWithMinMaxVarsPerChannelGradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p> <p><a href="../../raw_ops/fakequeue.html"><code translate="no" dir="ltr">FakeQueue(...)</code></a>: Deprecated. Do not use.</p> <p><a href="../../raw_ops/filesystemsetconfiguration.html"><code translate="no" dir="ltr">FileSystemSetConfiguration(...)</code></a>: Set configuration of the file system.</p> <p><a href="../../raw_ops/fill.html"><code translate="no" dir="ltr">Fill(...)</code></a>: Creates a tensor filled with a scalar value.</p> <p><a href="../../raw_ops/filterbylastcomponentdataset.html"><code translate="no" dir="ltr">FilterByLastComponentDataset(...)</code></a>: Creates a dataset containing elements of first component of <code translate="no" dir="ltr">input_dataset</code> having true in the last component.</p> <p><a href="../../raw_ops/filterdataset.html"><code translate="no" dir="ltr">FilterDataset(...)</code></a>: Creates a dataset containing elements of <code translate="no" dir="ltr">input_dataset</code> matching <code translate="no" dir="ltr">predicate</code>.</p> <p><a href="../../raw_ops/finalizedataset.html"><code translate="no" dir="ltr">FinalizeDataset(...)</code></a>: Creates a dataset by applying <a href="../../data/options.html"><code translate="no" dir="ltr">tf.data.Options</code></a> to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/fingerprint.html"><code translate="no" dir="ltr">Fingerprint(...)</code></a>: Generates fingerprint values.</p> <p><a href="../../raw_ops/fixedlengthrecorddataset.html"><code translate="no" dir="ltr">FixedLengthRecordDataset(...)</code></a>: Creates a dataset that emits the records from one or more binary files.</p> <p><a href="../../raw_ops/fixedlengthrecorddatasetv2.html"><code translate="no" dir="ltr">FixedLengthRecordDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/fixedlengthrecordreader.html"><code translate="no" dir="ltr">FixedLengthRecordReader(...)</code></a>: A Reader that outputs fixed-length records from a file.</p> <p><a href="../../raw_ops/fixedlengthrecordreaderv2.html"><code translate="no" dir="ltr">FixedLengthRecordReaderV2(...)</code></a>: A Reader that outputs fixed-length records from a file.</p> <p><a href="../../raw_ops/fixedunigramcandidatesampler.html"><code translate="no" dir="ltr">FixedUnigramCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/flatmapdataset.html"><code translate="no" dir="ltr">FlatMapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/floor.html"><code translate="no" dir="ltr">Floor(...)</code></a>: Returns element-wise largest integer not greater than x.</p> <p><a href="../../raw_ops/floordiv.html"><code translate="no" dir="ltr">FloorDiv(...)</code></a>: Returns x // y element-wise.</p> <p><a href="../../raw_ops/floormod.html"><code translate="no" dir="ltr">FloorMod(...)</code></a>: Returns element-wise remainder of division.</p> <p><a href="../../raw_ops/flushsummarywriter.html"><code translate="no" dir="ltr">FlushSummaryWriter(...)</code></a></p> <p><a href="../../raw_ops/for.html"><code translate="no" dir="ltr">For(...)</code></a>: Applies a for loop.</p> <p><a href="../../raw_ops/fractionalavgpool.html"><code translate="no" dir="ltr">FractionalAvgPool(...)</code></a>: Performs fractional average pooling on the input.</p> <p><a href="../../raw_ops/fractionalavgpoolgrad.html"><code translate="no" dir="ltr">FractionalAvgPoolGrad(...)</code></a>: Computes gradient of the FractionalAvgPool function.</p> <p><a href="../../raw_ops/fractionalmaxpool.html"><code translate="no" dir="ltr">FractionalMaxPool(...)</code></a>: Performs fractional max pooling on the input.</p> <p><a href="../../raw_ops/fractionalmaxpoolgrad.html"><code translate="no" dir="ltr">FractionalMaxPoolGrad(...)</code></a>: Computes gradient of the FractionalMaxPool function.</p> <p><a href="../../raw_ops/fresnelcos.html"><code translate="no" dir="ltr">FresnelCos(...)</code></a></p> <p><a href="../../raw_ops/fresnelsin.html"><code translate="no" dir="ltr">FresnelSin(...)</code></a></p> <p><a href="../../raw_ops/fusedbatchnorm.html"><code translate="no" dir="ltr">FusedBatchNorm(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormgrad.html"><code translate="no" dir="ltr">FusedBatchNormGrad(...)</code></a>: Gradient for batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormgradv2.html"><code translate="no" dir="ltr">FusedBatchNormGradV2(...)</code></a>: Gradient for batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormgradv3.html"><code translate="no" dir="ltr">FusedBatchNormGradV3(...)</code></a>: Gradient for batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormv2.html"><code translate="no" dir="ltr">FusedBatchNormV2(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormv3.html"><code translate="no" dir="ltr">FusedBatchNormV3(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/fusedpadconv2d.html"><code translate="no" dir="ltr">FusedPadConv2D(...)</code></a>: Performs a padding as a preprocess during a convolution.</p> <p><a href="../../raw_ops/fusedresizeandpadconv2d.html"><code translate="no" dir="ltr">FusedResizeAndPadConv2D(...)</code></a>: Performs a resize and padding as a preprocess during a convolution.</p> <p><a href="../../raw_ops/grublockcell.html"><code translate="no" dir="ltr">GRUBlockCell(...)</code></a>: Computes the GRU cell forward propagation for 1 time step.</p> <p><a href="../../raw_ops/grublockcellgrad.html"><code translate="no" dir="ltr">GRUBlockCellGrad(...)</code></a>: Computes the GRU cell back-propagation for 1 time step.</p> <p><a href="../../raw_ops/gather.html"><code translate="no" dir="ltr">Gather(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/gathernd.html"><code translate="no" dir="ltr">GatherNd(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> into a Tensor with shape specified by <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/gatherv2.html"><code translate="no" dir="ltr">GatherV2(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> axis <code translate="no" dir="ltr">axis</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/generateboundingboxproposals.html"><code translate="no" dir="ltr">GenerateBoundingBoxProposals(...)</code></a>: This op produces Region of Interests from given bounding boxes(bbox_deltas) encoded wrt anchors according to eq.2 in arXiv:1506.01497</p> <p><a href="../../raw_ops/generatevocabremapping.html"><code translate="no" dir="ltr">GenerateVocabRemapping(...)</code></a>: Given a path to new and old vocabulary files, returns a remapping Tensor of</p> <p><a href="../../raw_ops/generatordataset.html"><code translate="no" dir="ltr">GeneratorDataset(...)</code></a>: Creates a dataset that invokes a function to generate elements.</p> <p><a href="../../raw_ops/getelementatindex.html"><code translate="no" dir="ltr">GetElementAtIndex(...)</code></a>: Gets the element at the specified index in a dataset.</p> <p><a href="../../raw_ops/getminibatchsplitswithphysicalreplica.html"><code translate="no" dir="ltr">GetMinibatchSplitsWithPhysicalReplica(...)</code></a></p> <p><a href="../../raw_ops/getminibatchesincsrwithphysicalreplica.html"><code translate="no" dir="ltr">GetMinibatchesInCsrWithPhysicalReplica(...)</code></a></p> <p><a href="../../raw_ops/getoptions.html"><code translate="no" dir="ltr">GetOptions(...)</code></a>: Returns the <a href="../../data/options.html"><code translate="no" dir="ltr">tf.data.Options</code></a> attached to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/getsessionhandle.html"><code translate="no" dir="ltr">GetSessionHandle(...)</code></a>: Store the input tensor in the state of the current session.</p> <p><a href="../../raw_ops/getsessionhandlev2.html"><code translate="no" dir="ltr">GetSessionHandleV2(...)</code></a>: Store the input tensor in the state of the current session.</p> <p><a href="../../raw_ops/getsessiontensor.html"><code translate="no" dir="ltr">GetSessionTensor(...)</code></a>: Get the value of the tensor specified by its handle.</p> <p><a href="../../raw_ops/globaliterid.html"><code translate="no" dir="ltr">GlobalIterId(...)</code></a></p> <p><a href="../../raw_ops/greater.html"><code translate="no" dir="ltr">Greater(...)</code></a>: Returns the truth value of (x &gt; y) element-wise.</p> <p><a href="../../raw_ops/greaterequal.html"><code translate="no" dir="ltr">GreaterEqual(...)</code></a>: Returns the truth value of (x &gt;= y) element-wise.</p> <p><a href="../../raw_ops/groupbyreducerdataset.html"><code translate="no" dir="ltr">GroupByReducerDataset(...)</code></a>: Creates a dataset that computes a group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/groupbywindowdataset.html"><code translate="no" dir="ltr">GroupByWindowDataset(...)</code></a>: Creates a dataset that computes a windowed group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/guaranteeconst.html"><code translate="no" dir="ltr">GuaranteeConst(...)</code></a>: Gives a guarantee to the TF runtime that the input tensor is a constant.</p> <p><a href="../../raw_ops/hsvtorgb.html"><code translate="no" dir="ltr">HSVToRGB(...)</code></a>: Convert one or more images from HSV to RGB.</p> <p><a href="../../raw_ops/hashtable.html"><code translate="no" dir="ltr">HashTable(...)</code></a>: Creates a non-initialized hash table.</p> <p><a href="../../raw_ops/hashtablev2.html"><code translate="no" dir="ltr">HashTableV2(...)</code></a>: Creates a non-initialized hash table.</p> <p><a href="../../raw_ops/histogramfixedwidth.html"><code translate="no" dir="ltr">HistogramFixedWidth(...)</code></a>: Return histogram of values.</p> <p><a href="../../raw_ops/histogramsummary.html"><code translate="no" dir="ltr">HistogramSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with a histogram.</p> <p><a href="../../raw_ops/ifft.html"><code translate="no" dir="ltr">IFFT(...)</code></a>: Inverse fast Fourier transform.</p> <p><a href="../../raw_ops/ifft2d.html"><code translate="no" dir="ltr">IFFT2D(...)</code></a>: Inverse 2D fast Fourier transform.</p> <p><a href="../../raw_ops/ifft3d.html"><code translate="no" dir="ltr">IFFT3D(...)</code></a>: Inverse 3D fast Fourier transform.</p> <p><a href="../../raw_ops/ifftnd.html"><code translate="no" dir="ltr">IFFTND(...)</code></a>: ND inverse fast Fourier transform.</p> <p><a href="../../raw_ops/irfft.html"><code translate="no" dir="ltr">IRFFT(...)</code></a>: Inverse real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/irfft2d.html"><code translate="no" dir="ltr">IRFFT2D(...)</code></a>: Inverse 2D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/irfft3d.html"><code translate="no" dir="ltr">IRFFT3D(...)</code></a>: Inverse 3D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/irfftnd.html"><code translate="no" dir="ltr">IRFFTND(...)</code></a>: ND inverse real fast Fourier transform.</p> <p><a href="../../raw_ops/identity.html"><code translate="no" dir="ltr">Identity(...)</code></a>: Return a tensor with the same shape and contents as the input tensor or value.</p> <p><a href="../../raw_ops/identityn.html"><code translate="no" dir="ltr">IdentityN(...)</code></a>: Returns a list of tensors with the same shapes and contents as the input</p> <p><a href="../../raw_ops/identityreader.html"><code translate="no" dir="ltr">IdentityReader(...)</code></a>: A Reader that outputs the queued work as both the key and value.</p> <p><a href="../../raw_ops/identityreaderv2.html"><code translate="no" dir="ltr">IdentityReaderV2(...)</code></a>: A Reader that outputs the queued work as both the key and value.</p> <p><a href="../../raw_ops/if.html"><code translate="no" dir="ltr">If(...)</code></a>: output = cond ? then_branch(input) : else_branch(input)</p> <p><a href="../../raw_ops/igamma.html"><code translate="no" dir="ltr">Igamma(...)</code></a>: Compute the lower regularized incomplete Gamma function <code translate="no" dir="ltr">P(a, x)</code>.</p> <p><a href="../../raw_ops/igammagrada.html"><code translate="no" dir="ltr">IgammaGradA(...)</code></a>: Computes the gradient of <code translate="no" dir="ltr">igamma(a, x)</code> wrt <code translate="no" dir="ltr">a</code>.</p> <p><a href="../../raw_ops/igammac.html"><code translate="no" dir="ltr">Igammac(...)</code></a>: Compute the upper regularized incomplete Gamma function <code translate="no" dir="ltr">Q(a, x)</code>.</p> <p><a href="../../raw_ops/ignoreerrorsdataset.html"><code translate="no" dir="ltr">IgnoreErrorsDataset(...)</code></a>: Creates a dataset that contains the elements of <code translate="no" dir="ltr">input_dataset</code> ignoring errors.</p> <p><a href="../../raw_ops/imag.html"><code translate="no" dir="ltr">Imag(...)</code></a>: Returns the imaginary part of a complex number.</p> <p><a href="../../raw_ops/imageprojectivetransformv2.html"><code translate="no" dir="ltr">ImageProjectiveTransformV2(...)</code></a>: Applies the given transform to each of the images.</p> <p><a href="../../raw_ops/imageprojectivetransformv3.html"><code translate="no" dir="ltr">ImageProjectiveTransformV3(...)</code></a>: Applies the given transform to each of the images.</p> <p><a href="../../raw_ops/imagesummary.html"><code translate="no" dir="ltr">ImageSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with images.</p> <p><a href="../../raw_ops/immutableconst.html"><code translate="no" dir="ltr">ImmutableConst(...)</code></a>: Returns immutable tensor from memory region.</p> <p><a href="../../raw_ops/importevent.html"><code translate="no" dir="ltr">ImportEvent(...)</code></a></p> <p><a href="../../raw_ops/intopk.html"><code translate="no" dir="ltr">InTopK(...)</code></a>: Says whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="../../raw_ops/intopkv2.html"><code translate="no" dir="ltr">InTopKV2(...)</code></a>: Says whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="../../raw_ops/infeeddequeue.html"><code translate="no" dir="ltr">InfeedDequeue(...)</code></a>: A placeholder op for a value that will be fed into the computation.</p> <p><a href="../../raw_ops/infeeddequeuetuple.html"><code translate="no" dir="ltr">InfeedDequeueTuple(...)</code></a>: Fetches multiple values from infeed as an XLA tuple.</p> <p><a href="../../raw_ops/infeedenqueue.html"><code translate="no" dir="ltr">InfeedEnqueue(...)</code></a>: An op which feeds a single Tensor value into the computation.</p> <p><a href="../../raw_ops/infeedenqueueprelinearizedbuffer.html"><code translate="no" dir="ltr">InfeedEnqueuePrelinearizedBuffer(...)</code></a>: An op which enqueues prelinearized buffer into TPU infeed.</p> <p><a href="../../raw_ops/infeedenqueuetuple.html"><code translate="no" dir="ltr">InfeedEnqueueTuple(...)</code></a>: Feeds multiple Tensor values into the computation as an XLA tuple.</p> <p><a href="../../raw_ops/initializetable.html"><code translate="no" dir="ltr">InitializeTable(...)</code></a>: Table initializer that takes two tensors for keys and values respectively.</p> <p><a href="../../raw_ops/initializetablefromdataset.html"><code translate="no" dir="ltr">InitializeTableFromDataset(...)</code></a></p> <p><a href="../../raw_ops/initializetablefromtextfile.html"><code translate="no" dir="ltr">InitializeTableFromTextFile(...)</code></a>: Initializes a table from a text file.</p> <p><a href="../../raw_ops/initializetablefromtextfilev2.html"><code translate="no" dir="ltr">InitializeTableFromTextFileV2(...)</code></a>: Initializes a table from a text file.</p> <p><a href="../../raw_ops/initializetablev2.html"><code translate="no" dir="ltr">InitializeTableV2(...)</code></a>: Table initializer that takes two tensors for keys and values respectively.</p> <p><a href="../../raw_ops/inplaceadd.html"><code translate="no" dir="ltr">InplaceAdd(...)</code></a>: Adds v into specified rows of x.</p> <p><a href="../../raw_ops/inplacesub.html"><code translate="no" dir="ltr">InplaceSub(...)</code></a>: Subtracts <code translate="no" dir="ltr">v</code> into specified rows of <code translate="no" dir="ltr">x</code>.</p> <p><a href="../../raw_ops/inplaceupdate.html"><code translate="no" dir="ltr">InplaceUpdate(...)</code></a>: Updates specified rows 'i' with values 'v'.</p> <p><a href="../../raw_ops/interleavedataset.html"><code translate="no" dir="ltr">InterleaveDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/inv.html"><code translate="no" dir="ltr">Inv(...)</code></a>: Computes the reciprocal of x element-wise.</p> <p><a href="../../raw_ops/invgrad.html"><code translate="no" dir="ltr">InvGrad(...)</code></a>: Computes the gradient for the inverse of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/invert.html"><code translate="no" dir="ltr">Invert(...)</code></a>: Invert (flip) each bit of supported types; for example, type <code translate="no" dir="ltr">uint8</code> value 01010101 becomes 10101010.</p> <p><a href="../../raw_ops/invertpermutation.html"><code translate="no" dir="ltr">InvertPermutation(...)</code></a>: Computes the inverse permutation of a tensor.</p> <p><a href="../../raw_ops/isboostedtreesensembleinitialized.html"><code translate="no" dir="ltr">IsBoostedTreesEnsembleInitialized(...)</code></a>: Checks whether a tree ensemble has been initialized.</p> <p><a href="../../raw_ops/isboostedtreesquantilestreamresourceinitialized.html"><code translate="no" dir="ltr">IsBoostedTreesQuantileStreamResourceInitialized(...)</code></a>: Checks whether a quantile stream has been initialized.</p> <p><a href="../../raw_ops/isfinite.html"><code translate="no" dir="ltr">IsFinite(...)</code></a>: Returns which elements of x are finite.</p> <p><a href="../../raw_ops/isinf.html"><code translate="no" dir="ltr">IsInf(...)</code></a>: Returns which elements of x are Inf.</p> <p><a href="../../raw_ops/isnan.html"><code translate="no" dir="ltr">IsNan(...)</code></a>: Returns which elements of x are NaN.</p> <p><a href="../../raw_ops/istpuembeddinginitialized.html"><code translate="no" dir="ltr">IsTPUEmbeddingInitialized(...)</code></a>: Whether TPU Embedding is initialized in a distributed TPU system.</p> <p><a href="../../raw_ops/isvariableinitialized.html"><code translate="no" dir="ltr">IsVariableInitialized(...)</code></a>: Checks whether a tensor has been initialized.</p> <p><a href="../../raw_ops/isotonicregression.html"><code translate="no" dir="ltr">IsotonicRegression(...)</code></a>: Solves a batch of isotonic regression problems.</p> <p><a href="../../raw_ops/iterator.html"><code translate="no" dir="ltr">Iterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/iteratorfromstringhandle.html"><code translate="no" dir="ltr">IteratorFromStringHandle(...)</code></a>: Converts the given string representing a handle to an iterator to a resource.</p> <p><a href="../../raw_ops/iteratorfromstringhandlev2.html"><code translate="no" dir="ltr">IteratorFromStringHandleV2(...)</code></a></p> <p><a href="../../raw_ops/iteratorgetdevice.html"><code translate="no" dir="ltr">IteratorGetDevice(...)</code></a>: Returns the name of the device on which <code translate="no" dir="ltr">resource</code> has been placed.</p> <p><a href="../../raw_ops/iteratorgetnext.html"><code translate="no" dir="ltr">IteratorGetNext(...)</code></a>: Gets the next output from the given iterator .</p> <p><a href="../../raw_ops/iteratorgetnextasoptional.html"><code translate="no" dir="ltr">IteratorGetNextAsOptional(...)</code></a>: Gets the next output from the given iterator as an Optional variant.</p> <p><a href="../../raw_ops/iteratorgetnextsync.html"><code translate="no" dir="ltr">IteratorGetNextSync(...)</code></a>: Gets the next output from the given iterator.</p> <p><a href="../../raw_ops/iteratortostringhandle.html"><code translate="no" dir="ltr">IteratorToStringHandle(...)</code></a>: Converts the given <code translate="no" dir="ltr">resource_handle</code> representing an iterator to a string.</p> <p><a href="../../raw_ops/iteratorv2.html"><code translate="no" dir="ltr">IteratorV2(...)</code></a></p> <p><a href="../../raw_ops/kmc2chaininitialization.html"><code translate="no" dir="ltr">KMC2ChainInitialization(...)</code></a>: Returns the index of a data point that should be added to the seed set.</p> <p><a href="../../raw_ops/kmeansplusplusinitialization.html"><code translate="no" dir="ltr">KmeansPlusPlusInitialization(...)</code></a>: Selects num_to_sample rows of input using the KMeans++ criterion.</p> <p><a href="../../raw_ops/l2loss.html"><code translate="no" dir="ltr">L2Loss(...)</code></a>: L2 Loss.</p> <p><a href="../../raw_ops/lmdbdataset.html"><code translate="no" dir="ltr">LMDBDataset(...)</code></a>: Creates a dataset that emits the key-value pairs in one or more LMDB files.</p> <p><a href="../../raw_ops/lmdbreader.html"><code translate="no" dir="ltr">LMDBReader(...)</code></a>: A Reader that outputs the records from a LMDB file.</p> <p><a href="../../raw_ops/lrn.html"><code translate="no" dir="ltr">LRN(...)</code></a>: Local Response Normalization.</p> <p><a href="../../raw_ops/lrngrad.html"><code translate="no" dir="ltr">LRNGrad(...)</code></a>: Gradients for Local Response Normalization.</p> <p><a href="../../raw_ops/lstmblockcell.html"><code translate="no" dir="ltr">LSTMBlockCell(...)</code></a>: Computes the LSTM cell forward propagation for 1 time step.</p> <p><a href="../../raw_ops/lstmblockcellgrad.html"><code translate="no" dir="ltr">LSTMBlockCellGrad(...)</code></a>: Computes the LSTM cell backward propagation for 1 timestep.</p> <p><a href="../../raw_ops/latencystatsdataset.html"><code translate="no" dir="ltr">LatencyStatsDataset(...)</code></a>: Records the latency of producing <code translate="no" dir="ltr">input_dataset</code> elements in a StatsAggregator.</p> <p><a href="../../raw_ops/leakyrelu.html"><code translate="no" dir="ltr">LeakyRelu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, features * alpha)</code>.</p> <p><a href="../../raw_ops/leakyrelugrad.html"><code translate="no" dir="ltr">LeakyReluGrad(...)</code></a>: Computes rectified linear gradients for a LeakyRelu operation.</p> <p><a href="../../raw_ops/learnedunigramcandidatesampler.html"><code translate="no" dir="ltr">LearnedUnigramCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/leftshift.html"><code translate="no" dir="ltr">LeftShift(...)</code></a>: Elementwise computes the bitwise left-shift of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/legacyparallelinterleavedatasetv2.html"><code translate="no" dir="ltr">LegacyParallelInterleaveDatasetV2(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/less.html"><code translate="no" dir="ltr">Less(...)</code></a>: Returns the truth value of (x &lt; y) element-wise.</p> <p><a href="../../raw_ops/lessequal.html"><code translate="no" dir="ltr">LessEqual(...)</code></a>: Returns the truth value of (x &lt;= y) element-wise.</p> <p><a href="../../raw_ops/lgamma.html"><code translate="no" dir="ltr">Lgamma(...)</code></a>: Computes the log of the absolute value of <code translate="no" dir="ltr">Gamma(x)</code> element-wise.</p> <p><a href="../../raw_ops/linspace.html"><code translate="no" dir="ltr">LinSpace(...)</code></a>: Generates values in an interval.</p> <p><a href="../../raw_ops/listdataset.html"><code translate="no" dir="ltr">ListDataset(...)</code></a>: Creates a dataset that emits each of <code translate="no" dir="ltr">tensors</code> once.</p> <p><a href="../../raw_ops/listdiff.html"><code translate="no" dir="ltr">ListDiff(...)</code></a>: Computes the difference between two lists of numbers or strings.</p> <p><a href="../../raw_ops/listsnapshotchunksdataset.html"><code translate="no" dir="ltr">ListSnapshotChunksDataset(...)</code></a></p> <p><a href="../../raw_ops/loadandremapmatrix.html"><code translate="no" dir="ltr">LoadAndRemapMatrix(...)</code></a>: Loads a 2-D (matrix) <code translate="no" dir="ltr">Tensor</code> with name <code translate="no" dir="ltr">old_tensor_name</code> from the checkpoint</p> <p><a href="../../raw_ops/loaddataset.html"><code translate="no" dir="ltr">LoadDataset(...)</code></a></p> <p><a href="../../raw_ops/loadtpuembeddingadamparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingADAMParameters(...)</code></a>: Load ADAM embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingadadeltaparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingAdadeltaParameters(...)</code></a>: Load Adadelta embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingadagradmomentumparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingAdagradMomentumParameters(...)</code></a>: Load Adagrad Momentum embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingadagradparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingAdagradParameters(...)</code></a>: Load Adagrad embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingcenteredrmspropparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingCenteredRMSPropParameters(...)</code></a>: Load centered RMSProp embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingftrlparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingFTRLParameters(...)</code></a>: Load FTRL embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingfrequencyestimatorparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingFrequencyEstimatorParameters(...)</code></a>: Load frequency estimator embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingmdladagradlightparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingMDLAdagradLightParameters(...)</code></a>: Load MDL Adagrad Light embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingmomentumparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingMomentumParameters(...)</code></a>: Load Momentum embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingproximaladagradparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingProximalAdagradParameters(...)</code></a>: Load proximal Adagrad embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingproximalyogiparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingProximalYogiParameters(...)</code></a></p> <p><a href="../../raw_ops/loadtpuembeddingrmspropparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingRMSPropParameters(...)</code></a>: Load RMSProp embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingstochasticgradientdescentparameters.html"><code translate="no" dir="ltr">LoadTPUEmbeddingStochasticGradientDescentParameters(...)</code></a>: Load SGD embedding parameters.</p> <p><a href="../../raw_ops/log.html"><code translate="no" dir="ltr">Log(...)</code></a>: Computes natural logarithm of x element-wise.</p> <p><a href="../../raw_ops/log1p.html"><code translate="no" dir="ltr">Log1p(...)</code></a>: Computes natural logarithm of (1 + x) element-wise.</p> <p><a href="../../raw_ops/logmatrixdeterminant.html"><code translate="no" dir="ltr">LogMatrixDeterminant(...)</code></a>: Computes the sign and the log of the absolute value of the determinant of</p> <p><a href="../../raw_ops/logsoftmax.html"><code translate="no" dir="ltr">LogSoftmax(...)</code></a>: Computes log softmax activations.</p> <p><a href="../../raw_ops/loguniformcandidatesampler.html"><code translate="no" dir="ltr">LogUniformCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a log-uniform distribution.</p> <p><a href="../../raw_ops/logicaland.html"><code translate="no" dir="ltr">LogicalAnd(...)</code></a>: Returns the truth value of x AND y element-wise.</p> <p><a href="../../raw_ops/logicalnot.html"><code translate="no" dir="ltr">LogicalNot(...)</code></a>: Returns the truth value of <code translate="no" dir="ltr">NOT x</code> element-wise.</p> <p><a href="../../raw_ops/logicalor.html"><code translate="no" dir="ltr">LogicalOr(...)</code></a>: Returns the truth value of x OR y element-wise.</p> <p><a href="../../raw_ops/lookuptableexport.html"><code translate="no" dir="ltr">LookupTableExport(...)</code></a>: Outputs all keys and values in the table.</p> <p><a href="../../raw_ops/lookuptableexportv2.html"><code translate="no" dir="ltr">LookupTableExportV2(...)</code></a>: Outputs all keys and values in the table.</p> <p><a href="../../raw_ops/lookuptablefind.html"><code translate="no" dir="ltr">LookupTableFind(...)</code></a>: Looks up keys in a table, outputs the corresponding values.</p> <p><a href="../../raw_ops/lookuptablefindv2.html"><code translate="no" dir="ltr">LookupTableFindV2(...)</code></a>: Looks up keys in a table, outputs the corresponding values.</p> <p><a href="../../raw_ops/lookuptableimport.html"><code translate="no" dir="ltr">LookupTableImport(...)</code></a>: Replaces the contents of the table with the specified keys and values.</p> <p><a href="../../raw_ops/lookuptableimportv2.html"><code translate="no" dir="ltr">LookupTableImportV2(...)</code></a>: Replaces the contents of the table with the specified keys and values.</p> <p><a href="../../raw_ops/lookuptableinsert.html"><code translate="no" dir="ltr">LookupTableInsert(...)</code></a>: Updates the table to associates keys with values.</p> <p><a href="../../raw_ops/lookuptableinsertv2.html"><code translate="no" dir="ltr">LookupTableInsertV2(...)</code></a>: Updates the table to associates keys with values.</p> <p><a href="../../raw_ops/lookuptableremovev2.html"><code translate="no" dir="ltr">LookupTableRemoveV2(...)</code></a>: Removes keys and its associated values from a table.</p> <p><a href="../../raw_ops/lookuptablesize.html"><code translate="no" dir="ltr">LookupTableSize(...)</code></a>: Computes the number of elements in the given table.</p> <p><a href="../../raw_ops/lookuptablesizev2.html"><code translate="no" dir="ltr">LookupTableSizeV2(...)</code></a>: Computes the number of elements in the given table.</p> <p><a href="../../raw_ops/loopcond.html"><code translate="no" dir="ltr">LoopCond(...)</code></a>: Forwards the input to the output.</p> <p><a href="../../raw_ops/lowerbound.html"><code translate="no" dir="ltr">LowerBound(...)</code></a>: Applies lower_bound(sorted_search_values, values) along each row.</p> <p><a href="../../raw_ops/lu.html"><code translate="no" dir="ltr">Lu(...)</code></a>: Computes the LU decomposition of one or more square matrices.</p> <p><a href="../../raw_ops/makeiterator.html"><code translate="no" dir="ltr">MakeIterator(...)</code></a>: Makes a new iterator from the given <code translate="no" dir="ltr">dataset</code> and stores it in <code translate="no" dir="ltr">iterator</code>.</p> <p><a href="../../raw_ops/mapandbatchdataset.html"><code translate="no" dir="ltr">MapAndBatchDataset(...)</code></a>: Creates a dataset that fuses mapping with batching.</p> <p><a href="../../raw_ops/mapclear.html"><code translate="no" dir="ltr">MapClear(...)</code></a>: Op removes all elements in the underlying container.</p> <p><a href="../../raw_ops/mapdataset.html"><code translate="no" dir="ltr">MapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/mapdefun.html"><code translate="no" dir="ltr">MapDefun(...)</code></a>: Maps a function on the list of tensors unpacked from arguments on dimension 0.</p> <p><a href="../../raw_ops/mapincompletesize.html"><code translate="no" dir="ltr">MapIncompleteSize(...)</code></a>: Op returns the number of incomplete elements in the underlying container.</p> <p><a href="../../raw_ops/mappeek.html"><code translate="no" dir="ltr">MapPeek(...)</code></a>: Op peeks at the values at the specified key.</p> <p><a href="../../raw_ops/mapsize.html"><code translate="no" dir="ltr">MapSize(...)</code></a>: Op returns the number of elements in the underlying container.</p> <p><a href="../../raw_ops/mapstage.html"><code translate="no" dir="ltr">MapStage(...)</code></a>: Stage (key, values) in the underlying container which behaves like a hashtable.</p> <p><a href="../../raw_ops/mapunstage.html"><code translate="no" dir="ltr">MapUnstage(...)</code></a>: Op removes and returns the values associated with the key</p> <p><a href="../../raw_ops/mapunstagenokey.html"><code translate="no" dir="ltr">MapUnstageNoKey(...)</code></a>: Op removes and returns a random (key, value)</p> <p><a href="../../raw_ops/matmul.html"><code translate="no" dir="ltr">MatMul(...)</code></a>: Multiply the matrix "a" by the matrix "b".</p> <p><a href="../../raw_ops/matchingfiles.html"><code translate="no" dir="ltr">MatchingFiles(...)</code></a>: Returns the set of files matching one or more glob patterns.</p> <p><a href="../../raw_ops/matchingfilesdataset.html"><code translate="no" dir="ltr">MatchingFilesDataset(...)</code></a></p> <p><a href="../../raw_ops/matrixbandpart.html"><code translate="no" dir="ltr">MatrixBandPart(...)</code></a>: Copy a tensor setting everything outside a central band in each innermost matrix to zero.</p> <p><a href="../../raw_ops/matrixdeterminant.html"><code translate="no" dir="ltr">MatrixDeterminant(...)</code></a>: Computes the determinant of one or more square matrices.</p> <p><a href="../../raw_ops/matrixdiag.html"><code translate="no" dir="ltr">MatrixDiag(...)</code></a>: Returns a batched diagonal tensor with a given batched diagonal values.</p> <p><a href="../../raw_ops/matrixdiagpart.html"><code translate="no" dir="ltr">MatrixDiagPart(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../../raw_ops/matrixdiagpartv2.html"><code translate="no" dir="ltr">MatrixDiagPartV2(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../../raw_ops/matrixdiagpartv3.html"><code translate="no" dir="ltr">MatrixDiagPartV3(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../../raw_ops/matrixdiagv2.html"><code translate="no" dir="ltr">MatrixDiagV2(...)</code></a>: Returns a batched diagonal tensor with given batched diagonal values.</p> <p><a href="../../raw_ops/matrixdiagv3.html"><code translate="no" dir="ltr">MatrixDiagV3(...)</code></a>: Returns a batched diagonal tensor with given batched diagonal values.</p> <p><a href="../../raw_ops/matrixexponential.html"><code translate="no" dir="ltr">MatrixExponential(...)</code></a>: Deprecated, use python implementation tf.linalg.matrix_exponential.</p> <p><a href="../../raw_ops/matrixinverse.html"><code translate="no" dir="ltr">MatrixInverse(...)</code></a>: Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).</p> <p><a href="../../raw_ops/matrixlogarithm.html"><code translate="no" dir="ltr">MatrixLogarithm(...)</code></a>: Computes the matrix logarithm of one or more square matrices:</p> <p><a href="../../raw_ops/matrixsetdiag.html"><code translate="no" dir="ltr">MatrixSetDiag(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../../raw_ops/matrixsetdiagv2.html"><code translate="no" dir="ltr">MatrixSetDiagV2(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../../raw_ops/matrixsetdiagv3.html"><code translate="no" dir="ltr">MatrixSetDiagV3(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../../raw_ops/matrixsolve.html"><code translate="no" dir="ltr">MatrixSolve(...)</code></a>: Solves systems of linear equations.</p> <p><a href="../../raw_ops/matrixsolvels.html"><code translate="no" dir="ltr">MatrixSolveLs(...)</code></a>: Solves one or more linear least-squares problems.</p> <p><a href="../../raw_ops/matrixsquareroot.html"><code translate="no" dir="ltr">MatrixSquareRoot(...)</code></a>: Computes the matrix square root of one or more square matrices:</p> <p><a href="../../raw_ops/matrixtriangularsolve.html"><code translate="no" dir="ltr">MatrixTriangularSolve(...)</code></a>: Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.</p> <p><a href="../../raw_ops/max.html"><code translate="no" dir="ltr">Max(...)</code></a>: Computes the maximum of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/maxintraopparallelismdataset.html"><code translate="no" dir="ltr">MaxIntraOpParallelismDataset(...)</code></a>: Creates a dataset that overrides the maximum intra-op parallelism.</p> <p><a href="../../raw_ops/maxpool.html"><code translate="no" dir="ltr">MaxPool(...)</code></a>: Performs max pooling on the input.</p> <p><a href="../../raw_ops/maxpool3d.html"><code translate="no" dir="ltr">MaxPool3D(...)</code></a>: Performs 3D max pooling on the input.</p> <p><a href="../../raw_ops/maxpool3dgrad.html"><code translate="no" dir="ltr">MaxPool3DGrad(...)</code></a>: Computes gradients of 3D max pooling function.</p> <p><a href="../../raw_ops/maxpool3dgradgrad.html"><code translate="no" dir="ltr">MaxPool3DGradGrad(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgrad.html"><code translate="no" dir="ltr">MaxPoolGrad(...)</code></a>: Computes gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradgrad.html"><code translate="no" dir="ltr">MaxPoolGradGrad(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradgradv2.html"><code translate="no" dir="ltr">MaxPoolGradGradV2(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradgradwithargmax.html"><code translate="no" dir="ltr">MaxPoolGradGradWithArgmax(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradv2.html"><code translate="no" dir="ltr">MaxPoolGradV2(...)</code></a>: Computes gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradwithargmax.html"><code translate="no" dir="ltr">MaxPoolGradWithArgmax(...)</code></a>: Computes gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolv2.html"><code translate="no" dir="ltr">MaxPoolV2(...)</code></a>: Performs max pooling on the input.</p> <p><a href="../../raw_ops/maxpoolwithargmax.html"><code translate="no" dir="ltr">MaxPoolWithArgmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p> <p><a href="../../raw_ops/maximum.html"><code translate="no" dir="ltr">Maximum(...)</code></a>: Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise.</p> <p><a href="../../raw_ops/mean.html"><code translate="no" dir="ltr">Mean(...)</code></a>: Computes the mean of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/merge.html"><code translate="no" dir="ltr">Merge(...)</code></a>: Forwards the value of an available tensor from <code translate="no" dir="ltr">inputs</code> to <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/mergesummary.html"><code translate="no" dir="ltr">MergeSummary(...)</code></a>: Merges summaries.</p> <p><a href="../../raw_ops/mergev2checkpoints.html"><code translate="no" dir="ltr">MergeV2Checkpoints(...)</code></a>: V2 format specific: merges the metadata files of sharded checkpoints.</p> <p><a href="../../raw_ops/mfcc.html"><code translate="no" dir="ltr">Mfcc(...)</code></a>: Transforms a spectrogram into a form that's useful for speech recognition.</p> <p><a href="../../raw_ops/min.html"><code translate="no" dir="ltr">Min(...)</code></a>: Computes the minimum of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/minimum.html"><code translate="no" dir="ltr">Minimum(...)</code></a>: Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.</p> <p><a href="../../raw_ops/mirrorpad.html"><code translate="no" dir="ltr">MirrorPad(...)</code></a>: Pads a tensor with mirrored values.</p> <p><a href="../../raw_ops/mirrorpadgrad.html"><code translate="no" dir="ltr">MirrorPadGrad(...)</code></a>: Gradient op for <code translate="no" dir="ltr">MirrorPad</code> op. This op folds a mirror-padded tensor.</p> <p><a href="../../raw_ops/mod.html"><code translate="no" dir="ltr">Mod(...)</code></a>: Returns element-wise remainder of division.</p> <p><a href="../../raw_ops/modeldataset.html"><code translate="no" dir="ltr">ModelDataset(...)</code></a>: Identity transformation that models performance.</p> <p><a href="../../raw_ops/mul.html"><code translate="no" dir="ltr">Mul(...)</code></a>: Returns x * y element-wise.</p> <p><a href="../../raw_ops/mulnonan.html"><code translate="no" dir="ltr">MulNoNan(...)</code></a>: Returns x * y element-wise. Returns zero if y is zero, even if x if infinite or NaN.</p> <p><a href="../../raw_ops/multideviceiterator.html"><code translate="no" dir="ltr">MultiDeviceIterator(...)</code></a>: Creates a MultiDeviceIterator resource.</p> <p><a href="../../raw_ops/multideviceiteratorfromstringhandle.html"><code translate="no" dir="ltr">MultiDeviceIteratorFromStringHandle(...)</code></a>: Generates a MultiDeviceIterator resource from its provided string handle.</p> <p><a href="../../raw_ops/multideviceiteratorgetnextfromshard.html"><code translate="no" dir="ltr">MultiDeviceIteratorGetNextFromShard(...)</code></a>: Gets next element for the provided shard number.</p> <p><a href="../../raw_ops/multideviceiteratorinit.html"><code translate="no" dir="ltr">MultiDeviceIteratorInit(...)</code></a>: Initializes the multi device iterator with the given dataset.</p> <p><a href="../../raw_ops/multideviceiteratortostringhandle.html"><code translate="no" dir="ltr">MultiDeviceIteratorToStringHandle(...)</code></a>: Produces a string handle for the given MultiDeviceIterator.</p> <p><a href="../../raw_ops/multinomial.html"><code translate="no" dir="ltr">Multinomial(...)</code></a>: Draws samples from a multinomial distribution.</p> <p><a href="../../raw_ops/mutabledensehashtable.html"><code translate="no" dir="ltr">MutableDenseHashTable(...)</code></a>: Creates an empty hash table that uses tensors as the backing store.</p> <p><a href="../../raw_ops/mutabledensehashtablev2.html"><code translate="no" dir="ltr">MutableDenseHashTableV2(...)</code></a>: Creates an empty hash table that uses tensors as the backing store.</p> <p><a href="../../raw_ops/mutablehashtable.html"><code translate="no" dir="ltr">MutableHashTable(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutablehashtableoftensors.html"><code translate="no" dir="ltr">MutableHashTableOfTensors(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutablehashtableoftensorsv2.html"><code translate="no" dir="ltr">MutableHashTableOfTensorsV2(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutablehashtablev2.html"><code translate="no" dir="ltr">MutableHashTableV2(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutexlock.html"><code translate="no" dir="ltr">MutexLock(...)</code></a>: Locks a mutex resource.</p> <p><a href="../../raw_ops/mutexv2.html"><code translate="no" dir="ltr">MutexV2(...)</code></a>: Creates a Mutex resource that can be locked by <code translate="no" dir="ltr">MutexLock</code>.</p> <p><a href="../../raw_ops/ncclallreduce.html"><code translate="no" dir="ltr">NcclAllReduce(...)</code></a>: Outputs a tensor containing the reduction across all input tensors.</p> <p><a href="../../raw_ops/ncclbroadcast.html"><code translate="no" dir="ltr">NcclBroadcast(...)</code></a>: Sends <code translate="no" dir="ltr">input</code> to all devices that are connected to the output.</p> <p><a href="../../raw_ops/ncclreduce.html"><code translate="no" dir="ltr">NcclReduce(...)</code></a>: Reduces <code translate="no" dir="ltr">input</code> from <code translate="no" dir="ltr">num_devices</code> using <code translate="no" dir="ltr">reduction</code> to a single device.</p> <p><a href="../../raw_ops/ndtri.html"><code translate="no" dir="ltr">Ndtri(...)</code></a></p> <p><a href="../../raw_ops/nearestneighbors.html"><code translate="no" dir="ltr">NearestNeighbors(...)</code></a>: Selects the k nearest centers for each point.</p> <p><a href="../../raw_ops/neg.html"><code translate="no" dir="ltr">Neg(...)</code></a>: Computes numerical negative value element-wise.</p> <p><a href="../../raw_ops/nextafter.html"><code translate="no" dir="ltr">NextAfter(...)</code></a>: Returns the next representable value of <code translate="no" dir="ltr">x1</code> in the direction of <code translate="no" dir="ltr">x2</code>, element-wise.</p> <p><a href="../../raw_ops/nextiteration.html"><code translate="no" dir="ltr">NextIteration(...)</code></a>: Makes its input available to the next iteration.</p> <p><a href="../../raw_ops/noop.html"><code translate="no" dir="ltr">NoOp(...)</code></a>: Does nothing. Only useful as a placeholder for control edges.</p> <p><a href="../../raw_ops/nondeterministicints.html"><code translate="no" dir="ltr">NonDeterministicInts(...)</code></a>: Non-deterministically generates some integers.</p> <p><a href="../../raw_ops/nonmaxsuppression.html"><code translate="no" dir="ltr">NonMaxSuppression(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv2.html"><code translate="no" dir="ltr">NonMaxSuppressionV2(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv3.html"><code translate="no" dir="ltr">NonMaxSuppressionV3(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv4.html"><code translate="no" dir="ltr">NonMaxSuppressionV4(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv5.html"><code translate="no" dir="ltr">NonMaxSuppressionV5(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionwithoverlaps.html"><code translate="no" dir="ltr">NonMaxSuppressionWithOverlaps(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonserializabledataset.html"><code translate="no" dir="ltr">NonSerializableDataset(...)</code></a></p> <p><a href="../../raw_ops/notequal.html"><code translate="no" dir="ltr">NotEqual(...)</code></a>: Returns the truth value of (x != y) element-wise.</p> <p><a href="../../raw_ops/nthelement.html"><code translate="no" dir="ltr">NthElement(...)</code></a>: Finds values of the <code translate="no" dir="ltr">n</code>-th order statistic for the last dimension.</p> <p><a href="../../raw_ops/onehot.html"><code translate="no" dir="ltr">OneHot(...)</code></a>: Returns a one-hot tensor.</p> <p><a href="../../raw_ops/oneshotiterator.html"><code translate="no" dir="ltr">OneShotIterator(...)</code></a>: Makes a "one-shot" iterator that can be iterated only once.</p> <p><a href="../../raw_ops/oneslike.html"><code translate="no" dir="ltr">OnesLike(...)</code></a>: Returns a tensor of ones with the same shape and type as x.</p> <p><a href="../../raw_ops/optimizedataset.html"><code translate="no" dir="ltr">OptimizeDataset(...)</code></a>: Creates a dataset by applying optimizations to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/optimizedatasetv2.html"><code translate="no" dir="ltr">OptimizeDatasetV2(...)</code></a>: Creates a dataset by applying related optimizations to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/optionalfromvalue.html"><code translate="no" dir="ltr">OptionalFromValue(...)</code></a>: Constructs an Optional variant from a tuple of tensors.</p> <p><a href="../../raw_ops/optionalgetvalue.html"><code translate="no" dir="ltr">OptionalGetValue(...)</code></a>: Returns the value stored in an Optional variant or raises an error if none exists.</p> <p><a href="../../raw_ops/optionalhasvalue.html"><code translate="no" dir="ltr">OptionalHasValue(...)</code></a>: Returns true if and only if the given Optional variant has a value.</p> <p><a href="../../raw_ops/optionalnone.html"><code translate="no" dir="ltr">OptionalNone(...)</code></a>: Creates an Optional variant with no value.</p> <p><a href="../../raw_ops/optionsdataset.html"><code translate="no" dir="ltr">OptionsDataset(...)</code></a>: Creates a dataset by attaching tf.data.Options to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/orderedmapclear.html"><code translate="no" dir="ltr">OrderedMapClear(...)</code></a>: Op removes all elements in the underlying container.</p> <p><a href="../../raw_ops/orderedmapincompletesize.html"><code translate="no" dir="ltr">OrderedMapIncompleteSize(...)</code></a>: Op returns the number of incomplete elements in the underlying container.</p> <p><a href="../../raw_ops/orderedmappeek.html"><code translate="no" dir="ltr">OrderedMapPeek(...)</code></a>: Op peeks at the values at the specified key.</p> <p><a href="../../raw_ops/orderedmapsize.html"><code translate="no" dir="ltr">OrderedMapSize(...)</code></a>: Op returns the number of elements in the underlying container.</p> <p><a href="../../raw_ops/orderedmapstage.html"><code translate="no" dir="ltr">OrderedMapStage(...)</code></a>: Stage (key, values) in the underlying container which behaves like a ordered</p> <p><a href="../../raw_ops/orderedmapunstage.html"><code translate="no" dir="ltr">OrderedMapUnstage(...)</code></a>: Op removes and returns the values associated with the key</p> <p><a href="../../raw_ops/orderedmapunstagenokey.html"><code translate="no" dir="ltr">OrderedMapUnstageNoKey(...)</code></a>: Op removes and returns the (key, value) element with the smallest</p> <p><a href="../../raw_ops/outfeeddequeue.html"><code translate="no" dir="ltr">OutfeedDequeue(...)</code></a>: Retrieves a single tensor from the computation outfeed.</p> <p><a href="../../raw_ops/outfeeddequeuetuple.html"><code translate="no" dir="ltr">OutfeedDequeueTuple(...)</code></a>: Retrieve multiple values from the computation outfeed.</p> <p><a href="../../raw_ops/outfeeddequeuetuplev2.html"><code translate="no" dir="ltr">OutfeedDequeueTupleV2(...)</code></a>: Retrieve multiple values from the computation outfeed.</p> <p><a href="../../raw_ops/outfeeddequeuev2.html"><code translate="no" dir="ltr">OutfeedDequeueV2(...)</code></a>: Retrieves a single tensor from the computation outfeed.</p> <p><a href="../../raw_ops/outfeedenqueue.html"><code translate="no" dir="ltr">OutfeedEnqueue(...)</code></a>: Enqueue a Tensor on the computation outfeed.</p> <p><a href="../../raw_ops/outfeedenqueuetuple.html"><code translate="no" dir="ltr">OutfeedEnqueueTuple(...)</code></a>: Enqueue multiple Tensor values on the computation outfeed.</p> <p><a href="../../raw_ops/pack.html"><code translate="no" dir="ltr">Pack(...)</code></a>: Packs a list of <code translate="no" dir="ltr">N</code> rank-<code translate="no" dir="ltr">R</code> tensors into one rank-<code translate="no" dir="ltr">(R+1)</code> tensor.</p> <p><a href="../../raw_ops/pad.html"><code translate="no" dir="ltr">Pad(...)</code></a>: Pads a tensor with zeros.</p> <p><a href="../../raw_ops/padv2.html"><code translate="no" dir="ltr">PadV2(...)</code></a>: Pads a tensor.</p> <p><a href="../../raw_ops/paddedbatchdataset.html"><code translate="no" dir="ltr">PaddedBatchDataset(...)</code></a>: Creates a dataset that batches and pads <code translate="no" dir="ltr">batch_size</code> elements from the input.</p> <p><a href="../../raw_ops/paddedbatchdatasetv2.html"><code translate="no" dir="ltr">PaddedBatchDatasetV2(...)</code></a>: Creates a dataset that batches and pads <code translate="no" dir="ltr">batch_size</code> elements from the input.</p> <p><a href="../../raw_ops/paddingfifoqueue.html"><code translate="no" dir="ltr">PaddingFIFOQueue(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/paddingfifoqueuev2.html"><code translate="no" dir="ltr">PaddingFIFOQueueV2(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/parallelbatchdataset.html"><code translate="no" dir="ltr">ParallelBatchDataset(...)</code></a></p> <p><a href="../../raw_ops/parallelconcat.html"><code translate="no" dir="ltr">ParallelConcat(...)</code></a>: Concatenates a list of <code translate="no" dir="ltr">N</code> tensors along the first dimension.</p> <p><a href="../../raw_ops/paralleldynamicstitch.html"><code translate="no" dir="ltr">ParallelDynamicStitch(...)</code></a>: Interleave the values from the <code translate="no" dir="ltr">data</code> tensors into a single tensor.</p> <p><a href="../../raw_ops/parallelfilterdataset.html"><code translate="no" dir="ltr">ParallelFilterDataset(...)</code></a>: Creates a dataset containing elements of <code translate="no" dir="ltr">input_dataset</code> matching <code translate="no" dir="ltr">predicate</code>.</p> <p><a href="../../raw_ops/parallelinterleavedataset.html"><code translate="no" dir="ltr">ParallelInterleaveDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelinterleavedatasetv2.html"><code translate="no" dir="ltr">ParallelInterleaveDatasetV2(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelinterleavedatasetv3.html"><code translate="no" dir="ltr">ParallelInterleaveDatasetV3(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelinterleavedatasetv4.html"><code translate="no" dir="ltr">ParallelInterleaveDatasetV4(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelmapdataset.html"><code translate="no" dir="ltr">ParallelMapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelmapdatasetv2.html"><code translate="no" dir="ltr">ParallelMapDatasetV2(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parameterizedtruncatednormal.html"><code translate="no" dir="ltr">ParameterizedTruncatedNormal(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="../../raw_ops/parseexample.html"><code translate="no" dir="ltr">ParseExample(...)</code></a>: Transforms a vector of brain.Example protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parseexampledataset.html"><code translate="no" dir="ltr">ParseExampleDataset(...)</code></a>: Transforms <code translate="no" dir="ltr">input_dataset</code> containing <code translate="no" dir="ltr">Example</code> protos as vectors of DT_STRING into a dataset of <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects representing the parsed features.</p> <p><a href="../../raw_ops/parseexampledatasetv2.html"><code translate="no" dir="ltr">ParseExampleDatasetV2(...)</code></a>: Transforms <code translate="no" dir="ltr">input_dataset</code> containing <code translate="no" dir="ltr">Example</code> protos as vectors of DT_STRING into a dataset of <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects representing the parsed features.</p> <p><a href="../../raw_ops/parseexamplev2.html"><code translate="no" dir="ltr">ParseExampleV2(...)</code></a>: Transforms a vector of tf.Example protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsesequenceexample.html"><code translate="no" dir="ltr">ParseSequenceExample(...)</code></a>: Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsesequenceexamplev2.html"><code translate="no" dir="ltr">ParseSequenceExampleV2(...)</code></a>: Transforms a vector of tf.io.SequenceExample protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsesingleexample.html"><code translate="no" dir="ltr">ParseSingleExample(...)</code></a>: Transforms a tf.Example proto (as a string) into typed tensors.</p> <p><a href="../../raw_ops/parsesinglesequenceexample.html"><code translate="no" dir="ltr">ParseSingleSequenceExample(...)</code></a>: Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsetensor.html"><code translate="no" dir="ltr">ParseTensor(...)</code></a>: Transforms a serialized tensorflow.TensorProto proto into a Tensor.</p> <p><a href="../../raw_ops/partitionedcall.html"><code translate="no" dir="ltr">PartitionedCall(...)</code></a>: returns <code translate="no" dir="ltr">f(inputs)</code>, where <code translate="no" dir="ltr">f</code>'s body is placed and partitioned.</p> <p><a href="../../raw_ops/placeholder.html"><code translate="no" dir="ltr">Placeholder(...)</code></a>: A placeholder op for a value that will be fed into the computation.</p> <p><a href="../../raw_ops/placeholderv2.html"><code translate="no" dir="ltr">PlaceholderV2(...)</code></a>: A placeholder op for a value that will be fed into the computation.</p> <p><a href="../../raw_ops/placeholderwithdefault.html"><code translate="no" dir="ltr">PlaceholderWithDefault(...)</code></a>: A placeholder op that passes through <code translate="no" dir="ltr">input</code> when its output is not fed.</p> <p><a href="../../raw_ops/polygamma.html"><code translate="no" dir="ltr">Polygamma(...)</code></a>: Compute the polygamma function \(\psi^{(n)}(x)\).</p> <p><a href="../../raw_ops/populationcount.html"><code translate="no" dir="ltr">PopulationCount(...)</code></a>: Computes element-wise population count (a.k.a. popcount, bitsum, bitcount).</p> <p><a href="../../raw_ops/pow.html"><code translate="no" dir="ltr">Pow(...)</code></a>: Computes the power of one value to another.</p> <p><a href="../../raw_ops/prefetchdataset.html"><code translate="no" dir="ltr">PrefetchDataset(...)</code></a>: Creates a dataset that asynchronously prefetches elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/prelinearize.html"><code translate="no" dir="ltr">Prelinearize(...)</code></a>: An op which linearizes one Tensor value to an opaque variant tensor.</p> <p><a href="../../raw_ops/prelinearizetuple.html"><code translate="no" dir="ltr">PrelinearizeTuple(...)</code></a>: An op which linearizes multiple Tensor values to an opaque variant tensor.</p> <p><a href="../../raw_ops/preventgradient.html"><code translate="no" dir="ltr">PreventGradient(...)</code></a>: An identity op that triggers an error if a gradient is requested.</p> <p><a href="../../raw_ops/print.html"><code translate="no" dir="ltr">Print(...)</code></a>: Prints a list of tensors.</p> <p><a href="../../raw_ops/printv2.html"><code translate="no" dir="ltr">PrintV2(...)</code></a>: Prints a string scalar.</p> <p><a href="../../raw_ops/priorityqueue.html"><code translate="no" dir="ltr">PriorityQueue(...)</code></a>: A queue that produces elements sorted by the first component value.</p> <p><a href="../../raw_ops/priorityqueuev2.html"><code translate="no" dir="ltr">PriorityQueueV2(...)</code></a>: A queue that produces elements sorted by the first component value.</p> <p><a href="../../raw_ops/privatethreadpooldataset.html"><code translate="no" dir="ltr">PrivateThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/prod.html"><code translate="no" dir="ltr">Prod(...)</code></a>: Computes the product of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/pyfunc.html"><code translate="no" dir="ltr">PyFunc(...)</code></a>: Invokes a python function to compute func(input)-&gt;output.</p> <p><a href="../../raw_ops/pyfuncstateless.html"><code translate="no" dir="ltr">PyFuncStateless(...)</code></a>: A stateless version of PyFunc.</p> <p><a href="../../raw_ops/qr.html"><code translate="no" dir="ltr">Qr(...)</code></a>: Computes the QR decompositions of one or more matrices.</p> <p><a href="../../raw_ops/quantizeanddequantize.html"><code translate="no" dir="ltr">QuantizeAndDequantize(...)</code></a>: Use QuantizeAndDequantizeV2 instead.</p> <p><a href="../../raw_ops/quantizeanddequantizev2.html"><code translate="no" dir="ltr">QuantizeAndDequantizeV2(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="../../raw_ops/quantizeanddequantizev3.html"><code translate="no" dir="ltr">QuantizeAndDequantizeV3(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="../../raw_ops/quantizeanddequantizev4.html"><code translate="no" dir="ltr">QuantizeAndDequantizeV4(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="../../raw_ops/quantizeanddequantizev4grad.html"><code translate="no" dir="ltr">QuantizeAndDequantizeV4Grad(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">QuantizeAndDequantizeV4</code>.</p> <p><a href="../../raw_ops/quantizedownandshrinkrange.html"><code translate="no" dir="ltr">QuantizeDownAndShrinkRange(...)</code></a>: Convert the quantized 'input' tensor into a lower-precision 'output', using the</p> <p><a href="../../raw_ops/quantizev2.html"><code translate="no" dir="ltr">QuantizeV2(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <p><a href="../../raw_ops/quantizedadd.html"><code translate="no" dir="ltr">QuantizedAdd(...)</code></a>: Returns x + y element-wise, working on quantized buffers.</p> <p><a href="../../raw_ops/quantizedavgpool.html"><code translate="no" dir="ltr">QuantizedAvgPool(...)</code></a>: Produces the average pool of the input tensor for quantized types.</p> <p><a href="../../raw_ops/quantizedbatchnormwithglobalnormalization.html"><code translate="no" dir="ltr">QuantizedBatchNormWithGlobalNormalization(...)</code></a>: Quantized Batch normalization.</p> <p><a href="../../raw_ops/quantizedbiasadd.html"><code translate="no" dir="ltr">QuantizedBiasAdd(...)</code></a>: Adds Tensor 'bias' to Tensor 'input' for Quantized types.</p> <p><a href="../../raw_ops/quantizedconcat.html"><code translate="no" dir="ltr">QuantizedConcat(...)</code></a>: Concatenates quantized tensors along one dimension.</p> <p><a href="../../raw_ops/quantizedconv2d.html"><code translate="no" dir="ltr">QuantizedConv2D(...)</code></a>: Computes a 2D convolution given quantized 4D input and filter tensors.</p> <p><a href="../../raw_ops/quantizedconv2dandrelu.html"><code translate="no" dir="ltr">QuantizedConv2DAndRelu(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dandreluandrequantize.html"><code translate="no" dir="ltr">QuantizedConv2DAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dandrequantize.html"><code translate="no" dir="ltr">QuantizedConv2DAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dperchannel.html"><code translate="no" dir="ltr">QuantizedConv2DPerChannel(...)</code></a>: Computes QuantizedConv2D per channel.</p> <p><a href="../../raw_ops/quantizedconv2dwithbias.html"><code translate="no" dir="ltr">QuantizedConv2DWithBias(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiasandrelu.html"><code translate="no" dir="ltr">QuantizedConv2DWithBiasAndRelu(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiasandreluandrequantize.html"><code translate="no" dir="ltr">QuantizedConv2DWithBiasAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiasandrequantize.html"><code translate="no" dir="ltr">QuantizedConv2DWithBiasAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiassignedsumandreluandrequantize.html"><code translate="no" dir="ltr">QuantizedConv2DWithBiasSignedSumAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiassumandrelu.html"><code translate="no" dir="ltr">QuantizedConv2DWithBiasSumAndRelu(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiassumandreluandrequantize.html"><code translate="no" dir="ltr">QuantizedConv2DWithBiasSumAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizeddepthwiseconv2d.html"><code translate="no" dir="ltr">QuantizedDepthwiseConv2D(...)</code></a>: Computes quantized depthwise Conv2D.</p> <p><a href="../../raw_ops/quantizeddepthwiseconv2dwithbias.html"><code translate="no" dir="ltr">QuantizedDepthwiseConv2DWithBias(...)</code></a>: Computes quantized depthwise Conv2D with Bias.</p> <p><a href="../../raw_ops/quantizeddepthwiseconv2dwithbiasandrelu.html"><code translate="no" dir="ltr">QuantizedDepthwiseConv2DWithBiasAndRelu(...)</code></a>: Computes quantized depthwise Conv2D with Bias and Relu.</p> <p><a href="../../raw_ops/quantizeddepthwiseconv2dwithbiasandreluandrequantize.html"><code translate="no" dir="ltr">QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize(...)</code></a>: Computes quantized depthwise Conv2D with Bias, Relu and Requantize.</p> <p><a href="../../raw_ops/quantizedinstancenorm.html"><code translate="no" dir="ltr">QuantizedInstanceNorm(...)</code></a>: Quantized Instance normalization.</p> <p><a href="../../raw_ops/quantizedmatmul.html"><code translate="no" dir="ltr">QuantizedMatMul(...)</code></a>: Perform a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code>.</p> <p><a href="../../raw_ops/quantizedmatmulwithbias.html"><code translate="no" dir="ltr">QuantizedMatMulWithBias(...)</code></a>: Performs a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code> with bias add.</p> <p><a href="../../raw_ops/quantizedmatmulwithbiasanddequantize.html"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndDequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedmatmulwithbiasandrelu.html"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndRelu(...)</code></a>: Perform a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code> with bias add and relu fusion.</p> <p><a href="../../raw_ops/quantizedmatmulwithbiasandreluandrequantize.html"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndReluAndRequantize(...)</code></a>: Perform a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code> with bias add and relu and requantize fusion.</p> <p><a href="../../raw_ops/quantizedmatmulwithbiasandrequantize.html"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedmaxpool.html"><code translate="no" dir="ltr">QuantizedMaxPool(...)</code></a>: Produces the max pool of the input tensor for quantized types.</p> <p><a href="../../raw_ops/quantizedmul.html"><code translate="no" dir="ltr">QuantizedMul(...)</code></a>: Returns x * y element-wise, working on quantized buffers.</p> <p><a href="../../raw_ops/quantizedrelu.html"><code translate="no" dir="ltr">QuantizedRelu(...)</code></a>: Computes Quantized Rectified Linear: <code translate="no" dir="ltr">max(features, 0)</code></p> <p><a href="../../raw_ops/quantizedrelu6.html"><code translate="no" dir="ltr">QuantizedRelu6(...)</code></a>: Computes Quantized Rectified Linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code></p> <p><a href="../../raw_ops/quantizedrelux.html"><code translate="no" dir="ltr">QuantizedReluX(...)</code></a>: Computes Quantized Rectified Linear X: <code translate="no" dir="ltr">min(max(features, 0), max_value)</code></p> <p><a href="../../raw_ops/quantizedreshape.html"><code translate="no" dir="ltr">QuantizedReshape(...)</code></a>: Reshapes a quantized tensor as per the Reshape op.</p> <p><a href="../../raw_ops/quantizedresizebilinear.html"><code translate="no" dir="ltr">QuantizedResizeBilinear(...)</code></a>: Resize quantized <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using quantized bilinear interpolation.</p> <p><a href="../../raw_ops/queueclose.html"><code translate="no" dir="ltr">QueueClose(...)</code></a>: Closes the given queue.</p> <p><a href="../../raw_ops/queueclosev2.html"><code translate="no" dir="ltr">QueueCloseV2(...)</code></a>: Closes the given queue.</p> <p><a href="../../raw_ops/queuedequeue.html"><code translate="no" dir="ltr">QueueDequeue(...)</code></a>: Dequeues a tuple of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeuemany.html"><code translate="no" dir="ltr">QueueDequeueMany(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeuemanyv2.html"><code translate="no" dir="ltr">QueueDequeueManyV2(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeueupto.html"><code translate="no" dir="ltr">QueueDequeueUpTo(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeueuptov2.html"><code translate="no" dir="ltr">QueueDequeueUpToV2(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeuev2.html"><code translate="no" dir="ltr">QueueDequeueV2(...)</code></a>: Dequeues a tuple of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queueenqueue.html"><code translate="no" dir="ltr">QueueEnqueue(...)</code></a>: Enqueues a tuple of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueenqueuemany.html"><code translate="no" dir="ltr">QueueEnqueueMany(...)</code></a>: Enqueues zero or more tuples of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueenqueuemanyv2.html"><code translate="no" dir="ltr">QueueEnqueueManyV2(...)</code></a>: Enqueues zero or more tuples of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueenqueuev2.html"><code translate="no" dir="ltr">QueueEnqueueV2(...)</code></a>: Enqueues a tuple of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueisclosed.html"><code translate="no" dir="ltr">QueueIsClosed(...)</code></a>: Returns true if queue is closed.</p> <p><a href="../../raw_ops/queueisclosedv2.html"><code translate="no" dir="ltr">QueueIsClosedV2(...)</code></a>: Returns true if queue is closed.</p> <p><a href="../../raw_ops/queuesize.html"><code translate="no" dir="ltr">QueueSize(...)</code></a>: Computes the number of elements in the given queue.</p> <p><a href="../../raw_ops/queuesizev2.html"><code translate="no" dir="ltr">QueueSizeV2(...)</code></a>: Computes the number of elements in the given queue.</p> <p><a href="../../raw_ops/rfft.html"><code translate="no" dir="ltr">RFFT(...)</code></a>: Real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/rfft2d.html"><code translate="no" dir="ltr">RFFT2D(...)</code></a>: 2D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/rfft3d.html"><code translate="no" dir="ltr">RFFT3D(...)</code></a>: 3D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/rfftnd.html"><code translate="no" dir="ltr">RFFTND(...)</code></a>: ND fast real Fourier transform.</p> <p><a href="../../raw_ops/rgbtohsv.html"><code translate="no" dir="ltr">RGBToHSV(...)</code></a>: Converts one or more images from RGB to HSV.</p> <p><a href="../../raw_ops/raggedbincount.html"><code translate="no" dir="ltr">RaggedBincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/raggedcountsparseoutput.html"><code translate="no" dir="ltr">RaggedCountSparseOutput(...)</code></a>: Performs sparse-output bin counting for a ragged tensor input.</p> <p><a href="../../raw_ops/raggedcross.html"><code translate="no" dir="ltr">RaggedCross(...)</code></a>: Generates a feature cross from a list of tensors, and returns it as a RaggedTensor.</p> <p><a href="../../raw_ops/raggedfillemptyrows.html"><code translate="no" dir="ltr">RaggedFillEmptyRows(...)</code></a></p> <p><a href="../../raw_ops/raggedfillemptyrowsgrad.html"><code translate="no" dir="ltr">RaggedFillEmptyRowsGrad(...)</code></a></p> <p><a href="../../raw_ops/raggedgather.html"><code translate="no" dir="ltr">RaggedGather(...)</code></a>: Gather ragged slices from <code translate="no" dir="ltr">params</code> axis <code translate="no" dir="ltr">0</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/raggedrange.html"><code translate="no" dir="ltr">RaggedRange(...)</code></a>: Returns a <code translate="no" dir="ltr">RaggedTensor</code> containing the specified sequences of numbers.</p> <p><a href="../../raw_ops/raggedtensorfromvariant.html"><code translate="no" dir="ltr">RaggedTensorFromVariant(...)</code></a>: Decodes a <code translate="no" dir="ltr">variant</code> Tensor into a <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p><a href="../../raw_ops/raggedtensortosparse.html"><code translate="no" dir="ltr">RaggedTensorToSparse(...)</code></a>: Converts a <code translate="no" dir="ltr">RaggedTensor</code> into a <code translate="no" dir="ltr">SparseTensor</code> with the same values.</p> <p><a href="../../raw_ops/raggedtensortotensor.html"><code translate="no" dir="ltr">RaggedTensorToTensor(...)</code></a>: Create a dense tensor from a ragged tensor, possibly altering its shape.</p> <p><a href="../../raw_ops/raggedtensortovariant.html"><code translate="no" dir="ltr">RaggedTensorToVariant(...)</code></a>: Encodes a <code translate="no" dir="ltr">RaggedTensor</code> into a <code translate="no" dir="ltr">variant</code> Tensor.</p> <p><a href="../../raw_ops/raggedtensortovariantgradient.html"><code translate="no" dir="ltr">RaggedTensorToVariantGradient(...)</code></a>: Helper used to compute the gradient for <code translate="no" dir="ltr">RaggedTensorToVariant</code>.</p> <p><a href="../../raw_ops/randomcrop.html"><code translate="no" dir="ltr">RandomCrop(...)</code></a>: Randomly crop <code translate="no" dir="ltr">image</code>.</p> <p><a href="../../raw_ops/randomdataset.html"><code translate="no" dir="ltr">RandomDataset(...)</code></a>: Creates a Dataset that returns pseudorandom numbers.</p> <p><a href="../../raw_ops/randomdatasetv2.html"><code translate="no" dir="ltr">RandomDatasetV2(...)</code></a>: Creates a Dataset that returns pseudorandom numbers.</p> <p><a href="../../raw_ops/randomgamma.html"><code translate="no" dir="ltr">RandomGamma(...)</code></a>: Outputs random values from the Gamma distribution(s) described by alpha.</p> <p><a href="../../raw_ops/randomgammagrad.html"><code translate="no" dir="ltr">RandomGammaGrad(...)</code></a>: Computes the derivative of a Gamma random sample w.r.t. <code translate="no" dir="ltr">alpha</code>.</p> <p><a href="../../raw_ops/randomindexshuffle.html"><code translate="no" dir="ltr">RandomIndexShuffle(...)</code></a>: Outputs the position of <code translate="no" dir="ltr">value</code> in a permutation of [0, ..., max_index].</p> <p><a href="../../raw_ops/randompoisson.html"><code translate="no" dir="ltr">RandomPoisson(...)</code></a>: Use RandomPoissonV2 instead.</p> <p><a href="../../raw_ops/randompoissonv2.html"><code translate="no" dir="ltr">RandomPoissonV2(...)</code></a>: Outputs random values from the Poisson distribution(s) described by rate.</p> <p><a href="../../raw_ops/randomshuffle.html"><code translate="no" dir="ltr">RandomShuffle(...)</code></a>: Randomly shuffles a tensor along its first dimension.</p> <p><a href="../../raw_ops/randomshufflequeue.html"><code translate="no" dir="ltr">RandomShuffleQueue(...)</code></a>: A queue that randomizes the order of elements.</p> <p><a href="../../raw_ops/randomshufflequeuev2.html"><code translate="no" dir="ltr">RandomShuffleQueueV2(...)</code></a>: A queue that randomizes the order of elements.</p> <p><a href="../../raw_ops/randomstandardnormal.html"><code translate="no" dir="ltr">RandomStandardNormal(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="../../raw_ops/randomuniform.html"><code translate="no" dir="ltr">RandomUniform(...)</code></a>: Outputs random values from a uniform distribution.</p> <p><a href="../../raw_ops/randomuniformint.html"><code translate="no" dir="ltr">RandomUniformInt(...)</code></a>: Outputs random integers from a uniform distribution.</p> <p><a href="../../raw_ops/range.html"><code translate="no" dir="ltr">Range(...)</code></a>: Creates a sequence of numbers.</p> <p><a href="../../raw_ops/rangedataset.html"><code translate="no" dir="ltr">RangeDataset(...)</code></a>: Creates a dataset with a range of values. Corresponds to python's xrange.</p> <p><a href="../../raw_ops/rank.html"><code translate="no" dir="ltr">Rank(...)</code></a>: Returns the rank of a tensor.</p> <p><a href="../../raw_ops/readfile.html"><code translate="no" dir="ltr">ReadFile(...)</code></a>: Reads and outputs the entire contents of the input filename.</p> <p><a href="../../raw_ops/readvariableop.html"><code translate="no" dir="ltr">ReadVariableOp(...)</code></a>: Reads the value of a variable.</p> <p><a href="../../raw_ops/readvariablexlasplitnd.html"><code translate="no" dir="ltr">ReadVariableXlaSplitND(...)</code></a>: Splits resource variable input tensor across all dimensions.</p> <p><a href="../../raw_ops/readernumrecordsproduced.html"><code translate="no" dir="ltr">ReaderNumRecordsProduced(...)</code></a>: Returns the number of records this Reader has produced.</p> <p><a href="../../raw_ops/readernumrecordsproducedv2.html"><code translate="no" dir="ltr">ReaderNumRecordsProducedV2(...)</code></a>: Returns the number of records this Reader has produced.</p> <p><a href="../../raw_ops/readernumworkunitscompleted.html"><code translate="no" dir="ltr">ReaderNumWorkUnitsCompleted(...)</code></a>: Returns the number of work units this Reader has finished processing.</p> <p><a href="../../raw_ops/readernumworkunitscompletedv2.html"><code translate="no" dir="ltr">ReaderNumWorkUnitsCompletedV2(...)</code></a>: Returns the number of work units this Reader has finished processing.</p> <p><a href="../../raw_ops/readerread.html"><code translate="no" dir="ltr">ReaderRead(...)</code></a>: Returns the next record (key, value pair) produced by a Reader.</p> <p><a href="../../raw_ops/readerreadupto.html"><code translate="no" dir="ltr">ReaderReadUpTo(...)</code></a>: Returns up to <code translate="no" dir="ltr">num_records</code> (key, value) pairs produced by a Reader.</p> <p><a href="../../raw_ops/readerreaduptov2.html"><code translate="no" dir="ltr">ReaderReadUpToV2(...)</code></a>: Returns up to <code translate="no" dir="ltr">num_records</code> (key, value) pairs produced by a Reader.</p> <p><a href="../../raw_ops/readerreadv2.html"><code translate="no" dir="ltr">ReaderReadV2(...)</code></a>: Returns the next record (key, value pair) produced by a Reader.</p> <p><a href="../../raw_ops/readerreset.html"><code translate="no" dir="ltr">ReaderReset(...)</code></a>: Restore a Reader to its initial clean state.</p> <p><a href="../../raw_ops/readerresetv2.html"><code translate="no" dir="ltr">ReaderResetV2(...)</code></a>: Restore a Reader to its initial clean state.</p> <p><a href="../../raw_ops/readerrestorestate.html"><code translate="no" dir="ltr">ReaderRestoreState(...)</code></a>: Restore a reader to a previously saved state.</p> <p><a href="../../raw_ops/readerrestorestatev2.html"><code translate="no" dir="ltr">ReaderRestoreStateV2(...)</code></a>: Restore a reader to a previously saved state.</p> <p><a href="../../raw_ops/readerserializestate.html"><code translate="no" dir="ltr">ReaderSerializeState(...)</code></a>: Produce a string tensor that encodes the state of a Reader.</p> <p><a href="../../raw_ops/readerserializestatev2.html"><code translate="no" dir="ltr">ReaderSerializeStateV2(...)</code></a>: Produce a string tensor that encodes the state of a Reader.</p> <p><a href="../../raw_ops/real.html"><code translate="no" dir="ltr">Real(...)</code></a>: Returns the real part of a complex number.</p> <p><a href="../../raw_ops/realdiv.html"><code translate="no" dir="ltr">RealDiv(...)</code></a>: Returns x / y element-wise for real types.</p> <p><a href="../../raw_ops/rebatchdataset.html"><code translate="no" dir="ltr">RebatchDataset(...)</code></a>: Creates a dataset that changes the batch size.</p> <p><a href="../../raw_ops/rebatchdatasetv2.html"><code translate="no" dir="ltr">RebatchDatasetV2(...)</code></a>: Creates a dataset that changes the batch size.</p> <p><a href="../../raw_ops/reciprocal.html"><code translate="no" dir="ltr">Reciprocal(...)</code></a>: Computes the reciprocal of x element-wise.</p> <p><a href="../../raw_ops/reciprocalgrad.html"><code translate="no" dir="ltr">ReciprocalGrad(...)</code></a>: Computes the gradient for the inverse of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/recordinput.html"><code translate="no" dir="ltr">RecordInput(...)</code></a>: Emits randomized records.</p> <p><a href="../../raw_ops/recv.html"><code translate="no" dir="ltr">Recv(...)</code></a>: Receives the named tensor from send_device on recv_device.</p> <p><a href="../../raw_ops/recvtpuembeddingactivations.html"><code translate="no" dir="ltr">RecvTPUEmbeddingActivations(...)</code></a>: An op that receives embedding activations on the TPU.</p> <p><a href="../../raw_ops/reducedataset.html"><code translate="no" dir="ltr">ReduceDataset(...)</code></a>: Reduces the input dataset to a singleton using a reduce function.</p> <p><a href="../../raw_ops/reducejoin.html"><code translate="no" dir="ltr">ReduceJoin(...)</code></a>: Joins a string Tensor across the given dimensions.</p> <p><a href="../../raw_ops/refenter.html"><code translate="no" dir="ltr">RefEnter(...)</code></a>: Creates or finds a child frame, and makes <code translate="no" dir="ltr">data</code> available to the child frame.</p> <p><a href="../../raw_ops/refexit.html"><code translate="no" dir="ltr">RefExit(...)</code></a>: Exits the current frame to its parent frame.</p> <p><a href="../../raw_ops/refidentity.html"><code translate="no" dir="ltr">RefIdentity(...)</code></a>: Return the same ref tensor as the input ref tensor.</p> <p><a href="../../raw_ops/refmerge.html"><code translate="no" dir="ltr">RefMerge(...)</code></a>: Forwards the value of an available tensor from <code translate="no" dir="ltr">inputs</code> to <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/refnextiteration.html"><code translate="no" dir="ltr">RefNextIteration(...)</code></a>: Makes its input available to the next iteration.</p> <p><a href="../../raw_ops/refselect.html"><code translate="no" dir="ltr">RefSelect(...)</code></a>: Forwards the <code translate="no" dir="ltr">index</code>th element of <code translate="no" dir="ltr">inputs</code> to <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/refswitch.html"><code translate="no" dir="ltr">RefSwitch(...)</code></a>: Forwards the ref tensor <code translate="no" dir="ltr">data</code> to the output port determined by <code translate="no" dir="ltr">pred</code>.</p> <p><a href="../../raw_ops/regexfullmatch.html"><code translate="no" dir="ltr">RegexFullMatch(...)</code></a>: Check if the input matches the regex pattern.</p> <p><a href="../../raw_ops/regexreplace.html"><code translate="no" dir="ltr">RegexReplace(...)</code></a>: Replaces matches of the <code translate="no" dir="ltr">pattern</code> regular expression in <code translate="no" dir="ltr">input</code> with the replacement string provided in <code translate="no" dir="ltr">rewrite</code>.</p> <p><a href="../../raw_ops/registerdataset.html"><code translate="no" dir="ltr">RegisterDataset(...)</code></a>: Registers a dataset with the tf.data service.</p> <p><a href="../../raw_ops/registerdatasetv2.html"><code translate="no" dir="ltr">RegisterDatasetV2(...)</code></a>: Registers a dataset with the tf.data service.</p> <p><a href="../../raw_ops/relu.html"><code translate="no" dir="ltr">Relu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, 0)</code>.</p> <p><a href="../../raw_ops/relu6.html"><code translate="no" dir="ltr">Relu6(...)</code></a>: Computes rectified linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code>.</p> <p><a href="../../raw_ops/relu6grad.html"><code translate="no" dir="ltr">Relu6Grad(...)</code></a>: Computes rectified linear 6 gradients for a Relu6 operation.</p> <p><a href="../../raw_ops/relugrad.html"><code translate="no" dir="ltr">ReluGrad(...)</code></a>: Computes rectified linear gradients for a Relu operation.</p> <p><a href="../../raw_ops/remotecall.html"><code translate="no" dir="ltr">RemoteCall(...)</code></a>: Runs function <code translate="no" dir="ltr">f</code> on a remote device indicated by <code translate="no" dir="ltr">target</code>.</p> <p><a href="../../raw_ops/repeatdataset.html"><code translate="no" dir="ltr">RepeatDataset(...)</code></a>: Creates a dataset that emits the outputs of <code translate="no" dir="ltr">input_dataset</code> <code translate="no" dir="ltr">count</code> times.</p> <p><a href="../../raw_ops/requantizationrange.html"><code translate="no" dir="ltr">RequantizationRange(...)</code></a>: Computes a range that covers the actual values present in a quantized tensor.</p> <p><a href="../../raw_ops/requantizationrangeperchannel.html"><code translate="no" dir="ltr">RequantizationRangePerChannel(...)</code></a>: Computes requantization range per channel.</p> <p><a href="../../raw_ops/requantize.html"><code translate="no" dir="ltr">Requantize(...)</code></a>: Converts the quantized <code translate="no" dir="ltr">input</code> tensor into a lower-precision <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/requantizeperchannel.html"><code translate="no" dir="ltr">RequantizePerChannel(...)</code></a>: Requantizes input with min and max values known per channel.</p> <p><a href="../../raw_ops/reshape.html"><code translate="no" dir="ltr">Reshape(...)</code></a>: Reshapes a tensor.</p> <p><a href="../../raw_ops/resizearea.html"><code translate="no" dir="ltr">ResizeArea(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using area interpolation.</p> <p><a href="../../raw_ops/resizebicubic.html"><code translate="no" dir="ltr">ResizeBicubic(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using bicubic interpolation.</p> <p><a href="../../raw_ops/resizebicubicgrad.html"><code translate="no" dir="ltr">ResizeBicubicGrad(...)</code></a>: Computes the gradient of bicubic interpolation.</p> <p><a href="../../raw_ops/resizebilinear.html"><code translate="no" dir="ltr">ResizeBilinear(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using bilinear interpolation.</p> <p><a href="../../raw_ops/resizebilineargrad.html"><code translate="no" dir="ltr">ResizeBilinearGrad(...)</code></a>: Computes the gradient of bilinear interpolation.</p> <p><a href="../../raw_ops/resizenearestneighbor.html"><code translate="no" dir="ltr">ResizeNearestNeighbor(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using nearest neighbor interpolation.</p> <p><a href="../../raw_ops/resizenearestneighborgrad.html"><code translate="no" dir="ltr">ResizeNearestNeighborGrad(...)</code></a>: Computes the gradient of nearest neighbor interpolation.</p> <p><a href="../../raw_ops/resourceaccumulatorapplygradient.html"><code translate="no" dir="ltr">ResourceAccumulatorApplyGradient(...)</code></a>: Applies a gradient to a given accumulator.</p> <p><a href="../../raw_ops/resourceaccumulatornumaccumulated.html"><code translate="no" dir="ltr">ResourceAccumulatorNumAccumulated(...)</code></a>: Returns the number of gradients aggregated in the given accumulators.</p> <p><a href="../../raw_ops/resourceaccumulatorsetglobalstep.html"><code translate="no" dir="ltr">ResourceAccumulatorSetGlobalStep(...)</code></a>: Updates the accumulator with a new value for global_step.</p> <p><a href="../../raw_ops/resourceaccumulatortakegradient.html"><code translate="no" dir="ltr">ResourceAccumulatorTakeGradient(...)</code></a>: Extracts the average gradient in the given ConditionalAccumulator.</p> <p><a href="../../raw_ops/resourceapplyadamax.html"><code translate="no" dir="ltr">ResourceApplyAdaMax(...)</code></a>: Update '*var' according to the AdaMax algorithm.</p> <p><a href="../../raw_ops/resourceapplyadadelta.html"><code translate="no" dir="ltr">ResourceApplyAdadelta(...)</code></a>: Update '*var' according to the adadelta scheme.</p> <p><a href="../../raw_ops/resourceapplyadagrad.html"><code translate="no" dir="ltr">ResourceApplyAdagrad(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourceapplyadagradda.html"><code translate="no" dir="ltr">ResourceApplyAdagradDA(...)</code></a>: Update '*var' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/resourceapplyadagradv2.html"><code translate="no" dir="ltr">ResourceApplyAdagradV2(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourceapplyadam.html"><code translate="no" dir="ltr">ResourceApplyAdam(...)</code></a>: Update '*var' according to the Adam algorithm.</p> <p><a href="../../raw_ops/resourceapplyadamwithamsgrad.html"><code translate="no" dir="ltr">ResourceApplyAdamWithAmsgrad(...)</code></a>: Update '*var' according to the Adam algorithm.</p> <p><a href="../../raw_ops/resourceapplyaddsign.html"><code translate="no" dir="ltr">ResourceApplyAddSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/resourceapplycenteredrmsprop.html"><code translate="no" dir="ltr">ResourceApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/resourceapplyftrl.html"><code translate="no" dir="ltr">ResourceApplyFtrl(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourceapplyftrlv2.html"><code translate="no" dir="ltr">ResourceApplyFtrlV2(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourceapplygradientdescent.html"><code translate="no" dir="ltr">ResourceApplyGradientDescent(...)</code></a>: Update '*var' by subtracting 'alpha' * 'delta' from it.</p> <p><a href="../../raw_ops/resourceapplykerasmomentum.html"><code translate="no" dir="ltr">ResourceApplyKerasMomentum(...)</code></a>: Update '*var' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourceapplymomentum.html"><code translate="no" dir="ltr">ResourceApplyMomentum(...)</code></a>: Update '*var' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourceapplypowersign.html"><code translate="no" dir="ltr">ResourceApplyPowerSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/resourceapplyproximaladagrad.html"><code translate="no" dir="ltr">ResourceApplyProximalAdagrad(...)</code></a>: Update '<em>var' and '</em>accum' according to FOBOS with Adagrad learning rate.</p> <p><a href="../../raw_ops/resourceapplyproximalgradientdescent.html"><code translate="no" dir="ltr">ResourceApplyProximalGradientDescent(...)</code></a>: Update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/resourceapplyrmsprop.html"><code translate="no" dir="ltr">ResourceApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/resourceconditionalaccumulator.html"><code translate="no" dir="ltr">ResourceConditionalAccumulator(...)</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="../../raw_ops/resourcecountupto.html"><code translate="no" dir="ltr">ResourceCountUpTo(...)</code></a>: Increments variable pointed to by 'resource' until it reaches 'limit'.</p> <p><a href="../../raw_ops/resourcegather.html"><code translate="no" dir="ltr">ResourceGather(...)</code></a>: Gather slices from the variable pointed to by <code translate="no" dir="ltr">resource</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/resourcegathernd.html"><code translate="no" dir="ltr">ResourceGatherNd(...)</code></a></p> <p><a href="../../raw_ops/resourcescatteradd.html"><code translate="no" dir="ltr">ResourceScatterAdd(...)</code></a>: Adds sparse updates to the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescatterdiv.html"><code translate="no" dir="ltr">ResourceScatterDiv(...)</code></a>: Divides sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescattermax.html"><code translate="no" dir="ltr">ResourceScatterMax(...)</code></a>: Reduces sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code> using the <code translate="no" dir="ltr">max</code> operation.</p> <p><a href="../../raw_ops/resourcescattermin.html"><code translate="no" dir="ltr">ResourceScatterMin(...)</code></a>: Reduces sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code> using the <code translate="no" dir="ltr">min</code> operation.</p> <p><a href="../../raw_ops/resourcescattermul.html"><code translate="no" dir="ltr">ResourceScatterMul(...)</code></a>: Multiplies sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescatterndadd.html"><code translate="no" dir="ltr">ResourceScatterNdAdd(...)</code></a>: Applies sparse addition to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/resourcescatterndmax.html"><code translate="no" dir="ltr">ResourceScatterNdMax(...)</code></a></p> <p><a href="../../raw_ops/resourcescatterndmin.html"><code translate="no" dir="ltr">ResourceScatterNdMin(...)</code></a></p> <p><a href="../../raw_ops/resourcescatterndsub.html"><code translate="no" dir="ltr">ResourceScatterNdSub(...)</code></a>: Applies sparse subtraction to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/resourcescatterndupdate.html"><code translate="no" dir="ltr">ResourceScatterNdUpdate(...)</code></a>: Applies sparse <code translate="no" dir="ltr">updates</code> to individual values or slices within a given</p> <p><a href="../../raw_ops/resourcescattersub.html"><code translate="no" dir="ltr">ResourceScatterSub(...)</code></a>: Subtracts sparse updates from the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescatterupdate.html"><code translate="no" dir="ltr">ResourceScatterUpdate(...)</code></a>: Assigns sparse updates to the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcesparseapplyadadelta.html"><code translate="no" dir="ltr">ResourceSparseApplyAdadelta(...)</code></a>: var: Should be from a Variable().</p> <p><a href="../../raw_ops/resourcesparseapplyadagrad.html"><code translate="no" dir="ltr">ResourceSparseApplyAdagrad(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyadagradda.html"><code translate="no" dir="ltr">ResourceSparseApplyAdagradDA(...)</code></a>: Update entries in '<em>var' and '</em>accum' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyadagradv2.html"><code translate="no" dir="ltr">ResourceSparseApplyAdagradV2(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourcesparseapplycenteredrmsprop.html"><code translate="no" dir="ltr">ResourceSparseApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/resourcesparseapplyftrl.html"><code translate="no" dir="ltr">ResourceSparseApplyFtrl(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyftrlv2.html"><code translate="no" dir="ltr">ResourceSparseApplyFtrlV2(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourcesparseapplykerasmomentum.html"><code translate="no" dir="ltr">ResourceSparseApplyKerasMomentum(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourcesparseapplymomentum.html"><code translate="no" dir="ltr">ResourceSparseApplyMomentum(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyproximaladagrad.html"><code translate="no" dir="ltr">ResourceSparseApplyProximalAdagrad(...)</code></a>: Sparse update entries in '<em>var' and '</em>accum' according to FOBOS algorithm.</p> <p><a href="../../raw_ops/resourcesparseapplyproximalgradientdescent.html"><code translate="no" dir="ltr">ResourceSparseApplyProximalGradientDescent(...)</code></a>: Sparse update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/resourcesparseapplyrmsprop.html"><code translate="no" dir="ltr">ResourceSparseApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/resourcestridedsliceassign.html"><code translate="no" dir="ltr">ResourceStridedSliceAssign(...)</code></a>: Assign <code translate="no" dir="ltr">value</code> to the sliced l-value reference of <code translate="no" dir="ltr">ref</code>.</p> <p><a href="../../raw_ops/restore.html"><code translate="no" dir="ltr">Restore(...)</code></a>: Restores a tensor from checkpoint files.</p> <p><a href="../../raw_ops/restoreslice.html"><code translate="no" dir="ltr">RestoreSlice(...)</code></a>: Restores a tensor from checkpoint files.</p> <p><a href="../../raw_ops/restorev2.html"><code translate="no" dir="ltr">RestoreV2(...)</code></a>: Restores tensors from a V2 checkpoint.</p> <p><a href="../../raw_ops/retrievetpuembeddingadamparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingADAMParameters(...)</code></a>: Retrieve ADAM embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingadadeltaparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdadeltaParameters(...)</code></a>: Retrieve Adadelta embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingadagradmomentumparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdagradMomentumParameters(...)</code></a>: Retrieve Adagrad Momentum embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingadagradparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdagradParameters(...)</code></a>: Retrieve Adagrad embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingcenteredrmspropparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingCenteredRMSPropParameters(...)</code></a>: Retrieve centered RMSProp embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingftrlparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingFTRLParameters(...)</code></a>: Retrieve FTRL embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingfrequencyestimatorparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingFrequencyEstimatorParameters(...)</code></a>: Retrieve frequency estimator embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingmdladagradlightparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingMDLAdagradLightParameters(...)</code></a>: Retrieve MDL Adagrad Light embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingmomentumparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingMomentumParameters(...)</code></a>: Retrieve Momentum embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingproximaladagradparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingProximalAdagradParameters(...)</code></a>: Retrieve proximal Adagrad embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingproximalyogiparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingProximalYogiParameters(...)</code></a></p> <p><a href="../../raw_ops/retrievetpuembeddingrmspropparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingRMSPropParameters(...)</code></a>: Retrieve RMSProp embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingstochasticgradientdescentparameters.html"><code translate="no" dir="ltr">RetrieveTPUEmbeddingStochasticGradientDescentParameters(...)</code></a>: Retrieve SGD embedding parameters.</p> <p><a href="../../raw_ops/reverse.html"><code translate="no" dir="ltr">Reverse(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="../../raw_ops/reversesequence.html"><code translate="no" dir="ltr">ReverseSequence(...)</code></a>: Reverses variable length slices.</p> <p><a href="../../raw_ops/reversev2.html"><code translate="no" dir="ltr">ReverseV2(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="../../raw_ops/rewritedataset.html"><code translate="no" dir="ltr">RewriteDataset(...)</code></a></p> <p><a href="../../raw_ops/rightshift.html"><code translate="no" dir="ltr">RightShift(...)</code></a>: Elementwise computes the bitwise right-shift of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/rint.html"><code translate="no" dir="ltr">Rint(...)</code></a>: Returns element-wise integer closest to x.</p> <p><a href="../../raw_ops/rngreadandskip.html"><code translate="no" dir="ltr">RngReadAndSkip(...)</code></a>: Advance the counter of a counter-based RNG.</p> <p><a href="../../raw_ops/rngskip.html"><code translate="no" dir="ltr">RngSkip(...)</code></a>: Advance the counter of a counter-based RNG.</p> <p><a href="../../raw_ops/roll.html"><code translate="no" dir="ltr">Roll(...)</code></a>: Rolls the elements of a tensor along an axis.</p> <p><a href="../../raw_ops/round.html"><code translate="no" dir="ltr">Round(...)</code></a>: Rounds the values of a tensor to the nearest integer, element-wise.</p> <p><a href="../../raw_ops/rsqrt.html"><code translate="no" dir="ltr">Rsqrt(...)</code></a>: Computes reciprocal of square root of x element-wise.</p> <p><a href="../../raw_ops/rsqrtgrad.html"><code translate="no" dir="ltr">RsqrtGrad(...)</code></a>: Computes the gradient for the rsqrt of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/sampledistortedboundingbox.html"><code translate="no" dir="ltr">SampleDistortedBoundingBox(...)</code></a>: Generate a single randomly distorted bounding box for an image.</p> <p><a href="../../raw_ops/sampledistortedboundingboxv2.html"><code translate="no" dir="ltr">SampleDistortedBoundingBoxV2(...)</code></a>: Generate a single randomly distorted bounding box for an image.</p> <p><a href="../../raw_ops/samplingdataset.html"><code translate="no" dir="ltr">SamplingDataset(...)</code></a>: Creates a dataset that takes a Bernoulli sample of the contents of another dataset.</p> <p><a href="../../raw_ops/save.html"><code translate="no" dir="ltr">Save(...)</code></a>: Saves the input tensors to disk.</p> <p><a href="../../raw_ops/savedataset.html"><code translate="no" dir="ltr">SaveDataset(...)</code></a></p> <p><a href="../../raw_ops/savedatasetv2.html"><code translate="no" dir="ltr">SaveDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/saveslices.html"><code translate="no" dir="ltr">SaveSlices(...)</code></a>: Saves input tensors slices to disk.</p> <p><a href="../../raw_ops/savev2.html"><code translate="no" dir="ltr">SaveV2(...)</code></a>: Saves tensors in V2 checkpoint format.</p> <p><a href="../../raw_ops/scalarsummary.html"><code translate="no" dir="ltr">ScalarSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with scalar values.</p> <p><a href="../../raw_ops/scaleandtranslate.html"><code translate="no" dir="ltr">ScaleAndTranslate(...)</code></a></p> <p><a href="../../raw_ops/scaleandtranslategrad.html"><code translate="no" dir="ltr">ScaleAndTranslateGrad(...)</code></a></p> <p><a href="../../raw_ops/scandataset.html"><code translate="no" dir="ltr">ScanDataset(...)</code></a>: Creates a dataset successively reduces <code translate="no" dir="ltr">f</code> over the elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/scatteradd.html"><code translate="no" dir="ltr">ScatterAdd(...)</code></a>: Adds sparse updates to a variable reference.</p> <p><a href="../../raw_ops/scatterdiv.html"><code translate="no" dir="ltr">ScatterDiv(...)</code></a>: Divides a variable reference by sparse updates.</p> <p><a href="../../raw_ops/scattermax.html"><code translate="no" dir="ltr">ScatterMax(...)</code></a>: Reduces sparse updates into a variable reference using the <code translate="no" dir="ltr">max</code> operation.</p> <p><a href="../../raw_ops/scattermin.html"><code translate="no" dir="ltr">ScatterMin(...)</code></a>: Reduces sparse updates into a variable reference using the <code translate="no" dir="ltr">min</code> operation.</p> <p><a href="../../raw_ops/scattermul.html"><code translate="no" dir="ltr">ScatterMul(...)</code></a>: Multiplies sparse updates into a variable reference.</p> <p><a href="../../raw_ops/scatternd.html"><code translate="no" dir="ltr">ScatterNd(...)</code></a>: Scatters <code translate="no" dir="ltr">updates</code> into a tensor of shape <code translate="no" dir="ltr">shape</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/scatterndadd.html"><code translate="no" dir="ltr">ScatterNdAdd(...)</code></a>: Applies sparse addition to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/scatterndmax.html"><code translate="no" dir="ltr">ScatterNdMax(...)</code></a>: Computes element-wise maximum.</p> <p><a href="../../raw_ops/scatterndmin.html"><code translate="no" dir="ltr">ScatterNdMin(...)</code></a>: Computes element-wise minimum.</p> <p><a href="../../raw_ops/scatterndnonaliasingadd.html"><code translate="no" dir="ltr">ScatterNdNonAliasingAdd(...)</code></a>: Applies sparse addition to <code translate="no" dir="ltr">input</code> using individual values or slices</p> <p><a href="../../raw_ops/scatterndsub.html"><code translate="no" dir="ltr">ScatterNdSub(...)</code></a>: Applies sparse subtraction to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/scatterndupdate.html"><code translate="no" dir="ltr">ScatterNdUpdate(...)</code></a>: Applies sparse <code translate="no" dir="ltr">updates</code> to individual values or slices within a given</p> <p><a href="../../raw_ops/scattersub.html"><code translate="no" dir="ltr">ScatterSub(...)</code></a>: Subtracts sparse updates to a variable reference.</p> <p><a href="../../raw_ops/scatterupdate.html"><code translate="no" dir="ltr">ScatterUpdate(...)</code></a>: Applies sparse updates to a variable reference.</p> <p><a href="../../raw_ops/sdcafprint.html"><code translate="no" dir="ltr">SdcaFprint(...)</code></a>: Computes fingerprints of the input strings.</p> <p><a href="../../raw_ops/sdcaoptimizer.html"><code translate="no" dir="ltr">SdcaOptimizer(...)</code></a>: Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p> <p><a href="../../raw_ops/sdcaoptimizerv2.html"><code translate="no" dir="ltr">SdcaOptimizerV2(...)</code></a>: Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p> <p><a href="../../raw_ops/sdcashrinkl1.html"><code translate="no" dir="ltr">SdcaShrinkL1(...)</code></a>: Applies L1 regularization shrink step on the parameters.</p> <p><a href="../../raw_ops/segmentmax.html"><code translate="no" dir="ltr">SegmentMax(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentmaxv2.html"><code translate="no" dir="ltr">SegmentMaxV2(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentmean.html"><code translate="no" dir="ltr">SegmentMean(...)</code></a>: Computes the mean along segments of a tensor.</p> <p><a href="../../raw_ops/segmentmin.html"><code translate="no" dir="ltr">SegmentMin(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentminv2.html"><code translate="no" dir="ltr">SegmentMinV2(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentprod.html"><code translate="no" dir="ltr">SegmentProd(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../../raw_ops/segmentprodv2.html"><code translate="no" dir="ltr">SegmentProdV2(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../../raw_ops/segmentsum.html"><code translate="no" dir="ltr">SegmentSum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentsumv2.html"><code translate="no" dir="ltr">SegmentSumV2(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../../raw_ops/select.html"><code translate="no" dir="ltr">Select(...)</code></a>: Selects elements from <code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>, depending on <code translate="no" dir="ltr">condition</code>.</p> <p><a href="../../raw_ops/selectv2.html"><code translate="no" dir="ltr">SelectV2(...)</code></a></p> <p><a href="../../raw_ops/selfadjointeig.html"><code translate="no" dir="ltr">SelfAdjointEig(...)</code></a>: Computes the Eigen Decomposition of a batch of square self-adjoint matrices.</p> <p><a href="../../raw_ops/selfadjointeigv2.html"><code translate="no" dir="ltr">SelfAdjointEigV2(...)</code></a>: Computes the eigen decomposition of one or more square self-adjoint matrices.</p> <p><a href="../../raw_ops/selu.html"><code translate="no" dir="ltr">Selu(...)</code></a>: Computes scaled exponential linear: <code translate="no" dir="ltr">scale * alpha * (exp(features) - 1)</code></p> <p><a href="../../raw_ops/selugrad.html"><code translate="no" dir="ltr">SeluGrad(...)</code></a>: Computes gradients for the scaled exponential linear (Selu) operation.</p> <p><a href="../../raw_ops/send.html"><code translate="no" dir="ltr">Send(...)</code></a>: Sends the named tensor from send_device to recv_device.</p> <p><a href="../../raw_ops/sendtpuembeddinggradients.html"><code translate="no" dir="ltr">SendTPUEmbeddingGradients(...)</code></a>: Performs gradient updates of embedding tables.</p> <p><a href="../../raw_ops/serializeiterator.html"><code translate="no" dir="ltr">SerializeIterator(...)</code></a>: Converts the given <code translate="no" dir="ltr">resource_handle</code> representing an iterator to a variant tensor.</p> <p><a href="../../raw_ops/serializemanysparse.html"><code translate="no" dir="ltr">SerializeManySparse(...)</code></a>: Serialize an <code translate="no" dir="ltr">N</code>-minibatch <code translate="no" dir="ltr">SparseTensor</code> into an <code translate="no" dir="ltr">[N, 3]</code> <code translate="no" dir="ltr">Tensor</code> object.</p> <p><a href="../../raw_ops/serializesparse.html"><code translate="no" dir="ltr">SerializeSparse(...)</code></a>: Serialize a <code translate="no" dir="ltr">SparseTensor</code> into a <code translate="no" dir="ltr">[3]</code> <code translate="no" dir="ltr">Tensor</code> object.</p> <p><a href="../../raw_ops/serializetensor.html"><code translate="no" dir="ltr">SerializeTensor(...)</code></a>: Transforms a Tensor into a serialized TensorProto proto.</p> <p><a href="../../raw_ops/setsize.html"><code translate="no" dir="ltr">SetSize(...)</code></a>: Number of unique elements along last dimension of input <code translate="no" dir="ltr">set</code>.</p> <p><a href="../../raw_ops/setstatsaggregatordataset.html"><code translate="no" dir="ltr">SetStatsAggregatorDataset(...)</code></a></p> <p><a href="../../raw_ops/shape.html"><code translate="no" dir="ltr">Shape(...)</code></a>: Returns the shape of a tensor.</p> <p><a href="../../raw_ops/shapen.html"><code translate="no" dir="ltr">ShapeN(...)</code></a>: Returns shape of tensors.</p> <p><a href="../../raw_ops/sharddataset.html"><code translate="no" dir="ltr">ShardDataset(...)</code></a>: Creates a <code translate="no" dir="ltr">Dataset</code> that includes only 1/<code translate="no" dir="ltr">num_shards</code> of this dataset.</p> <p><a href="../../raw_ops/shardedfilename.html"><code translate="no" dir="ltr">ShardedFilename(...)</code></a>: Generate a sharded filename.</p> <p><a href="../../raw_ops/shardedfilespec.html"><code translate="no" dir="ltr">ShardedFilespec(...)</code></a>: Generate a glob pattern matching all sharded file names.</p> <p><a href="../../raw_ops/shuffleandrepeatdataset.html"><code translate="no" dir="ltr">ShuffleAndRepeatDataset(...)</code></a>: Creates a dataset that shuffles and repeats elements from <code translate="no" dir="ltr">input_dataset</code></p> <p><a href="../../raw_ops/shuffleandrepeatdatasetv2.html"><code translate="no" dir="ltr">ShuffleAndRepeatDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/shuffledataset.html"><code translate="no" dir="ltr">ShuffleDataset(...)</code></a>: Creates a dataset that shuffles elements from <code translate="no" dir="ltr">input_dataset</code> pseudorandomly.</p> <p><a href="../../raw_ops/shuffledatasetv2.html"><code translate="no" dir="ltr">ShuffleDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/shuffledatasetv3.html"><code translate="no" dir="ltr">ShuffleDatasetV3(...)</code></a></p> <p><a href="../../raw_ops/shutdowndistributedtpu.html"><code translate="no" dir="ltr">ShutdownDistributedTPU(...)</code></a>: Shuts down a running distributed TPU system.</p> <p><a href="../../raw_ops/sigmoid.html"><code translate="no" dir="ltr">Sigmoid(...)</code></a>: Computes sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/sigmoidgrad.html"><code translate="no" dir="ltr">SigmoidGrad(...)</code></a>: Computes the gradient of the sigmoid of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/sign.html"><code translate="no" dir="ltr">Sign(...)</code></a>: Returns an element-wise indication of the sign of a number.</p> <p><a href="../../raw_ops/sin.html"><code translate="no" dir="ltr">Sin(...)</code></a>: Computes sine of x element-wise.</p> <p><a href="../../raw_ops/sinh.html"><code translate="no" dir="ltr">Sinh(...)</code></a>: Computes hyperbolic sine of x element-wise.</p> <p><a href="../../raw_ops/size.html"><code translate="no" dir="ltr">Size(...)</code></a>: Returns the size of a tensor.</p> <p><a href="../../raw_ops/skipdataset.html"><code translate="no" dir="ltr">SkipDataset(...)</code></a>: Creates a dataset that skips <code translate="no" dir="ltr">count</code> elements from the <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/sleepdataset.html"><code translate="no" dir="ltr">SleepDataset(...)</code></a></p> <p><a href="../../raw_ops/slice.html"><code translate="no" dir="ltr">Slice(...)</code></a>: Return a slice from 'input'.</p> <p><a href="../../raw_ops/slidingwindowdataset.html"><code translate="no" dir="ltr">SlidingWindowDataset(...)</code></a>: Creates a dataset that passes a sliding window over <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/snapshot.html"><code translate="no" dir="ltr">Snapshot(...)</code></a>: Returns a copy of the input tensor.</p> <p><a href="../../raw_ops/snapshotchunkdataset.html"><code translate="no" dir="ltr">SnapshotChunkDataset(...)</code></a></p> <p><a href="../../raw_ops/snapshotdataset.html"><code translate="no" dir="ltr">SnapshotDataset(...)</code></a>: Creates a dataset that will write to / read from a snapshot.</p> <p><a href="../../raw_ops/snapshotdatasetreader.html"><code translate="no" dir="ltr">SnapshotDatasetReader(...)</code></a></p> <p><a href="../../raw_ops/snapshotdatasetv2.html"><code translate="no" dir="ltr">SnapshotDatasetV2(...)</code></a>: Creates a dataset that will write to / read from a snapshot.</p> <p><a href="../../raw_ops/snapshotnesteddatasetreader.html"><code translate="no" dir="ltr">SnapshotNestedDatasetReader(...)</code></a></p> <p><a href="../../raw_ops/sobolsample.html"><code translate="no" dir="ltr">SobolSample(...)</code></a>: Generates points from the Sobol sequence.</p> <p><a href="../../raw_ops/softmax.html"><code translate="no" dir="ltr">Softmax(...)</code></a>: Computes softmax activations.</p> <p><a href="../../raw_ops/softmaxcrossentropywithlogits.html"><code translate="no" dir="ltr">SoftmaxCrossEntropyWithLogits(...)</code></a>: Computes softmax cross entropy cost and gradients to backpropagate.</p> <p><a href="../../raw_ops/softplus.html"><code translate="no" dir="ltr">Softplus(...)</code></a></p> <p><a href="../../raw_ops/softplusgrad.html"><code translate="no" dir="ltr">SoftplusGrad(...)</code></a>: Computes softplus gradients for a softplus operation.</p> <p><a href="../../raw_ops/softsign.html"><code translate="no" dir="ltr">Softsign(...)</code></a>: Computes softsign: <code translate="no" dir="ltr">features / (abs(features) + 1)</code>.</p> <p><a href="../../raw_ops/softsigngrad.html"><code translate="no" dir="ltr">SoftsignGrad(...)</code></a>: Computes softsign gradients for a softsign operation.</p> <p><a href="../../raw_ops/spacetobatch.html"><code translate="no" dir="ltr">SpaceToBatch(...)</code></a>: SpaceToBatch for 4-D tensors of type T.</p> <p><a href="../../raw_ops/spacetobatchnd.html"><code translate="no" dir="ltr">SpaceToBatchND(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="../../raw_ops/spacetodepth.html"><code translate="no" dir="ltr">SpaceToDepth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="../../raw_ops/sparseaccumulatorapplygradient.html"><code translate="no" dir="ltr">SparseAccumulatorApplyGradient(...)</code></a>: Applies a sparse gradient to a given accumulator.</p> <p><a href="../../raw_ops/sparseaccumulatortakegradient.html"><code translate="no" dir="ltr">SparseAccumulatorTakeGradient(...)</code></a>: Extracts the average sparse gradient in a SparseConditionalAccumulator.</p> <p><a href="../../raw_ops/sparseadd.html"><code translate="no" dir="ltr">SparseAdd(...)</code></a>: Adds two <code translate="no" dir="ltr">SparseTensor</code> objects to produce another <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/sparseaddgrad.html"><code translate="no" dir="ltr">SparseAddGrad(...)</code></a>: The gradient operator for the SparseAdd op.</p> <p><a href="../../raw_ops/sparseapplyadadelta.html"><code translate="no" dir="ltr">SparseApplyAdadelta(...)</code></a>: var: Should be from a Variable().</p> <p><a href="../../raw_ops/sparseapplyadagrad.html"><code translate="no" dir="ltr">SparseApplyAdagrad(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/sparseapplyadagradda.html"><code translate="no" dir="ltr">SparseApplyAdagradDA(...)</code></a>: Update entries in '<em>var' and '</em>accum' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/sparseapplyadagradv2.html"><code translate="no" dir="ltr">SparseApplyAdagradV2(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/sparseapplycenteredrmsprop.html"><code translate="no" dir="ltr">SparseApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/sparseapplyftrl.html"><code translate="no" dir="ltr">SparseApplyFtrl(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/sparseapplyftrlv2.html"><code translate="no" dir="ltr">SparseApplyFtrlV2(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/sparseapplymomentum.html"><code translate="no" dir="ltr">SparseApplyMomentum(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the momentum scheme.</p> <p><a href="../../raw_ops/sparseapplyproximaladagrad.html"><code translate="no" dir="ltr">SparseApplyProximalAdagrad(...)</code></a>: Sparse update entries in '<em>var' and '</em>accum' according to FOBOS algorithm.</p> <p><a href="../../raw_ops/sparseapplyproximalgradientdescent.html"><code translate="no" dir="ltr">SparseApplyProximalGradientDescent(...)</code></a>: Sparse update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/sparseapplyrmsprop.html"><code translate="no" dir="ltr">SparseApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/sparsebincount.html"><code translate="no" dir="ltr">SparseBincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/sparseconcat.html"><code translate="no" dir="ltr">SparseConcat(...)</code></a>: Concatenates a list of <code translate="no" dir="ltr">SparseTensor</code> along the specified dimension.</p> <p><a href="../../raw_ops/sparseconditionalaccumulator.html"><code translate="no" dir="ltr">SparseConditionalAccumulator(...)</code></a>: A conditional accumulator for aggregating sparse gradients.</p> <p><a href="../../raw_ops/sparsecountsparseoutput.html"><code translate="no" dir="ltr">SparseCountSparseOutput(...)</code></a>: Performs sparse-output bin counting for a sparse tensor input.</p> <p><a href="../../raw_ops/sparsecross.html"><code translate="no" dir="ltr">SparseCross(...)</code></a>: Generates sparse cross from a list of sparse and dense tensors.</p> <p><a href="../../raw_ops/sparsecrosshashed.html"><code translate="no" dir="ltr">SparseCrossHashed(...)</code></a>: Generates sparse cross from a list of sparse and dense tensors.</p> <p><a href="../../raw_ops/sparsecrossv2.html"><code translate="no" dir="ltr">SparseCrossV2(...)</code></a>: Generates sparse cross from a list of sparse and dense tensors.</p> <p><a href="../../raw_ops/sparsedensecwiseadd.html"><code translate="no" dir="ltr">SparseDenseCwiseAdd(...)</code></a>: Adds up a SparseTensor and a dense Tensor, using these special rules:</p> <p><a href="../../raw_ops/sparsedensecwisediv.html"><code translate="no" dir="ltr">SparseDenseCwiseDiv(...)</code></a>: Component-wise divides a SparseTensor by a dense Tensor.</p> <p><a href="../../raw_ops/sparsedensecwisemul.html"><code translate="no" dir="ltr">SparseDenseCwiseMul(...)</code></a>: Component-wise multiplies a SparseTensor by a dense Tensor.</p> <p><a href="../../raw_ops/sparsefillemptyrows.html"><code translate="no" dir="ltr">SparseFillEmptyRows(...)</code></a>: Fills empty rows in the input 2-D <code translate="no" dir="ltr">SparseTensor</code> with a default value.</p> <p><a href="../../raw_ops/sparsefillemptyrowsgrad.html"><code translate="no" dir="ltr">SparseFillEmptyRowsGrad(...)</code></a>: The gradient of SparseFillEmptyRows.</p> <p><a href="../../raw_ops/sparsematmul.html"><code translate="no" dir="ltr">SparseMatMul(...)</code></a>: Multiply matrix "a" by matrix "b".</p> <p><a href="../../raw_ops/sparsematrixadd.html"><code translate="no" dir="ltr">SparseMatrixAdd(...)</code></a>: Sparse addition of two CSR matrices, C = alpha * A + beta * B.</p> <p><a href="../../raw_ops/sparsematrixmatmul.html"><code translate="no" dir="ltr">SparseMatrixMatMul(...)</code></a>: Matrix-multiplies a sparse matrix with a dense matrix.</p> <p><a href="../../raw_ops/sparsematrixmul.html"><code translate="no" dir="ltr">SparseMatrixMul(...)</code></a>: Element-wise multiplication of a sparse matrix with a dense tensor.</p> <p><a href="../../raw_ops/sparsematrixnnz.html"><code translate="no" dir="ltr">SparseMatrixNNZ(...)</code></a>: Returns the number of nonzeroes of <code translate="no" dir="ltr">sparse_matrix</code>.</p> <p><a href="../../raw_ops/sparsematrixorderingamd.html"><code translate="no" dir="ltr">SparseMatrixOrderingAMD(...)</code></a>: Computes the Approximate Minimum Degree (AMD) ordering of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/sparsematrixsoftmax.html"><code translate="no" dir="ltr">SparseMatrixSoftmax(...)</code></a>: Calculates the softmax of a CSRSparseMatrix.</p> <p><a href="../../raw_ops/sparsematrixsoftmaxgrad.html"><code translate="no" dir="ltr">SparseMatrixSoftmaxGrad(...)</code></a>: Calculates the gradient of the SparseMatrixSoftmax op.</p> <p><a href="../../raw_ops/sparsematrixsparsecholesky.html"><code translate="no" dir="ltr">SparseMatrixSparseCholesky(...)</code></a>: Computes the sparse Cholesky decomposition of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/sparsematrixsparsematmul.html"><code translate="no" dir="ltr">SparseMatrixSparseMatMul(...)</code></a>: Sparse-matrix-multiplies two CSR matrices <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>.</p> <p><a href="../../raw_ops/sparsematrixtranspose.html"><code translate="no" dir="ltr">SparseMatrixTranspose(...)</code></a>: Transposes the inner (matrix) dimensions of a CSRSparseMatrix.</p> <p><a href="../../raw_ops/sparsematrixzeros.html"><code translate="no" dir="ltr">SparseMatrixZeros(...)</code></a>: Creates an all-zeros CSRSparseMatrix with shape <code translate="no" dir="ltr">dense_shape</code>.</p> <p><a href="../../raw_ops/sparsereducemax.html"><code translate="no" dir="ltr">SparseReduceMax(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereducemaxsparse.html"><code translate="no" dir="ltr">SparseReduceMaxSparse(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereducesum.html"><code translate="no" dir="ltr">SparseReduceSum(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereducesumsparse.html"><code translate="no" dir="ltr">SparseReduceSumSparse(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereorder.html"><code translate="no" dir="ltr">SparseReorder(...)</code></a>: Reorders a SparseTensor into the canonical, row-major ordering.</p> <p><a href="../../raw_ops/sparsereshape.html"><code translate="no" dir="ltr">SparseReshape(...)</code></a>: Reshapes a SparseTensor to represent values in a new dense shape.</p> <p><a href="../../raw_ops/sparsesegmentmean.html"><code translate="no" dir="ltr">SparseSegmentMean(...)</code></a>: Computes the mean along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparsesegmentmeangrad.html"><code translate="no" dir="ltr">SparseSegmentMeanGrad(...)</code></a>: Computes gradients for SparseSegmentMean.</p> <p><a href="../../raw_ops/sparsesegmentmeangradv2.html"><code translate="no" dir="ltr">SparseSegmentMeanGradV2(...)</code></a>: Computes gradients for SparseSegmentMean.</p> <p><a href="../../raw_ops/sparsesegmentmeanwithnumsegments.html"><code translate="no" dir="ltr">SparseSegmentMeanWithNumSegments(...)</code></a>: Computes the mean along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparsesegmentsqrtn.html"><code translate="no" dir="ltr">SparseSegmentSqrtN(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt of N.</p> <p><a href="../../raw_ops/sparsesegmentsqrtngrad.html"><code translate="no" dir="ltr">SparseSegmentSqrtNGrad(...)</code></a>: Computes gradients for SparseSegmentSqrtN.</p> <p><a href="../../raw_ops/sparsesegmentsqrtngradv2.html"><code translate="no" dir="ltr">SparseSegmentSqrtNGradV2(...)</code></a>: Computes gradients for SparseSegmentSqrtN.</p> <p><a href="../../raw_ops/sparsesegmentsqrtnwithnumsegments.html"><code translate="no" dir="ltr">SparseSegmentSqrtNWithNumSegments(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt of N.</p> <p><a href="../../raw_ops/sparsesegmentsum.html"><code translate="no" dir="ltr">SparseSegmentSum(...)</code></a>: Computes the sum along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparsesegmentsumgrad.html"><code translate="no" dir="ltr">SparseSegmentSumGrad(...)</code></a>: Computes gradients for SparseSegmentSum.</p> <p><a href="../../raw_ops/sparsesegmentsumgradv2.html"><code translate="no" dir="ltr">SparseSegmentSumGradV2(...)</code></a>: Computes gradients for SparseSegmentSum.</p> <p><a href="../../raw_ops/sparsesegmentsumwithnumsegments.html"><code translate="no" dir="ltr">SparseSegmentSumWithNumSegments(...)</code></a>: Computes the sum along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparseslice.html"><code translate="no" dir="ltr">SparseSlice(...)</code></a>: Slice a <code translate="no" dir="ltr">SparseTensor</code> based on the <code translate="no" dir="ltr">start</code> and <code translate="no" dir="ltr">size</code>.</p> <p><a href="../../raw_ops/sparseslicegrad.html"><code translate="no" dir="ltr">SparseSliceGrad(...)</code></a>: The gradient operator for the SparseSlice op.</p> <p><a href="../../raw_ops/sparsesoftmax.html"><code translate="no" dir="ltr">SparseSoftmax(...)</code></a>: Applies softmax to a batched N-D <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/sparsesoftmaxcrossentropywithlogits.html"><code translate="no" dir="ltr">SparseSoftmaxCrossEntropyWithLogits(...)</code></a>: Computes softmax cross entropy cost and gradients to backpropagate.</p> <p><a href="../../raw_ops/sparsesparsemaximum.html"><code translate="no" dir="ltr">SparseSparseMaximum(...)</code></a>: Returns the element-wise max of two SparseTensors.</p> <p><a href="../../raw_ops/sparsesparseminimum.html"><code translate="no" dir="ltr">SparseSparseMinimum(...)</code></a>: Returns the element-wise min of two SparseTensors.</p> <p><a href="../../raw_ops/sparsesplit.html"><code translate="no" dir="ltr">SparseSplit(...)</code></a>: Split a <code translate="no" dir="ltr">SparseTensor</code> into <code translate="no" dir="ltr">num_split</code> tensors along one dimension.</p> <p><a href="../../raw_ops/sparsetensordenseadd.html"><code translate="no" dir="ltr">SparseTensorDenseAdd(...)</code></a>: Adds up a <code translate="no" dir="ltr">SparseTensor</code> and a dense <code translate="no" dir="ltr">Tensor</code>, producing a dense <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="../../raw_ops/sparsetensordensematmul.html"><code translate="no" dir="ltr">SparseTensorDenseMatMul(...)</code></a>: Multiply SparseTensor (of rank 2) "A" by dense matrix "B".</p> <p><a href="../../raw_ops/sparsetensorslicedataset.html"><code translate="no" dir="ltr">SparseTensorSliceDataset(...)</code></a>: Creates a dataset that splits a SparseTensor into elements row-wise.</p> <p><a href="../../raw_ops/sparsetensortocsrsparsematrix.html"><code translate="no" dir="ltr">SparseTensorToCSRSparseMatrix(...)</code></a>: Converts a SparseTensor to a (possibly batched) CSRSparseMatrix.</p> <p><a href="../../raw_ops/sparsetodense.html"><code translate="no" dir="ltr">SparseToDense(...)</code></a>: Converts a sparse representation into a dense tensor.</p> <p><a href="../../raw_ops/sparsetosparsesetoperation.html"><code translate="no" dir="ltr">SparseToSparseSetOperation(...)</code></a>: Applies set operation along last dimension of 2 <code translate="no" dir="ltr">SparseTensor</code> inputs.</p> <p><a href="../../raw_ops/spence.html"><code translate="no" dir="ltr">Spence(...)</code></a></p> <p><a href="../../raw_ops/split.html"><code translate="no" dir="ltr">Split(...)</code></a>: Splits a tensor into <code translate="no" dir="ltr">num_split</code> tensors along one dimension.</p> <p><a href="../../raw_ops/splitv.html"><code translate="no" dir="ltr">SplitV(...)</code></a>: Splits a tensor into <code translate="no" dir="ltr">num_split</code> tensors along one dimension.</p> <p><a href="../../raw_ops/sqldataset.html"><code translate="no" dir="ltr">SqlDataset(...)</code></a>: Creates a dataset that executes a SQL query and emits rows of the result set.</p> <p><a href="../../raw_ops/sqrt.html"><code translate="no" dir="ltr">Sqrt(...)</code></a>: Computes square root of x element-wise.</p> <p><a href="../../raw_ops/sqrtgrad.html"><code translate="no" dir="ltr">SqrtGrad(...)</code></a>: Computes the gradient for the sqrt of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/square.html"><code translate="no" dir="ltr">Square(...)</code></a>: Computes square of x element-wise.</p> <p><a href="../../raw_ops/squareddifference.html"><code translate="no" dir="ltr">SquaredDifference(...)</code></a>: Returns conj(x - y)(x - y) element-wise.</p> <p><a href="../../raw_ops/squeeze.html"><code translate="no" dir="ltr">Squeeze(...)</code></a>: Removes dimensions of size 1 from the shape of a tensor.</p> <p><a href="../../raw_ops/stack.html"><code translate="no" dir="ltr">Stack(...)</code></a>: Deprecated, use StackV2.</p> <p><a href="../../raw_ops/stackclose.html"><code translate="no" dir="ltr">StackClose(...)</code></a>: Deprecated, use StackCloseV2.</p> <p><a href="../../raw_ops/stackclosev2.html"><code translate="no" dir="ltr">StackCloseV2(...)</code></a>: Delete the stack from its resource container.</p> <p><a href="../../raw_ops/stackpop.html"><code translate="no" dir="ltr">StackPop(...)</code></a>: Deprecated, use StackPopV2.</p> <p><a href="../../raw_ops/stackpopv2.html"><code translate="no" dir="ltr">StackPopV2(...)</code></a>: Pop the element at the top of the stack.</p> <p><a href="../../raw_ops/stackpush.html"><code translate="no" dir="ltr">StackPush(...)</code></a>: Deprecated, use StackPushV2.</p> <p><a href="../../raw_ops/stackpushv2.html"><code translate="no" dir="ltr">StackPushV2(...)</code></a>: Push an element onto the stack.</p> <p><a href="../../raw_ops/stackv2.html"><code translate="no" dir="ltr">StackV2(...)</code></a>: A stack that produces elements in first-in last-out order.</p> <p><a href="../../raw_ops/stage.html"><code translate="no" dir="ltr">Stage(...)</code></a>: Stage values similar to a lightweight Enqueue.</p> <p><a href="../../raw_ops/stageclear.html"><code translate="no" dir="ltr">StageClear(...)</code></a>: Op removes all elements in the underlying container.</p> <p><a href="../../raw_ops/stagepeek.html"><code translate="no" dir="ltr">StagePeek(...)</code></a>: Op peeks at the values at the specified index.</p> <p><a href="../../raw_ops/stagesize.html"><code translate="no" dir="ltr">StageSize(...)</code></a>: Op returns the number of elements in the underlying container.</p> <p><a href="../../raw_ops/statefulpartitionedcall.html"><code translate="no" dir="ltr">StatefulPartitionedCall(...)</code></a>: returns <code translate="no" dir="ltr">f(inputs)</code>, where <code translate="no" dir="ltr">f</code>'s body is placed and partitioned.</p> <p><a href="../../raw_ops/statefulrandombinomial.html"><code translate="no" dir="ltr">StatefulRandomBinomial(...)</code></a></p> <p><a href="../../raw_ops/statefulstandardnormal.html"><code translate="no" dir="ltr">StatefulStandardNormal(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="../../raw_ops/statefulstandardnormalv2.html"><code translate="no" dir="ltr">StatefulStandardNormalV2(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="../../raw_ops/statefultruncatednormal.html"><code translate="no" dir="ltr">StatefulTruncatedNormal(...)</code></a>: Outputs random values from a truncated normal distribution.</p> <p><a href="../../raw_ops/statefuluniform.html"><code translate="no" dir="ltr">StatefulUniform(...)</code></a>: Outputs random values from a uniform distribution.</p> <p><a href="../../raw_ops/statefuluniformfullint.html"><code translate="no" dir="ltr">StatefulUniformFullInt(...)</code></a>: Outputs random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statefuluniformint.html"><code translate="no" dir="ltr">StatefulUniformInt(...)</code></a>: Outputs random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelesscase.html"><code translate="no" dir="ltr">StatelessCase(...)</code></a>: An n-way switch statement which calls a single branch function.</p> <p><a href="../../raw_ops/statelessif.html"><code translate="no" dir="ltr">StatelessIf(...)</code></a>: output = cond ? then_branch(input) : else_branch(input)</p> <p><a href="../../raw_ops/statelessmultinomial.html"><code translate="no" dir="ltr">StatelessMultinomial(...)</code></a>: Draws samples from a multinomial distribution.</p> <p><a href="../../raw_ops/statelessparameterizedtruncatednormal.html"><code translate="no" dir="ltr">StatelessParameterizedTruncatedNormal(...)</code></a></p> <p><a href="../../raw_ops/statelessrandombinomial.html"><code translate="no" dir="ltr">StatelessRandomBinomial(...)</code></a>: Outputs deterministic pseudorandom random numbers from a binomial distribution.</p> <p><a href="../../raw_ops/statelessrandomgammav2.html"><code translate="no" dir="ltr">StatelessRandomGammaV2(...)</code></a>: Outputs deterministic pseudorandom random numbers from a gamma distribution.</p> <p><a href="../../raw_ops/statelessrandomgammav3.html"><code translate="no" dir="ltr">StatelessRandomGammaV3(...)</code></a>: Outputs deterministic pseudorandom random numbers from a gamma distribution.</p> <p><a href="../../raw_ops/statelessrandomgetalg.html"><code translate="no" dir="ltr">StatelessRandomGetAlg(...)</code></a>: Picks the best counter-based RNG algorithm based on device.</p> <p><a href="../../raw_ops/statelessrandomgetkeycounter.html"><code translate="no" dir="ltr">StatelessRandomGetKeyCounter(...)</code></a>: Scrambles seed into key and counter, using the best algorithm based on device.</p> <p><a href="../../raw_ops/statelessrandomgetkeycounteralg.html"><code translate="no" dir="ltr">StatelessRandomGetKeyCounterAlg(...)</code></a>: Picks the best algorithm based on device, and scrambles seed into key and counter.</p> <p><a href="../../raw_ops/statelessrandomnormal.html"><code translate="no" dir="ltr">StatelessRandomNormal(...)</code></a>: Outputs deterministic pseudorandom values from a normal distribution.</p> <p><a href="../../raw_ops/statelessrandomnormalv2.html"><code translate="no" dir="ltr">StatelessRandomNormalV2(...)</code></a>: Outputs deterministic pseudorandom values from a normal distribution.</p> <p><a href="../../raw_ops/statelessrandompoisson.html"><code translate="no" dir="ltr">StatelessRandomPoisson(...)</code></a>: Outputs deterministic pseudorandom random numbers from a Poisson distribution.</p> <p><a href="../../raw_ops/statelessrandomuniform.html"><code translate="no" dir="ltr">StatelessRandomUniform(...)</code></a>: Outputs deterministic pseudorandom random values from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformfullint.html"><code translate="no" dir="ltr">StatelessRandomUniformFullInt(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformfullintv2.html"><code translate="no" dir="ltr">StatelessRandomUniformFullIntV2(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformint.html"><code translate="no" dir="ltr">StatelessRandomUniformInt(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformintv2.html"><code translate="no" dir="ltr">StatelessRandomUniformIntV2(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformv2.html"><code translate="no" dir="ltr">StatelessRandomUniformV2(...)</code></a>: Outputs deterministic pseudorandom random values from a uniform distribution.</p> <p><a href="../../raw_ops/statelesssampledistortedboundingbox.html"><code translate="no" dir="ltr">StatelessSampleDistortedBoundingBox(...)</code></a>: Generate a randomly distorted bounding box for an image deterministically.</p> <p><a href="../../raw_ops/statelessshuffle.html"><code translate="no" dir="ltr">StatelessShuffle(...)</code></a>: Randomly and deterministically shuffles a tensor along its first dimension.</p> <p><a href="../../raw_ops/statelesstruncatednormal.html"><code translate="no" dir="ltr">StatelessTruncatedNormal(...)</code></a>: Outputs deterministic pseudorandom values from a truncated normal distribution.</p> <p><a href="../../raw_ops/statelesstruncatednormalv2.html"><code translate="no" dir="ltr">StatelessTruncatedNormalV2(...)</code></a>: Outputs deterministic pseudorandom values from a truncated normal distribution.</p> <p><a href="../../raw_ops/statelesswhile.html"><code translate="no" dir="ltr">StatelessWhile(...)</code></a>: output = input; While (Cond(output)) { output = Body(output) }</p> <p><a href="../../raw_ops/staticregexfullmatch.html"><code translate="no" dir="ltr">StaticRegexFullMatch(...)</code></a>: Check if the input matches the regex pattern.</p> <p><a href="../../raw_ops/staticregexreplace.html"><code translate="no" dir="ltr">StaticRegexReplace(...)</code></a>: Replaces the match of pattern in input with rewrite.</p> <p><a href="../../raw_ops/statsaggregatorhandle.html"><code translate="no" dir="ltr">StatsAggregatorHandle(...)</code></a>: Creates a statistics manager resource.</p> <p><a href="../../raw_ops/statsaggregatorhandlev2.html"><code translate="no" dir="ltr">StatsAggregatorHandleV2(...)</code></a></p> <p><a href="../../raw_ops/statsaggregatorsetsummarywriter.html"><code translate="no" dir="ltr">StatsAggregatorSetSummaryWriter(...)</code></a>: Set a summary_writer_interface to record statistics using given stats_aggregator.</p> <p><a href="../../raw_ops/statsaggregatorsummary.html"><code translate="no" dir="ltr">StatsAggregatorSummary(...)</code></a>: Produces a summary of any statistics recorded by the given statistics manager.</p> <p><a href="../../raw_ops/stopgradient.html"><code translate="no" dir="ltr">StopGradient(...)</code></a>: Stops gradient computation.</p> <p><a href="../../raw_ops/storeminibatchstatisticsinfdo.html"><code translate="no" dir="ltr">StoreMinibatchStatisticsInFdo(...)</code></a></p> <p><a href="../../raw_ops/stridedslice.html"><code translate="no" dir="ltr">StridedSlice(...)</code></a>: Return a strided slice from <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/stridedsliceassign.html"><code translate="no" dir="ltr">StridedSliceAssign(...)</code></a>: Assign <code translate="no" dir="ltr">value</code> to the sliced l-value reference of <code translate="no" dir="ltr">ref</code>.</p> <p><a href="../../raw_ops/stridedslicegrad.html"><code translate="no" dir="ltr">StridedSliceGrad(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">StridedSlice</code>.</p> <p><a href="../../raw_ops/stringformat.html"><code translate="no" dir="ltr">StringFormat(...)</code></a>: Formats a string template using a list of tensors.</p> <p><a href="../../raw_ops/stringjoin.html"><code translate="no" dir="ltr">StringJoin(...)</code></a>: Joins the strings in the given list of string tensors into one tensor;</p> <p><a href="../../raw_ops/stringlength.html"><code translate="no" dir="ltr">StringLength(...)</code></a>: String lengths of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/stringlower.html"><code translate="no" dir="ltr">StringLower(...)</code></a>: Converts all uppercase characters into their respective lowercase replacements.</p> <p><a href="../../raw_ops/stringngrams.html"><code translate="no" dir="ltr">StringNGrams(...)</code></a>: Creates ngrams from ragged string data.</p> <p><a href="../../raw_ops/stringsplit.html"><code translate="no" dir="ltr">StringSplit(...)</code></a>: Split elements of <code translate="no" dir="ltr">input</code> based on <code translate="no" dir="ltr">delimiter</code> into a <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/stringsplitv2.html"><code translate="no" dir="ltr">StringSplitV2(...)</code></a>: Split elements of <code translate="no" dir="ltr">source</code> based on <code translate="no" dir="ltr">sep</code> into a <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/stringstrip.html"><code translate="no" dir="ltr">StringStrip(...)</code></a>: Strip leading and trailing whitespaces from the Tensor.</p> <p><a href="../../raw_ops/stringtohashbucket.html"><code translate="no" dir="ltr">StringToHashBucket(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../../raw_ops/stringtohashbucketfast.html"><code translate="no" dir="ltr">StringToHashBucketFast(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../../raw_ops/stringtohashbucketstrong.html"><code translate="no" dir="ltr">StringToHashBucketStrong(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../../raw_ops/stringtonumber.html"><code translate="no" dir="ltr">StringToNumber(...)</code></a>: Converts each string in the input Tensor to the specified numeric type.</p> <p><a href="../../raw_ops/stringupper.html"><code translate="no" dir="ltr">StringUpper(...)</code></a>: Converts all lowercase characters into their respective uppercase replacements.</p> <p><a href="../../raw_ops/sub.html"><code translate="no" dir="ltr">Sub(...)</code></a>: Returns x - y element-wise.</p> <p><a href="../../raw_ops/substr.html"><code translate="no" dir="ltr">Substr(...)</code></a>: Return substrings from <code translate="no" dir="ltr">Tensor</code> of strings.</p> <p><a href="../../raw_ops/sum.html"><code translate="no" dir="ltr">Sum(...)</code></a>: Computes the sum of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/summarywriter.html"><code translate="no" dir="ltr">SummaryWriter(...)</code></a></p> <p><a href="../../raw_ops/svd.html"><code translate="no" dir="ltr">Svd(...)</code></a>: Computes the singular value decompositions of one or more matrices.</p> <p><a href="../../raw_ops/switch.html"><code translate="no" dir="ltr">Switch(...)</code></a>: Forwards <code translate="no" dir="ltr">data</code> to the output port determined by <code translate="no" dir="ltr">pred</code>.</p> <p><a href="../../raw_ops/symbolicgradient.html"><code translate="no" dir="ltr">SymbolicGradient(...)</code></a>: Computes the gradient function for function f via backpropagation.</p> <p><a href="../../raw_ops/syncdevice.html"><code translate="no" dir="ltr">SyncDevice(...)</code></a>: Synchronizes the device this op is run on.</p> <p><a href="../../raw_ops/tfrecorddataset.html"><code translate="no" dir="ltr">TFRecordDataset(...)</code></a>: Creates a dataset that emits the records from one or more TFRecord files.</p> <p><a href="../../raw_ops/tfrecorddatasetv2.html"><code translate="no" dir="ltr">TFRecordDatasetV2(...)</code></a>: Creates a dataset that emits the records from one or more TFRecord files.</p> <p><a href="../../raw_ops/tfrecordreader.html"><code translate="no" dir="ltr">TFRecordReader(...)</code></a>: A Reader that outputs the records from a TensorFlow Records file.</p> <p><a href="../../raw_ops/tfrecordreaderv2.html"><code translate="no" dir="ltr">TFRecordReaderV2(...)</code></a>: A Reader that outputs the records from a TensorFlow Records file.</p> <p><a href="../../raw_ops/tpuannotatetensorswithdynamicshape.html"><code translate="no" dir="ltr">TPUAnnotateTensorsWithDynamicShape(...)</code></a></p> <p><a href="../../raw_ops/tpucompilationresult.html"><code translate="no" dir="ltr">TPUCompilationResult(...)</code></a>: Returns the result of a TPU compilation.</p> <p><a href="../../raw_ops/tpucopywithdynamicshape.html"><code translate="no" dir="ltr">TPUCopyWithDynamicShape(...)</code></a>: Op that copies host tensor to device with dynamic shape support.</p> <p><a href="../../raw_ops/tpuembeddingactivations.html"><code translate="no" dir="ltr">TPUEmbeddingActivations(...)</code></a>: An op enabling differentiation of TPU Embeddings.</p> <p><a href="../../raw_ops/tpuordinalselector.html"><code translate="no" dir="ltr">TPUOrdinalSelector(...)</code></a>: A TPU core selector Op.</p> <p><a href="../../raw_ops/tpupartitionedcall.html"><code translate="no" dir="ltr">TPUPartitionedCall(...)</code></a>: Calls a function placed on a specified TPU device.</p> <p><a href="../../raw_ops/tpupartitionedinput.html"><code translate="no" dir="ltr">TPUPartitionedInput(...)</code></a>: An op that groups a list of partitioned inputs together.</p> <p><a href="../../raw_ops/tpupartitionedinputv2.html"><code translate="no" dir="ltr">TPUPartitionedInputV2(...)</code></a>: An op that groups a list of partitioned inputs together. Supports ND sharding.</p> <p><a href="../../raw_ops/tpupartitionedoutput.html"><code translate="no" dir="ltr">TPUPartitionedOutput(...)</code></a>: An op that demultiplexes a tensor to be sharded by XLA to a list of partitioned</p> <p><a href="../../raw_ops/tpupartitionedoutputv2.html"><code translate="no" dir="ltr">TPUPartitionedOutputV2(...)</code></a>: An op that demultiplexes a tensor to be sharded by XLA to a list of partitioned</p> <p><a href="../../raw_ops/tpureplicatemetadata.html"><code translate="no" dir="ltr">TPUReplicateMetadata(...)</code></a>: Metadata indicating how the TPU computation should be replicated.</p> <p><a href="../../raw_ops/tpureplicatedinput.html"><code translate="no" dir="ltr">TPUReplicatedInput(...)</code></a>: Connects N inputs to an N-way replicated TPU computation.</p> <p><a href="../../raw_ops/tpureplicatedoutput.html"><code translate="no" dir="ltr">TPUReplicatedOutput(...)</code></a>: Connects N outputs from an N-way replicated TPU computation.</p> <p><a href="../../raw_ops/takedataset.html"><code translate="no" dir="ltr">TakeDataset(...)</code></a>: Creates a dataset that contains <code translate="no" dir="ltr">count</code> elements from the <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/takemanysparsefromtensorsmap.html"><code translate="no" dir="ltr">TakeManySparseFromTensorsMap(...)</code></a>: Read <code translate="no" dir="ltr">SparseTensors</code> from a <code translate="no" dir="ltr">SparseTensorsMap</code> and concatenate them.</p> <p><a href="../../raw_ops/takewhiledataset.html"><code translate="no" dir="ltr">TakeWhileDataset(...)</code></a>: Creates a dataset that stops iteration when predicate` is false.</p> <p><a href="../../raw_ops/tan.html"><code translate="no" dir="ltr">Tan(...)</code></a>: Computes tan of x element-wise.</p> <p><a href="../../raw_ops/tanh.html"><code translate="no" dir="ltr">Tanh(...)</code></a>: Computes hyperbolic tangent of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/tanhgrad.html"><code translate="no" dir="ltr">TanhGrad(...)</code></a>: Computes the gradient for the tanh of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/temporaryvariable.html"><code translate="no" dir="ltr">TemporaryVariable(...)</code></a>: Returns a tensor that may be mutated, but only persists within a single step.</p> <p><a href="../../raw_ops/tensorarray.html"><code translate="no" dir="ltr">TensorArray(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayclose.html"><code translate="no" dir="ltr">TensorArrayClose(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayclosev2.html"><code translate="no" dir="ltr">TensorArrayCloseV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarrayclosev3.html"><code translate="no" dir="ltr">TensorArrayCloseV3(...)</code></a>: Delete the TensorArray from its resource container.</p> <p><a href="../../raw_ops/tensorarrayconcat.html"><code translate="no" dir="ltr">TensorArrayConcat(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayconcatv2.html"><code translate="no" dir="ltr">TensorArrayConcatV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarrayconcatv3.html"><code translate="no" dir="ltr">TensorArrayConcatV3(...)</code></a>: Concat the elements from the TensorArray into value <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/tensorarraygather.html"><code translate="no" dir="ltr">TensorArrayGather(...)</code></a></p> <p><a href="../../raw_ops/tensorarraygatherv2.html"><code translate="no" dir="ltr">TensorArrayGatherV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarraygatherv3.html"><code translate="no" dir="ltr">TensorArrayGatherV3(...)</code></a>: Gather specific elements from the TensorArray into output <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/tensorarraygrad.html"><code translate="no" dir="ltr">TensorArrayGrad(...)</code></a></p> <p><a href="../../raw_ops/tensorarraygradv2.html"><code translate="no" dir="ltr">TensorArrayGradV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarraygradv3.html"><code translate="no" dir="ltr">TensorArrayGradV3(...)</code></a>: Creates a TensorArray for storing the gradients of values in the given handle.</p> <p><a href="../../raw_ops/tensorarraygradwithshape.html"><code translate="no" dir="ltr">TensorArrayGradWithShape(...)</code></a>: Creates a TensorArray for storing multiple gradients of values in the given handle.</p> <p><a href="../../raw_ops/tensorarraypack.html"><code translate="no" dir="ltr">TensorArrayPack(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayread.html"><code translate="no" dir="ltr">TensorArrayRead(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayreadv2.html"><code translate="no" dir="ltr">TensorArrayReadV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarrayreadv3.html"><code translate="no" dir="ltr">TensorArrayReadV3(...)</code></a>: Read an element from the TensorArray into output <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/tensorarrayscatter.html"><code translate="no" dir="ltr">TensorArrayScatter(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayscatterv2.html"><code translate="no" dir="ltr">TensorArrayScatterV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarrayscatterv3.html"><code translate="no" dir="ltr">TensorArrayScatterV3(...)</code></a>: Scatter the data from the input value into specific TensorArray elements.</p> <p><a href="../../raw_ops/tensorarraysize.html"><code translate="no" dir="ltr">TensorArraySize(...)</code></a></p> <p><a href="../../raw_ops/tensorarraysizev2.html"><code translate="no" dir="ltr">TensorArraySizeV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarraysizev3.html"><code translate="no" dir="ltr">TensorArraySizeV3(...)</code></a>: Get the current size of the TensorArray.</p> <p><a href="../../raw_ops/tensorarraysplit.html"><code translate="no" dir="ltr">TensorArraySplit(...)</code></a></p> <p><a href="../../raw_ops/tensorarraysplitv2.html"><code translate="no" dir="ltr">TensorArraySplitV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarraysplitv3.html"><code translate="no" dir="ltr">TensorArraySplitV3(...)</code></a>: Split the data from the input value into TensorArray elements.</p> <p><a href="../../raw_ops/tensorarrayunpack.html"><code translate="no" dir="ltr">TensorArrayUnpack(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayv2.html"><code translate="no" dir="ltr">TensorArrayV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarrayv3.html"><code translate="no" dir="ltr">TensorArrayV3(...)</code></a>: An array of Tensors of given size.</p> <p><a href="../../raw_ops/tensorarraywrite.html"><code translate="no" dir="ltr">TensorArrayWrite(...)</code></a></p> <p><a href="../../raw_ops/tensorarraywritev2.html"><code translate="no" dir="ltr">TensorArrayWriteV2(...)</code></a>: Deprecated.</p> <p><a href="../../raw_ops/tensorarraywritev3.html"><code translate="no" dir="ltr">TensorArrayWriteV3(...)</code></a>: Push an element onto the tensor_array.</p> <p><a href="../../raw_ops/tensordataset.html"><code translate="no" dir="ltr">TensorDataset(...)</code></a>: Creates a dataset that emits <code translate="no" dir="ltr">components</code> as a tuple of tensors once.</p> <p><a href="../../raw_ops/tensorlistconcat.html"><code translate="no" dir="ltr">TensorListConcat(...)</code></a>: Concats all tensors in the list along the 0th dimension.</p> <p><a href="../../raw_ops/tensorlistconcatlists.html"><code translate="no" dir="ltr">TensorListConcatLists(...)</code></a></p> <p><a href="../../raw_ops/tensorlistconcatv2.html"><code translate="no" dir="ltr">TensorListConcatV2(...)</code></a>: Concats all tensors in the list along the 0th dimension.</p> <p><a href="../../raw_ops/tensorlistelementshape.html"><code translate="no" dir="ltr">TensorListElementShape(...)</code></a>: The shape of the elements of the given list, as a tensor.</p> <p><a href="../../raw_ops/tensorlistfromtensor.html"><code translate="no" dir="ltr">TensorListFromTensor(...)</code></a>: Creates a TensorList which, when stacked, has the value of <code translate="no" dir="ltr">tensor</code>.</p> <p><a href="../../raw_ops/tensorlistgather.html"><code translate="no" dir="ltr">TensorListGather(...)</code></a>: Creates a Tensor by indexing into the TensorList.</p> <p><a href="../../raw_ops/tensorlistgetitem.html"><code translate="no" dir="ltr">TensorListGetItem(...)</code></a>: Returns the item in the list with the given index.</p> <p><a href="../../raw_ops/tensorlistlength.html"><code translate="no" dir="ltr">TensorListLength(...)</code></a>: Returns the number of tensors in the input tensor list.</p> <p><a href="../../raw_ops/tensorlistpopback.html"><code translate="no" dir="ltr">TensorListPopBack(...)</code></a>: Returns the last element of the input list as well as a list with all but that element.</p> <p><a href="../../raw_ops/tensorlistpushback.html"><code translate="no" dir="ltr">TensorListPushBack(...)</code></a>: Returns a list which has the passed-in <code translate="no" dir="ltr">Tensor</code> as last element and the other elements of the given list in <code translate="no" dir="ltr">input_handle</code>.</p> <p><a href="../../raw_ops/tensorlistpushbackbatch.html"><code translate="no" dir="ltr">TensorListPushBackBatch(...)</code></a></p> <p><a href="../../raw_ops/tensorlistreserve.html"><code translate="no" dir="ltr">TensorListReserve(...)</code></a>: List of the given size with empty elements.</p> <p><a href="../../raw_ops/tensorlistresize.html"><code translate="no" dir="ltr">TensorListResize(...)</code></a>: Resizes the list.</p> <p><a href="../../raw_ops/tensorlistscatter.html"><code translate="no" dir="ltr">TensorListScatter(...)</code></a>: Creates a TensorList by indexing into a Tensor.</p> <p><a href="../../raw_ops/tensorlistscatterintoexistinglist.html"><code translate="no" dir="ltr">TensorListScatterIntoExistingList(...)</code></a>: Scatters tensor at indices in an input list.</p> <p><a href="../../raw_ops/tensorlistscatterv2.html"><code translate="no" dir="ltr">TensorListScatterV2(...)</code></a>: Creates a TensorList by indexing into a Tensor.</p> <p><a href="../../raw_ops/tensorlistsetitem.html"><code translate="no" dir="ltr">TensorListSetItem(...)</code></a>: Sets the index-th position of the list to contain the given tensor.</p> <p><a href="../../raw_ops/tensorlistsplit.html"><code translate="no" dir="ltr">TensorListSplit(...)</code></a>: Splits a tensor into a list.</p> <p><a href="../../raw_ops/tensorliststack.html"><code translate="no" dir="ltr">TensorListStack(...)</code></a>: Stacks all tensors in the list.</p> <p><a href="../../raw_ops/tensormaperase.html"><code translate="no" dir="ltr">TensorMapErase(...)</code></a>: Returns a tensor map with item from given key erased.</p> <p><a href="../../raw_ops/tensormaphaskey.html"><code translate="no" dir="ltr">TensorMapHasKey(...)</code></a>: Returns whether the given key exists in the map.</p> <p><a href="../../raw_ops/tensormapinsert.html"><code translate="no" dir="ltr">TensorMapInsert(...)</code></a>: Returns a map that is the 'input_handle' with the given key-value pair inserted.</p> <p><a href="../../raw_ops/tensormaplookup.html"><code translate="no" dir="ltr">TensorMapLookup(...)</code></a>: Returns the value from a given key in a tensor map.</p> <p><a href="../../raw_ops/tensormapsize.html"><code translate="no" dir="ltr">TensorMapSize(...)</code></a>: Returns the number of tensors in the input tensor map.</p> <p><a href="../../raw_ops/tensormapstackkeys.html"><code translate="no" dir="ltr">TensorMapStackKeys(...)</code></a>: Returns a Tensor stack of all keys in a tensor map.</p> <p><a href="../../raw_ops/tensorscatteradd.html"><code translate="no" dir="ltr">TensorScatterAdd(...)</code></a>: Adds sparse <code translate="no" dir="ltr">updates</code> to an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/tensorscattermax.html"><code translate="no" dir="ltr">TensorScatterMax(...)</code></a>: Apply a sparse update to a tensor taking the element-wise maximum.</p> <p><a href="../../raw_ops/tensorscattermin.html"><code translate="no" dir="ltr">TensorScatterMin(...)</code></a></p> <p><a href="../../raw_ops/tensorscattersub.html"><code translate="no" dir="ltr">TensorScatterSub(...)</code></a>: Subtracts sparse <code translate="no" dir="ltr">updates</code> from an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/tensorscatterupdate.html"><code translate="no" dir="ltr">TensorScatterUpdate(...)</code></a>: Scatter <code translate="no" dir="ltr">updates</code> into an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/tensorslicedataset.html"><code translate="no" dir="ltr">TensorSliceDataset(...)</code></a>: Creates a dataset that emits each dim-0 slice of <code translate="no" dir="ltr">components</code> once.</p> <p><a href="../../raw_ops/tensorstridedsliceupdate.html"><code translate="no" dir="ltr">TensorStridedSliceUpdate(...)</code></a>: Assign <code translate="no" dir="ltr">value</code> to the sliced l-value reference of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/tensorsummary.html"><code translate="no" dir="ltr">TensorSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with a tensor.</p> <p><a href="../../raw_ops/tensorsummaryv2.html"><code translate="no" dir="ltr">TensorSummaryV2(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with a tensor and per-plugin data.</p> <p><a href="../../raw_ops/textlinedataset.html"><code translate="no" dir="ltr">TextLineDataset(...)</code></a>: Creates a dataset that emits the lines of one or more text files.</p> <p><a href="../../raw_ops/textlinereader.html"><code translate="no" dir="ltr">TextLineReader(...)</code></a>: A Reader that outputs the lines of a file delimited by '\n'.</p> <p><a href="../../raw_ops/textlinereaderv2.html"><code translate="no" dir="ltr">TextLineReaderV2(...)</code></a>: A Reader that outputs the lines of a file delimited by '\n'.</p> <p><a href="../../raw_ops/threadpooldataset.html"><code translate="no" dir="ltr">ThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/threadpoolhandle.html"><code translate="no" dir="ltr">ThreadPoolHandle(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/threadunsafeunigramcandidatesampler.html"><code translate="no" dir="ltr">ThreadUnsafeUnigramCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/tile.html"><code translate="no" dir="ltr">Tile(...)</code></a>: Constructs a tensor by tiling a given tensor.</p> <p><a href="../../raw_ops/tilegrad.html"><code translate="no" dir="ltr">TileGrad(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">Tile</code>.</p> <p><a href="../../raw_ops/timestamp.html"><code translate="no" dir="ltr">Timestamp(...)</code></a>: Provides the time since epoch in seconds.</p> <p><a href="../../raw_ops/tobool.html"><code translate="no" dir="ltr">ToBool(...)</code></a>: Converts a tensor to a scalar predicate.</p> <p><a href="../../raw_ops/topk.html"><code translate="no" dir="ltr">TopK(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest elements for the last dimension.</p> <p><a href="../../raw_ops/topkv2.html"><code translate="no" dir="ltr">TopKV2(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest elements for the last dimension.</p> <p><a href="../../raw_ops/transpose.html"><code translate="no" dir="ltr">Transpose(...)</code></a>: Shuffle dimensions of x according to a permutation.</p> <p><a href="../../raw_ops/tridiagonalmatmul.html"><code translate="no" dir="ltr">TridiagonalMatMul(...)</code></a>: Calculate product with tridiagonal matrix.</p> <p><a href="../../raw_ops/tridiagonalsolve.html"><code translate="no" dir="ltr">TridiagonalSolve(...)</code></a>: Solves tridiagonal systems of equations.</p> <p><a href="../../raw_ops/truncatediv.html"><code translate="no" dir="ltr">TruncateDiv(...)</code></a>: Returns x / y element-wise, rounded towards zero.</p> <p><a href="../../raw_ops/truncatemod.html"><code translate="no" dir="ltr">TruncateMod(...)</code></a>: Returns element-wise remainder of division.</p> <p><a href="../../raw_ops/truncatednormal.html"><code translate="no" dir="ltr">TruncatedNormal(...)</code></a>: Outputs random values from a truncated normal distribution.</p> <p><a href="../../raw_ops/unbatch.html"><code translate="no" dir="ltr">Unbatch(...)</code></a>: Reverses the operation of Batch for a single output Tensor.</p> <p><a href="../../raw_ops/unbatchdataset.html"><code translate="no" dir="ltr">UnbatchDataset(...)</code></a>: A dataset that splits the elements of its input into multiple elements.</p> <p><a href="../../raw_ops/unbatchgrad.html"><code translate="no" dir="ltr">UnbatchGrad(...)</code></a>: Gradient of Unbatch.</p> <p><a href="../../raw_ops/uncompresselement.html"><code translate="no" dir="ltr">UncompressElement(...)</code></a>: Uncompresses a compressed dataset element.</p> <p><a href="../../raw_ops/unicodedecode.html"><code translate="no" dir="ltr">UnicodeDecode(...)</code></a>: Decodes each string in <code translate="no" dir="ltr">input</code> into a sequence of Unicode code points.</p> <p><a href="../../raw_ops/unicodedecodewithoffsets.html"><code translate="no" dir="ltr">UnicodeDecodeWithOffsets(...)</code></a>: Decodes each string in <code translate="no" dir="ltr">input</code> into a sequence of Unicode code points.</p> <p><a href="../../raw_ops/unicodeencode.html"><code translate="no" dir="ltr">UnicodeEncode(...)</code></a>: Encode a tensor of ints into unicode strings.</p> <p><a href="../../raw_ops/unicodescript.html"><code translate="no" dir="ltr">UnicodeScript(...)</code></a>: Determine the script codes of a given tensor of Unicode integer code points.</p> <p><a href="../../raw_ops/unicodetranscode.html"><code translate="no" dir="ltr">UnicodeTranscode(...)</code></a>: Transcode the input text from a source encoding to a destination encoding.</p> <p><a href="../../raw_ops/uniformcandidatesampler.html"><code translate="no" dir="ltr">UniformCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a uniform distribution.</p> <p><a href="../../raw_ops/uniformdequantize.html"><code translate="no" dir="ltr">UniformDequantize(...)</code></a>: Perform dequantization on the quantized Tensor <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/uniformquantize.html"><code translate="no" dir="ltr">UniformQuantize(...)</code></a>: Perform quantization on Tensor <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/uniformquantizedadd.html"><code translate="no" dir="ltr">UniformQuantizedAdd(...)</code></a>: Perform quantized add of quantized Tensor <code translate="no" dir="ltr">lhs</code> and quantized Tensor <code translate="no" dir="ltr">rhs</code> to make quantized <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/uniformquantizedclipbyvalue.html"><code translate="no" dir="ltr">UniformQuantizedClipByValue(...)</code></a>: Perform clip by value on the quantized Tensor <code translate="no" dir="ltr">operand</code>.</p> <p><a href="../../raw_ops/uniformquantizedconvolution.html"><code translate="no" dir="ltr">UniformQuantizedConvolution(...)</code></a>: Perform quantized convolution of quantized Tensor <code translate="no" dir="ltr">lhs</code> and quantized Tensor <code translate="no" dir="ltr">rhs</code>. to make quantized <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/uniformquantizedconvolutionhybrid.html"><code translate="no" dir="ltr">UniformQuantizedConvolutionHybrid(...)</code></a>: Perform hybrid quantized convolution of float Tensor <code translate="no" dir="ltr">lhs</code> and quantized Tensor <code translate="no" dir="ltr">rhs</code>.</p> <p><a href="../../raw_ops/uniformquantizeddot.html"><code translate="no" dir="ltr">UniformQuantizedDot(...)</code></a>: Perform quantized dot of quantized Tensor <code translate="no" dir="ltr">lhs</code> and quantized Tensor <code translate="no" dir="ltr">rhs</code> to make quantized <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/uniformquantizeddothybrid.html"><code translate="no" dir="ltr">UniformQuantizedDotHybrid(...)</code></a>: Perform hybrid quantized dot of float Tensor <code translate="no" dir="ltr">lhs</code> and quantized Tensor <code translate="no" dir="ltr">rhs</code>.</p> <p><a href="../../raw_ops/uniformrequantize.html"><code translate="no" dir="ltr">UniformRequantize(...)</code></a>: Given quantized tensor <code translate="no" dir="ltr">input</code>, requantize it with new quantization parameters.</p> <p><a href="../../raw_ops/unique.html"><code translate="no" dir="ltr">Unique(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="../../raw_ops/uniquedataset.html"><code translate="no" dir="ltr">UniqueDataset(...)</code></a>: Creates a dataset that contains the unique elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/uniquev2.html"><code translate="no" dir="ltr">UniqueV2(...)</code></a>: Finds unique elements along an axis of a tensor.</p> <p><a href="../../raw_ops/uniquewithcounts.html"><code translate="no" dir="ltr">UniqueWithCounts(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="../../raw_ops/uniquewithcountsv2.html"><code translate="no" dir="ltr">UniqueWithCountsV2(...)</code></a>: Finds unique elements along an axis of a tensor.</p> <p><a href="../../raw_ops/unpack.html"><code translate="no" dir="ltr">Unpack(...)</code></a>: Unpacks a given dimension of a rank-<code translate="no" dir="ltr">R</code> tensor into <code translate="no" dir="ltr">num</code> rank-<code translate="no" dir="ltr">(R-1)</code> tensors.</p> <p><a href="../../raw_ops/unravelindex.html"><code translate="no" dir="ltr">UnravelIndex(...)</code></a>: Converts an array of flat indices into a tuple of coordinate arrays.</p> <p><a href="../../raw_ops/unsortedsegmentjoin.html"><code translate="no" dir="ltr">UnsortedSegmentJoin(...)</code></a></p> <p><a href="../../raw_ops/unsortedsegmentmax.html"><code translate="no" dir="ltr">UnsortedSegmentMax(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../../raw_ops/unsortedsegmentmin.html"><code translate="no" dir="ltr">UnsortedSegmentMin(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../../raw_ops/unsortedsegmentprod.html"><code translate="no" dir="ltr">UnsortedSegmentProd(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../../raw_ops/unsortedsegmentsum.html"><code translate="no" dir="ltr">UnsortedSegmentSum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../../raw_ops/unstage.html"><code translate="no" dir="ltr">Unstage(...)</code></a>: Op is similar to a lightweight Dequeue.</p> <p><a href="../../raw_ops/unwrapdatasetvariant.html"><code translate="no" dir="ltr">UnwrapDatasetVariant(...)</code></a></p> <p><a href="../../raw_ops/upperbound.html"><code translate="no" dir="ltr">UpperBound(...)</code></a>: Applies upper_bound(sorted_search_values, values) along each row.</p> <p><a href="../../raw_ops/varhandleop.html"><code translate="no" dir="ltr">VarHandleOp(...)</code></a>: Creates a handle to a Variable resource.</p> <p><a href="../../raw_ops/varisinitializedop.html"><code translate="no" dir="ltr">VarIsInitializedOp(...)</code></a>: Checks whether a resource handle-based variable has been initialized.</p> <p><a href="../../raw_ops/variable.html"><code translate="no" dir="ltr">Variable(...)</code></a>: Use VariableV2 instead.</p> <p><a href="../../raw_ops/variableshape.html"><code translate="no" dir="ltr">VariableShape(...)</code></a>: Returns the shape of the variable pointed to by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/variablev2.html"><code translate="no" dir="ltr">VariableV2(...)</code></a>: Holds state in the form of a tensor that persists across steps.</p> <p><a href="../../raw_ops/where.html"><code translate="no" dir="ltr">Where(...)</code></a>: Returns locations of nonzero / true values in a tensor.</p> <p><a href="../../raw_ops/while.html"><code translate="no" dir="ltr">While(...)</code></a>: output = input; While (Cond(output)) { output = Body(output) }</p> <p><a href="../../raw_ops/wholefilereader.html"><code translate="no" dir="ltr">WholeFileReader(...)</code></a>: A Reader that outputs the entire contents of a file as a value.</p> <p><a href="../../raw_ops/wholefilereaderv2.html"><code translate="no" dir="ltr">WholeFileReaderV2(...)</code></a>: A Reader that outputs the entire contents of a file as a value.</p> <p><a href="../../raw_ops/windowdataset.html"><code translate="no" dir="ltr">WindowDataset(...)</code></a>: Combines (nests of) input elements into a dataset of (nests of) windows.</p> <p><a href="../../raw_ops/windowop.html"><code translate="no" dir="ltr">WindowOp(...)</code></a></p> <p><a href="../../raw_ops/workerheartbeat.html"><code translate="no" dir="ltr">WorkerHeartbeat(...)</code></a>: Worker heartbeat op.</p> <p><a href="../../raw_ops/wrapdatasetvariant.html"><code translate="no" dir="ltr">WrapDatasetVariant(...)</code></a></p> <p><a href="../../raw_ops/writeaudiosummary.html"><code translate="no" dir="ltr">WriteAudioSummary(...)</code></a>: Writes an audio summary.</p> <p><a href="../../raw_ops/writefile.html"><code translate="no" dir="ltr">WriteFile(...)</code></a>: Writes <code translate="no" dir="ltr">contents</code> to the file at input <code translate="no" dir="ltr">filename</code>.</p> <p><a href="../../raw_ops/writegraphsummary.html"><code translate="no" dir="ltr">WriteGraphSummary(...)</code></a>: Writes a graph summary.</p> <p><a href="../../raw_ops/writehistogramsummary.html"><code translate="no" dir="ltr">WriteHistogramSummary(...)</code></a>: Writes a histogram summary.</p> <p><a href="../../raw_ops/writeimagesummary.html"><code translate="no" dir="ltr">WriteImageSummary(...)</code></a>: Writes an image summary.</p> <p><a href="../../raw_ops/writerawprotosummary.html"><code translate="no" dir="ltr">WriteRawProtoSummary(...)</code></a>: Writes a serialized proto summary.</p> <p><a href="../../raw_ops/writescalarsummary.html"><code translate="no" dir="ltr">WriteScalarSummary(...)</code></a>: Writes a scalar summary.</p> <p><a href="../../raw_ops/writesummary.html"><code translate="no" dir="ltr">WriteSummary(...)</code></a>: Writes a tensor summary.</p> <p><a href="../../raw_ops/xdivy.html"><code translate="no" dir="ltr">Xdivy(...)</code></a>: Returns 0 if x == 0, and x / y otherwise, elementwise.</p> <p><a href="../../raw_ops/xlaconcatnd.html"><code translate="no" dir="ltr">XlaConcatND(...)</code></a>: Concats input tensor across all dimensions.</p> <p><a href="../../raw_ops/xlasparsecoreadagrad.html"><code translate="no" dir="ltr">XlaSparseCoreAdagrad(...)</code></a></p> <p><a href="../../raw_ops/xlasparsecoreadagradmomentum.html"><code translate="no" dir="ltr">XlaSparseCoreAdagradMomentum(...)</code></a></p> <p><a href="../../raw_ops/xlasparsecoreadam.html"><code translate="no" dir="ltr">XlaSparseCoreAdam(...)</code></a></p> <p><a href="../../raw_ops/xlasparsecoreftrl.html"><code translate="no" dir="ltr">XlaSparseCoreFtrl(...)</code></a></p> <p><a href="../../raw_ops/xlasparsecoresgd.html"><code translate="no" dir="ltr">XlaSparseCoreSgd(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmul.html"><code translate="no" dir="ltr">XlaSparseDenseMatmul(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmulgradwithadagradandcsrinput.html"><code translate="no" dir="ltr">XlaSparseDenseMatmulGradWithAdagradAndCsrInput(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmulgradwithadagradmomentumandcsrinput.html"><code translate="no" dir="ltr">XlaSparseDenseMatmulGradWithAdagradMomentumAndCsrInput(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmulgradwithadamandcsrinput.html"><code translate="no" dir="ltr">XlaSparseDenseMatmulGradWithAdamAndCsrInput(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmulgradwithftrlandcsrinput.html"><code translate="no" dir="ltr">XlaSparseDenseMatmulGradWithFtrlAndCsrInput(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmulgradwithsgdandcsrinput.html"><code translate="no" dir="ltr">XlaSparseDenseMatmulGradWithSgdAndCsrInput(...)</code></a></p> <p><a href="../../raw_ops/xlasparsedensematmulwithcsrinput.html"><code translate="no" dir="ltr">XlaSparseDenseMatmulWithCsrInput(...)</code></a></p> <p><a href="../../raw_ops/xlasplitnd.html"><code translate="no" dir="ltr">XlaSplitND(...)</code></a>: Splits input tensor across all dimensions.</p> <p><a href="../../raw_ops/xlog1py.html"><code translate="no" dir="ltr">Xlog1py(...)</code></a>: Returns 0 if x == 0, and x * log1p(y) otherwise, elementwise.</p> <p><a href="../../raw_ops/xlogy.html"><code translate="no" dir="ltr">Xlogy(...)</code></a>: Returns 0 if x == 0, and x * log(y) otherwise, elementwise.</p> <p><a href="../../raw_ops/zeroslike.html"><code translate="no" dir="ltr">ZerosLike(...)</code></a>: Returns a tensor of zeros with the same shape and type as x.</p> <p><a href="../../raw_ops/zeta.html"><code translate="no" dir="ltr">Zeta(...)</code></a>: Compute the Hurwitz zeta function \(\zeta(x, q)\).</p> <p><a href="../../raw_ops/zipdataset.html"><code translate="no" dir="ltr">ZipDataset(...)</code></a>: Creates a dataset that zips together <code translate="no" dir="ltr">input_datasets</code>.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/raw_ops" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/raw_ops</a>
  </p>
</div>
