<h1 class="devsite-page-title" tabindex="-1"> tf.compat.v1.losses.mean_squared_error </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.losses.mean_squared_error"> <meta itemprop="path" content="Stable"> </div>   <p>Adds a Sum-of-Squares loss to the training procedure.</p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.compat.v1.losses.mean_squared_error(
    labels,
    predictions,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
</pre></devsite-code> <p><section><devsite-expandable expanded> <h2 class="showalways" id="migrate-to-tf2" data-text="Migrate to TF2" tabindex="-1">Migrate to TF2</h2></devsite-expandable></section></p> <aside class="caution"><strong>Caution:</strong><span> This API was designed for TensorFlow v1. Continue reading for details on how to migrate from this API to a native TensorFlow v2 equivalent. See the <a href="https://www.tensorflow.org/guide/migrate">TensorFlow v1 to TensorFlow v2 migration guide</a> for instructions on how to migrate the rest of your code.</span></aside> <p><a href="mean_squared_error.html"><code translate="no" dir="ltr">tf.compat.v1.losses.mean_squared_error</code></a> is mostly compatible with eager execution and <a href="../../../function.html"><code translate="no" dir="ltr">tf.function</code></a>. But, the <code translate="no" dir="ltr">loss_collection</code> argument is ignored when executing eagerly and no loss will be written to the loss collections. You will need to either hold on to the return value manually or rely on <a href="../../../keras/model.html"><code translate="no" dir="ltr">tf.keras.Model</code></a> loss tracking.</p> <p>To switch to native TF2 style, instantiate the <a href="../../../keras/losses/meansquarederror.html"><code translate="no" dir="ltr">tf.keras.losses.MeanSquaredError</code></a> class and call the object instead.</p> <h4 id="structural_mapping_to_native_tf2" data-text="Structural Mapping to Native TF2" tabindex="-1">Structural Mapping to Native TF2</h4> <p>Before:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">loss = tf.compat.v1.losses.mean_squared_error(
  labels=labels,
  predictions=predictions,
  weights=weights,
  reduction=reduction)
</pre></devsite-code> <p>After:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">loss_fn = tf.keras.losses.MeanSquaredError(
  reduction=reduction)
loss = loss_fn(
  y_true=labels,
  y_pred=predictions,
  sample_weight=weights)
</pre></devsite-code> <h4 id="how_to_map_arguments" data-text="How to Map Arguments" tabindex="-1">How to Map Arguments</h4> <table> <thead> <tr> <th style="text-align: left">TF1 Arg Name</th> <th style="text-align: left">TF2 Arg Name</th> <th style="text-align: left">Note</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code translate="no" dir="ltr">labels</code></td> <td style="text-align: left"><code translate="no" dir="ltr">y_true</code></td> <td style="text-align: left">In <code translate="no" dir="ltr">__call__()</code> method</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">predictions</code></td> <td style="text-align: left"><code translate="no" dir="ltr">y_pred</code></td> <td style="text-align: left">In <code translate="no" dir="ltr">__call__()</code> method</td> </tr> <tr> <td style="text-align: left">
<code translate="no" dir="ltr">weights</code> </td> <td style="text-align: left">
<code translate="no" dir="ltr">sample_weight</code> </td> <td style="text-align: left">In <code translate="no" dir="ltr">__call__()</code> method. The shape requirements for <code translate="no" dir="ltr">sample_weight</code> is different from <code translate="no" dir="ltr">weights</code>. Please check the <a href="../../../keras/losses/meansquarederror.html#__call__">argument definition</a> for details.</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">scope</code></td> <td style="text-align: left">Not supported</td> <td style="text-align: left">-</td> </tr> <tr> <td style="text-align: left">
<code translate="no" dir="ltr">loss_collection</code> </td> <td style="text-align: left">Not supported </td> <td style="text-align: left">Losses should be tracked explicitly or with Keras APIs, for example, <a href="../../../keras/layers/layer.html#add_loss">add_loss</a>, instead of via collections</td> </tr> <tr> <td style="text-align: left">
<code translate="no" dir="ltr">reduction</code> </td> <td style="text-align: left">
<code translate="no" dir="ltr">reduction</code> </td> <td style="text-align: left">In constructor. Value of <a href="reduction.html#SUM_OVER_BATCH_SIZE"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.SUM_OVER_BATCH_SIZE</code></a>, <a href="reduction.html#SUM"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.SUM</code></a>, <a href="reduction.html#NONE"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.NONE</code></a> in <a href="softmax_cross_entropy.html"><code translate="no" dir="ltr">tf.compat.v1.losses.softmax_cross_entropy</code></a> correspond to <a href="../../../keras/losses/reduction.html#SUM_OVER_BATCH_SIZE"><code translate="no" dir="ltr">tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE</code></a>, <a href="../../../keras/losses/reduction.html#SUM"><code translate="no" dir="ltr">tf.keras.losses.Reduction.SUM</code></a>, <a href="../../../keras/losses/reduction.html#NONE"><code translate="no" dir="ltr">tf.keras.losses.Reduction.NONE</code></a>, respectively. If you used other value for <code translate="no" dir="ltr">reduction</code>, including the default value <a href="reduction.html#SUM_BY_NONZERO_WEIGHTS"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS</code></a>, there is no directly corresponding value. Please modify the loss implementation manually.</td> </tr> </tbody> </table> <h4 id="before_after_usage_example" data-text="Before &amp; After Usage Example" tabindex="-1">Before &amp; After Usage Example</h4> <p>Before:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">y_true = [1, 2, 3]
y_pred = [1, 3, 5]
weights = [0, 1, 0.25]
# samples with zero-weight are excluded from calculation when `reduction`
# argument is set to default value `Reduction.SUM_BY_NONZERO_WEIGHTS`
tf.compat.v1.losses.mean_squared_error(
   labels=y_true,
   predictions=y_pred,
   weights=weights).numpy()
1.0</pre></devsite-code> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.compat.v1.losses.mean_squared_error(
   labels=y_true,
   predictions=y_pred,
   weights=weights,
   reduction=tf.compat.v1.losses.Reduction.SUM_OVER_BATCH_SIZE).numpy()
0.66667</pre></devsite-code> <p>After:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">y_true = [[1.0], [2.0], [3.0]]
y_pred = [[1.0], [3.0], [5.0]]
weights = [1, 1, 0.25]
mse = tf.keras.losses.MeanSquaredError(
   reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)
mse(y_true=y_true, y_pred=y_pred, sample_weight=weights).numpy()
0.66667</pre></devsite-code>  <h2 id="description" data-text="Description" tabindex="-1">Description</h2> <h3 id="used-in-the-notebooks" data-text="Used in the notebooks" tabindex="-1">Used in the notebooks</h3> <table class="vertical-rules"> <thead> <tr> <th>Used in the guide</th> </tr> </thead> <tbody> <tr> <td> <ul> <li><a href="https://www.tensorflow.org/guide/migrate/logging_stop_hook">Migrate LoggingTensorHook and StopAtStepHook to Keras callbacks</a></li> <li><a href="https://www.tensorflow.org/guide/migrate/migrating_estimator">Migrate from Estimator to Keras APIs</a></li> <li><a href="https://www.tensorflow.org/guide/migrate/mirrored_strategy">Migrate single-worker multiple-GPU training</a></li> <li><a href="https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training">Migrate multi-worker CPU/GPU training</a></li> <li><a href="https://www.tensorflow.org/guide/migrate/sessionrunhook_callback">Migrate SessionRunHook to Keras callbacks</a></li> </ul> </td> </tr> </tbody> </table> <p><code translate="no" dir="ltr">weights</code> acts as a coefficient for the loss. If a scalar is provided, then the loss is simply scaled by the given value. If <code translate="no" dir="ltr">weights</code> is a tensor of size <code translate="no" dir="ltr">[batch_size]</code>, then the total loss for each sample of the batch is rescaled by the corresponding element in the <code translate="no" dir="ltr">weights</code> vector. If the shape of <code translate="no" dir="ltr">weights</code> matches the shape of <code translate="no" dir="ltr">predictions</code>, then the loss of each measurable element of <code translate="no" dir="ltr">predictions</code> is scaled by the corresponding value of <code translate="no" dir="ltr">weights</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">labels</code> </td> <td> The ground truth output tensor, same dimensions as 'predictions'. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">predictions</code> </td> <td> The predicted outputs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">weights</code> </td> <td> Optional <code translate="no" dir="ltr">Tensor</code> whose rank is either 0, or the same rank as <code translate="no" dir="ltr">labels</code>, and must be broadcastable to <code translate="no" dir="ltr">labels</code> (i.e., all dimensions must be either <code translate="no" dir="ltr">1</code>, or the same as the corresponding <code translate="no" dir="ltr">losses</code> dimension). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">scope</code> </td> <td> The scope for the operations performed in computing the loss. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss_collection</code> </td> <td> collection to which the loss will be added. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reduction</code> </td> <td> Type of reduction to apply to loss. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Weighted loss float <code translate="no" dir="ltr">Tensor</code>. If <code translate="no" dir="ltr">reduction</code> is <code translate="no" dir="ltr">NONE</code>, this has the same shape as <code translate="no" dir="ltr">labels</code>; otherwise, it is scalar. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the shape of <code translate="no" dir="ltr">predictions</code> doesn't match that of <code translate="no" dir="ltr">labels</code> or if the shape of <code translate="no" dir="ltr">weights</code> is invalid. Also if <code translate="no" dir="ltr">labels</code> or <code translate="no" dir="ltr">predictions</code> is None. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/mean_squared_error" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/mean_squared_error</a>
  </p>
</div>
