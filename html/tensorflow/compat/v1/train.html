<h1 class="devsite-page-title" tabindex="-1"> Module: tf.compat.v1.train </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.train"> <meta itemprop="path" content="Stable"> </div>   <p>Public API for tf._api.v2.train namespace</p> <h2 id="modules" data-text="Modules" tabindex="-1">Modules</h2> <p><a href="train/experimental.html"><code translate="no" dir="ltr">experimental</code></a> module: Public API for tf._api.v2.train.experimental namespace</p> <p><a href="train/queue_runner.html"><code translate="no" dir="ltr">queue_runner</code></a> module: Public API for tf._api.v2.train.queue_runner namespace</p> <h2 id="classes" data-text="Classes" tabindex="-1">Classes</h2> <p><a href="train/adadeltaoptimizer.html"><code translate="no" dir="ltr">class AdadeltaOptimizer</code></a>: Optimizer that implements the Adadelta algorithm.</p> <p><a href="train/adagraddaoptimizer.html"><code translate="no" dir="ltr">class AdagradDAOptimizer</code></a>: Adagrad Dual Averaging algorithm for sparse linear models.</p> <p><a href="train/adagradoptimizer.html"><code translate="no" dir="ltr">class AdagradOptimizer</code></a>: Optimizer that implements the Adagrad algorithm.</p> <p><a href="train/adamoptimizer.html"><code translate="no" dir="ltr">class AdamOptimizer</code></a>: Optimizer that implements the Adam algorithm.</p> <p><a href="../../train/byteslist.html"><code translate="no" dir="ltr">class BytesList</code></a>: Used in <a href="../../train/example.html"><code translate="no" dir="ltr">tf.train.Example</code></a> protos. Holds a list of byte-strings.</p> <p><a href="train/checkpoint.html"><code translate="no" dir="ltr">class Checkpoint</code></a>: Groups trackable objects, saving and restoring them.</p> <p><a href="../../train/checkpointmanager.html"><code translate="no" dir="ltr">class CheckpointManager</code></a>: Manages multiple checkpoints by keeping some and deleting unneeded ones.</p> <p><a href="../../train/checkpointoptions.html"><code translate="no" dir="ltr">class CheckpointOptions</code></a>: Options for constructing a Checkpoint.</p> <p><a href="train/checkpointsaverhook.html"><code translate="no" dir="ltr">class CheckpointSaverHook</code></a>: Saves checkpoints every N steps or seconds.</p> <p><a href="train/checkpointsaverlistener.html"><code translate="no" dir="ltr">class CheckpointSaverListener</code></a>: Interface for listeners that take action before or after checkpoint save.</p> <p><a href="train/chiefsessioncreator.html"><code translate="no" dir="ltr">class ChiefSessionCreator</code></a>: Creates a tf.compat.v1.Session for a chief.</p> <p><a href="../../train/clusterdef.html"><code translate="no" dir="ltr">class ClusterDef</code></a>: A ProtocolMessage</p> <p><a href="../../train/clusterspec.html"><code translate="no" dir="ltr">class ClusterSpec</code></a>: Represents a cluster as a set of "tasks", organized into "jobs".</p> <p><a href="../../train/coordinator.html"><code translate="no" dir="ltr">class Coordinator</code></a>: A coordinator for threads.</p> <p><a href="../../train/example.html"><code translate="no" dir="ltr">class Example</code></a>: An <code translate="no" dir="ltr">Example</code> is a standard proto storing data for training and inference.</p> <p><a href="../../train/exponentialmovingaverage.html"><code translate="no" dir="ltr">class ExponentialMovingAverage</code></a>: Maintains moving averages of variables by employing an exponential decay.</p> <p><a href="../../train/feature.html"><code translate="no" dir="ltr">class Feature</code></a>: Used in <a href="../../train/example.html"><code translate="no" dir="ltr">tf.train.Example</code></a> protos. Contains a list of values.</p> <p><a href="../../train/featurelist.html"><code translate="no" dir="ltr">class FeatureList</code></a>: Mainly used as part of a <a href="../../train/sequenceexample.html"><code translate="no" dir="ltr">tf.train.SequenceExample</code></a>.</p> <p><a href="../../train/featurelists.html"><code translate="no" dir="ltr">class FeatureLists</code></a>: Mainly used as part of a <a href="../../train/sequenceexample.html"><code translate="no" dir="ltr">tf.train.SequenceExample</code></a>.</p> <p><a href="../../train/features.html"><code translate="no" dir="ltr">class Features</code></a>: Used in <a href="../../train/example.html"><code translate="no" dir="ltr">tf.train.Example</code></a> protos. Contains the mapping from keys to <code translate="no" dir="ltr">Feature</code>.</p> <p><a href="train/feedfnhook.html"><code translate="no" dir="ltr">class FeedFnHook</code></a>: Runs <code translate="no" dir="ltr">feed_fn</code> and sets the <code translate="no" dir="ltr">feed_dict</code> accordingly.</p> <p><a href="train/finalopshook.html"><code translate="no" dir="ltr">class FinalOpsHook</code></a>: A hook which evaluates <code translate="no" dir="ltr">Tensors</code> at the end of a session.</p> <p><a href="../../train/floatlist.html"><code translate="no" dir="ltr">class FloatList</code></a>: Used in <a href="../../train/example.html"><code translate="no" dir="ltr">tf.train.Example</code></a> protos. Holds a list of floats.</p> <p><a href="train/ftrloptimizer.html"><code translate="no" dir="ltr">class FtrlOptimizer</code></a>: Optimizer that implements the FTRL algorithm.</p> <p><a href="train/globalstepwaiterhook.html"><code translate="no" dir="ltr">class GlobalStepWaiterHook</code></a>: Delays execution until global step reaches <code translate="no" dir="ltr">wait_until_step</code>.</p> <p><a href="train/gradientdescentoptimizer.html"><code translate="no" dir="ltr">class GradientDescentOptimizer</code></a>: Optimizer that implements the gradient descent algorithm.</p> <p><a href="../../train/int64list.html"><code translate="no" dir="ltr">class Int64List</code></a>: Used in <a href="../../train/example.html"><code translate="no" dir="ltr">tf.train.Example</code></a> protos. Holds a list of Int64s.</p> <p><a href="../../train/jobdef.html"><code translate="no" dir="ltr">class JobDef</code></a>: A ProtocolMessage</p> <p><a href="train/loggingtensorhook.html"><code translate="no" dir="ltr">class LoggingTensorHook</code></a>: Prints the given tensors every N local steps, every N seconds, or at end.</p> <p><a href="train/looperthread.html"><code translate="no" dir="ltr">class LooperThread</code></a>: A thread that runs code repeatedly, optionally on a timer.</p> <p><a href="train/momentumoptimizer.html"><code translate="no" dir="ltr">class MomentumOptimizer</code></a>: Optimizer that implements the Momentum algorithm.</p> <p><a href="train/monitoredsession.html"><code translate="no" dir="ltr">class MonitoredSession</code></a>: Session-like object that handles initialization, recovery and hooks.</p> <p><a href="train/nanlossduringtrainingerror.html"><code translate="no" dir="ltr">class NanLossDuringTrainingError</code></a>: Unspecified run-time error.</p> <p><a href="train/nantensorhook.html"><code translate="no" dir="ltr">class NanTensorHook</code></a>: Monitors the loss tensor and stops training if loss is NaN.</p> <p><a href="train/optimizer.html"><code translate="no" dir="ltr">class Optimizer</code></a>: Base class for optimizers.</p> <p><a href="train/profilerhook.html"><code translate="no" dir="ltr">class ProfilerHook</code></a>: Captures CPU/GPU profiling information every N steps or seconds.</p> <p><a href="train/proximaladagradoptimizer.html"><code translate="no" dir="ltr">class ProximalAdagradOptimizer</code></a>: Optimizer that implements the Proximal Adagrad algorithm.</p> <p><a href="train/proximalgradientdescentoptimizer.html"><code translate="no" dir="ltr">class ProximalGradientDescentOptimizer</code></a>: Optimizer that implements the proximal gradient descent algorithm.</p> <p><a href="train/queuerunner.html"><code translate="no" dir="ltr">class QueueRunner</code></a>: Holds a list of enqueue operations for a queue, each to be run in a thread.</p> <p><a href="train/rmspropoptimizer.html"><code translate="no" dir="ltr">class RMSPropOptimizer</code></a>: Optimizer that implements the RMSProp algorithm (Tielemans et al.</p> <p><a href="train/saver.html"><code translate="no" dir="ltr">class Saver</code></a>: Saves and restores variables.</p> <p><a href="train/saverdef.html"><code translate="no" dir="ltr">class SaverDef</code></a>: A ProtocolMessage</p> <p><a href="train/scaffold.html"><code translate="no" dir="ltr">class Scaffold</code></a>: Structure to create or gather pieces commonly needed to train a model.</p> <p><a href="train/secondorsteptimer.html"><code translate="no" dir="ltr">class SecondOrStepTimer</code></a>: Timer that triggers at most once every N seconds or once every N steps.</p> <p><a href="../../train/sequenceexample.html"><code translate="no" dir="ltr">class SequenceExample</code></a>: A <code translate="no" dir="ltr">SequenceExample</code> represents a sequence of features and some context.</p> <p><a href="../../distribute/server.html"><code translate="no" dir="ltr">class Server</code></a>: An in-process TensorFlow server, for use in distributed training.</p> <p><a href="../../train/serverdef.html"><code translate="no" dir="ltr">class ServerDef</code></a>: A ProtocolMessage</p> <p><a href="train/sessioncreator.html"><code translate="no" dir="ltr">class SessionCreator</code></a>: A factory for tf.Session.</p> <p><a href="train/sessionmanager.html"><code translate="no" dir="ltr">class SessionManager</code></a>: Training helper that restores from checkpoint and creates session.</p> <p><a href="train/sessionrunargs.html"><code translate="no" dir="ltr">class SessionRunArgs</code></a>: Represents arguments to be added to a <code translate="no" dir="ltr">Session.run()</code> call.</p> <p><a href="train/sessionruncontext.html"><code translate="no" dir="ltr">class SessionRunContext</code></a>: Provides information about the <code translate="no" dir="ltr">session.run()</code> call being made.</p> <p><a href="train/sessionrunhook.html"><code translate="no" dir="ltr">class SessionRunHook</code></a>: Hook to extend calls to MonitoredSession.run().</p> <p><a href="train/sessionrunvalues.html"><code translate="no" dir="ltr">class SessionRunValues</code></a>: Contains the results of <code translate="no" dir="ltr">Session.run()</code>.</p> <p><a href="train/singularmonitoredsession.html"><code translate="no" dir="ltr">class SingularMonitoredSession</code></a>: Session-like object that handles initialization, restoring, and hooks.</p> <p><a href="train/stepcounterhook.html"><code translate="no" dir="ltr">class StepCounterHook</code></a>: Hook that counts steps per second.</p> <p><a href="train/stopatstephook.html"><code translate="no" dir="ltr">class StopAtStepHook</code></a>: Hook that requests stop at a specified step.</p> <p><a href="train/summarysaverhook.html"><code translate="no" dir="ltr">class SummarySaverHook</code></a>: Saves summaries every N steps.</p> <p><a href="train/supervisor.html"><code translate="no" dir="ltr">class Supervisor</code></a>: A training helper that checkpoints models and computes summaries.</p> <p><a href="train/syncreplicasoptimizer.html"><code translate="no" dir="ltr">class SyncReplicasOptimizer</code></a>: Class to synchronize, aggregate gradients and pass them to the optimizer.</p> <p><a href="train/vocabinfo.html"><code translate="no" dir="ltr">class VocabInfo</code></a>: Vocabulary information for warm-starting.</p> <p><a href="train/workersessioncreator.html"><code translate="no" dir="ltr">class WorkerSessionCreator</code></a>: Creates a tf.compat.v1.Session for a worker.</p> <h2 id="functions" data-text="Functions" tabindex="-1">Functions</h2> <p><a href="train/monitoredtrainingsession.html"><code translate="no" dir="ltr">MonitoredTrainingSession(...)</code></a>: Creates a <code translate="no" dir="ltr">MonitoredSession</code> for training.</p> <p><a href="train/newcheckpointreader.html"><code translate="no" dir="ltr">NewCheckpointReader(...)</code></a>: A function that returns a CheckPointReader.</p> <p><a href="train/add_queue_runner.html"><code translate="no" dir="ltr">add_queue_runner(...)</code></a>: Adds a <code translate="no" dir="ltr">QueueRunner</code> to a collection in the graph. (deprecated)</p> <p><a href="train/assert_global_step.html"><code translate="no" dir="ltr">assert_global_step(...)</code></a>: Asserts <code translate="no" dir="ltr">global_step_tensor</code> is a scalar int <code translate="no" dir="ltr">Variable</code> or <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="train/basic_train_loop.html"><code translate="no" dir="ltr">basic_train_loop(...)</code></a>: Basic loop to train a model.</p> <p><a href="train/batch.html"><code translate="no" dir="ltr">batch(...)</code></a>: Creates batches of tensors in <code translate="no" dir="ltr">tensors</code>. (deprecated)</p> <p><a href="train/batch_join.html"><code translate="no" dir="ltr">batch_join(...)</code></a>: Runs a list of tensors to fill a queue to create batches of examples. (deprecated)</p> <p><a href="train/checkpoint_exists.html"><code translate="no" dir="ltr">checkpoint_exists(...)</code></a>: Checks whether a V1 or V2 checkpoint exists with the specified prefix. (deprecated)</p> <p><a href="../../train/checkpoints_iterator.html"><code translate="no" dir="ltr">checkpoints_iterator(...)</code></a>: Continuously yield new checkpoint files as they appear.</p> <p><a href="train/cosine_decay.html"><code translate="no" dir="ltr">cosine_decay(...)</code></a>: Applies cosine decay to the learning rate.</p> <p><a href="train/cosine_decay_restarts.html"><code translate="no" dir="ltr">cosine_decay_restarts(...)</code></a>: Applies cosine decay with restarts to the learning rate.</p> <p><a href="train/create_global_step.html"><code translate="no" dir="ltr">create_global_step(...)</code></a>: Create global step tensor in graph.</p> <p><a href="train/do_quantize_training_on_graphdef.html"><code translate="no" dir="ltr">do_quantize_training_on_graphdef(...)</code></a>: A general quantization scheme is being developed in <code translate="no" dir="ltr">tf.contrib.quantize</code>. (deprecated)</p> <p><a href="train/exponential_decay.html"><code translate="no" dir="ltr">exponential_decay(...)</code></a>: Applies exponential decay to the learning rate.</p> <p><a href="train/export_meta_graph.html"><code translate="no" dir="ltr">export_meta_graph(...)</code></a>: Returns <code translate="no" dir="ltr">MetaGraphDef</code> proto.</p> <p><a href="train/generate_checkpoint_state_proto.html"><code translate="no" dir="ltr">generate_checkpoint_state_proto(...)</code></a>: Generates a checkpoint state proto.</p> <p><a href="train/get_checkpoint_mtimes.html"><code translate="no" dir="ltr">get_checkpoint_mtimes(...)</code></a>: Returns the mtimes (modification timestamps) of the checkpoints. (deprecated)</p> <p><a href="../../train/get_checkpoint_state.html"><code translate="no" dir="ltr">get_checkpoint_state(...)</code></a>: Returns CheckpointState proto from the "checkpoint" file.</p> <p><a href="train/get_global_step.html"><code translate="no" dir="ltr">get_global_step(...)</code></a>: Get the global step tensor.</p> <p><a href="train/get_or_create_global_step.html"><code translate="no" dir="ltr">get_or_create_global_step(...)</code></a>: Returns and create (if necessary) the global step tensor.</p> <p><a href="train/global_step.html"><code translate="no" dir="ltr">global_step(...)</code></a>: Small helper to get the global step.</p> <p><a href="train/import_meta_graph.html"><code translate="no" dir="ltr">import_meta_graph(...)</code></a>: Recreates a Graph saved in a <code translate="no" dir="ltr">MetaGraphDef</code> proto.</p> <p><a href="train/init_from_checkpoint.html"><code translate="no" dir="ltr">init_from_checkpoint(...)</code></a>: Replaces <a href="../../variable.html"><code translate="no" dir="ltr">tf.Variable</code></a> initializers so they load from a checkpoint file.</p> <p><a href="train/input_producer.html"><code translate="no" dir="ltr">input_producer(...)</code></a>: Output the rows of <code translate="no" dir="ltr">input_tensor</code> to a queue for an input pipeline. (deprecated)</p> <p><a href="train/inverse_time_decay.html"><code translate="no" dir="ltr">inverse_time_decay(...)</code></a>: Applies inverse time decay to the initial learning rate.</p> <p><a href="../../train/latest_checkpoint.html"><code translate="no" dir="ltr">latest_checkpoint(...)</code></a>: Finds the filename of latest saved checkpoint file.</p> <p><a href="train/limit_epochs.html"><code translate="no" dir="ltr">limit_epochs(...)</code></a>: Returns tensor <code translate="no" dir="ltr">num_epochs</code> times and then raises an <code translate="no" dir="ltr">OutOfRange</code> error. (deprecated)</p> <p><a href="train/linear_cosine_decay.html"><code translate="no" dir="ltr">linear_cosine_decay(...)</code></a>: Applies linear cosine decay to the learning rate.</p> <p><a href="../../train/list_variables.html"><code translate="no" dir="ltr">list_variables(...)</code></a>: Lists the checkpoint keys and shapes of variables in a checkpoint.</p> <p><a href="../../train/load_checkpoint.html"><code translate="no" dir="ltr">load_checkpoint(...)</code></a>: Returns <code translate="no" dir="ltr">CheckpointReader</code> for checkpoint found in <code translate="no" dir="ltr">ckpt_dir_or_file</code>.</p> <p><a href="../../train/load_variable.html"><code translate="no" dir="ltr">load_variable(...)</code></a>: Returns the tensor value of the given variable in the checkpoint.</p> <p><a href="../../io/match_filenames_once.html"><code translate="no" dir="ltr">match_filenames_once(...)</code></a>: Save the list of files matching pattern, so it is only computed once.</p> <p><a href="train/maybe_batch.html"><code translate="no" dir="ltr">maybe_batch(...)</code></a>: Conditionally creates batches of tensors based on <code translate="no" dir="ltr">keep_input</code>. (deprecated)</p> <p><a href="train/maybe_batch_join.html"><code translate="no" dir="ltr">maybe_batch_join(...)</code></a>: Runs a list of tensors to conditionally fill a queue to create batches. (deprecated)</p> <p><a href="train/maybe_shuffle_batch.html"><code translate="no" dir="ltr">maybe_shuffle_batch(...)</code></a>: Creates batches by randomly shuffling conditionally-enqueued tensors. (deprecated)</p> <p><a href="train/maybe_shuffle_batch_join.html"><code translate="no" dir="ltr">maybe_shuffle_batch_join(...)</code></a>: Create batches by randomly shuffling conditionally-enqueued tensors. (deprecated)</p> <p><a href="train/natural_exp_decay.html"><code translate="no" dir="ltr">natural_exp_decay(...)</code></a>: Applies natural exponential decay to the initial learning rate.</p> <p><a href="train/noisy_linear_cosine_decay.html"><code translate="no" dir="ltr">noisy_linear_cosine_decay(...)</code></a>: Applies noisy linear cosine decay to the learning rate.</p> <p><a href="train/piecewise_constant.html"><code translate="no" dir="ltr">piecewise_constant(...)</code></a>: Piecewise constant from boundaries and interval values.</p> <p><a href="train/piecewise_constant.html"><code translate="no" dir="ltr">piecewise_constant_decay(...)</code></a>: Piecewise constant from boundaries and interval values.</p> <p><a href="train/polynomial_decay.html"><code translate="no" dir="ltr">polynomial_decay(...)</code></a>: Applies a polynomial decay to the learning rate.</p> <p><a href="train/range_input_producer.html"><code translate="no" dir="ltr">range_input_producer(...)</code></a>: Produces the integers from 0 to limit-1 in a queue. (deprecated)</p> <p><a href="train/remove_checkpoint.html"><code translate="no" dir="ltr">remove_checkpoint(...)</code></a>: Removes a checkpoint given by <code translate="no" dir="ltr">checkpoint_prefix</code>. (deprecated)</p> <p><a href="train/replica_device_setter.html"><code translate="no" dir="ltr">replica_device_setter(...)</code></a>: Return a <code translate="no" dir="ltr">device function</code> to use when building a Graph for replicas.</p> <p><a href="train/sdca_fprint.html"><code translate="no" dir="ltr">sdca_fprint(...)</code></a>: Computes fingerprints of the input strings.</p> <p><a href="train/sdca_optimizer.html"><code translate="no" dir="ltr">sdca_optimizer(...)</code></a>: Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p> <p><a href="train/sdca_shrink_l1.html"><code translate="no" dir="ltr">sdca_shrink_l1(...)</code></a>: Applies L1 regularization shrink step on the parameters.</p> <p><a href="train/shuffle_batch.html"><code translate="no" dir="ltr">shuffle_batch(...)</code></a>: Creates batches by randomly shuffling tensors. (deprecated)</p> <p><a href="train/shuffle_batch_join.html"><code translate="no" dir="ltr">shuffle_batch_join(...)</code></a>: Create batches by randomly shuffling tensors. (deprecated)</p> <p><a href="train/slice_input_producer.html"><code translate="no" dir="ltr">slice_input_producer(...)</code></a>: Produces a slice of each <code translate="no" dir="ltr">Tensor</code> in <code translate="no" dir="ltr">tensor_list</code>. (deprecated)</p> <p><a href="train/start_queue_runners.html"><code translate="no" dir="ltr">start_queue_runners(...)</code></a>: Starts all queue runners collected in the graph. (deprecated)</p> <p><a href="train/string_input_producer.html"><code translate="no" dir="ltr">string_input_producer(...)</code></a>: Output strings (e.g. filenames) to a queue for an input pipeline. (deprecated)</p> <p><a href="train/summary_iterator.html"><code translate="no" dir="ltr">summary_iterator(...)</code></a>: Returns a iterator for reading <code translate="no" dir="ltr">Event</code> protocol buffers from an event file.</p> <p><a href="train/update_checkpoint_state.html"><code translate="no" dir="ltr">update_checkpoint_state(...)</code></a>: Updates the content of the 'checkpoint' file. (deprecated)</p> <p><a href="train/warm_start.html"><code translate="no" dir="ltr">warm_start(...)</code></a>: Warm-starts a model using the given settings.</p> <p><a href="../../io/write_graph.html"><code translate="no" dir="ltr">write_graph(...)</code></a>: Writes a graph proto to a file.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/train</a>
  </p>
</div>
