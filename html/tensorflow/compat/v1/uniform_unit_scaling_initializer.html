<h1 class="devsite-page-title" tabindex="-1"> tf.compat.v1.uniform_unit_scaling_initializer </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.uniform_unit_scaling_initializer"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__call__"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="get_config"> </div>   <p>Initializer that generates tensors without scaling variance.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="uniform_unit_scaling_initializer.html"><code translate="no" dir="ltr">tf.compat.v1.initializers.uniform_unit_scaling</code></a></p> </section> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.compat.v1.uniform_unit_scaling_initializer(
    factor=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
</pre></devsite-code>  <p>When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer. If the input is <code translate="no" dir="ltr">x</code> and the operation <code translate="no" dir="ltr">x * W</code>, and we want to initialize <code translate="no" dir="ltr">W</code> uniformly at random, we need to pick <code translate="no" dir="ltr">W</code> from</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]
</pre></devsite-code> <p>to keep the scale intact, where <code translate="no" dir="ltr">dim = W.shape[0]</code> (the size of the input). A similar calculation for convolutional networks gives an analogous result with <code translate="no" dir="ltr">dim</code> equal to the product of the first 3 dimensions. When nonlinearities are present, we need to multiply this by a constant <code translate="no" dir="ltr">factor</code>. See (Sussillo et al., 2014) for deeper motivation, experiments and the calculation of constants. In section 2.3 there, the constants were numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">factor</code> </td> <td> Float. A multiplicative factor by which the values will be scaled. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">seed</code> </td> <td> A Python integer. Used to create random seeds. See <a href="set_random_seed.html"><code translate="no" dir="ltr">tf.compat.v1.set_random_seed</code></a> for behavior. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> Default data type, used if no <code translate="no" dir="ltr">dtype</code> argument is provided when calling the initializer. Only floating point types are supported. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">References</th></tr> <tr class="alt"> <td colspan="2"> <a href="https://arxiv.org/abs/1412.6558">Sussillo et al., 2014</a> (<a href="http://arxiv.org/pdf/1412.6558.pdf">pdf</a>) </td> </tr> 
</table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/ops/init_ops.py#L75-L94">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config
)
</pre></devsite-code> <p>Instantiates an initializer from a configuration dictionary.</p> <h4 id="example" data-text="Example:" tabindex="-1">Example:</h4> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">initializer = RandomUniform(-1, 1)
config = initializer.get_config()
initializer = RandomUniform.from_config(config)
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">config</code> </td> <td> A Python dictionary. It will typically be the output of <code translate="no" dir="ltr">get_config</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> An Initializer instance. </td> </tr> 
</table> <h3 id="get_config" data-text="get_config" tabindex="-1"><code translate="no" dir="ltr">get_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/ops/init_ops.py#L737-L738">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">get_config()
</pre></devsite-code> <p>Returns the configuration of the initializer as a JSON-serializable dict.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A JSON-serializable Python dict. </td> </tr> 
</table> <h3 id="__call__" data-text="__call__" tabindex="-1"><code translate="no" dir="ltr">__call__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/ops/init_ops.py#L718-L735">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">__call__(
    shape, dtype=None, partition_info=None
)
</pre></devsite-code> <p>Returns a tensor object initialized as specified by the initializer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> Shape of the tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> Optional dtype of the tensor. If not provided use the initializer dtype. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">partition_info</code> </td> <td> Optional information about the possible partitioning of a tensor. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/uniform_unit_scaling_initializer" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/uniform_unit_scaling_initializer</a>
  </p>
</div>
