<h1 class="devsite-page-title" tabindex="-1"> tf.compat.v1.variable_axis_size_partitioner </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.variable_axis_size_partitioner"> <meta itemprop="path" content="Stable"> </div>   <p>Get a partitioner for VariableScope to keep shards below <code translate="no" dir="ltr">max_shard_bytes</code>.</p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.compat.v1.variable_axis_size_partitioner(
    max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None
)
</pre></devsite-code>  <p>This partitioner will shard a Variable along one axis, attempting to keep the maximum shard size below <code translate="no" dir="ltr">max_shard_bytes</code>. In practice, this is not always possible when sharding along only one axis. When this happens, this axis is sharded as much as possible (i.e., every dimension becomes a separate shard).</p> <p>If the partitioner hits the <code translate="no" dir="ltr">max_shards</code> limit, then each shard may end up larger than <code translate="no" dir="ltr">max_shard_bytes</code>. By default <code translate="no" dir="ltr">max_shards</code> equals <code translate="no" dir="ltr">None</code> and no limit on the number of shards is enforced.</p> <p>One reasonable value for <code translate="no" dir="ltr">max_shard_bytes</code> is <code translate="no" dir="ltr">(64 &lt;&lt; 20) - 1</code>, or almost <code translate="no" dir="ltr">64MB</code>, to keep below the protobuf byte limit.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">max_shard_bytes</code> </td> <td> The maximum size any given shard is allowed to be. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">axis</code> </td> <td> The axis to partition along. Default: outermost axis. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bytes_per_string_element</code> </td> <td> If the <code translate="no" dir="ltr">Variable</code> is of type string, this provides an estimate of how large each scalar in the <code translate="no" dir="ltr">Variable</code> is. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_shards</code> </td> <td> The maximum number of shards in int created taking precedence over <code translate="no" dir="ltr">max_shard_bytes</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A partition function usable as the <code translate="no" dir="ltr">partitioner</code> argument to <code translate="no" dir="ltr">variable_scope</code> and <code translate="no" dir="ltr">get_variable</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If any of the byte counts are non-positive. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/variable_axis_size_partitioner" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/variable_axis_size_partitioner</a>
  </p>
</div>
