<h1 class="devsite-page-title" tabindex="-1"> tf.AggregationMethod </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.AggregationMethod"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="ADD_N"> <meta itemprop="property" content="DEFAULT"> <meta itemprop="property" content="EXPERIMENTAL_ACCUMULATE_N"> <meta itemprop="property" content="EXPERIMENTAL_TREE"> </div>   <p>A class listing aggregation methods used to combine gradients.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="aggregationmethod.html"><code translate="no" dir="ltr">tf.compat.v1.AggregationMethod</code></a></p> </section>  <p>Computing partial derivatives can require aggregating gradient contributions. This class lists the various methods that can be used to combine gradients in the graph.</p> <p>The following aggregation methods are part of the stable API for aggregating gradients:</p> <ul> <li>
<code translate="no" dir="ltr">ADD_N</code>: All of the gradient terms are summed as part of one operation using the "AddN" op (see <a href="math/add_n.html"><code translate="no" dir="ltr">tf.add_n</code></a>). This method has the property that all gradients must be ready and buffered separately in memory before any aggregation is performed.</li> <li>
<code translate="no" dir="ltr">DEFAULT</code>: The system-chosen default aggregation method.</li> </ul> <p>The following aggregation methods are experimental and may not be supported in future releases:</p> <ul> <li>
<code translate="no" dir="ltr">EXPERIMENTAL_TREE</code>: Gradient terms are summed in pairs using the "AddN" op. This method of summing gradients may reduce performance, but it can improve memory utilization because the gradients can be released earlier.</li> <li>
<code translate="no" dir="ltr">EXPERIMENTAL_ACCUMULATE_N</code>: Same as <code translate="no" dir="ltr">EXPERIMENTAL_TREE</code>.</li> </ul> <p>Example usage when computing gradient:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@tf.function
def example():
  x = tf.constant(1.0)
  y = x * 2.0
  z = y + y + y + y
  return tf.gradients(z, [x, y],
    aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)
example()
[&lt;tf.Tensor: shape=(), dtype=float32, numpy=8.0&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=4.0&gt;]</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Class Variables</th></tr> 
<tr> <td> ADD_N </td> <td> <code translate="no" dir="ltr">0</code> </td> </tr>
<tr> <td> DEFAULT </td> <td> <code translate="no" dir="ltr">0</code> </td> </tr>
<tr> <td> EXPERIMENTAL_ACCUMULATE_N </td> <td> <code translate="no" dir="ltr">2</code> </td> </tr>
<tr> <td> EXPERIMENTAL_TREE </td> <td> <code translate="no" dir="ltr">1</code> </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/AggregationMethod" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/AggregationMethod</a>
  </p>
</div>
