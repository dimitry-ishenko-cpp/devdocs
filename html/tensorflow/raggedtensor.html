<h1 class="devsite-page-title">tf.RaggedTensor</h1> <devsite-bookmark></devsite-bookmark>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>   <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L60-L2248">  View source on GitHub </a> </td> </table> <p>Represents a ragged tensor.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor"><code translate="no" dir="ltr">tf.compat.v1.RaggedTensor</code></a></p> </section>  <p>A <code translate="no" dir="ltr">RaggedTensor</code> is a tensor with one or more <em>ragged dimensions</em>, which are dimensions whose slices may have different lengths. For example, the inner (column) dimension of <code translate="no" dir="ltr">rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is ragged, since the column slices (<code translate="no" dir="ltr">rt[0, :]</code>, ..., <code translate="no" dir="ltr">rt[4, :]</code>) have different lengths. Dimensions whose slices all have the same length are called <em>uniform dimensions</em>. The outermost dimension of a <code translate="no" dir="ltr">RaggedTensor</code> is always uniform, since it consists of a single slice (and so there is no possibility for differing slice lengths).</p> <p>The total number of dimensions in a <code translate="no" dir="ltr">RaggedTensor</code> is called its <em>rank</em>, and the number of ragged dimensions in a <code translate="no" dir="ltr">RaggedTensor</code> is called its <em>ragged-rank</em>. A <code translate="no" dir="ltr">RaggedTensor</code>'s ragged-rank is fixed at graph creation time: it can't depend on the runtime values of <code translate="no" dir="ltr">Tensor</code>s, and can't vary dynamically for different session runs.</p> <p>Note that the <code translate="no" dir="ltr">__init__</code> constructor is private. Please use one of the following methods to construct a <code translate="no" dir="ltr">RaggedTensor</code>:</p> <ul> <li><a href="raggedtensor.html#from_row_lengths"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_lengths</code></a></li> <li><a href="raggedtensor.html#from_value_rowids"><code translate="no" dir="ltr">tf.RaggedTensor.from_value_rowids</code></a></li> <li><a href="raggedtensor.html#from_row_splits"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_splits</code></a></li> <li><a href="raggedtensor.html#from_row_starts"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_starts</code></a></li> <li><a href="raggedtensor.html#from_row_limits"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_limits</code></a></li> <li><a href="raggedtensor.html#from_nested_row_splits"><code translate="no" dir="ltr">tf.RaggedTensor.from_nested_row_splits</code></a></li> <li><a href="raggedtensor.html#from_nested_row_lengths"><code translate="no" dir="ltr">tf.RaggedTensor.from_nested_row_lengths</code></a></li> <li><a href="raggedtensor.html#from_nested_value_rowids"><code translate="no" dir="ltr">tf.RaggedTensor.from_nested_value_rowids</code></a></li> </ul> <h3 id="potentially_ragged_tensors" data-text="Potentially Ragged Tensors">Potentially Ragged Tensors</h3> <p>Many ops support both <code translate="no" dir="ltr">Tensor</code>s and <code translate="no" dir="ltr">RaggedTensor</code>s (see <a href="https://www.tensorflow.org/api_docs/python/tf/ragged">tf.ragged</a> for a full listing). The term "potentially ragged tensor" may be used to refer to a tensor that might be either a <code translate="no" dir="ltr">Tensor</code> or a <code translate="no" dir="ltr">RaggedTensor</code>. The ragged-rank of a <code translate="no" dir="ltr">Tensor</code> is zero.</p> <h3 id="documenting_raggedtensor_shapes" data-text="Documenting RaggedTensor Shapes">Documenting RaggedTensor Shapes</h3> <p>When documenting the shape of a RaggedTensor, ragged dimensions can be indicated by enclosing them in parentheses. For example, the shape of a 3-D <code translate="no" dir="ltr">RaggedTensor</code> that stores the fixed-size word embedding for each word in a sentence, for each sentence in a batch, could be written as <code translate="no" dir="ltr">[num_sentences, (num_words), embedding_size]</code>. The parentheses around <code translate="no" dir="ltr">(num_words)</code> indicate that dimension is ragged, and that the length of each element list in that dimension may vary for each item.</p> <h3 id="component_tensors" data-text="Component Tensors">Component Tensors</h3> <p>Internally, a <code translate="no" dir="ltr">RaggedTensor</code> consists of a concatenated list of values that are partitioned into variable-length rows. In particular, each <code translate="no" dir="ltr">RaggedTensor</code> consists of:</p> <ul> <li><p>A <code translate="no" dir="ltr">values</code> tensor, which concatenates the variable-length rows into a flattened list. For example, the <code translate="no" dir="ltr">values</code> tensor for <code translate="no" dir="ltr">[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is <code translate="no" dir="ltr">[3, 1, 4, 1, 5, 9, 2, 6]</code>.</p></li> <li><p>A <code translate="no" dir="ltr">row_splits</code> vector, which indicates how those flattened values are divided into rows. In particular, the values for row <code translate="no" dir="ltr">rt[i]</code> are stored in the slice <code translate="no" dir="ltr">rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p></li> </ul> <h4 id="example" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
print(tf.RaggedTensor.from_row_splits(
      values=[3, 1, 4, 1, 5, 9, 2, 6],
      row_splits=[0, 4, 4, 7, 8, 8]))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
</pre> <h3 id="alternative_row-partitioning_schemes" data-text="Alternative Row-Partitioning Schemes">Alternative Row-Partitioning Schemes</h3> <p>In addition to <code translate="no" dir="ltr">row_splits</code>, ragged tensors provide support for five other row-partitioning schemes:</p> <ul> <li><p><code translate="no" dir="ltr">row_lengths</code>: a vector with shape <code translate="no" dir="ltr">[nrows]</code>, which specifies the length of each row.</p></li> <li><p><code translate="no" dir="ltr">value_rowids</code> and <code translate="no" dir="ltr">nrows</code>: <code translate="no" dir="ltr">value_rowids</code> is a vector with shape <code translate="no" dir="ltr">[nvals]</code>, corresponding one-to-one with <code translate="no" dir="ltr">values</code>, which specifies each value's row index. In particular, the row <code translate="no" dir="ltr">rt[row]</code> consists of the values <code translate="no" dir="ltr">rt.values[j]</code> where <code translate="no" dir="ltr">value_rowids[j]==row</code>. <code translate="no" dir="ltr">nrows</code> is an integer scalar that specifies the number of rows in the <code translate="no" dir="ltr">RaggedTensor</code>. (<code translate="no" dir="ltr">nrows</code> is used to indicate trailing empty rows.)</p></li> <li><p><code translate="no" dir="ltr">row_starts</code>: a vector with shape <code translate="no" dir="ltr">[nrows]</code>, which specifies the start offset of each row. Equivalent to <code translate="no" dir="ltr">row_splits[:-1]</code>.</p></li> <li><p><code translate="no" dir="ltr">row_limits</code>: a vector with shape <code translate="no" dir="ltr">[nrows]</code>, which specifies the stop offset of each row. Equivalent to <code translate="no" dir="ltr">row_splits[1:]</code>.</p></li> <li><p><code translate="no" dir="ltr">uniform_row_length</code>: A scalar tensor, specifying the length of every row. This row-partitioning scheme may only be used if all rows have the same length.</p></li> </ul> <p>Example: The following ragged tensors are equivalent, and all represent the nested list <code translate="no" dir="ltr">[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
values = [3, 1, 4, 1, 5, 9, 2, 6]
RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
RaggedTensor.from_value_rowids(
    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)
&lt;tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]&gt;
</pre> <h3 id="multiple_ragged_dimensions" data-text="Multiple Ragged Dimensions">Multiple Ragged Dimensions</h3> <p><code translate="no" dir="ltr">RaggedTensor</code>s with multiple ragged dimensions can be defined by using a nested <code translate="no" dir="ltr">RaggedTensor</code> for the <code translate="no" dir="ltr">values</code> tensor. Each nested <code translate="no" dir="ltr">RaggedTensor</code> adds a single ragged dimension.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above
    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])
outer_rt = RaggedTensor.from_row_splits(
    values=inner_rt, row_splits=[0, 3, 3, 5])
print(outer_rt.to_list())
[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]
print(outer_rt.ragged_rank)
2
</pre> <p>The factory function <a href="raggedtensor.html#from_nested_row_splits"><code translate="no" dir="ltr">RaggedTensor.from_nested_row_splits</code></a> may be used to construct a <code translate="no" dir="ltr">RaggedTensor</code> with multiple ragged dimensions directly, by providing a list of <code translate="no" dir="ltr">row_splits</code> tensors:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
RaggedTensor.from_nested_row_splits(
    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],
    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()
[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]
</pre> <h3 id="uniform_inner_dimensions" data-text="Uniform Inner Dimensions">Uniform Inner Dimensions</h3> <p><code translate="no" dir="ltr">RaggedTensor</code>s with uniform inner dimensions can be defined by using a multidimensional <code translate="no" dir="ltr">Tensor</code> for <code translate="no" dir="ltr">values</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),
                                  row_splits=[0, 2, 5])
print(rt.to_list())
[[[1, 1, 1], [1, 1, 1]],
 [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]
print(rt.shape)
(2, None, 3)
</pre> <h3 id="uniform_outer_dimensions" data-text="Uniform Outer Dimensions">Uniform Outer Dimensions</h3> <p><code translate="no" dir="ltr">RaggedTensor</code>s with uniform outer dimensions can be defined by using one or more <code translate="no" dir="ltr">RaggedTensor</code> with a <code translate="no" dir="ltr">uniform_row_length</code> row-partitioning tensor. For example, a <code translate="no" dir="ltr">RaggedTensor</code> with shape <code translate="no" dir="ltr">[2, 2, None]</code> can be constructed with this method from a <code translate="no" dir="ltr">RaggedTensor</code> values with shape <code translate="no" dir="ltr">[4, None]</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])
print(values.shape)
(4, None)
rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)
print(rt6)
&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt;
print(rt6.shape)
(2, 2, None)
</pre> <p>Note that <code translate="no" dir="ltr">rt6</code> only contains one ragged dimension (the innermost dimension). In contrast, if <code translate="no" dir="ltr">from_row_splits</code> is used to construct a similar <code translate="no" dir="ltr">RaggedTensor</code>, then that <code translate="no" dir="ltr">RaggedTensor</code> will have two ragged dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])
print(rt7.shape)
(2, None, None)
</pre> <p>Uniform and ragged outer dimensions may be interleaved, meaning that a tensor with any combination of ragged and uniform dimensions may be created. For example, a RaggedTensor <code translate="no" dir="ltr">t4</code> with shape <code translate="no" dir="ltr">[3, None, 4, 8, None, 2]</code> could be constructed as follows:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]
t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]
t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]
t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]
t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> The <code translate="no" dir="ltr">DType</code> of values in this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">flat_values</code> </td> <td> The innermost <code translate="no" dir="ltr">values</code> tensor for this ragged tensor. <p>Concretely, if <code translate="no" dir="ltr">rt.values</code> is a <code translate="no" dir="ltr">Tensor</code>, then <code translate="no" dir="ltr">rt.flat_values</code> is <code translate="no" dir="ltr">rt.values</code>; otherwise, <code translate="no" dir="ltr">rt.flat_values</code> is <code translate="no" dir="ltr">rt.values.flat_values</code>.</p> <p>Conceptually, <code translate="no" dir="ltr">flat_values</code> is the tensor formed by flattening the outermost dimension and all of the ragged dimensions into a single dimension.</p> <p><code translate="no" dir="ltr">rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]</code> (where <code translate="no" dir="ltr">nvals</code> is the number of items in the flattened dimensions).</p> <h4 id="example_2" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])
print(rt.flat_values)
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)
</pre> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">nested_row_splits</code> </td> <td> A tuple containing the row_splits for all ragged dimensions. <p><code translate="no" dir="ltr">rt.nested_row_splits</code> is a tuple containing the <code translate="no" dir="ltr">row_splits</code> tensors for all ragged dimensions in <code translate="no" dir="ltr">rt</code>, ordered from outermost to innermost. In particular, <code translate="no" dir="ltr">rt.nested_row_splits = (rt.row_splits,) + value_splits</code> where:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">* `value_splits = ()` if `rt.values` is a `Tensor`.
* `value_splits = rt.values.nested_row_splits` otherwise.
</pre> <h4 id="example_3" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant(
    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])
for i, splits in enumerate(rt.nested_row_splits):
  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))
Splits for dimension 1: [0 3]
Splits for dimension 2: [0 3 3 5]
Splits for dimension 3: [0 4 4 7 8 8]
</pre> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">ragged_rank</code> </td> <td> The number of times the RaggedTensor's flat_values is partitioned. <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])
values.ragged_rank
1
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.RaggedTensor.from_uniform_row_length(values, 2)
rt.ragged_rank
2
</pre> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_splits</code> </td> <td> The row-split indices for this ragged tensor's <code translate="no" dir="ltr">values</code>. <p><code translate="no" dir="ltr">rt.row_splits</code> specifies where the values for each row begin and end in <code translate="no" dir="ltr">rt.values</code>. In particular, the values for row <code translate="no" dir="ltr">rt[i]</code> are stored in the slice <code translate="no" dir="ltr">rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p> <h4 id="example_4" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(rt.row_splits)  # indices of row splits in rt.values
tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)
</pre> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> The statically known shape of this ragged tensor. <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.ragged.constant([[0], [1, 2]]).shape
TensorShape([2, None])
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape
TensorShape([2, None, 2])
</pre> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">uniform_row_length</code> </td> <td> The length of each row in this ragged tensor, or None if rows are ragged. <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])
print(rt1.uniform_row_length)  # rows are ragged.
None
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt2 = tf.RaggedTensor.from_uniform_row_length(
    values=rt1, uniform_row_length=2)
print(rt2)
&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt;
print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).
tf.Tensor(2, shape=(), dtype=int64)
</pre> <p>A RaggedTensor's rows are only considered to be uniform (i.e. non-ragged) if it can be determined statically (at graph construction time) that the rows all have the same length. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> The concatenated rows for this ragged tensor. <p><code translate="no" dir="ltr">rt.values</code> is a potentially ragged tensor formed by flattening the two outermost dimensions of <code translate="no" dir="ltr">rt</code> into a single dimension.</p> <p><code translate="no" dir="ltr">rt.values.shape = [nvals] + rt.shape[2:]</code> (where <code translate="no" dir="ltr">nvals</code> is the number of items in the outer two dimensions of <code translate="no" dir="ltr">rt</code>).</p> <p><code translate="no" dir="ltr">rt.ragged_rank = self.ragged_rank - 1</code></p> <h4 id="example_5" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(rt.values)
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)
</pre> 
</td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="bounding_shape" data-text="bounding_shape"><code translate="no" dir="ltr">bounding_shape</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1318-L1376">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
bounding_shape(
    axis=None, name=None, out_type=None
)
</pre> <p>Returns the tight bounding box shape for this <code translate="no" dir="ltr">RaggedTensor</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">axis</code> </td> <td> An integer scalar or vector indicating which axes to return the bounding box for. If not specified, then the full bounding box is returned. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">out_type</code> </td> <td> <code translate="no" dir="ltr">dtype</code> for the returned tensor. Defaults to <code translate="no" dir="ltr">self.row_splits.dtype</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> An integer <code translate="no" dir="ltr">Tensor</code> (<code translate="no" dir="ltr">dtype=self.row_splits.dtype</code>). If <code translate="no" dir="ltr">axis</code> is not specified, then <code translate="no" dir="ltr">output</code> is a vector with <code translate="no" dir="ltr">output.shape=[self.shape.ndims]</code>. If <code translate="no" dir="ltr">axis</code> is a scalar, then the <code translate="no" dir="ltr">output</code> is a scalar. If <code translate="no" dir="ltr">axis</code> is a vector, then <code translate="no" dir="ltr">output</code> is a vector, where <code translate="no" dir="ltr">output[i]</code> is the bounding size for dimension <code translate="no" dir="ltr">axis[i]</code>. </td> </tr> 
</table> <h4 id="example_6" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])
rt.bounding_shape().numpy()
array([5, 4])
</pre> <h3 id="consumers" data-text="consumers"><code translate="no" dir="ltr">consumers</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L2244-L2245">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
consumers()
</pre> <h3 id="from_nested_row_lengths" data-text="from_nested_row_lengths"><code translate="no" dir="ltr">from_nested_row_lengths</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L764-L804">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_nested_row_lengths(
    flat_values, nested_row_lengths, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> from a nested list of <code translate="no" dir="ltr">row_lengths</code> tensors.</p> <h4 id="equivalent_to" data-text="Equivalent to:">Equivalent to:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = flat_values
for row_lengths in reversed(nested_row_lengths):
  result = from_row_lengths(result, row_lengths)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">flat_values</code> </td> <td> A potentially ragged tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">nested_row_lengths</code> </td> <td> A list of 1-D integer tensors. The <code translate="no" dir="ltr">i</code>th tensor is used as the <code translate="no" dir="ltr">row_lengths</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code> (or <code translate="no" dir="ltr">flat_values</code> if <code translate="no" dir="ltr">nested_row_lengths</code> is empty). </td> </tr> 
</table> <h3 id="from_nested_row_splits" data-text="from_nested_row_splits"><code translate="no" dir="ltr">from_nested_row_splits</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L722-L762">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_nested_row_splits(
    flat_values, nested_row_splits, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> from a nested list of <code translate="no" dir="ltr">row_splits</code> tensors.</p> <h4 id="equivalent_to_2" data-text="Equivalent to:">Equivalent to:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = flat_values
for row_splits in reversed(nested_row_splits):
  result = from_row_splits(result, row_splits)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">flat_values</code> </td> <td> A potentially ragged tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">nested_row_splits</code> </td> <td> A list of 1-D integer tensors. The <code translate="no" dir="ltr">i</code>th tensor is used as the <code translate="no" dir="ltr">row_splits</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code> (or <code translate="no" dir="ltr">flat_values</code> if <code translate="no" dir="ltr">nested_row_splits</code> is empty). </td> </tr> 
</table> <h3 id="from_nested_value_rowids" data-text="from_nested_value_rowids"><code translate="no" dir="ltr">from_nested_value_rowids</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L659-L720">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_nested_value_rowids(
    flat_values,
    nested_value_rowids,
    nested_nrows=None,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> from a nested list of <code translate="no" dir="ltr">value_rowids</code> tensors.</p> <h4 id="equivalent_to_3" data-text="Equivalent to:">Equivalent to:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = flat_values
for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):
  result = from_value_rowids(result, rowids, nrows)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">flat_values</code> </td> <td> A potentially ragged tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">nested_value_rowids</code> </td> <td> A list of 1-D integer tensors. The <code translate="no" dir="ltr">i</code>th tensor is used as the <code translate="no" dir="ltr">value_rowids</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">nested_nrows</code> </td> <td> A list of integer scalars. The <code translate="no" dir="ltr">i</code>th scalar is used as the <code translate="no" dir="ltr">nrows</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code> (or <code translate="no" dir="ltr">flat_values</code> if <code translate="no" dir="ltr">nested_value_rowids</code> is empty). </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">len(nested_values_rowids) != len(nested_nrows)</code>. </td> </tr> </table> <h3 id="from_row_lengths" data-text="from_row_lengths"><code translate="no" dir="ltr">from_row_lengths</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L459-L501">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_row_lengths(
    values, row_lengths, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_lengths</code>.</p> <p>The returned <code translate="no" dir="ltr">RaggedTensor</code> corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [[values.pop(0) for i in range(length)]
          for length in row_lengths]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_lengths</code> </td> <td> A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>. Must be nonnegative. <code translate="no" dir="ltr">sum(row_lengths)</code> must be <code translate="no" dir="ltr">nvals</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>. </td> </tr> 
</table> <h4 id="example_7" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
print(tf.RaggedTensor.from_row_lengths(
    values=[3, 1, 4, 1, 5, 9, 2, 6],
    row_lengths=[4, 0, 3, 1, 0]))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
</pre> <h3 id="from_row_limits" data-text="from_row_limits"><code translate="no" dir="ltr">from_row_limits</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L544-L581">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_row_limits(
    values, row_limits, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_limits</code>.</p> <p>Equivalent to: <code translate="no" dir="ltr">from_row_splits(values, concat([0, row_limits]))</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_limits</code> </td> <td> A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>. Must be sorted in ascending order. If <code translate="no" dir="ltr">nrows&gt;0</code>, then <code translate="no" dir="ltr">row_limits[-1]</code> must be <code translate="no" dir="ltr">nvals</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>. </td> </tr> 
</table> <h4 id="example_8" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
print(tf.RaggedTensor.from_row_limits(
    values=[3, 1, 4, 1, 5, 9, 2, 6],
    row_limits=[4, 4, 7, 8, 8]))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
</pre> <h3 id="from_row_splits" data-text="from_row_splits"><code translate="no" dir="ltr">from_row_splits</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L411-L457">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_row_splits(
    values, row_splits, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_splits</code>.</p> <p>The returned <code translate="no" dir="ltr">RaggedTensor</code> corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [values[row_splits[i]:row_splits[i + 1]]
          for i in range(len(row_splits) - 1)]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_splits</code> </td> <td> A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows+1]</code>. Must not be empty, and must be sorted in ascending order. <code translate="no" dir="ltr">row_splits[0]</code> must be zero and <code translate="no" dir="ltr">row_splits[-1]</code> must be <code translate="no" dir="ltr">nvals</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">row_splits</code> is an empty list. </td> </tr> </table> <h4 id="example_9" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
print(tf.RaggedTensor.from_row_splits(
    values=[3, 1, 4, 1, 5, 9, 2, 6],
    row_splits=[0, 4, 4, 7, 8, 8]))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
</pre> <h3 id="from_row_starts" data-text="from_row_starts"><code translate="no" dir="ltr">from_row_starts</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L503-L542">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_row_starts(
    values, row_starts, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_starts</code>.</p> <p>Equivalent to: <code translate="no" dir="ltr">from_row_splits(values, concat([row_starts, nvals]))</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_starts</code> </td> <td> A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>. Must be nonnegative and sorted in ascending order. If <code translate="no" dir="ltr">nrows&gt;0</code>, then <code translate="no" dir="ltr">row_starts[0]</code> must be zero. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>. </td> </tr> 
</table> <h4 id="example_10" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
print(tf.RaggedTensor.from_row_starts(
    values=[3, 1, 4, 1, 5, 9, 2, 6],
    row_starts=[0, 4, 4, 7, 8]))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
</pre> <h3 id="from_sparse" data-text="from_sparse"><code translate="no" dir="ltr">from_sparse</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1862-L1925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_sparse(
    st_input,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
</pre> <p>Converts a 2D <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> to a <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>Each row of the <code translate="no" dir="ltr">output</code> <code translate="no" dir="ltr">RaggedTensor</code> will contain the explicit values from the same row in <code translate="no" dir="ltr">st_input</code>. <code translate="no" dir="ltr">st_input</code> must be ragged-right. If not it is not ragged-right, then an error will be generated.</p> <h4 id="example_11" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
indices = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]]
st = tf.sparse.SparseTensor(indices=indices,
                            values=[1, 2, 3, 4, 5],
                            dense_shape=[4, 3])
tf.RaggedTensor.from_sparse(st).to_list()
[[1, 2, 3], [4], [], [5]]
</pre> <p>Currently, only two-dimensional <code translate="no" dir="ltr">SparseTensors</code> are supported.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">st_input</code> </td> <td> The sparse tensor to convert. Must have rank 2. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensors (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_splits_dtype</code> </td> <td> <code translate="no" dir="ltr">dtype</code> for the returned <code translate="no" dir="ltr">RaggedTensor</code>'s <code translate="no" dir="ltr">row_splits</code> tensor. One of <a href="../tf.html#int32"><code translate="no" dir="ltr">tf.int32</code></a> or <a href="../tf.html#int64"><code translate="no" dir="ltr">tf.int64</code></a>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code> with the same values as <code translate="no" dir="ltr">st_input</code>. <code translate="no" dir="ltr">output.ragged_rank = rank(st_input) - 1</code>. <code translate="no" dir="ltr">output.shape = [st_input.dense_shape[0], None]</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the number of dimensions in <code translate="no" dir="ltr">st_input</code> is not known statically, or is not two. </td> </tr> </table> <h3 id="from_tensor" data-text="from_tensor"><code translate="no" dir="ltr">from_tensor</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1573-L1787">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_tensor(
    tensor,
    lengths=None,
    padding=None,
    ragged_rank=1,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
</pre> <p>Converts a <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> into a <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>The set of absent/default values may be specified using a vector of lengths or a padding value (but not both). If <code translate="no" dir="ltr">lengths</code> is specified, then the output tensor will satisfy <code translate="no" dir="ltr">output[row] = tensor[row][:lengths[row]]</code>. If 'lengths' is a list of lists or tuple of lists, those lists will be used as nested row lengths. If <code translate="no" dir="ltr">padding</code> is specified, then any row <em>suffix</em> consisting entirely of <code translate="no" dir="ltr">padding</code> will be excluded from the returned <code translate="no" dir="ltr">RaggedTensor</code>. If neither <code translate="no" dir="ltr">lengths</code> nor <code translate="no" dir="ltr">padding</code> is specified, then the returned <code translate="no" dir="ltr">RaggedTensor</code> will have no absent/default values.</p> <h4 id="examples" data-text="Examples:">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])
tf.RaggedTensor.from_tensor(dt)
&lt;tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]&gt;
tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])
&lt;tf.RaggedTensor [[5], [], [6, 0, 0]]&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.RaggedTensor.from_tensor(dt, padding=0)
&lt;tf.RaggedTensor [[5, 7], [0, 3], [6]]&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
dt = tf.constant([[[5, 0], [7, 0], [0, 0]],
                  [[0, 0], [3, 0], [0, 0]],
                  [[6, 0], [0, 0], [0, 0]]])
tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))
&lt;tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor</code> </td> <td> The <code translate="no" dir="ltr">Tensor</code> to convert. Must have rank <code translate="no" dir="ltr">ragged_rank + 1</code> or higher. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">lengths</code> </td> <td> An optional set of row lengths, specified using a 1-D integer <code translate="no" dir="ltr">Tensor</code> whose length is equal to <code translate="no" dir="ltr">tensor.shape[0]</code> (the number of rows in <code translate="no" dir="ltr">tensor</code>). If specified, then <code translate="no" dir="ltr">output[row]</code> will contain <code translate="no" dir="ltr">tensor[row][:lengths[row]]</code>. Negative lengths are treated as zero. You may optionally pass a list or tuple of lengths to this argument, which will be used as nested row lengths to construct a ragged tensor with multiple ragged dimensions. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">padding</code> </td> <td> An optional padding value. If specified, then any row suffix consisting entirely of <code translate="no" dir="ltr">padding</code> will be excluded from the returned RaggedTensor. <code translate="no" dir="ltr">padding</code> is a <code translate="no" dir="ltr">Tensor</code> with the same dtype as <code translate="no" dir="ltr">tensor</code> and with <code translate="no" dir="ltr">shape=tensor.shape[ragged_rank + 1:]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ragged_rank</code> </td> <td> Integer specifying the ragged rank for the returned <code translate="no" dir="ltr">RaggedTensor</code>. Must be greater than zero. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensors (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">row_splits_dtype</code> </td> <td> <code translate="no" dir="ltr">dtype</code> for the returned <code translate="no" dir="ltr">RaggedTensor</code>'s <code translate="no" dir="ltr">row_splits</code> tensor. One of <a href="../tf.html#int32"><code translate="no" dir="ltr">tf.int32</code></a> or <a href="../tf.html#int64"><code translate="no" dir="ltr">tf.int64</code></a>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code> with the specified <code translate="no" dir="ltr">ragged_rank</code>. The shape of the returned ragged tensor is compatible with the shape of <code translate="no" dir="ltr">tensor</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If both <code translate="no" dir="ltr">lengths</code> and <code translate="no" dir="ltr">padding</code> are specified. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the rank of <code translate="no" dir="ltr">tensor</code> is 0 or 1. </td> </tr> </table> <h3 id="from_uniform_row_length" data-text="from_uniform_row_length"><code translate="no" dir="ltr">from_uniform_row_length</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L583-L657">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_uniform_row_length(
    values, uniform_row_length, nrows=None, validate=True, name=None
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">uniform_row_length</code>.</p> <p>This method can be used to create <code translate="no" dir="ltr">RaggedTensor</code>s with multiple uniform outer dimensions. For example, a <code translate="no" dir="ltr">RaggedTensor</code> with shape <code translate="no" dir="ltr">[2, 2, None]</code> can be constructed with this method from a <code translate="no" dir="ltr">RaggedTensor</code> values with shape <code translate="no" dir="ltr">[4, None]</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])
print(values.shape)
(4, None)
rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)
print(rt1)
&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt;
print(rt1.shape)
(2, 2, None)
</pre> <p>Note that <code translate="no" dir="ltr">rt1</code> only contains one ragged dimension (the innermost dimension). In contrast, if <code translate="no" dir="ltr">from_row_splits</code> is used to construct a similar <code translate="no" dir="ltr">RaggedTensor</code>, then that <code translate="no" dir="ltr">RaggedTensor</code> will have two ragged dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])
print(rt2.shape)
(2, None, None)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">uniform_row_length</code> </td> <td> A scalar integer tensor. Must be nonnegative. The size of the outer axis of <code translate="no" dir="ltr">values</code> must be evenly divisible by <code translate="no" dir="ltr">uniform_row_length</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">nrows</code> </td> <td> The number of rows in the constructed RaggedTensor. If not specified, then it defaults to <code translate="no" dir="ltr">nvals/uniform_row_length</code> (or <code translate="no" dir="ltr">0</code> if <code translate="no" dir="ltr">uniform_row_length==0</code>). <code translate="no" dir="ltr">nrows</code> only needs to be specified if <code translate="no" dir="ltr">uniform_row_length</code> might be zero. <code translate="no" dir="ltr">uniform_row_length*nrows</code> must be <code translate="no" dir="ltr">nvals</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code> that corresponds with the python list defined by: <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [[values.pop(0) for i in range(uniform_row_length)]
          for _ in range(nrows)]
</pre> <p><code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>. </p>
</td> </tr> 
</table> <h3 id="from_value_rowids" data-text="from_value_rowids"><code translate="no" dir="ltr">from_value_rowids</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L351-L409">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
from_value_rowids(
    values, value_rowids, nrows=None, name=None, validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">value_rowids</code>.</p> <p>The returned <code translate="no" dir="ltr">RaggedTensor</code> corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]
          for row in range(nrows)]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">values</code> </td> <td> A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_rowids</code> </td> <td> A 1-D integer tensor with shape <code translate="no" dir="ltr">[nvals]</code>, which corresponds one-to-one with <code translate="no" dir="ltr">values</code>, and specifies each value's row index. Must be nonnegative, and must be sorted in ascending order. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">nrows</code> </td> <td> An integer scalar specifying the number of rows. This should be specified if the <code translate="no" dir="ltr">RaggedTensor</code> may containing empty training rows. Must be greater than <code translate="no" dir="ltr">value_rowids[-1]</code> (or zero if <code translate="no" dir="ltr">value_rowids</code> is empty). Defaults to <code translate="no" dir="ltr">value_rowids[-1] + 1</code> (or zero if <code translate="no" dir="ltr">value_rowids</code> is empty). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the RaggedTensor (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validate</code> </td> <td> If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>. Note: these assertions incur a runtime cost, since they must be checked for each tensor value. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">nrows</code> is incompatible with <code translate="no" dir="ltr">value_rowids</code>. </td> </tr> </table> <h4 id="example_12" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
print(tf.RaggedTensor.from_value_rowids(
    values=[3, 1, 4, 1, 5, 9, 2, 6],
    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],
    nrows=5))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;
</pre> <h3 id="get_shape" data-text="get_shape"><code translate="no" dir="ltr">get_shape</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L920-L939">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_shape()
</pre> <p>The statically known shape of this ragged tensor.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">TensorShape</code> containing the statically known shape of this ragged tensor. Ragged dimensions have a size of <code translate="no" dir="ltr">None</code>. </td> </tr> 
</table> <p>Alias for <code translate="no" dir="ltr">shape</code> property.</p> <h4 id="examples_2" data-text="Examples:">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.ragged.constant([[0], [1, 2]]).get_shape()
TensorShape([2, None])
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.ragged.constant(
   [[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).get_shape()
TensorShape([2, None, 2])
</pre> <h3 id="merge_dims" data-text="merge_dims"><code translate="no" dir="ltr">merge_dims</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1464-L1510">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
merge_dims(
    outer_axis, inner_axis
)
</pre> <p>Merges outer_axis...inner_axis into a single dimension.</p> <p>Returns a copy of this RaggedTensor with the specified range of dimensions flattened into a single dimension, with elements in row-major order.</p> <h4 id="examples_3" data-text="Examples:">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]])
print(rt.merge_dims(0, 1))
&lt;tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]&gt;
print(rt.merge_dims(1, 2))
&lt;tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]&gt;
print(rt.merge_dims(0, 2))
tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)
</pre> <p>To mimic the behavior of <code translate="no" dir="ltr">np.flatten</code> (which flattens all dimensions), use <code translate="no" dir="ltr">rt.merge_dims(0, -1). To mimic the behavior of</code>tf.layers.Flatten<code translate="no" dir="ltr">(which flattens all dimensions except the outermost batch dimension), use</code>rt.merge_dims(1, -1)`.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">outer_axis</code> </td> <td> <code translate="no" dir="ltr">int</code>: The first dimension in the range of dimensions to merge. May be negative if <code translate="no" dir="ltr">self.shape.rank</code> is statically known. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">inner_axis</code> </td> <td> <code translate="no" dir="ltr">int</code>: The last dimension in the range of dimensions to merge. May be negative if <code translate="no" dir="ltr">self.shape.rank</code> is statically known. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A copy of this tensor, with the specified dimensions merged into a single dimension. The shape of the returned tensor will be <code translate="no" dir="ltr">self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]</code>, where <code translate="no" dir="ltr">N</code> is the total number of slices in the merged dimensions. </td> </tr> 
</table> <h3 id="nested_row_lengths" data-text="nested_row_lengths"><code translate="no" dir="ltr">nested_row_lengths</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1297-L1316">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
nested_row_lengths(
    name=None
)
</pre> <p>Returns a tuple containing the row_lengths for all ragged dimensions.</p> <p><code translate="no" dir="ltr">rt.nested_row_lengths()</code> is a tuple containing the <code translate="no" dir="ltr">row_lengths</code> tensors for all ragged dimensions in <code translate="no" dir="ltr">rt</code>, ordered from outermost to innermost.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensors (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">tuple</code> of 1-D integer <code translate="no" dir="ltr">Tensors</code>. The length of the tuple is equal to <code translate="no" dir="ltr">self.ragged_rank</code>. </td> </tr> 
</table> <h3 id="nested_value_rowids" data-text="nested_value_rowids"><code translate="no" dir="ltr">nested_value_rowids</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1135-L1170">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
nested_value_rowids(
    name=None
)
</pre> <p>Returns a tuple containing the value_rowids for all ragged dimensions.</p> <p><code translate="no" dir="ltr">rt.nested_value_rowids</code> is a tuple containing the <code translate="no" dir="ltr">value_rowids</code> tensors for all ragged dimensions in <code translate="no" dir="ltr">rt</code>, ordered from outermost to innermost. In particular, <code translate="no" dir="ltr">rt.nested_value_rowids = (rt.value_rowids(),) + value_ids</code> where:</p> <ul> <li>
<code translate="no" dir="ltr">value_ids = ()</code> if <code translate="no" dir="ltr">rt.values</code> is a <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<code translate="no" dir="ltr">value_ids = rt.values.nested_value_rowids</code> otherwise.</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensors (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">tuple</code> of 1-D integer <code translate="no" dir="ltr">Tensor</code>s. </td> </tr> 
</table> <h4 id="example_13" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant(
    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])
for i, ids in enumerate(rt.nested_value_rowids()):
  print('row ids for dimension %d: %s' % (i+1, ids.numpy()))
row ids for dimension 1: [0 0 0]
row ids for dimension 2: [0 0 0 2 2]
row ids for dimension 3: [0 0 0 0 2 2 2 3]
</pre> <h3 id="nrows" data-text="nrows"><code translate="no" dir="ltr">nrows</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1172-L1196">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
nrows(
    out_type=None, name=None
)
</pre> <p>Returns the number of rows in this ragged tensor.</p> <p>I.e., the size of the outermost dimension of the tensor.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">out_type</code> </td> <td> <code translate="no" dir="ltr">dtype</code> for the returned tensor. Defaults to <code translate="no" dir="ltr">self.row_splits.dtype</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensor (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A scalar <code translate="no" dir="ltr">Tensor</code> with dtype <code translate="no" dir="ltr">out_type</code>. </td> </tr> 
</table> <h4 id="example_14" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(rt.nrows())  # rt has 5 rows.
tf.Tensor(5, shape=(), dtype=int64)
</pre> <h3 id="numpy" data-text="numpy"><code translate="no" dir="ltr">numpy</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L2077-L2119">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
numpy()
</pre> <p>Returns a numpy <code translate="no" dir="ltr">array</code> with the values for this <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>Requires that this <code translate="no" dir="ltr">RaggedTensor</code> was constructed in eager execution mode.</p> <p>Ragged dimensions are encoded using numpy <code translate="no" dir="ltr">arrays</code> with <code translate="no" dir="ltr">dtype=object</code> and <code translate="no" dir="ltr">rank=1</code>, where each element is a single row.</p> <h4 id="examples" data-text="Examples">Examples</h4> <p>In the following example, the value returned by <a href="raggedtensor.html#numpy"><code translate="no" dir="ltr">RaggedTensor.numpy()</code></a> contains three numpy <code translate="no" dir="ltr">array</code> objects: one for each row (with <code translate="no" dir="ltr">rank=1</code> and <code translate="no" dir="ltr">dtype=int64</code>), and one to combine them (with <code translate="no" dir="ltr">rank=1</code> and <code translate="no" dir="ltr">dtype=object</code>):</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.ragged.constant([[1, 2, 3], [4, 5]], dtype=tf.int64).numpy()
array([array([1, 2, 3]), array([4, 5])], dtype=object)
</pre> <p>Uniform dimensions are encoded using multidimensional numpy <code translate="no" dir="ltr">array</code>s. In the following example, the value returned by <a href="raggedtensor.html#numpy"><code translate="no" dir="ltr">RaggedTensor.numpy()</code></a> contains a single numpy <code translate="no" dir="ltr">array</code> object, with <code translate="no" dir="ltr">rank=2</code> and <code translate="no" dir="ltr">dtype=int64</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.ragged.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int64).numpy()
array([[1, 2, 3], [4, 5, 6]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A numpy <code translate="no" dir="ltr">array</code>. </td> </tr> 
</table> <h3 id="row_lengths" data-text="row_lengths"><code translate="no" dir="ltr">row_lengths</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1248-L1295">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
row_lengths(
    axis=1, name=None
)
</pre> <p>Returns the lengths of the rows in this ragged tensor.</p> <p><code translate="no" dir="ltr">rt.row_lengths()[i]</code> indicates the number of values in the <code translate="no" dir="ltr">i</code>th row of <code translate="no" dir="ltr">rt</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">axis</code> </td> <td> An integer constant indicating the axis whose row lengths should be returned. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensor (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A potentially ragged integer Tensor with shape <code translate="no" dir="ltr">self.shape[:axis]</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">axis</code> is out of bounds. </td> </tr> </table> <h4 id="example_15" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant(
    [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])
print(rt.row_lengths())  # lengths of rows in rt
tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64)
print(rt.row_lengths(axis=2))  # lengths of axis=2 rows.
&lt;tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]&gt;
</pre> <h3 id="row_limits" data-text="row_limits"><code translate="no" dir="ltr">row_limits</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1223-L1246">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
row_limits(
    name=None
)
</pre> <p>Returns the limit indices for rows in this ragged tensor.</p> <p>These indices specify where the values for each row end in <code translate="no" dir="ltr">self.values</code>. <code translate="no" dir="ltr">rt.row_limits(self)</code> is equal to <code translate="no" dir="ltr">rt.row_splits[:-1]</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensor (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A 1-D integer Tensor with shape <code translate="no" dir="ltr">[nrows]</code>. The returned tensor is nonnegative, and is sorted in ascending order. </td> </tr> 
</table> <h4 id="example_16" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(rt.values)
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)
print(rt.row_limits())  # indices of row limits in rt.values
tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64)
</pre> <h3 id="row_starts" data-text="row_starts"><code translate="no" dir="ltr">row_starts</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1198-L1221">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
row_starts(
    name=None
)
</pre> <p>Returns the start indices for rows in this ragged tensor.</p> <p>These indices specify where the values for each row begin in <code translate="no" dir="ltr">self.values</code>. <code translate="no" dir="ltr">rt.row_starts()</code> is equal to <code translate="no" dir="ltr">rt.row_splits[:-1]</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensor (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A 1-D integer Tensor with shape <code translate="no" dir="ltr">[nrows]</code>. The returned tensor is nonnegative, and is sorted in ascending order. </td> </tr> 
</table> <h4 id="example_17" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(rt.values)
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)
print(rt.row_starts())  # indices of row starts in rt.values
tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64)
</pre> <h3 id="to_list" data-text="to_list"><code translate="no" dir="ltr">to_list</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L2121-L2151">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
to_list()
</pre> <p>Returns a nested Python <code translate="no" dir="ltr">list</code> with the values for this <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>Requires that <code translate="no" dir="ltr">rt</code> was constructed in eager execution mode.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A nested Python <code translate="no" dir="ltr">list</code>. </td> </tr> 
</table> <h3 id="to_sparse" data-text="to_sparse"><code translate="no" dir="ltr">to_sparse</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1927-L1951">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
to_sparse(
    name=None
)
</pre> <p>Converts this <code translate="no" dir="ltr">RaggedTensor</code> into a <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a>.</p> <h4 id="example_18" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]])
print(rt.to_sparse())
SparseTensor(indices=tf.Tensor(
                 [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]],
                 shape=(6, 2), dtype=int64),
             values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32),
             dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64))
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensors (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A SparseTensor with the same values as <code translate="no" dir="ltr">self</code>. </td> </tr> 
</table> <h3 id="to_tensor" data-text="to_tensor"><code translate="no" dir="ltr">to_tensor</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1789-L1860">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
to_tensor(
    default_value=None, name=None, shape=None
)
</pre> <p>Converts this <code translate="no" dir="ltr">RaggedTensor</code> into a <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>.</p> <p>If <code translate="no" dir="ltr">shape</code> is specified, then the result is padded and/or truncated to the specified shape.</p> <h4 id="examples_4" data-text="Examples:">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])
print(rt.to_tensor())
tf.Tensor(
    [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32)
print(rt.to_tensor(shape=[5, 2]))
tf.Tensor(
    [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">default_value</code> </td> <td> Value to set for indices not specified in <code translate="no" dir="ltr">self</code>. Defaults to zero. <code translate="no" dir="ltr">default_value</code> must be broadcastable to <code translate="no" dir="ltr">self.shape[self.ragged_rank + 1:]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensors (optional). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> The shape of the resulting dense tensor. In particular, <code translate="no" dir="ltr">result.shape[i]</code> is <code translate="no" dir="ltr">shape[i]</code> (if <code translate="no" dir="ltr">shape[i]</code> is not None), or <code translate="no" dir="ltr">self.bounding_shape(i)</code> (otherwise).<code translate="no" dir="ltr">shape.rank</code> must be <code translate="no" dir="ltr">None</code> or equal to <code translate="no" dir="ltr">self.rank</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">ragged.bounding_shape(self)</code> and the values specified by the non-empty values in <code translate="no" dir="ltr">self</code>. Empty values are assigned <code translate="no" dir="ltr">default_value</code>. </td> </tr> 
</table> <h3 id="value_rowids" data-text="value_rowids"><code translate="no" dir="ltr">value_rowids</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1108-L1133">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
value_rowids(
    name=None
)
</pre> <p>Returns the row indices for the <code translate="no" dir="ltr">values</code> in this ragged tensor.</p> <p><code translate="no" dir="ltr">rt.value_rowids()</code> corresponds one-to-one with the outermost dimension of <code translate="no" dir="ltr">rt.values</code>, and specifies the row containing each value. In particular, the row <code translate="no" dir="ltr">rt[row]</code> consists of the values <code translate="no" dir="ltr">rt.values[j]</code> where <code translate="no" dir="ltr">rt.value_rowids()[j] == row</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name prefix for the returned tensor (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A 1-D integer <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">self.values.shape[:1]</code>. The returned tensor is nonnegative, and is sorted in ascending order. </td> </tr> 
</table> <h4 id="example_19" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(rt.values)
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)
print(rt.value_rowids())  # corresponds 1:1 with rt.values
tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64)
</pre> <h3 id="with_flat_values" data-text="with_flat_values"><code translate="no" dir="ltr">with_flat_values</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1411-L1431">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
with_flat_values(
    new_values
)
</pre> <p>Returns a copy of <code translate="no" dir="ltr">self</code> with <code translate="no" dir="ltr">flat_values</code> replaced by <code translate="no" dir="ltr">new_value</code>.</p> <p>Preserves cached row-partitioning tensors such as <code translate="no" dir="ltr">self.cached_nrows</code> and <code translate="no" dir="ltr">self.cached_value_rowids</code> if they have values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">new_values</code> </td> <td> Potentially ragged tensor that should replace <code translate="no" dir="ltr">self.flat_values</code>. Must have <code translate="no" dir="ltr">rank &gt; 0</code>, and must have the same number of rows as <code translate="no" dir="ltr">self.flat_values</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = self.ragged_rank + new_values.rank</code>. <code translate="no" dir="ltr">result.ragged_rank = self.ragged_rank + new_values.ragged_rank</code>. </td> </tr> 
</table> <h3 id="with_row_splits_dtype" data-text="with_row_splits_dtype"><code translate="no" dir="ltr">with_row_splits_dtype</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1433-L1462">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
with_row_splits_dtype(
    dtype
)
</pre> <p>Returns a copy of this RaggedTensor with the given <code translate="no" dir="ltr">row_splits</code> dtype.</p> <p>For RaggedTensors with multiple ragged dimensions, the <code translate="no" dir="ltr">row_splits</code> for all nested <code translate="no" dir="ltr">RaggedTensor</code> objects are cast to the given dtype.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> The dtype for <code translate="no" dir="ltr">row_splits</code>. One of <a href="../tf.html#int32"><code translate="no" dir="ltr">tf.int32</code></a> or <a href="../tf.html#int64"><code translate="no" dir="ltr">tf.int64</code></a>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A copy of this RaggedTensor, with the <code translate="no" dir="ltr">row_splits</code> cast to the given type. </td> </tr> 
</table> <h3 id="with_values" data-text="with_values"><code translate="no" dir="ltr">with_values</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1382-L1409">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
with_values(
    new_values
)
</pre> <p>Returns a copy of <code translate="no" dir="ltr">self</code> with <code translate="no" dir="ltr">values</code> replaced by <code translate="no" dir="ltr">new_value</code>.</p> <p>Preserves cached row-partitioning tensors such as <code translate="no" dir="ltr">self.cached_nrows</code> and <code translate="no" dir="ltr">self.cached_value_rowids</code> if they have values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">new_values</code> </td> <td> Potentially ragged tensor to use as the <code translate="no" dir="ltr">values</code> for the returned <code translate="no" dir="ltr">RaggedTensor</code>. Must have <code translate="no" dir="ltr">rank &gt; 0</code>, and must have the same number of rows as <code translate="no" dir="ltr">self.values</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = 1 + new_values.rank</code>. <code translate="no" dir="ltr">result.ragged_rank = 1 + new_values.ragged_rank</code> </td> </tr> 
</table> <h3 id="__abs__" data-text="__abs__"><code translate="no" dir="ltr">__abs__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L364-L408">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__abs__(
    name=None
)
</pre> <p>Computes the absolute value of a tensor.</p> <p>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> of complex numbers, this operation returns a tensor of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code> that is the absolute value of each element in <code translate="no" dir="ltr">x</code>. For a complex number \(a + bj\), its absolute value is computed as \(\sqrt{a^2 + b^2}\).</p> <h4 id="for_example" data-text="For example:">For example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# real number
x = tf.constant([-2.25, 3.25])
tf.abs(x)
&lt;tf.Tensor: shape=(2,), dtype=float32,
numpy=array([2.25, 3.25], dtype=float32)&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# complex number
x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)
&lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy=
array([[5.25594901],
       [6.60492241]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of the same size, type and sparsity as <code translate="no" dir="ltr">x</code>, with absolute values. Note, for <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code> input, the returned <code translate="no" dir="ltr">Tensor</code> will be of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code>, respectively. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__add__" data-text="__add__"><code translate="no" dir="ltr">__add__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L3925-L4003">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__add__(
    y, name=None
)
</pre> <p>Returns x + y element-wise.</p> <p>Example usages below.</p> <p>Add a scalar and a list:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = 1
tf.add(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],
dtype=int32)&gt;
</pre> <p>Note that binary <code translate="no" dir="ltr">+</code> operator can be used instead:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.convert_to_tensor([1, 2, 3, 4, 5])
y = tf.convert_to_tensor(1)
x + y
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],
dtype=int32)&gt;
</pre> <p>Add a tensor and a list of same shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = tf.constant([1, 2, 3, 4, 5])
tf.add(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 2,  4,  6,  8, 10], dtype=int32)&gt;
</pre> <aside class="warning"><strong>Warning:</strong><span> If one of the inputs (<code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>) is a tensor and the other is a non-tensor, the non-tensor input will adopt (or get casted to) the data type of the tensor input. This can potentially cause unwanted overflow or underflow conversion.</span></aside> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([1, 2], dtype=tf.int8)
y = [2**7 + 1, 2**7 + 2]
tf.add(x, y)
&lt;tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)&gt;
</pre> <p>When adding two input values of different shapes, <code translate="no" dir="ltr">Add</code> follows NumPy broadcasting rules. The two input array shapes are compared element-wise. Starting with the trailing dimensions, the two dimensions either have to be equal or one of them needs to be <code translate="no" dir="ltr">1</code>.</p> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(1, 2, 1, 3)
y = np.ones(6).reshape(2, 1, 3, 1)
tf.add(x, y).shape.as_list()
[2, 2, 3, 3]
</pre> <p>Another example with two arrays of different dimension.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones([1, 2, 1, 4])
y = np.ones([3, 4])
tf.add(x, y).shape.as_list()
[1, 2, 3, 4]
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_sum.html"><code translate="no" dir="ltr">tf.math.reduce_sum</code></a></p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>. Must be one of the following types: bfloat16, half, float32, float64, uint8, int8, int16, int32, int64, complex64, complex128, string. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>. Must have the same type as x. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional) </td> </tr> </table> <h3 id="__and__" data-text="__and__"><code translate="no" dir="ltr">__and__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__and__(
    y, name=None
)
</pre> <p>Returns the truth value of x AND y element-wise.</p> <p>Logical AND function.</p> <p>Requires that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have the same shape or have <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast-compatible</a> shapes. For example, <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> can be:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>.</li> <li>One <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</li> </ul> <p>You can also use the <code translate="no" dir="ltr">&amp;</code> operator instead.</p> <h4 id="usage" data-text="Usage:">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_and(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])&gt;
a &amp; b
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_and(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
c &amp; x
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_and(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])&gt;
y &amp; z
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])&gt;
</pre> <p>This op also supports broadcasting</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.logical_and([[True, False]], [[True], [False]])
&lt;tf.Tensor: shape=(2, 2), dtype=bool, numpy=
  array([[ True, False],
         [False, False]])&gt;
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_all.html"><code translate="no" dir="ltr">tf.math.reduce_all</code></a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the shape that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> broadcast to. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__bool__" data-text="__bool__"><code translate="no" dir="ltr">__bool__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_operators.py#L85-L87">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__bool__()
</pre> <p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p> <h3 id="__div__" data-text="__div__"><code translate="no" dir="ltr">__div__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1592-L1621">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__div__(
    y, name=None
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <p><section><devsite-expandable> <h4 class="showalways" id="migrate-to-tf2" data-text="Migrate to TF2">Migrate to TF2</h4></devsite-expandable></section></p> <p>This function is deprecated in TF2. Prefer using the Tensor division operator, <a href="math/divide.html"><code translate="no" dir="ltr">tf.divide</code></a>, or <a href="math/divide.html"><code translate="no" dir="ltr">tf.math.divide</code></a>, which obey the Python 3 division operator semantics.</p>  <h3 id="__eq__" data-text="__eq__"><code translate="no" dir="ltr">__eq__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1962-L1998">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__eq__(
    other
)
</pre> <p>The operation invoked by the <a href="raggedtensor.html#__eq__"><code translate="no" dir="ltr">Tensor.<strong>eq</strong></code></a> operator.</p> <p>Compares two tensors element-wise for equality if they are broadcast-compatible; or returns False if they are not broadcast-compatible. (Note that this behavior differs from <a href="math/equal.html"><code translate="no" dir="ltr">tf.math.equal</code></a>, which raises an exception if the two tensors are not broadcast-compatible.)</p> <h4 id="purpose_in_the_api" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="raggedtensor.html#__eq__"><code translate="no" dir="ltr">Tensor.<strong>eq</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">self</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">==</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">other</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">==</code> operator. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">==</code> operation, or <code translate="no" dir="ltr">False</code> if the arguments are not broadcast-compatible. </td> </tr> 
</table> <h3 id="__floordiv__" data-text="__floordiv__"><code translate="no" dir="ltr">__floordiv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1691-L1718">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__floordiv__(
    y, name=None
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>Mathematically, this is equivalent to floor(x / y). For example: floor(8.4 / 4.0) = floor(2.1) = 2.0 floor(-8.4 / 4.0) = floor(-2.1) = -3.0 This is equivalent to the '//' operator in Python 3.0 and above.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded toward -infinity. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__ge__" data-text="__ge__"><code translate="no" dir="ltr">__ge__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ge__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &gt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater_equal.html"><code translate="no" dir="ltr">math.greater_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_20" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6, 7])
y = tf.constant([5, 2, 5, 10])
tf.math.greater_equal(x, y) ==&gt; [True, True, True, False]

x = tf.constant([5, 4, 6, 7])
y = tf.constant([5])
tf.math.greater_equal(x, y) ==&gt; [True, False, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__getitem__" data-text="__getitem__"><code translate="no" dir="ltr">__getitem__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_getitem.py#L33-L105">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__getitem__(
    key
)
</pre> <p>Returns the specified piece of this RaggedTensor.</p> <p>Supports multidimensional indexing and slicing, with one restriction: indexing into a ragged inner dimension is not allowed. This case is problematic because the indicated value may exist in some rows but not others. In such cases, it's not obvious whether we should (1) report an IndexError; (2) use a default value; or (3) skip that value and return a tensor with fewer rows than we started with. Following the guiding principles of Python ("In the face of ambiguity, refuse the temptation to guess"), we simply disallow this operation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">rt_input</code> </td> <td> The RaggedTensor to slice. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">key</code> </td> <td> Indicates which piece of the RaggedTensor to return, using standard Python semantics (e.g., negative values index from the end). <code translate="no" dir="ltr">key</code> may have any of the following types: <ul> <li>
<code translate="no" dir="ltr">int</code> constant</li> <li>Scalar integer <code translate="no" dir="ltr">Tensor</code>
</li> <li><p><code translate="no" dir="ltr">slice</code> containing integer constants and/or scalar integer <code translate="no" dir="ltr">Tensor</code>s</p></li> <li><p><code translate="no" dir="ltr">Ellipsis</code></p></li> <li><p><a href="../tf.html#newaxis"><code translate="no" dir="ltr">tf.newaxis</code></a></p></li> <li><p><code translate="no" dir="ltr">tuple</code> containing any of the above (for multidimensional indexing) </p></li>
</ul>
</td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">RaggedTensor</code> object. Values that include at least one ragged dimension are returned as <code translate="no" dir="ltr">RaggedTensor</code>. Values that include no ragged dimensions are returned as <code translate="no" dir="ltr">Tensor</code>. See above for examples of expressions that return <code translate="no" dir="ltr">Tensor</code>s vs <code translate="no" dir="ltr">RaggedTensor</code>s. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">key</code> is out of bounds. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">key</code> is not supported. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the indices in <code translate="no" dir="ltr">key</code> have an unsupported type. </td> </tr> </table> <h4 id="examples_5" data-text="Examples:">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# A 2-D ragged tensor with 1 ragged dimension.
rt = tf.ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']])
rt[0].numpy()                 # First row (1-D `Tensor`)
array([b'a', b'b', b'c'], dtype=object)
rt[:3].to_list()              # First three rows (2-D RaggedTensor)
[[b'a', b'b', b'c'], [b'd', b'e'], [b'f']]
rt[3, 0].numpy()              # 1st element of 4th row (scalar)
b'g'
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# A 3-D ragged tensor with 2 ragged dimensions.
rt = tf.ragged.constant([[[1, 2, 3], [4]],
                         [[5], [], [6]],
                         [[7]],
                         [[8, 9], [10]]])
rt[1].to_list()               # Second row (2-D RaggedTensor)
[[5], [], [6]]
rt[3, 0].numpy()              # First element of fourth row (1-D Tensor)
array([8, 9], dtype=int32)
rt[:, 1:3].to_list()          # Items 1-3 of each row (3-D RaggedTensor)
[[[4]], [[], [6]], [], [[10]]]
rt[:, -1:].to_list()          # Last item of each row (3-D RaggedTensor)
[[[4]], [[6]], [[7]], [[10]]]
</pre> <h3 id="__gt__" data-text="__gt__"><code translate="no" dir="ltr">__gt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__gt__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &gt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater.html"><code translate="no" dir="ltr">math.greater</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_21" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5, 2, 5])
tf.math.greater(x, y) ==&gt; [False, True, True]

x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.greater(x, y) ==&gt; [False, False, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__invert__" data-text="__invert__"><code translate="no" dir="ltr">__invert__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__invert__(
    name=None
)
</pre> <p>Returns the truth value of <code translate="no" dir="ltr">NOT x</code> element-wise.</p> <h4 id="example_22" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.math.logical_not(tf.constant([True, False]))
&lt;tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__le__" data-text="__le__"><code translate="no" dir="ltr">__le__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__le__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &lt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less_equal.html"><code translate="no" dir="ltr">math.less_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_23" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less_equal(x, y) ==&gt; [True, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 6])
tf.math.less_equal(x, y) ==&gt; [True, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__lt__" data-text="__lt__"><code translate="no" dir="ltr">__lt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__lt__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &lt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less.html"><code translate="no" dir="ltr">math.less</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_24" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less(x, y) ==&gt; [False, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 7])
tf.math.less(x, y) ==&gt; [False, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__mod__" data-text="__mod__"><code translate="no" dir="ltr">__mod__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mod__(
    y, name=None
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod.html"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__mul__" data-text="__mul__"><code translate="no" dir="ltr">__mul__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L480-L529">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mul__(
    y, name=None
)
</pre> <p>Returns an element-wise x * y.</p> <h4 id="for_example_2" data-text="For example:">For example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant(([1, 2, 3, 4]))
tf.math.multiply(x, x)
&lt;tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)&gt;
</pre> <p>Since <a href="math/multiply.html"><code translate="no" dir="ltr">tf.math.multiply</code></a> will convert its arguments to <code translate="no" dir="ltr">Tensor</code>s, you can also pass in non-<code translate="no" dir="ltr">Tensor</code> arguments:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.math.multiply(7,6)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=42&gt;
</pre> <p>If <code translate="no" dir="ltr">x.shape</code> is not the same as <code translate="no" dir="ltr">y.shape</code>, they will be broadcast to a compatible shape. (More about broadcasting <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a>.)</p> <h4 id="for_example_3" data-text="For example:">For example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.ones([1, 2]);
y = tf.ones([2, 1]);
x * y  # Taking advantage of operator overriding
&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[1., 1.],
     [1., 1.]], dtype=float32)&gt;
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_prod.html"><code translate="no" dir="ltr">tf.math.reduce_prod</code></a></p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A Tensor. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> 
</table> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <ul> <li>InvalidArgumentError: When <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have incompatible shapes or types. </li>
</ul>
</td> </tr> 
</table> <h3 id="__ne__" data-text="__ne__"><code translate="no" dir="ltr">__ne__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L2001-L2035">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ne__(
    other
)
</pre> <p>The operation invoked by the <a href="raggedtensor.html#__ne__"><code translate="no" dir="ltr">Tensor.<strong>ne</strong></code></a> operator.</p> <p>Compares two tensors element-wise for inequality if they are broadcast-compatible; or returns True if they are not broadcast-compatible. (Note that this behavior differs from <a href="math/not_equal.html"><code translate="no" dir="ltr">tf.math.not_equal</code></a>, which raises an exception if the two tensors are not broadcast-compatible.)</p> <h4 id="purpose_in_the_api_2" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="raggedtensor.html#__ne__"><code translate="no" dir="ltr">Tensor.<strong>ne</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">self</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">!=</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">other</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">!=</code> operator. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">!=</code> operation, or <code translate="no" dir="ltr">True</code> if the arguments are not broadcast-compatible. </td> </tr> 
</table> <h3 id="__neg__" data-text="__neg__"><code translate="no" dir="ltr">__neg__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__neg__(
    name=None
)
</pre> <p>Computes numerical negative value element-wise.</p> <p>I.e., \(y = -x\).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__nonzero__" data-text="__nonzero__"><code translate="no" dir="ltr">__nonzero__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/ragged/ragged_operators.py#L85-L87">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__nonzero__()
</pre> <p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p> <h3 id="__or__" data-text="__or__"><code translate="no" dir="ltr">__or__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__or__(
    y, name=None
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <p>Logical OR function.</p> <p>Requires that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have the same shape or have <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast-compatible</a> shapes. For example, <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> can be:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>.</li> <li>One <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical OR with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical OR of the two input tensors.</li> </ul> <p>You can also use the <code translate="no" dir="ltr">|</code> operator instead.</p> <h4 id="usage_2" data-text="Usage:">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_or(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
a | b
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([False])
x = tf.constant([False, True, True, False])
tf.math.logical_or(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])&gt;
c | x
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_or(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])&gt;
y | z
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])&gt;
</pre> <p>This op also supports broadcasting</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.logical_or([[True, False]], [[True], [False]])
&lt;tf.Tensor: shape=(2, 2), dtype=bool, numpy=
array([[ True,  True],
     [ True, False]])&gt;
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_any.html"><code translate="no" dir="ltr">tf.math.reduce_any</code></a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the shape that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> broadcast to. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__pow__" data-text="__pow__"><code translate="no" dir="ltr">__pow__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L668-L694">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__pow__(
    y, name=None
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__radd__" data-text="__radd__"><code translate="no" dir="ltr">__radd__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L3925-L4003">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__radd__(
    y, name=None
)
</pre> <p>Returns x + y element-wise.</p> <p>Example usages below.</p> <p>Add a scalar and a list:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = 1
tf.add(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],
dtype=int32)&gt;
</pre> <p>Note that binary <code translate="no" dir="ltr">+</code> operator can be used instead:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.convert_to_tensor([1, 2, 3, 4, 5])
y = tf.convert_to_tensor(1)
x + y
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],
dtype=int32)&gt;
</pre> <p>Add a tensor and a list of same shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = tf.constant([1, 2, 3, 4, 5])
tf.add(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 2,  4,  6,  8, 10], dtype=int32)&gt;
</pre> <aside class="warning"><strong>Warning:</strong><span> If one of the inputs (<code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>) is a tensor and the other is a non-tensor, the non-tensor input will adopt (or get casted to) the data type of the tensor input. This can potentially cause unwanted overflow or underflow conversion.</span></aside> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([1, 2], dtype=tf.int8)
y = [2**7 + 1, 2**7 + 2]
tf.add(x, y)
&lt;tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)&gt;
</pre> <p>When adding two input values of different shapes, <code translate="no" dir="ltr">Add</code> follows NumPy broadcasting rules. The two input array shapes are compared element-wise. Starting with the trailing dimensions, the two dimensions either have to be equal or one of them needs to be <code translate="no" dir="ltr">1</code>.</p> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(1, 2, 1, 3)
y = np.ones(6).reshape(2, 1, 3, 1)
tf.add(x, y).shape.as_list()
[2, 2, 3, 3]
</pre> <p>Another example with two arrays of different dimension.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones([1, 2, 1, 4])
y = np.ones([3, 4])
tf.add(x, y).shape.as_list()
[1, 2, 3, 4]
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_sum.html"><code translate="no" dir="ltr">tf.math.reduce_sum</code></a></p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>. Must be one of the following types: bfloat16, half, float32, float64, uint8, int8, int16, int32, int64, complex64, complex128, string. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>. Must have the same type as x. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional) </td> </tr> </table> <h3 id="__rand__" data-text="__rand__"><code translate="no" dir="ltr">__rand__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rand__(
    y, name=None
)
</pre> <p>Returns the truth value of x AND y element-wise.</p> <p>Logical AND function.</p> <p>Requires that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have the same shape or have <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast-compatible</a> shapes. For example, <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> can be:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>.</li> <li>One <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</li> </ul> <p>You can also use the <code translate="no" dir="ltr">&amp;</code> operator instead.</p> <h4 id="usage_3" data-text="Usage:">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_and(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])&gt;
a &amp; b
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_and(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
c &amp; x
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_and(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])&gt;
y &amp; z
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])&gt;
</pre> <p>This op also supports broadcasting</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.logical_and([[True, False]], [[True], [False]])
&lt;tf.Tensor: shape=(2, 2), dtype=bool, numpy=
  array([[ True, False],
         [False, False]])&gt;
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_all.html"><code translate="no" dir="ltr">tf.math.reduce_all</code></a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the shape that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> broadcast to. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__rdiv__" data-text="__rdiv__"><code translate="no" dir="ltr">__rdiv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1592-L1621">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rdiv__(
    y, name=None
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <p><section><devsite-expandable> <h4 class="showalways" id="migrate-to-tf2_1" data-text="Migrate to TF2">Migrate to TF2</h4></devsite-expandable></section></p> <p>This function is deprecated in TF2. Prefer using the Tensor division operator, <a href="math/divide.html"><code translate="no" dir="ltr">tf.divide</code></a>, or <a href="math/divide.html"><code translate="no" dir="ltr">tf.math.divide</code></a>, which obey the Python 3 division operator semantics.</p>  <h3 id="__rfloordiv__" data-text="__rfloordiv__"><code translate="no" dir="ltr">__rfloordiv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1691-L1718">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rfloordiv__(
    y, name=None
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>Mathematically, this is equivalent to floor(x / y). For example: floor(8.4 / 4.0) = floor(2.1) = 2.0 floor(-8.4 / 4.0) = floor(-2.1) = -3.0 This is equivalent to the '//' operator in Python 3.0 and above.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded toward -infinity. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__rmod__" data-text="__rmod__"><code translate="no" dir="ltr">__rmod__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmod__(
    y, name=None
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod.html"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rmul__" data-text="__rmul__"><code translate="no" dir="ltr">__rmul__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L480-L529">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmul__(
    y, name=None
)
</pre> <p>Returns an element-wise x * y.</p> <h4 id="for_example_4" data-text="For example:">For example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant(([1, 2, 3, 4]))
tf.math.multiply(x, x)
&lt;tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)&gt;
</pre> <p>Since <a href="math/multiply.html"><code translate="no" dir="ltr">tf.math.multiply</code></a> will convert its arguments to <code translate="no" dir="ltr">Tensor</code>s, you can also pass in non-<code translate="no" dir="ltr">Tensor</code> arguments:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.math.multiply(7,6)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=42&gt;
</pre> <p>If <code translate="no" dir="ltr">x.shape</code> is not the same as <code translate="no" dir="ltr">y.shape</code>, they will be broadcast to a compatible shape. (More about broadcasting <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a>.)</p> <h4 id="for_example_5" data-text="For example:">For example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.ones([1, 2]);
y = tf.ones([2, 1]);
x * y  # Taking advantage of operator overriding
&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[1., 1.],
     [1., 1.]], dtype=float32)&gt;
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_prod.html"><code translate="no" dir="ltr">tf.math.reduce_prod</code></a></p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A Tensor. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> 
</table> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <ul> <li>InvalidArgumentError: When <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have incompatible shapes or types. </li>
</ul>
</td> </tr> 
</table> <h3 id="__ror__" data-text="__ror__"><code translate="no" dir="ltr">__ror__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ror__(
    y, name=None
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <p>Logical OR function.</p> <p>Requires that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have the same shape or have <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast-compatible</a> shapes. For example, <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> can be:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>.</li> <li>One <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical OR with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical OR of the two input tensors.</li> </ul> <p>You can also use the <code translate="no" dir="ltr">|</code> operator instead.</p> <h4 id="usage_4" data-text="Usage:">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_or(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
a | b
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([False])
x = tf.constant([False, True, True, False])
tf.math.logical_or(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])&gt;
c | x
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_or(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])&gt;
y | z
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])&gt;
</pre> <p>This op also supports broadcasting</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.logical_or([[True, False]], [[True], [False]])
&lt;tf.Tensor: shape=(2, 2), dtype=bool, numpy=
array([[ True,  True],
     [ True, False]])&gt;
</pre> <p>The reduction version of this elementwise operation is <a href="math/reduce_any.html"><code translate="no" dir="ltr">tf.math.reduce_any</code></a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the shape that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> broadcast to. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__rpow__" data-text="__rpow__"><code translate="no" dir="ltr">__rpow__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L668-L694">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rpow__(
    y, name=None
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__rsub__" data-text="__rsub__"><code translate="no" dir="ltr">__rsub__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L544-L548">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rsub__(
    y, name=None
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <p>Both input and output have a range <code translate="no" dir="ltr">(-inf, inf)</code>.</p> <p>Example usages below.</p> <p>Subtract operation between an array and a scalar:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = 1
tf.subtract(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 0, -1, -2, -3, -4], dtype=int32)&gt;
</pre> <p>Note that binary <code translate="no" dir="ltr">-</code> operator can be used instead:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.convert_to_tensor([1, 2, 3, 4, 5])
y = tf.convert_to_tensor(1)
x - y
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
</pre> <p>Subtract operation between an array and a tensor of same shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = tf.constant([5, 4, 3, 2, 1])
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 4,  2,  0, -2, -4], dtype=int32)&gt;
</pre> <aside class="warning"><strong>Warning:</strong><span> If one of the inputs (<code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>) is a tensor and the other is a non-tensor, the non-tensor input will adopt (or get casted to) the data type of the tensor input. This can potentially cause unwanted overflow or underflow conversion.</span></aside> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([1, 2], dtype=tf.int8)
y = [2**8 + 1, 2**8 + 2]
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)&gt;
</pre> <p>When subtracting two input values of different shapes, <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> follows the <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules">general broadcasting rules</a> . The two input array shapes are compared element-wise. Starting with the trailing dimensions, the two dimensions either have to be equal or one of them needs to be <code translate="no" dir="ltr">1</code>.</p> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(2, 1, 3)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=
array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]],
       [[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]]])&gt;
</pre> <p>Example with inputs of different dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(1, 6)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=
array([[[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]],
       [[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rtruediv__" data-text="__rtruediv__"><code translate="no" dir="ltr">__rtruediv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1558-L1589">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rtruediv__(
    y, name=None
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</span>
</blockquote> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> evaluated in floating point. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes. </td> </tr> </table> <h3 id="__rxor__" data-text="__rxor__"><code translate="no" dir="ltr">__rxor__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1789-L1838">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rxor__(
    y, name='LogicalXor'
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>Requires that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have the same shape or have <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast-compatible</a> shapes. For example, <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> can be:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>
</li> <li>One <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</li> </ul> <h4 id="usage_5" data-text="Usage:">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_xor(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_xor(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_xor(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h3 id="__sub__" data-text="__sub__"><code translate="no" dir="ltr">__sub__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L544-L548">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__sub__(
    y, name=None
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <p>Both input and output have a range <code translate="no" dir="ltr">(-inf, inf)</code>.</p> <p>Example usages below.</p> <p>Subtract operation between an array and a scalar:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = 1
tf.subtract(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 0, -1, -2, -3, -4], dtype=int32)&gt;
</pre> <p>Note that binary <code translate="no" dir="ltr">-</code> operator can be used instead:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.convert_to_tensor([1, 2, 3, 4, 5])
y = tf.convert_to_tensor(1)
x - y
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
</pre> <p>Subtract operation between an array and a tensor of same shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = tf.constant([5, 4, 3, 2, 1])
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 4,  2,  0, -2, -4], dtype=int32)&gt;
</pre> <aside class="warning"><strong>Warning:</strong><span> If one of the inputs (<code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>) is a tensor and the other is a non-tensor, the non-tensor input will adopt (or get casted to) the data type of the tensor input. This can potentially cause unwanted overflow or underflow conversion.</span></aside> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([1, 2], dtype=tf.int8)
y = [2**8 + 1, 2**8 + 2]
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)&gt;
</pre> <p>When subtracting two input values of different shapes, <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> follows the <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules">general broadcasting rules</a> . The two input array shapes are compared element-wise. Starting with the trailing dimensions, the two dimensions either have to be equal or one of them needs to be <code translate="no" dir="ltr">1</code>.</p> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(2, 1, 3)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=
array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]],
       [[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]]])&gt;
</pre> <p>Example with inputs of different dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(1, 6)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=
array([[[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]],
       [[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__truediv__" data-text="__truediv__"><code translate="no" dir="ltr">__truediv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1558-L1589">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__truediv__(
    y, name=None
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</span>
</blockquote> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> evaluated in floating point. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes. </td> </tr> </table> <h3 id="__xor__" data-text="__xor__"><code translate="no" dir="ltr">__xor__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1789-L1838">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__xor__(
    y, name='LogicalXor'
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>Requires that <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have the same shape or have <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast-compatible</a> shapes. For example, <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> can be:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>
</li> <li>One <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</li> </ul> <h4 id="usage_6" data-text="Usage:">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_xor(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_xor(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_xor(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the same size as that of x or y. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/RaggedTensor" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/RaggedTensor</a>
  </p>
</div>
