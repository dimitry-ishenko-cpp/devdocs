<h1 class="devsite-page-title">tf.experimental.dtensor.relayout</h1> <devsite-bookmark></devsite-bookmark>       <p>Changes the layout of <code translate="no" dir="ltr">tensor</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.experimental.dtensor.relayout(
    tensor: tf.Tensor,
    layout: tf.experimental.dtensor.Layout
) -&gt; tf.Tensor
</pre>  <p>Changes the layout of <code translate="no" dir="ltr">tensor</code> to <code translate="no" dir="ltr">layout</code>. This is used to fine-tune the behavior of ops following/connected to <code translate="no" dir="ltr">tensor</code>, such as choosing one SPMD expansion pattern over another. This works by forward propagating <code translate="no" dir="ltr">layout</code> to connected TensorFlow computation graphs during layout propagation.</p> <p>Currently, only converting layouts from replicated to sharded or sharded to replicated per mesh dimension is supported. That is, "x, y" -&gt; "unsharded, y" is supported, while "x, y" -&gt; "z, y" is not supported.</p> <p>We also support a special "match" sharding spec, which instructs the relayout to act as an identity operation with respect to any sharding on these mesh dimensions.</p> <p>Relayout is internally lowered to a set of Split and/or AllToAll ops. When tensor layouts are converted from replicated to sharded, the cost is comparatively low because we only insert Split ops and no cross-device communication is needed. However, when tensor layouts are converted from sharded to replicated, cross-device communication may occur, causing potential performance impact.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor</code> </td> <td> A DTensor to specify a new layout for. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">layout</code> </td> <td> A Layout object specifying a new sharding spec. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A DTensor output from the Relayout op. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/experimental/dtensor/relayout" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/experimental/dtensor/relayout</a>
  </p>
</div>
