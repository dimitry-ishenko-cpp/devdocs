<h1 class="devsite-page-title">tf.experimental.dtensor.DTensorCheckpoint</h1> <devsite-bookmark></devsite-bookmark>       <p>Manages saving/restoring trackable values to disk, for DTensor.</p> <p>Inherits From: <a href="../../train/checkpoint.html"><code translate="no" dir="ltr">Checkpoint</code></a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.experimental.dtensor.DTensorCheckpoint(
    mesh: tf.experimental.dtensor.Mesh,
    root=None,
    **kwargs
)
</pre>   
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">root</code> </td> <td> The root object to checkpoint. <code translate="no" dir="ltr">root</code> may be a trackable object or <code translate="no" dir="ltr">WeakRef</code> of a trackable object. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Keyword arguments are set as attributes of this object, and are saved with the checkpoint. All <code translate="no" dir="ltr">kwargs</code> must be trackable objects, or a nested structure of trackable objects (<code translate="no" dir="ltr">list</code>, <code translate="no" dir="ltr">dict</code>, or <code translate="no" dir="ltr">tuple</code>). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">root</code> or the objects in <code translate="no" dir="ltr">kwargs</code> are not trackable. A <code translate="no" dir="ltr">ValueError</code> is also raised if the <code translate="no" dir="ltr">root</code> object tracks different objects from the ones listed in attributes in kwargs (e.g. <code translate="no" dir="ltr">root.child = A</code> and <a href="../../train/checkpoint.html"><code translate="no" dir="ltr">tf.train.Checkpoint(root, child=B)</code></a> are incompatible). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">save_counter</code> </td> <td> An integer variable which starts at zero and is incremented on save. <p>Used to number checkpoints. </p>
</td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="read" data-text="read"><code translate="no" dir="ltr">read</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/tracking/util.py#L2376-L2421">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
read(
    save_path, options=None
)
</pre> <p>Reads a training checkpoint written with <code translate="no" dir="ltr">write</code>.</p> <p>Reads this <code translate="no" dir="ltr">Checkpoint</code> and any objects it depends on.</p> <p>This method is just like <code translate="no" dir="ltr">restore()</code> but does not expect the <code translate="no" dir="ltr">save_counter</code> variable in the checkpoint. It only restores the objects that the checkpoint already depends on.</p> <p>The method is primarily intended for use by higher level checkpoint management utilities that use <code translate="no" dir="ltr">write()</code> instead of <code translate="no" dir="ltr">save()</code> and have their own mechanisms to number and track checkpoints.</p> <h4 id="example_usage" data-text="Example usage:">Example usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Create a checkpoint with write()
ckpt = tf.train.Checkpoint(v=tf.Variable(1.))
path = ckpt.write('/tmp/my_checkpoint')

# Later, load the checkpoint with read()
# With restore() assert_consumed() would have failed.
checkpoint.read(path).assert_consumed()

# You can also pass options to read(). For example this
# runs the IO ops on the localhost:
options = tf.train.CheckpointOptions(
    experimental_io_device="/job:localhost")
checkpoint.read(path, options=options)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">save_path</code> </td> <td> The path to the checkpoint as returned by <code translate="no" dir="ltr">write</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">options</code> </td> <td> Optional <a href="../../train/checkpointoptions.html"><code translate="no" dir="ltr">tf.train.CheckpointOptions</code></a> object. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A load status object, which can be used to make assertions about the status of a checkpoint restoration. See <code translate="no" dir="ltr">restore</code> for details. </td> </tr> 
</table> <h3 id="restore" data-text="restore"><code translate="no" dir="ltr">restore</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/tracking/util.py#L2423-L2553">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
restore(
    save_path, options=None
)
</pre> <p>Restores a training checkpoint.</p> <p>Restores this <code translate="no" dir="ltr">Checkpoint</code> and any objects it depends on.</p> <p>This method is intended to be used to load checkpoints created by <code translate="no" dir="ltr">save()</code>. For checkpoints created by <code translate="no" dir="ltr">write()</code> use the <code translate="no" dir="ltr">read()</code> method which does not expect the <code translate="no" dir="ltr">save_counter</code> variable added by <code translate="no" dir="ltr">save()</code>.</p> <p><code translate="no" dir="ltr">restore()</code> either assigns values immediately if variables to restore have been created already, or defers restoration until the variables are created. Dependencies added after this call will be matched if they have a corresponding object in the checkpoint (the restore request will queue in any trackable object waiting for the expected dependency to be added).</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">checkpoint = tf.train.Checkpoint( ... )
checkpoint.restore(path)

# You can additionally pass options to restore():
options = tf.CheckpointOptions(experimental_io_device="/job:localhost")
checkpoint.restore(path, options=options)
</pre> <p>To ensure that loading is complete and no more deferred restorations will take place, use the <code translate="no" dir="ltr">assert_consumed()</code> method of the status object returned by <code translate="no" dir="ltr">restore()</code>:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">checkpoint.restore(path, options=options).assert_consumed()
</pre> <p>The assert will raise an error if any Python objects in the dependency graph were not found in the checkpoint, or if any checkpointed values do not have a matching Python object.</p> <p>Name-based <a href="../../compat/v1/train/saver.html"><code translate="no" dir="ltr">tf.compat.v1.train.Saver</code></a> checkpoints from TensorFlow 1.x can be loaded using this method. Names are used to match variables. Re-encode name-based checkpoints using <a href="../../train/checkpoint.html#save"><code translate="no" dir="ltr">tf.train.Checkpoint.save</code></a> as soon as possible.</p> <p><strong>Loading from SavedModel checkpoints</strong></p> <p>To load values from a SavedModel, just pass the SavedModel directory to checkpoint.restore:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">model = tf.keras.Model(...)
tf.saved_model.save(model, path)  # or model.save(path, save_format='tf')

checkpoint = tf.train.Checkpoint(model)
checkpoint.restore(path).expect_partial()
</pre> <p>This example calls <code translate="no" dir="ltr">expect_partial()</code> on the loaded status, since SavedModels saved from Keras often generates extra keys in the checkpoint. Otherwise, the program prints a lot of warnings about unused keys at exit time.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">save_path</code> </td> <td> The path to the checkpoint, as returned by <code translate="no" dir="ltr">save</code> or <a href="../../train/latest_checkpoint.html"><code translate="no" dir="ltr">tf.train.latest_checkpoint</code></a>. If the checkpoint was written by the name-based <a href="../../compat/v1/train/saver.html"><code translate="no" dir="ltr">tf.compat.v1.train.Saver</code></a>, names are used to match variables. This path may also be a SavedModel directory. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">options</code> </td> <td> Optional <a href="../../train/checkpointoptions.html"><code translate="no" dir="ltr">tf.train.CheckpointOptions</code></a> object. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A load status object, which can be used to make assertions about the status of a checkpoint restoration. <p>The returned status object has the following methods:</p> <ul> <li><p><code translate="no" dir="ltr">assert_consumed()</code>: Raises an exception if any variables are unmatched: either checkpointed values which don't have a matching Python object or Python objects in the dependency graph with no values in the checkpoint. This method returns the status object, and so may be chained with other assertions.</p></li> <li><p><code translate="no" dir="ltr">assert_existing_objects_matched()</code>: Raises an exception if any existing Python objects in the dependency graph are unmatched. Unlike <code translate="no" dir="ltr">assert_consumed</code>, this assertion will pass if values in the checkpoint have no corresponding Python objects. For example a <code translate="no" dir="ltr">tf.keras.Layer</code> object which has not yet been built, and so has not created any variables, will pass this assertion but fail <code translate="no" dir="ltr">assert_consumed</code>. Useful when loading part of a larger checkpoint into a new Python program, e.g. a training checkpoint with a <a href="../../compat/v1/train/optimizer.html"><code translate="no" dir="ltr">tf.compat.v1.train.Optimizer</code></a> was saved but only the state required for inference is being loaded. This method returns the status object, and so may be chained with other assertions.</p></li> <li><p><code translate="no" dir="ltr">assert_nontrivial_match()</code>: Asserts that something aside from the root object was matched. This is a very weak assertion, but is useful for sanity checking in library code where objects may exist in the checkpoint which haven't been created in Python and some Python objects may not have a checkpointed value.</p></li> <li><p><code translate="no" dir="ltr">expect_partial()</code>: Silence warnings about incomplete checkpoint restores. Warnings are otherwise printed for unused parts of the checkpoint file or object when the <code translate="no" dir="ltr">Checkpoint</code> object is deleted (often at program shutdown). </p></li>
</ul>
</td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">NotFoundError</code> </td> <td> if the a checkpoint or SavedModel cannot be found at <code translate="no" dir="ltr">save_path</code>. </td> </tr> </table> <h3 id="save" data-text="save"><code translate="no" dir="ltr">save</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/tracking/util.py#L2276-L2374">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
save(
    file_prefix, options=None
)
</pre> <p>Saves a training checkpoint and provides basic checkpoint management.</p> <p>The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time <a href="../../train/checkpoint.html#save"><code translate="no" dir="ltr">Checkpoint.save()</code></a> is called.</p> <p><code translate="no" dir="ltr">save</code> is a basic convenience wrapper around the <code translate="no" dir="ltr">write</code> method, sequentially numbering checkpoints using <code translate="no" dir="ltr">save_counter</code> and updating the metadata used by <a href="../../train/latest_checkpoint.html"><code translate="no" dir="ltr">tf.train.latest_checkpoint</code></a>. More advanced checkpoint management, for example garbage collection and custom numbering, may be provided by other utilities which also wrap <code translate="no" dir="ltr">write</code> and <code translate="no" dir="ltr">read</code>. (<a href="../../train/checkpointmanager.html"><code translate="no" dir="ltr">tf.train.CheckpointManager</code></a> for example).</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">step = tf.Variable(0, name="step")
checkpoint = tf.train.Checkpoint(step=step)
checkpoint.save("/tmp/ckpt")

# Later, read the checkpoint with restore()
checkpoint.restore("/tmp/ckpt-1")

# You can also pass options to save() and restore(). For example this
# runs the IO ops on the localhost:
options = tf.train.CheckpointOptions(experimental_io_device="/job:localhost")
checkpoint.save("/tmp/ckpt", options=options)

# Later, read the checkpoint with restore()
checkpoint.restore("/tmp/ckpt-1", options=options)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">file_prefix</code> </td> <td> A prefix to use for the checkpoint filenames (/path/to/directory/and_a_prefix). Names are generated based on this prefix and <a href="../../train/checkpoint.html#save_counter"><code translate="no" dir="ltr">Checkpoint.save_counter</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">options</code> </td> <td> Optional <a href="../../train/checkpointoptions.html"><code translate="no" dir="ltr">tf.train.CheckpointOptions</code></a> object. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The full path to the checkpoint. </td> </tr> 
</table> <h3 id="write" data-text="write"><code translate="no" dir="ltr">write</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/tracking/util.py#L2176-L2217">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
write(
    file_prefix, options=None
)
</pre> <p>Writes a training checkpoint.</p> <p>The checkpoint includes variables created by this object and any trackable objects it depends on at the time <a href="../../train/checkpoint.html#write"><code translate="no" dir="ltr">Checkpoint.write()</code></a> is called.</p> <p><code translate="no" dir="ltr">write</code> does not number checkpoints, increment <code translate="no" dir="ltr">save_counter</code>, or update the metadata used by <a href="../../train/latest_checkpoint.html"><code translate="no" dir="ltr">tf.train.latest_checkpoint</code></a>. It is primarily intended for use by higher level checkpoint management utilities. <code translate="no" dir="ltr">save</code> provides a very basic implementation of these features.</p> <p>Checkpoints written with <code translate="no" dir="ltr">write</code> must be read with <code translate="no" dir="ltr">read</code>.</p> <h4 id="example_usage_2" data-text="Example usage:">Example usage:</h4> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">step = tf.Variable(0, name="step")
checkpoint = tf.Checkpoint(step=step)
checkpoint.write("/tmp/ckpt")

# Later, read the checkpoint with read()
checkpoint.read("/tmp/ckpt")

# You can also pass options to write() and read(). For example this
# runs the IO ops on the localhost:
options = tf.CheckpointOptions(experimental_io_device="/job:localhost")
checkpoint.write("/tmp/ckpt", options=options)

# Later, read the checkpoint with read()
checkpoint.read("/tmp/ckpt", options=options)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">file_prefix</code> </td> <td> A prefix to use for the checkpoint filenames (/path/to/directory/and_a_prefix). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">options</code> </td> <td> Optional <a href="../../train/checkpointoptions.html"><code translate="no" dir="ltr">tf.train.CheckpointOptions</code></a> object. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The full path to the checkpoint (i.e. <code translate="no" dir="ltr">file_prefix</code>). </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/experimental/dtensor/DTensorCheckpoint" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/experimental/dtensor/DTensorCheckpoint</a>
  </p>
</div>
