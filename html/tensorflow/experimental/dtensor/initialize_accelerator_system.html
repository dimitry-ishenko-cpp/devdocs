<h1 class="devsite-page-title" tabindex="-1"> tf.experimental.dtensor.initialize_accelerator_system </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.experimental.dtensor.initialize_accelerator_system"> <meta itemprop="path" content="Stable"> </div>   <p>Initializes accelerators and communication fabrics for DTensor.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="initialize_accelerator_system.html"><code translate="no" dir="ltr">tf.experimental.dtensor.initialize_multi_client</code></a>, <a href="initialize_accelerator_system.html"><code translate="no" dir="ltr">tf.experimental.dtensor.initialize_tpu_system</code></a></p> </section> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.experimental.dtensor.initialize_accelerator_system(
    device_type: Optional[str] = None,
    enable_coordination_service: Optional[bool] = True,
    num_logical_cpu_devices: Optional[int] = None,
    experimental_reset_context: Optional[bool] = False,
    experimental_enable_megcore: Optional[bool] = False
) -&gt; str
</pre></devsite-code>  <p>DTensor configures TensorFlow to run in the local mode or multi-client mode.</p> <ul> <li>In local mode, a mesh can only use devices attached to the current process.</li> <li>In multi-client mode, a mesh can span across devices from multiple clients.</li> </ul> <p>If <code translate="no" dir="ltr">DTENSOR_JOBS</code> is non-empty, DTensor configures TensorFlow to run in the multi-client mode using the distributed runtime. In multi-client mode devices on different clients can communicate with each other.</p> <p>The following environment variables controls the behavior of this function.</p> <ul> <li>
<code translate="no" dir="ltr">DTENSOR_JOBS</code>: string, a comma separated list. Each item in the list is of format <code translate="no" dir="ltr">{hostname}:{port}</code>. If empty, DTensor runs in the local mode. Examples of valid <code translate="no" dir="ltr">DTENSOR_JOBS</code> values: <ul> <li>4 clients on localhost: <code translate="no" dir="ltr">localhost:10000,localhost:10001,localhost:10002,localhost:10003</code>
</li> <li>2 clients on host1, 2 clients on host2 <code translate="no" dir="ltr">host1:10000,host1:10001,host2:10000,host2:10003</code> If the hostnames are BNS addresses, the items must be sorted in alphabetical order.</li> </ul>
</li> <li>
<code translate="no" dir="ltr">DTENSOR_CLIENT_ID</code>: integer, between <code translate="no" dir="ltr">0</code> to <code translate="no" dir="ltr">num_clients - 1</code>, to identify the client id of the current process. The default value is <code translate="no" dir="ltr">0</code>.</li> <li>
<code translate="no" dir="ltr">DTENSOR_JOB_NAME</code>: string, a string for the name of the TensorFlow job. The job name controls the job name section of the TensorFlow DeviceSpecs, e.g., <code translate="no" dir="ltr">job:worker</code> in <code translate="no" dir="ltr">/job:worker/replica:0/task:0/device:TPU:0</code> when the job name is <code translate="no" dir="ltr">worker</code>. The default value is <code translate="no" dir="ltr">localhost</code> in local mode, and <code translate="no" dir="ltr">worker</code> when in the multi-client mode. All DTensor clients within the same multi-client cluster share the same job name.</li> <li>
<code translate="no" dir="ltr">DTENSOR_USE_PARALLEL_EXECUTOR</code>: string, with its value being <code translate="no" dir="ltr">pw</code> to specify that the backend is Pathways, and TensorFlow otherwise.</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">device_type</code> </td> <td> Type of accelerator to use, can be CPU, GPU, or TPU. If None, uses <a href="preferred_device_type.html"><code translate="no" dir="ltr">tf.experimental.dtensor.preferred_device_type()</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">enable_coordination_service</code> </td> <td> If true, enable distributed coordination service to make sure that workers know the devices on each other, when there is more than 1 client. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_logical_cpu_devices</code> </td> <td> the number of logical CPU devices per DTensor client. Default to the current number of logical CPU (<code translate="no" dir="ltr">dtensor.num_local_devices("CPU")</code>),when <code translate="no" dir="ltr">device_type</code> is CPU, otherwise set automatially to match the number of local GPU/TPU devices. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_reset_context</code> </td> <td> Reset the tensorflow context. Behaviors of existing TensorFlow objects (e.g. Tensors) are undefined. Set this to True as an escape hatch, if there is no clear way to refactor your code to call initialize_accelerator_system() before calling TensorFlow APIs that initialize the context. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_enable_megcore</code> </td> <td> Optionally enable megcore in backend. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> 
<tr> <td> <code translate="no" dir="ltr">device_type</code> </td> <td> the type of accelerator that was initialized. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/experimental/dtensor/initialize_accelerator_system" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/experimental/dtensor/initialize_accelerator_system</a>
  </p>
</div>
