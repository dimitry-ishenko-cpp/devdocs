<h1 class="devsite-page-title">tf.Tensor</h1> <devsite-bookmark></devsite-bookmark>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>   <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L293-L1044">  View source on GitHub </a> </td> </table> <p>A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> represents a multidimensional array of elements.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"><code translate="no" dir="ltr">tf.experimental.numpy.ndarray</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"><code translate="no" dir="ltr">tf.compat.v1.Tensor</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.Tensor(
    op, value_index, dtype
)
</pre>  <p>All elements are of a single known data type.</p> <p>When writing a TensorFlow program, the main object that is manipulated and passed around is the <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>.</p> <p>A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> has the following properties:</p> <ul> <li>a single data type (float32, int32, or string, for example)</li> <li>a shape</li> </ul> <p>TensorFlow supports eager execution and graph execution. In eager execution, operations are evaluated immediately. In graph execution, a computational graph is constructed for later evaluation.</p> <p>TensorFlow defaults to eager execution. In the example below, the matrix multiplication results are calculated immediately.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# Compute some values using a Tensor
c = tf.constant([[1.0, 2.0], [3.0, 4.0]])
d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
e = tf.matmul(c, d)
print(e)
tf.Tensor(
[[1. 3.]
 [3. 7.]], shape=(2, 2), dtype=float32)
</pre> <p>Note that during eager execution, you may discover your <code translate="no" dir="ltr">Tensors</code> are actually of type <code translate="no" dir="ltr">EagerTensor</code>. This is an internal detail, but it does give you access to a useful function, <code translate="no" dir="ltr">numpy</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
type(e)
&lt;class '...ops.EagerTensor'&gt;
print(e.numpy())
  [[1. 3.]
   [3. 7.]]
</pre> <p>In TensorFlow, <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a>s are a common way to define graph execution.</p> <p>A Tensor's shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known. In <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a> definitions, the shape may only be partially known.</p> <p>Most operations produce tensors of fully-known shapes if the shapes of their inputs are also fully known, but in some cases it's only possible to find the shape of a tensor at execution time.</p> <p>A number of specialized tensors are available: see <a href="variable.html"><code translate="no" dir="ltr">tf.Variable</code></a>, <a href="constant.html"><code translate="no" dir="ltr">tf.constant</code></a>, <code translate="no" dir="ltr">tf.placeholder</code>, <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a>, and <a href="raggedtensor.html"><code translate="no" dir="ltr">tf.RaggedTensor</code></a>.</p> <aside class="caution"><strong>Caution:</strong><span> when constructing a tensor from a numpy array or pandas dataframe the underlying buffer may be re-used:</span></aside><pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">a = np.array([1, 2, 3])
b = tf.constant(a)
a[0] = 4
print(b)  # tf.Tensor([4 2 3], shape=(3,), dtype=int64)
</pre>
<blockquote class="note">
<strong>Note:</strong><span> this is an implementation detail that is subject to change and users should not rely on this behaviour.</span>
</blockquote> <p>For more on Tensors, see the <a href="https://tensorflow.org/guide/tensor">guide</a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">op</code> </td> <td> An <code translate="no" dir="ltr">Operation</code>. <code translate="no" dir="ltr">Operation</code> that computes this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_index</code> </td> <td> An <code translate="no" dir="ltr">int</code>. Index of the operation's endpoint that produces this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> A <code translate="no" dir="ltr">DType</code>. Type of elements stored in this tensor. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the op is not an <code translate="no" dir="ltr">Operation</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">device</code> </td> <td> The name of the device on which this tensor will be produced, or None. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> The <code translate="no" dir="ltr">DType</code> of elements in this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">graph</code> </td> <td> The <code translate="no" dir="ltr">Graph</code> that contains this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> The string name of this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">op</code> </td> <td> The <code translate="no" dir="ltr">Operation</code> that produces this tensor as an output. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> Returns a <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> that represents the shape of this tensor. <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.constant([1,2,3,4,5])
t.shape
TensorShape([5])
</pre> <p><a href="tensor.html#shape"><code translate="no" dir="ltr">tf.Tensor.shape</code></a> is equivalent to <a href="tensor.html#get_shape"><code translate="no" dir="ltr">tf.Tensor.get_shape()</code></a>.</p> <p>In a <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a> or when building a model using <a href="keras/input.html"><code translate="no" dir="ltr">tf.keras.Input</code></a>, they return the build-time shape of the tensor, which may be partially unknown.</p> <p>A <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> is not a tensor. Use <a href="shape.html"><code translate="no" dir="ltr">tf.shape(t)</code></a> to get a tensor containing the shape, calculated at runtime.</p> <p>See <a href="tensor.html#get_shape"><code translate="no" dir="ltr">tf.Tensor.get_shape()</code></a>, and <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> for details and examples. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_index</code> </td> <td> The index of this tensor in the outputs of its <code translate="no" dir="ltr">Operation</code>. </td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="consumers" data-text="consumers"><code translate="no" dir="ltr">consumers</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L843-L855">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
consumers()
</pre> <p>Returns a list of <code translate="no" dir="ltr">Operation</code>s that consume this tensor.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of <code translate="no" dir="ltr">Operation</code>s. </td> </tr> 
</table> <h3 id="eval" data-text="eval"><code translate="no" dir="ltr">eval</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L971-L995">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
eval(
    feed_dict=None, session=None
)
</pre> <p>Evaluates this tensor in a <code translate="no" dir="ltr">Session</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> If you are not using <a href="compat/v1.html"><code translate="no" dir="ltr">compat.v1</code></a> libraries, you should not need this, (or <code translate="no" dir="ltr">feed_dict</code> or <code translate="no" dir="ltr">Session</code>). In eager execution (or within <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a>) you do not need to call <code translate="no" dir="ltr">eval</code>.</span>
</blockquote> <p>Calling this method will execute all preceding operations that produce the inputs needed for the operation that produces this tensor.</p> <blockquote class="note">
<strong>Note:</strong><span> Before invoking <a href="tensor.html#eval"><code translate="no" dir="ltr">Tensor.eval()</code></a>, its graph must have been launched in a session, and either a default session must be available, or <code translate="no" dir="ltr">session</code> must be specified explicitly.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">feed_dict</code> </td> <td> A dictionary that maps <code translate="no" dir="ltr">Tensor</code> objects to feed values. See <code translate="no" dir="ltr">tf.Session.run</code> for a description of the valid feed values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">session</code> </td> <td> (Optional.) The <code translate="no" dir="ltr">Session</code> to be used to evaluate this tensor. If none, the default session will be used. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A numpy array corresponding to the value of this tensor. </td> </tr> 
</table> <h3 id="experimental_ref" data-text="experimental_ref"><code translate="no" dir="ltr">experimental_ref</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L997-L999">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
experimental_ref()
</pre> <p>DEPRECATED FUNCTION</p> <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use ref() instead.</span></aside> <h3 id="get_shape" data-text="get_shape"><code translate="no" dir="ltr">get_shape</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L611-L690">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_shape()
</pre> <p>Returns a <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> that represents the shape of this tensor.</p> <p>In eager execution the shape is always fully-known.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
print(a.shape)
(2, 3)
</pre> <p><a href="tensor.html#get_shape"><code translate="no" dir="ltr">tf.Tensor.get_shape()</code></a> is equivalent to <a href="tensor.html#shape"><code translate="no" dir="ltr">tf.Tensor.shape</code></a>.</p> <p>When executing in a <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a> or building a model using <a href="keras/input.html"><code translate="no" dir="ltr">tf.keras.Input</code></a>, <a href="tensor.html#shape"><code translate="no" dir="ltr">Tensor.shape</code></a> may return a partial shape (including <code translate="no" dir="ltr">None</code> for unknown dimensions). See <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> for more details.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
inputs = tf.keras.Input(shape = [10])
# Unknown batch size
print(inputs.shape)
(None, 10)
</pre> <p>The shape is computed using shape inference functions that are registered for each <a href="operation.html"><code translate="no" dir="ltr">tf.Operation</code></a>.</p> <p>The returned <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> is determined at <em>build</em> time, without executing the underlying kernel. It is not a <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a>. If you need a shape <em>tensor</em>, either convert the <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> to a <a href="constant.html"><code translate="no" dir="ltr">tf.constant</code></a>, or use the <a href="shape.html"><code translate="no" dir="ltr">tf.shape(tensor)</code></a> function, which returns the tensor's shape at <em>execution</em> time.</p> <p>This is useful for debugging and providing early errors. For example, when tracing a <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a>, no ops are being executed, shapes may be unknown (See the <a href="https://www.tensorflow.org/guide/concrete_function">Concrete Functions Guide</a> for details).</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def my_matmul(a, b):
  result = a@b
  # the `print` executes during tracing.
  print("Result shape: ", result.shape)
  return result
</pre> <p>The shape inference functions propagate shapes to the extent possible:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
f = my_matmul.get_concrete_function(
  tf.TensorSpec([None,3]),
  tf.TensorSpec([3,5]))
Result shape: (None, 5)
</pre> <p>Tracing may fail if a shape missmatch can be detected:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cf = my_matmul.get_concrete_function(
  tf.TensorSpec([None,3]),
  tf.TensorSpec([4,5]))
Traceback (most recent call last):

ValueError: Dimensions must be equal, but are 3 and 4 for 'matmul' (op:
'MatMul') with input shapes: [?,3], [4,5].
</pre> <p>In some cases, the inferred shape may have unknown dimensions. If the caller has additional information about the values of these dimensions, <a href="ensure_shape.html"><code translate="no" dir="ltr">tf.ensure_shape</code></a> or <a href="tensor.html#set_shape"><code translate="no" dir="ltr">Tensor.set_shape()</code></a> can be used to augment the inferred shape.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def my_fun(a):
  a = tf.ensure_shape(a, [5, 5])
  # the `print` executes during tracing.
  print("Result shape: ", a.shape)
  return a
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cf = my_fun.get_concrete_function(
  tf.TensorSpec([None, None]))
Result shape: (5, 5)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensorshape.html"><code translate="no" dir="ltr">tf.TensorShape</code></a> representing the shape of this tensor. </td> </tr> 
</table> <h3 id="ref" data-text="ref"><code translate="no" dir="ltr">ref</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L1001-L1040">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
ref()
</pre> <p>Returns a hashable reference object to this Tensor.</p> <p>The primary use case for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as <code translate="no" dir="ltr">tensor.__hash__()</code> is no longer available starting Tensorflow 2.0.</p> <p>The following will raise an exception starting 2.0</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant(5)
y = tf.constant(10)
z = tf.constant(10)
tensor_set = {x, y, z}
Traceback (most recent call last):

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
tensor_dict = {x: 'five', y: 'ten'}
Traceback (most recent call last):

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
</pre> <p>Instead, we can use <code translate="no" dir="ltr">tensor.ref()</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tensor_set = {x.ref(), y.ref(), z.ref()}
x.ref() in tensor_set
True
tensor_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}
tensor_dict[y.ref()]
'ten'
</pre> <p>Also, the reference object provides <code translate="no" dir="ltr">.deref()</code> function that returns the original Tensor.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant(5)
x.ref().deref()
&lt;tf.Tensor: shape=(), dtype=int32, numpy=5&gt;
</pre> <h3 id="set_shape" data-text="set_shape"><code translate="no" dir="ltr">set_shape</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L692-L836">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_shape(
    shape
)
</pre> <p>Updates the shape of this tensor.</p> <blockquote class="note">
<strong>Note:</strong><span> It is recommended to use <a href="ensure_shape.html"><code translate="no" dir="ltr">tf.ensure_shape</code></a> instead of <a href="tensor.html#set_shape"><code translate="no" dir="ltr">Tensor.set_shape</code></a>, because <a href="ensure_shape.html"><code translate="no" dir="ltr">tf.ensure_shape</code></a> provides better checking for programming errors and can create guarantees for compiler optimization.</span>
</blockquote> <p>With eager execution this operates as a shape assertion. Here the shapes match:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.constant([[1,2,3]])
t.set_shape([1, 3])
</pre> <p>Passing a <code translate="no" dir="ltr">None</code> in the new shape allows any value for that axis:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t.set_shape([1,None])
</pre> <p>An error is raised if an incompatible shape is passed.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t.set_shape([1,5])
Traceback (most recent call last):

ValueError: Tensor's shape (1, 3) is not compatible with supplied
shape [1, 5]
</pre> <p>When executing in a <a href="function.html"><code translate="no" dir="ltr">tf.function</code></a>, or building a model using <a href="keras/input.html"><code translate="no" dir="ltr">tf.keras.Input</code></a>, <a href="tensor.html#set_shape"><code translate="no" dir="ltr">Tensor.set_shape</code></a> will <em>merge</em> the given <code translate="no" dir="ltr">shape</code> with the current shape of this tensor, and set the tensor's shape to the merged value (see <a href="tensorshape.html#merge_with"><code translate="no" dir="ltr">tf.TensorShape.merge_with</code></a> for details):</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.keras.Input(shape=[None, None, 3])
print(t.shape)
(None, None, None, 3)
</pre> <p>Dimensions set to <code translate="no" dir="ltr">None</code> are not updated:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t.set_shape([None, 224, 224, None])
print(t.shape)
(None, 224, 224, 3)
</pre> <p>The main use case for this is to provide additional shape information that cannot be inferred from the graph alone.</p> <p>For example if you know all the images in a dataset have shape [28,28,3] you can set it with <code translate="no" dir="ltr">tf.set_shape</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def load_image(filename):
  raw = tf.io.read_file(filename)
  image = tf.image.decode_png(raw, channels=3)
  # the `print` executes during tracing.
  print("Initial shape: ", image.shape)
  image.set_shape([28, 28, 3])
  print("Final shape: ", image.shape)
  return image
</pre> <p>Trace the function, see the <a href="https://www.tensorflow.org/guide/concrete_function">Concrete Functions Guide</a> for details.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cf = load_image.get_concrete_function(
    tf.TensorSpec([], dtype=tf.string))
Initial shape:  (None, None, 3)
Final shape: (28, 28, 3)
</pre> <p>Similarly the <a href="io/parse_tensor.html"><code translate="no" dir="ltr">tf.io.parse_tensor</code></a> function could return a tensor with any shape, even the <a href="rank.html"><code translate="no" dir="ltr">tf.rank</code></a> is unknown. If you know that all your serialized tensors will be 2d, set it with <code translate="no" dir="ltr">set_shape</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def my_parse(string_tensor):
  result = tf.io.parse_tensor(string_tensor, out_type=tf.float32)
  # the `print` executes during tracing.
  print("Initial shape: ", result.shape)
  result.set_shape([None, None])
  print("Final shape: ", result.shape)
  return result
</pre> <p>Trace the function</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
concrete_parse = my_parse.get_concrete_function(
    tf.TensorSpec([], dtype=tf.string))
Initial shape:  &lt;unknown&gt;
Final shape:  (None, None)
</pre> <h4 id="make_sure_it_works" data-text="Make sure it works:">Make sure it works:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.ones([5,3], dtype=tf.float32)
serialized = tf.io.serialize_tensor(t)
print(serialized.dtype)
&lt;dtype: 'string'&gt;
print(serialized.shape)
()
t2 = concrete_parse(serialized)
print(t2.shape)
(5, 3)
</pre> <aside class="caution"><strong>Caution:</strong><span> <code translate="no" dir="ltr">set_shape</code> ensures that the applied shape is compatible with the existing shape, but it does not check at runtime. Setting incorrect shapes can result in inconsistencies between the statically-known graph and the runtime value of tensors. For runtime validation of the shape, use <a href="ensure_shape.html"><code translate="no" dir="ltr">tf.ensure_shape</code></a> instead. It also modifies the <code translate="no" dir="ltr">shape</code> of the tensor.</span></aside> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# Serialize a rank-3 tensor
t = tf.ones([5,5,5], dtype=tf.float32)
serialized = tf.io.serialize_tensor(t)
# The function still runs, even though it `set_shape([None,None])`
t2 = concrete_parse(serialized)
print(t2.shape)
(5, 5, 5)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> A <code translate="no" dir="ltr">TensorShape</code> representing the shape of this tensor, a <code translate="no" dir="ltr">TensorShapeProto</code>, a list, a tuple, or None. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">shape</code> is not compatible with the current shape of this tensor. </td> </tr> </table> <h3 id="__abs__" data-text="__abs__"><code translate="no" dir="ltr">__abs__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L364-L408">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__abs__(
    name=None
)
</pre> <p>Computes the absolute value of a tensor.</p> <p>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> of complex numbers, this operation returns a tensor of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code> that is the absolute value of each element in <code translate="no" dir="ltr">x</code>. For a complex number \(a + bj\), its absolute value is computed as \(\sqrt{a^2 + b^2}\).</p> <h4 id="for_example" data-text="For example:">For example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# real number
x = tf.constant([-2.25, 3.25])
tf.abs(x)
&lt;tf.Tensor: shape=(2,), dtype=float32,
numpy=array([2.25, 3.25], dtype=float32)&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# complex number
x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)
&lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy=
array([[5.25594901],
       [6.60492241]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of the same size, type and sparsity as <code translate="no" dir="ltr">x</code>, with absolute values. Note, for <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code> input, the returned <code translate="no" dir="ltr">Tensor</code> will be of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code>, respectively. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__add__" data-text="__add__"><code translate="no" dir="ltr">__add__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__add__(
    y
)
</pre> <p>The operation invoked by the <a href="tensor.html#__add__"><code translate="no" dir="ltr">Tensor.<strong>add</strong></code></a> operator.</p> <h4 id="purpose_in_the_api" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="tensor.html#__add__"><code translate="no" dir="ltr">Tensor.<strong>add</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> an optional name for the operation. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">+</code> operation. </td> </tr> 
</table> <h3 id="__and__" data-text="__and__"><code translate="no" dir="ltr">__and__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__and__(
    y
)
</pre> <h3 id="__array__" data-text="__array__"><code translate="no" dir="ltr">__array__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L924-L929">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__array__(
    dtype=None
)
</pre> <h3 id="__bool__" data-text="__bool__"><code translate="no" dir="ltr">__bool__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L941-L959">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__bool__()
</pre> <p>Dummy method to prevent a tensor from being used as a Python <code translate="no" dir="ltr">bool</code>.</p> <p>This overload raises a <code translate="no" dir="ltr">TypeError</code> when the user inadvertently treats a <code translate="no" dir="ltr">Tensor</code> as a boolean (most commonly in an <code translate="no" dir="ltr">if</code> or <code translate="no" dir="ltr">while</code> statement), in code that was not converted by AutoGraph. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">if tf.constant(True):  # Will raise.
  # ...

if tf.constant(5) &lt; tf.constant(7):  # Will raise.
  # ...
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">TypeError</code>. </td> </tr> 
</table> <h3 id="__div__" data-text="__div__"><code translate="no" dir="ltr">__div__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__div__(
    y
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <p><section><devsite-expandable> <h4 class="showalways" id="migrate-to-tf2" data-text="Migrate to TF2">Migrate to TF2</h4></devsite-expandable></section></p> <p>This function is deprecated in TF2. Prefer using the Tensor division operator, <a href="math/divide.html"><code translate="no" dir="ltr">tf.divide</code></a>, or <a href="math/divide.html"><code translate="no" dir="ltr">tf.math.divide</code></a>, which obey the Python 3 division operator semantics.</p>  <h3 id="__eq__" data-text="__eq__"><code translate="no" dir="ltr">__eq__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1962-L1998">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__eq__(
    other
)
</pre> <p>The operation invoked by the <a href="raggedtensor.html#__eq__"><code translate="no" dir="ltr">Tensor.<strong>eq</strong></code></a> operator.</p> <p>Compares two tensors element-wise for equality if they are broadcast-compatible; or returns False if they are not broadcast-compatible. (Note that this behavior differs from <a href="math/equal.html"><code translate="no" dir="ltr">tf.math.equal</code></a>, which raises an exception if the two tensors are not broadcast-compatible.)</p> <h4 id="purpose_in_the_api_2" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="raggedtensor.html#__eq__"><code translate="no" dir="ltr">Tensor.<strong>eq</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">self</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">==</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">other</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">==</code> operator. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">==</code> operation, or <code translate="no" dir="ltr">False</code> if the arguments are not broadcast-compatible. </td> </tr> 
</table> <h3 id="__floordiv__" data-text="__floordiv__"><code translate="no" dir="ltr">__floordiv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__floordiv__(
    y
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>Mathematically, this is equivalent to floor(x / y). For example: floor(8.4 / 4.0) = floor(2.1) = 2.0 floor(-8.4 / 4.0) = floor(-2.1) = -3.0 This is equivalent to the '//' operator in Python 3.0 and above.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded toward -infinity. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__ge__" data-text="__ge__"><code translate="no" dir="ltr">__ge__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ge__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &gt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater_equal.html"><code translate="no" dir="ltr">math.greater_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6, 7])
y = tf.constant([5, 2, 5, 10])
tf.math.greater_equal(x, y) ==&gt; [True, True, True, False]

x = tf.constant([5, 4, 6, 7])
y = tf.constant([5])
tf.math.greater_equal(x, y) ==&gt; [True, False, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__getitem__" data-text="__getitem__"><code translate="no" dir="ltr">__getitem__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/array_ops.py#L914-L1108">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__getitem__(
    slice_spec, var=None
)
</pre> <p>Overload for Tensor.<strong>getitem</strong>.</p> <p>This operation extracts the specified region from the tensor. The notation is similar to NumPy with the restriction that currently only support basic indexing. That means that using a non-scalar tensor as input is not currently allowed.</p> <h4 id="some_useful_examples" data-text="Some useful examples:">Some useful examples:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Strip leading and trailing 2 elements
foo = tf.constant([1,2,3,4,5,6])
print(foo[2:-2].eval())  # =&gt; [3,4]

# Skip every other row and reverse the order of the columns
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[::2,::-1].eval())  # =&gt; [[3,2,1], [9,8,7]]

# Use scalar tensors as indices on both dimensions
print(foo[tf.constant(0), tf.constant(2)].eval())  # =&gt; 3

# Insert another dimension
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[tf.newaxis, :, :].eval()) # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[:, tf.newaxis, :].eval()) # =&gt; [[[1,2,3]], [[4,5,6]], [[7,8,9]]]
print(foo[:, :, tf.newaxis].eval()) # =&gt; [[[1],[2],[3]], [[4],[5],[6]],
[[7],[8],[9]]]

# Ellipses (3 equivalent operations)
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[tf.newaxis, :, :].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[tf.newaxis, ...].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[tf.newaxis].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]

# Masks
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[foo &gt; 2].eval())  # =&gt; [3, 4, 5, 6, 7, 8, 9]
</pre> <h4 id="notes" data-text="Notes:">Notes:</h4> <ul> <li>
<a href="../tf.html#newaxis"><code translate="no" dir="ltr">tf.newaxis</code></a> is <code translate="no" dir="ltr">None</code> as in NumPy.</li> <li>An implicit ellipsis is placed at the end of the <code translate="no" dir="ltr">slice_spec</code>
</li> <li>NumPy advanced indexing is currently not supported.</li> </ul> <h4 id="purpose_in_the_api_3" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="tensor.html#__getitem__"><code translate="no" dir="ltr">Tensor.<strong>getitem</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor</code> </td> <td> An ops.Tensor object. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">slice_spec</code> </td> <td> The arguments to Tensor.<strong>getitem</strong>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">var</code> </td> <td> In the case of variable slice assignment, the Variable object to slice (i.e. tensor is the read-only view of this variable). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The appropriate slice of "tensor", based on "slice_spec". </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If a slice range is negative size. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the slice indices aren't int, slice, ellipsis, tf.newaxis or scalar int32/int64 tensors. </td> </tr> </table> <h3 id="__gt__" data-text="__gt__"><code translate="no" dir="ltr">__gt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__gt__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &gt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater.html"><code translate="no" dir="ltr">math.greater</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_2" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5, 2, 5])
tf.math.greater(x, y) ==&gt; [False, True, True]

x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.greater(x, y) ==&gt; [False, False, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__invert__" data-text="__invert__"><code translate="no" dir="ltr">__invert__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1859-L1862">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__invert__(
    name=None
)
</pre> <h3 id="__iter__" data-text="__iter__"><code translate="no" dir="ltr">__iter__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L577-L589">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__iter__()
</pre> <h3 id="__le__" data-text="__le__"><code translate="no" dir="ltr">__le__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__le__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &lt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less_equal.html"><code translate="no" dir="ltr">math.less_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_3" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less_equal(x, y) ==&gt; [True, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 6])
tf.math.less_equal(x, y) ==&gt; [True, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__len__" data-text="__len__"><code translate="no" dir="ltr">__len__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L931-L934">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__len__()
</pre> <h3 id="__lt__" data-text="__lt__"><code translate="no" dir="ltr">__lt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__lt__(
    y, name=None
)
</pre> <p>Returns the truth value of (x &lt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less.html"><code translate="no" dir="ltr">math.less</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_4" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less(x, y) ==&gt; [False, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 7])
tf.math.less(x, y) ==&gt; [False, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__matmul__" data-text="__matmul__"><code translate="no" dir="ltr">__matmul__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__matmul__(
    y
)
</pre> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <p>A simple 2-D tensor matrix multiplication:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])
a  # 2-D tensor
&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)&gt;
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])
b  # 2-D tensor
&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[ 7,  8],
       [ 9, 10],
       [11, 12]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=
array([[ 58,  64],
       [139, 154]], dtype=int32)&gt;
</pre> <p>A batch matrix multiplication with batch shape [2]:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])
a  # 3-D tensor
&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]], dtype=int32)&gt;
b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])
b  # 3-D tensor
&lt;tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=
array([[[13, 14],
        [15, 16],
        [17, 18]],
       [[19, 20],
        [21, 22],
        [23, 24]]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=
array([[[ 94, 100],
        [229, 244]],
       [[508, 532],
        [697, 730]]], dtype=int32)&gt;
</pre> <p>Since python &gt;= 3.5 the @ operator is supported (see <a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>). In TensorFlow, it simply calls the <a href="linalg/matmul.html"><code translate="no" dir="ltr">tf.matmul()</code></a> function, so the following lines are equivalent:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d = a @ b @ [[10], [11]]
d = tf.matmul(tf.matmul(a, b), [[10], [11]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_type</code> </td> <td> The output datatype if needed. Defaults to None in which case the output_type is the same as input type. Currently only works when input tensors are type (u)int8 and output_type can be int32. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])</code>, for all indices <code translate="no" dir="ltr">i</code>, <code translate="no" dir="ltr">j</code>. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">transpose_a</code> and <code translate="no" dir="ltr">adjoint_a</code>, or <code translate="no" dir="ltr">transpose_b</code> and <code translate="no" dir="ltr">adjoint_b</code> are both set to <code translate="no" dir="ltr">True</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If output_type is specified but the types of <code translate="no" dir="ltr">a</code>, <code translate="no" dir="ltr">b</code> and <code translate="no" dir="ltr">output_type</code> is not (u)int8, (u)int8 and int32. </td> </tr> </table> <h3 id="__mod__" data-text="__mod__"><code translate="no" dir="ltr">__mod__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mod__(
    y
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod.html"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__mul__" data-text="__mul__"><code translate="no" dir="ltr">__mul__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mul__(
    y
)
</pre> <p>Dispatches cwise mul for "Dense<em>Dense" and "Dense</em>Sparse".</p> <h3 id="__ne__" data-text="__ne__"><code translate="no" dir="ltr">__ne__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L2001-L2035">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ne__(
    other
)
</pre> <p>The operation invoked by the <a href="raggedtensor.html#__ne__"><code translate="no" dir="ltr">Tensor.<strong>ne</strong></code></a> operator.</p> <p>Compares two tensors element-wise for inequality if they are broadcast-compatible; or returns True if they are not broadcast-compatible. (Note that this behavior differs from <a href="math/not_equal.html"><code translate="no" dir="ltr">tf.math.not_equal</code></a>, which raises an exception if the two tensors are not broadcast-compatible.)</p> <h4 id="purpose_in_the_api_4" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="raggedtensor.html#__ne__"><code translate="no" dir="ltr">Tensor.<strong>ne</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">self</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">!=</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">other</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">!=</code> operator. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">!=</code> operation, or <code translate="no" dir="ltr">True</code> if the arguments are not broadcast-compatible. </td> </tr> 
</table> <h3 id="__neg__" data-text="__neg__"><code translate="no" dir="ltr">__neg__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__neg__(
    name=None
)
</pre> <p>Computes numerical negative value element-wise.</p> <p>I.e., \(y = -x\).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__nonzero__" data-text="__nonzero__"><code translate="no" dir="ltr">__nonzero__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/framework/ops.py#L961-L969">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__nonzero__()
</pre> <p>Dummy method to prevent a tensor from being used as a Python <code translate="no" dir="ltr">bool</code>.</p> <p>This is the Python 2.x counterpart to <code translate="no" dir="ltr">__bool__()</code> above.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">TypeError</code>. </td> </tr> 
</table> <h3 id="__or__" data-text="__or__"><code translate="no" dir="ltr">__or__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__or__(
    y
)
</pre> <h3 id="__pow__" data-text="__pow__"><code translate="no" dir="ltr">__pow__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__pow__(
    y
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__radd__" data-text="__radd__"><code translate="no" dir="ltr">__radd__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__radd__(
    x
)
</pre> <p>The operation invoked by the <a href="tensor.html#__add__"><code translate="no" dir="ltr">Tensor.<strong>add</strong></code></a> operator.</p> <h4 id="purpose_in_the_api_5" data-text="Purpose in the API:">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="tensor.html#__add__"><code translate="no" dir="ltr">Tensor.<strong>add</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> an optional name for the operation. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">+</code> operation. </td> </tr> 
</table> <h3 id="__rand__" data-text="__rand__"><code translate="no" dir="ltr">__rand__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rand__(
    x
)
</pre> <h3 id="__rdiv__" data-text="__rdiv__"><code translate="no" dir="ltr">__rdiv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rdiv__(
    x
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <p><section><devsite-expandable> <h4 class="showalways" id="migrate-to-tf2_1" data-text="Migrate to TF2">Migrate to TF2</h4></devsite-expandable></section></p> <p>This function is deprecated in TF2. Prefer using the Tensor division operator, <a href="math/divide.html"><code translate="no" dir="ltr">tf.divide</code></a>, or <a href="math/divide.html"><code translate="no" dir="ltr">tf.math.divide</code></a>, which obey the Python 3 division operator semantics.</p>  <h3 id="__rfloordiv__" data-text="__rfloordiv__"><code translate="no" dir="ltr">__rfloordiv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rfloordiv__(
    x
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>Mathematically, this is equivalent to floor(x / y). For example: floor(8.4 / 4.0) = floor(2.1) = 2.0 floor(-8.4 / 4.0) = floor(-2.1) = -3.0 This is equivalent to the '//' operator in Python 3.0 and above.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded toward -infinity. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__rmatmul__" data-text="__rmatmul__"><code translate="no" dir="ltr">__rmatmul__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmatmul__(
    x
)
</pre> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <p>A simple 2-D tensor matrix multiplication:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])
a  # 2-D tensor
&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)&gt;
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])
b  # 2-D tensor
&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[ 7,  8],
       [ 9, 10],
       [11, 12]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=
array([[ 58,  64],
       [139, 154]], dtype=int32)&gt;
</pre> <p>A batch matrix multiplication with batch shape [2]:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])
a  # 3-D tensor
&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]], dtype=int32)&gt;
b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])
b  # 3-D tensor
&lt;tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=
array([[[13, 14],
        [15, 16],
        [17, 18]],
       [[19, 20],
        [21, 22],
        [23, 24]]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=
array([[[ 94, 100],
        [229, 244]],
       [[508, 532],
        [697, 730]]], dtype=int32)&gt;
</pre> <p>Since python &gt;= 3.5 the @ operator is supported (see <a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>). In TensorFlow, it simply calls the <a href="linalg/matmul.html"><code translate="no" dir="ltr">tf.matmul()</code></a> function, so the following lines are equivalent:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d = a @ b @ [[10], [11]]
d = tf.matmul(tf.matmul(a, b), [[10], [11]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_type</code> </td> <td> The output datatype if needed. Defaults to None in which case the output_type is the same as input type. Currently only works when input tensors are type (u)int8 and output_type can be int32. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])</code>, for all indices <code translate="no" dir="ltr">i</code>, <code translate="no" dir="ltr">j</code>. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">transpose_a</code> and <code translate="no" dir="ltr">adjoint_a</code>, or <code translate="no" dir="ltr">transpose_b</code> and <code translate="no" dir="ltr">adjoint_b</code> are both set to <code translate="no" dir="ltr">True</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If output_type is specified but the types of <code translate="no" dir="ltr">a</code>, <code translate="no" dir="ltr">b</code> and <code translate="no" dir="ltr">output_type</code> is not (u)int8, (u)int8 and int32. </td> </tr> </table> <h3 id="__rmod__" data-text="__rmod__"><code translate="no" dir="ltr">__rmod__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmod__(
    x
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod.html"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rmul__" data-text="__rmul__"><code translate="no" dir="ltr">__rmul__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmul__(
    x
)
</pre> <p>Dispatches cwise mul for "Dense<em>Dense" and "Dense</em>Sparse".</p> <h3 id="__ror__" data-text="__ror__"><code translate="no" dir="ltr">__ror__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ror__(
    x
)
</pre> <h3 id="__rpow__" data-text="__rpow__"><code translate="no" dir="ltr">__rpow__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rpow__(
    x
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__rsub__" data-text="__rsub__"><code translate="no" dir="ltr">__rsub__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rsub__(
    x
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <p>Both input and output have a range <code translate="no" dir="ltr">(-inf, inf)</code>.</p> <p>Example usages below.</p> <p>Subtract operation between an array and a scalar:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = 1
tf.subtract(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 0, -1, -2, -3, -4], dtype=int32)&gt;
</pre> <p>Note that binary <code translate="no" dir="ltr">-</code> operator can be used instead:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.convert_to_tensor([1, 2, 3, 4, 5])
y = tf.convert_to_tensor(1)
x - y
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
</pre> <p>Subtract operation between an array and a tensor of same shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = tf.constant([5, 4, 3, 2, 1])
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 4,  2,  0, -2, -4], dtype=int32)&gt;
</pre> <aside class="warning"><strong>Warning:</strong><span> If one of the inputs (<code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>) is a tensor and the other is a non-tensor, the non-tensor input will adopt (or get casted to) the data type of the tensor input. This can potentially cause unwanted overflow or underflow conversion.</span></aside> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([1, 2], dtype=tf.int8)
y = [2**8 + 1, 2**8 + 2]
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)&gt;
</pre> <p>When subtracting two input values of different shapes, <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> follows the <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules">general broadcasting rules</a> . The two input array shapes are compared element-wise. Starting with the trailing dimensions, the two dimensions either have to be equal or one of them needs to be <code translate="no" dir="ltr">1</code>.</p> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(2, 1, 3)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=
array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]],
       [[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]]])&gt;
</pre> <p>Example with inputs of different dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(1, 6)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=
array([[[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]],
       [[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rtruediv__" data-text="__rtruediv__"><code translate="no" dir="ltr">__rtruediv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rtruediv__(
    x
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</span>
</blockquote> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> evaluated in floating point. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes. </td> </tr> </table> <h3 id="__rxor__" data-text="__rxor__"><code translate="no" dir="ltr">__rxor__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1435-L1441">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rxor__(
    x
)
</pre> <h3 id="__sub__" data-text="__sub__"><code translate="no" dir="ltr">__sub__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__sub__(
    y
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <p>Both input and output have a range <code translate="no" dir="ltr">(-inf, inf)</code>.</p> <p>Example usages below.</p> <p>Subtract operation between an array and a scalar:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = 1
tf.subtract(x, y)
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 0, -1, -2, -3, -4], dtype=int32)&gt;
</pre> <p>Note that binary <code translate="no" dir="ltr">-</code> operator can be used instead:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.convert_to_tensor([1, 2, 3, 4, 5])
y = tf.convert_to_tensor(1)
x - y
&lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)&gt;
</pre> <p>Subtract operation between an array and a tensor of same shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1, 2, 3, 4, 5]
y = tf.constant([5, 4, 3, 2, 1])
tf.subtract(y, x)
&lt;tf.Tensor: shape=(5,), dtype=int32,
numpy=array([ 4,  2,  0, -2, -4], dtype=int32)&gt;
</pre> <aside class="warning"><strong>Warning:</strong><span> If one of the inputs (<code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>) is a tensor and the other is a non-tensor, the non-tensor input will adopt (or get casted to) the data type of the tensor input. This can potentially cause unwanted overflow or underflow conversion.</span></aside> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([1, 2], dtype=tf.int8)
y = [2**8 + 1, 2**8 + 2]
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)&gt;
</pre> <p>When subtracting two input values of different shapes, <a href="math/subtract.html"><code translate="no" dir="ltr">tf.subtract</code></a> follows the <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules">general broadcasting rules</a> . The two input array shapes are compared element-wise. Starting with the trailing dimensions, the two dimensions either have to be equal or one of them needs to be <code translate="no" dir="ltr">1</code>.</p> <p>For example,</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(2, 1, 3)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=
array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]],
       [[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]]])&gt;
</pre> <p>Example with inputs of different dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = np.ones(6).reshape(2, 3, 1)
y = np.ones(6).reshape(1, 6)
tf.subtract(x, y)
&lt;tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=
array([[[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]],
       [[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__truediv__" data-text="__truediv__"><code translate="no" dir="ltr">__truediv__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__truediv__(
    y
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</span>
</blockquote> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> evaluated in floating point. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes. </td> </tr> </table> <h3 id="__xor__" data-text="__xor__"><code translate="no" dir="ltr">__xor__</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L1398-L1424">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__xor__(
    y
)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Class Variables</th></tr> 
<tr> <td> OVERLOADABLE_OPERATORS </td> <td> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">{
 '__abs__',
 '__add__',
 '__and__',
 '__div__',
 '__eq__',
 '__floordiv__',
 '__ge__',
 '__getitem__',
 '__gt__',
 '__invert__',
 '__le__',
 '__lt__',
 '__matmul__',
 '__mod__',
 '__mul__',
 '__ne__',
 '__neg__',
 '__or__',
 '__pow__',
 '__radd__',
 '__rand__',
 '__rdiv__',
 '__rfloordiv__',
 '__rmatmul__',
 '__rmod__',
 '__rmul__',
 '__ror__',
 '__rpow__',
 '__rsub__',
 '__rtruediv__',
 '__rxor__',
 '__sub__',
 '__truediv__',
 '__xor__'
}
</pre> 
</td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/Tensor" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/Tensor</a>
  </p>
</div>
