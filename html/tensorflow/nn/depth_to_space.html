<h1 class="devsite-page-title">tf.nn.depth_to_space</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/array_ops.py#L4125-L4128">  View source on GitHub </a> </td> </table> <p>DepthToSpace for tensors of type T.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.nn.depth_to_space(
    input, block_size, data_format='NHWC', name=None
)
</pre>  <p>Rearranges data from depth into blocks of spatial data. This is the reverse transformation of SpaceToDepth. More specifically, this op outputs a copy of the input tensor where values from the <code translate="no" dir="ltr">depth</code> dimension are moved in spatial blocks to the <code translate="no" dir="ltr">height</code> and <code translate="no" dir="ltr">width</code> dimensions. The attr <code translate="no" dir="ltr">block_size</code> indicates the input block size and how the data is moved.</p> <ul> <li>Chunks of data of size <code translate="no" dir="ltr">block_size * block_size</code> from depth are rearranged into non-overlapping blocks of size <code translate="no" dir="ltr">block_size x block_size</code>
</li> <li>The width the output tensor is <code translate="no" dir="ltr">input_depth * block_size</code>, whereas the height is <code translate="no" dir="ltr">input_height * block_size</code>.</li> <li>The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.</li> <li>The depth of the input tensor must be divisible by <code translate="no" dir="ltr">block_size * block_size</code>.</li> </ul> <p>The <code translate="no" dir="ltr">data_format</code> attr specifies the layout of the input and output tensors with the following options: "NHWC": <code translate="no" dir="ltr">[ batch, height, width, channels ]</code> "NCHW": <code translate="no" dir="ltr">[ batch, channels, height, width ]</code> "NCHW_VECT_C": <code translate="no" dir="ltr">qint8 [ batch, channels / 4, height, width, 4 ]</code></p> <p>It is useful to consider the operation as transforming a 6-D Tensor. e.g. for data_format = NHWC, Each element in the input tensor can be specified via 6 coordinates, ordered by decreasing memory layout significance as: n,iY,iX,bY,bX,oC (where n=batch index, iX, iY means X or Y coordinates within the input image, bX, bY means coordinates within the output block, oC means output channels). The output would be the input transposed to the following layout: n,iY,bY,iX,bX,oC</p> <p>This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.</p> <p>For example, given an input of shape <code translate="no" dir="ltr">[1, 1, 1, 4]</code>, data_format = "NHWC" and block_size = 2:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">x = [[[[1, 2, 3, 4]]]]

</pre> <p>This operation will output a tensor of shape <code translate="no" dir="ltr">[1, 2, 2, 1]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">[[[[1], [2]],
  [[3], [4]]]]
</pre> <p>Here, the input has a batch of 1 and each batch element has shape <code translate="no" dir="ltr">[1, 1, 4]</code>, the corresponding output will have 2x2 elements and will have a depth of 1 channel (1 = <code translate="no" dir="ltr">4 / (block_size * block_size)</code>). The output element shape is <code translate="no" dir="ltr">[2, 2, 1]</code>.</p> <p>For an input tensor with larger depth, here of shape <code translate="no" dir="ltr">[1, 1, 1, 12]</code>, e.g.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
</pre> <p>This operation, for block size of 2, will return the following tensor of shape <code translate="no" dir="ltr">[1, 2, 2, 3]</code></p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">[[[[1, 2, 3], [4, 5, 6]],
  [[7, 8, 9], [10, 11, 12]]]]

</pre> <p>Similarly, for the following input of shape <code translate="no" dir="ltr">[1 2 2 4]</code>, and a block size of 2:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">x =  [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]
</pre> <p>the operator will return the following tensor of shape <code translate="no" dir="ltr">[1 4 4 1]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">x = [[[ [1],   [2],  [5],  [6]],
      [ [3],   [4],  [7],  [8]],
      [ [9],  [10], [13],  [14]],
      [ [11], [12], [15],  [16]]]]

</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">block_size</code> </td> <td> An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 2</code>. The size of the spatial block, same as in Space2Depth. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">data_format</code> </td> <td> An optional <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"NHWC", "NCHW", "NCHW_VECT_C"</code>. Defaults to <code translate="no" dir="ltr">"NHWC"</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">input</code>. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/depth_to_space" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/depth_to_space</a>
  </p>
</div>
