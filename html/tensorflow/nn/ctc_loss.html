<h1 class="devsite-page-title" tabindex="-1"> tf.nn.ctc_loss </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.nn.ctc_loss"> <meta itemprop="path" content="Stable"> </div>   <p>Computes CTC (Connectionist Temporal Classification) loss.</p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.nn.ctc_loss(
    labels,
    logits,
    label_length,
    logit_length,
    logits_time_major=True,
    unique=None,
    blank_index=None,
    name=None
)
</pre></devsite-code>  <p>This op implements the CTC loss as presented in <a href="https://www.cs.toronto.edu/%7Egraves/icml_2006.pdf">Graves et al., 2006</a></p> <p>Connectionist temporal classification (CTC) is a type of neural network output and associated scoring function, for training recurrent neural networks (RNNs) such as LSTM networks to tackle sequence problems where the timing is variable. It can be used for tasks like on-line handwriting recognition or recognizing phones in speech audio. CTC refers to the outputs and scoring, and is independent of the underlying neural network structure.</p> <h4 id="notes" data-text="Notes:" tabindex="-1">Notes:</h4> <ul> <li>This class performs the softmax operation for you, so <code translate="no" dir="ltr">logits</code> should be e.g. linear projections of outputs by an LSTM.</li> <li>Outputs true repeated classes with blanks in between, and can also output repeated classes with no blanks in between that need to be collapsed by the decoder.</li> <li>
<code translate="no" dir="ltr">labels</code> may be supplied as either a dense, zero-padded <code translate="no" dir="ltr">Tensor</code> with a vector of label sequence lengths OR as a <code translate="no" dir="ltr">SparseTensor</code>.</li> <li>On TPU: Only dense padded <code translate="no" dir="ltr">labels</code> are supported.</li> <li>On CPU and GPU: Caller may use <code translate="no" dir="ltr">SparseTensor</code> or dense padded <code translate="no" dir="ltr">labels</code> but calling with a <code translate="no" dir="ltr">SparseTensor</code> will be significantly faster.</li> <li>Default blank label is <code translate="no" dir="ltr">0</code> instead of <code translate="no" dir="ltr">num_labels - 1</code> (where <code translate="no" dir="ltr">num_labels</code> is the innermost dimension size of <code translate="no" dir="ltr">logits</code>), unless overridden by <code translate="no" dir="ltr">blank_index</code>.</li> </ul> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.random.set_seed(50)
batch_size = 8
num_labels = 6
max_label_length = 5
num_frames = 12
labels = tf.random.uniform([batch_size, max_label_length],
                           minval=1, maxval=num_labels, dtype=tf.int64)
logits = tf.random.uniform([num_frames, batch_size, num_labels])
label_length = tf.random.uniform([batch_size], minval=2,
                                 maxval=max_label_length, dtype=tf.int64)
label_mask = tf.sequence_mask(label_length, maxlen=max_label_length,
                              dtype=label_length.dtype)
labels *= label_mask
logit_length = [num_frames] * batch_size
with tf.GradientTape() as t:
  t.watch(logits)
  ref_loss = tf.nn.ctc_loss(
      labels=labels,
      logits=logits,
      label_length=label_length,
      logit_length=logit_length,
      blank_index=0)
ref_grad = t.gradient(ref_loss, logits)</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">labels</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[batch_size, max_label_seq_length]</code> or <code translate="no" dir="ltr">SparseTensor</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">logits</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[frames, batch_size, num_labels]</code>. If <code translate="no" dir="ltr">logits_time_major == False</code>, shape is <code translate="no" dir="ltr">[batch_size, frames, num_labels]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">label_length</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[batch_size]</code>. None, if <code translate="no" dir="ltr">labels</code> is a <code translate="no" dir="ltr">SparseTensor</code>. Length of reference label sequence in <code translate="no" dir="ltr">labels</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">logit_length</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[batch_size]</code>. Length of input sequence in <code translate="no" dir="ltr">logits</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">logits_time_major</code> </td> <td> (optional) If True (default), <code translate="no" dir="ltr">logits</code> is shaped [frames, batch_size, num_labels]. If False, shape is <code translate="no" dir="ltr">[batch_size, frames, num_labels]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">unique</code> </td> <td> (optional) Unique label indices as computed by <code translate="no" dir="ltr">ctc_unique_labels(labels)</code>. If supplied, enable a faster, memory efficient implementation on TPU. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">blank_index</code> </td> <td> (optional) Set the class index to use for the blank label. Negative values will start from <code translate="no" dir="ltr">num_labels</code>, ie, <code translate="no" dir="ltr">-1</code> will reproduce the ctc_loss behavior of using <code translate="no" dir="ltr">num_labels - 1</code> for the blank symbol. There is some memory/performance overhead to switching from the default of 0 as an additional shifted copy of <code translate="no" dir="ltr">logits</code> may be created. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for this <code translate="no" dir="ltr">Op</code>. Defaults to "ctc_loss_dense". </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> 
<tr> <td> <code translate="no" dir="ltr">loss</code> </td> <td> A 1-D <code translate="no" dir="ltr">float Tensor</code> of shape <code translate="no" dir="ltr">[batch_size]</code>, containing negative log probabilities. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> Argument <code translate="no" dir="ltr">blank_index</code> must be provided when <code translate="no" dir="ltr">labels</code> is a <code translate="no" dir="ltr">SparseTensor</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">References</th></tr> <tr class="alt"> <td colspan="2"> Connectionist Temporal Classification - Labeling Unsegmented Sequence Data with Recurrent Neural Networks: <a href="https://dl.acm.org/citation.cfm?id=1143891">Graves et al., 2006</a> (<a href="http://www.cs.toronto.edu/%7Egraves/icml_2006.pdf">pdf</a>) <p><a href="https://en.wikipedia.org/wiki/Connectionist_temporal_classification">https://en.wikipedia.org/wiki/Connectionist_temporal_classification</a> </p>
</td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss</a>
  </p>
</div>
