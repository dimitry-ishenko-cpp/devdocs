<h1 class="devsite-page-title">tf.nn.conv2d</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/nn_ops.py#L2223-L2327">  View source on GitHub </a> </td> </table> <p>Computes a 2-D convolution given <code translate="no" dir="ltr">input</code> and 4-D <code translate="no" dir="ltr">filters</code> tensors.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.nn.conv2d(
    input,
    filters,
    strides,
    padding,
    data_format='NHWC',
    dilations=None,
    name=None
)
</pre>  <p>The <code translate="no" dir="ltr">input</code> tensor may have rank <code translate="no" dir="ltr">4</code> or higher, where shape dimensions <code translate="no" dir="ltr">[:-3]</code> are considered batch dimensions (<code translate="no" dir="ltr">batch_shape</code>).</p> <p>Given an input tensor of shape <code translate="no" dir="ltr">batch_shape + [in_height, in_width, in_channels]</code> and a filter / kernel tensor of shape <code translate="no" dir="ltr">[filter_height, filter_width, in_channels, out_channels]</code>, this op performs the following:</p> <ol> <li>Flattens the filter to a 2-D matrix with shape <code translate="no" dir="ltr">[filter_height * filter_width * in_channels, output_channels]</code>.</li> <li>Extracts image patches from the input tensor to form a <em>virtual</em> tensor of shape <code translate="no" dir="ltr">[batch, out_height, out_width, filter_height * filter_width * in_channels]</code>.</li> <li>For each patch, right-multiplies the filter matrix and the image patch vector.</li> </ol> <p>In detail, with the default NHWC format,</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">output[b, i, j, k] =
    sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
                    filter[di, dj, q, k]
</pre> <p>Must have <code translate="no" dir="ltr">strides[0] = strides[3] = 1</code>. For the most common case of the same horizontal and vertical strides, <code translate="no" dir="ltr">strides = [1, stride, stride, 1]</code>.</p> <h4 id="usage_example" data-text="Usage Example:">Usage Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x_in = np.array([[
  [[2], [1], [2], [0], [1]],
  [[1], [3], [2], [2], [3]],
  [[1], [1], [3], [3], [0]],
  [[2], [2], [0], [1], [1]],
  [[0], [0], [3], [1], [2]], ]])
kernel_in = np.array([
 [ [[2, 0.1]], [[3, 0.2]] ],
 [ [[0, 0.3]],[[1, 0.4]] ], ])
x = tf.constant(x_in, dtype=tf.float32)
kernel = tf.constant(kernel_in, dtype=tf.float32)
tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')
&lt;tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=..., dtype=float32)&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. A Tensor of rank at least 4. The dimension order is interpreted according to the value of <code translate="no" dir="ltr">data_format</code>; with the all-but-inner-3 dimensions acting as batch dimensions. See below for details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">filters</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">input</code>. A 4-D tensor of shape <code translate="no" dir="ltr">[filter_height, filter_width, in_channels, out_channels]</code> </td> </tr>
<tr> <td> <code translate="no" dir="ltr">strides</code> </td> <td> An int or list of <code translate="no" dir="ltr">ints</code> that has length <code translate="no" dir="ltr">1</code>, <code translate="no" dir="ltr">2</code> or <code translate="no" dir="ltr">4</code>. The stride of the sliding window for each dimension of <code translate="no" dir="ltr">input</code>. If a single value is given it is replicated in the <code translate="no" dir="ltr">H</code> and <code translate="no" dir="ltr">W</code> dimension. By default the <code translate="no" dir="ltr">N</code> and <code translate="no" dir="ltr">C</code> dimensions are set to 1. The dimension order is determined by the value of <code translate="no" dir="ltr">data_format</code>, see below for details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">padding</code> </td> <td> Either the <code translate="no" dir="ltr">string</code> <code translate="no" dir="ltr">"SAME"</code> or <code translate="no" dir="ltr">"VALID"</code> indicating the type of padding algorithm to use, or a list indicating the explicit paddings at the start and end of each dimension. See <a href="https://www.tensorflow.org/api_docs/python/tf/nn#notes_on_padding_2">here</a> for more information. When explicit padding is used and data_format is <code translate="no" dir="ltr">"NHWC"</code>, this should be in the form <code translate="no" dir="ltr">[[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]</code>. When explicit padding used and data_format is <code translate="no" dir="ltr">"NCHW"</code>, this should be in the form <code translate="no" dir="ltr">[[0, 0], [0, 0], [pad_top, pad_bottom], [pad_left, pad_right]]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">data_format</code> </td> <td> An optional <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"NHWC", "NCHW"</code>. Defaults to <code translate="no" dir="ltr">"NHWC"</code>. Specify the data format of the input and output data. With the default format "NHWC", the data is stored in the order of: <code translate="no" dir="ltr">batch_shape + [height, width, channels]</code>. Alternatively, the format could be "NCHW", the data storage order of: <code translate="no" dir="ltr">batch_shape + [channels, height, width]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dilations</code> </td> <td> An int or list of <code translate="no" dir="ltr">ints</code> that has length <code translate="no" dir="ltr">1</code>, <code translate="no" dir="ltr">2</code> or <code translate="no" dir="ltr">4</code>, defaults to 1. The dilation factor for each dimension of<code translate="no" dir="ltr">input</code>. If a single value is given it is replicated in the <code translate="no" dir="ltr">H</code> and <code translate="no" dir="ltr">W</code> dimension. By default the <code translate="no" dir="ltr">N</code> and <code translate="no" dir="ltr">C</code> dimensions are set to 1. If set to k &gt; 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of <code translate="no" dir="ltr">data_format</code>, see above for details. Dilations in the batch and depth dimensions if a 4-d tensor must be 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">input</code> and the same outer batch shape. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/conv2d" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/conv2d</a>
  </p>
</div>
