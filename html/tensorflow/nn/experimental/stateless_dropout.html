<h1 class="devsite-page-title">tf.nn.experimental.stateless_dropout</h1> <devsite-bookmark></devsite-bookmark>       <p>Computes dropout: randomly sets elements to zero to prevent overfitting.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/experimental/stateless_dropout"><code translate="no" dir="ltr">tf.compat.v1.nn.experimental.stateless_dropout</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.nn.experimental.stateless_dropout(
    x, rate, seed, rng_alg=None, noise_shape=None, name=None
)
</pre>  <p><a href="https://arxiv.org/abs/1207.0580">Dropout</a> is useful for regularizing DNN models. Inputs elements are randomly set to zero (and the other elements are rescaled). This encourages each node to be independently useful, as it cannot rely on the output of other nodes.</p> <p>More precisely: With probability <code translate="no" dir="ltr">rate</code> elements of <code translate="no" dir="ltr">x</code> are set to <code translate="no" dir="ltr">0</code>. The remaining elements are scaled up by <code translate="no" dir="ltr">1.0 / (1 - rate)</code>, so that the expected value is preserved.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.ones([3,5])
tf.nn.experimental.stateless_dropout(x, rate=0.5, seed=[1, 0])
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[2., 0., 2., 0., 0.],
       [0., 0., 2., 0., 2.],
       [0., 0., 0., 0., 2.]], dtype=float32)&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.ones([3,5])
tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[1, 0])
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[5., 0., 0., 0., 0.],
       [0., 0., 0., 0., 5.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.nn.experimental.stateless_dropout(x, rate=0.0, seed=[1, 0]) == x
&lt;tf.Tensor: shape=(3, 5), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True]])&gt;
</pre> <p>This function is a stateless version of <a href="../dropout.html"><code translate="no" dir="ltr">tf.nn.dropout</code></a>, in the sense that no matter how many times you call this function, the same <code translate="no" dir="ltr">seed</code> will lead to the same results, and different <code translate="no" dir="ltr">seed</code> will lead to different results.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.ones([3,5])
tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[1, 0])
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[5., 0., 0., 0., 0.],
       [0., 0., 0., 0., 5.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[1, 0])
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[5., 0., 0., 0., 0.],
       [0., 0., 0., 0., 5.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[2, 0])
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[5., 0., 0., 0., 0.],
       [0., 0., 0., 5., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[2, 0])
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[5., 0., 0., 0., 0.],
       [0., 0., 0., 5., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
</pre> <p>Compare the above results to those of <a href="../dropout.html"><code translate="no" dir="ltr">tf.nn.dropout</code></a> below. The second time <a href="../dropout.html"><code translate="no" dir="ltr">tf.nn.dropout</code></a> is called with the same seed, it will give a different output.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.random.set_seed(0)
x = tf.ones([3,5])
tf.nn.dropout(x, rate=0.8, seed=1)
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[0., 0., 0., 5., 5.],
       [0., 5., 0., 5., 0.],
       [5., 0., 5., 0., 5.]], dtype=float32)&gt;
tf.nn.dropout(x, rate=0.8, seed=1)
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 5., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
tf.nn.dropout(x, rate=0.8, seed=2)
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 5., 0., 5., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
tf.nn.dropout(x, rate=0.8, seed=2)
&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[0., 0., 0., 0., 0.],
       [5., 0., 5., 0., 5.],
       [0., 5., 0., 0., 5.]], dtype=float32)&gt;
</pre> <p>The difference between this function and <a href="../dropout.html"><code translate="no" dir="ltr">tf.nn.dropout</code></a> is analogous to the difference between <a href="../../random/stateless_uniform.html"><code translate="no" dir="ltr">tf.random.stateless_uniform</code></a> and <a href="../../random/uniform.html"><code translate="no" dir="ltr">tf.random.uniform</code></a>. Please see <a href="https://www.tensorflow.org/guide/random_numbers">Random number generation</a> guide for a detailed description of the various RNG systems in TF. As the guide states, legacy stateful RNG ops like <a href="../../random/uniform.html"><code translate="no" dir="ltr">tf.random.uniform</code></a> and <a href="../dropout.html"><code translate="no" dir="ltr">tf.nn.dropout</code></a> are not deprecated yet but highly discouraged, because their states are hard to control.</p> <p>By default, each element is kept or dropped independently. If <code translate="no" dir="ltr">noise_shape</code> is specified, it must be <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcastable</a> to the shape of <code translate="no" dir="ltr">x</code>, and only dimensions with <code translate="no" dir="ltr">noise_shape[i] == shape(x)[i]</code> will make independent decisions. This is useful for dropping whole channels from an image or sequence. For example:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.ones([3,10])
tf.nn.experimental.stateless_dropout(x, rate=2/3, noise_shape=[1,10],
                                     seed=[1, 0])
&lt;tf.Tensor: shape=(3, 10), dtype=float32, numpy=
array([[3., 0., 0., 0., 0., 0., 0., 3., 0., 3.],
       [3., 0., 0., 0., 0., 0., 0., 3., 0., 3.],
       [3., 0., 0., 0., 0., 0., 0., 3., 0., 3.]], dtype=float32)&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A floating point tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">rate</code> </td> <td> A scalar <code translate="no" dir="ltr">Tensor</code> with the same type as x. The probability that each element is dropped. For example, setting rate=0.1 would drop 10% of input elements. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">seed</code> </td> <td> An integer tensor of shape <code translate="no" dir="ltr">[2]</code>. The seed of the random numbers. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">rng_alg</code> </td> <td> The algorithm used to generate the random numbers (default to <code translate="no" dir="ltr">"auto_select"</code>). See the <code translate="no" dir="ltr">alg</code> argument of <a href="../../random/stateless_uniform.html"><code translate="no" dir="ltr">tf.random.stateless_uniform</code></a> for the supported values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">noise_shape</code> </td> <td> A 1-D integer <code translate="no" dir="ltr">Tensor</code>, representing the shape for randomly generated keep/drop flags. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for this operation. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A Tensor of the same shape and dtype of <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">rate</code> is not in <code translate="no" dir="ltr">[0, 1)</code> or if <code translate="no" dir="ltr">x</code> is not a floating point tensor. <code translate="no" dir="ltr">rate=1</code> is disallowed, because the output would be all zeros, which is likely not what was intended. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/experimental/stateless_dropout" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/experimental/stateless_dropout</a>
  </p>
</div>
