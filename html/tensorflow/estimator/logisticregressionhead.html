<h1 class="devsite-page-title">tf.estimator.LogisticRegressionHead</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py#L500-L583">  View source on GitHub </a> </td> </table> <p>Creates a <code translate="no" dir="ltr">Head</code> for logistic regression.</p> <p>Inherits From: <a href="regressionhead.html"><code translate="no" dir="ltr">RegressionHead</code></a>, <a href="head.html"><code translate="no" dir="ltr">Head</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/estimator/LogisticRegressionHead"><code translate="no" dir="ltr">tf.compat.v1.estimator.LogisticRegressionHead</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.estimator.LogisticRegressionHead(
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    name=None
)
</pre>  <p>Uses <code translate="no" dir="ltr">sigmoid_cross_entropy_with_logits</code> loss, which is the same as <code translate="no" dir="ltr">BinaryClassHead</code>. The differences compared to <code translate="no" dir="ltr">BinaryClassHead</code> are:</p> <ul> <li>Does not support <code translate="no" dir="ltr">label_vocabulary</code>. Instead, labels must be float in the range [0, 1].</li> <li>Does not calculate some metrics that do not make sense, such as AUC.</li> <li>In <code translate="no" dir="ltr">PREDICT</code> mode, only returns logits and predictions (<code translate="no" dir="ltr">=tf.sigmoid(logits)</code>), whereas <code translate="no" dir="ltr">BinaryClassHead</code> also returns probabilities, classes, and class_ids.</li> <li>Export output defaults to <code translate="no" dir="ltr">RegressionOutput</code>, whereas <code translate="no" dir="ltr">BinaryClassHead</code> defaults to <code translate="no" dir="ltr">PredictOutput</code>.</li> </ul> <p>The head expects <code translate="no" dir="ltr">logits</code> with shape <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>. In many applications, the shape is <code translate="no" dir="ltr">[batch_size, 1]</code>.</p> <p>The <code translate="no" dir="ltr">labels</code> shape must match <code translate="no" dir="ltr">logits</code>, namely <code translate="no" dir="ltr">[D0, D1, ... DN]</code> or <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>.</p> <p>If <code translate="no" dir="ltr">weight_column</code> is specified, weights must be of shape <code translate="no" dir="ltr">[D0, D1, ... DN]</code> or <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>.</p> <p>This is implemented as a generalized linear model, see <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">https://en.wikipedia.org/wiki/Generalized_linear_model</a></p> <p>The head can be used with a canned estimator. Example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">my_head = tf.estimator.LogisticRegressionHead()
my_estimator = tf.estimator.DNNEstimator(
    head=my_head,
    hidden_units=...,
    feature_columns=...)
</pre> <p>It can also be used with a custom <code translate="no" dir="ltr">model_fn</code>. Example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def _my_model_fn(features, labels, mode):
  my_head = tf.estimator.LogisticRegressionHead()
  logits = tf.keras.Model(...)(features)

  return my_head.create_estimator_spec(
      features=features,
      mode=mode,
      labels=labels,
      optimizer=tf.keras.optimizers.Adagrad(lr=0.1),
      logits=logits)

my_estimator = tf.estimator.Estimator(model_fn=_my_model_fn)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">weight_column</code> </td> <td> A string or a <code translate="no" dir="ltr">NumericColumn</code> created by <a href="../feature_column/numeric_column.html"><code translate="no" dir="ltr">tf.feature_column.numeric_column</code></a> defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss_reduction</code> </td> <td> One of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction"><code translate="no" dir="ltr">tf.losses.Reduction</code></a> except <code translate="no" dir="ltr">NONE</code>. Decides how to reduce training loss over batch and label dimension. Defaults to <code translate="no" dir="ltr">SUM_OVER_BATCH_SIZE</code>, namely weighted sum of losses divided by <code translate="no" dir="ltr">batch size * label_dimension</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> name of the head. If provided, summary and metrics keys will be suffixed by <code translate="no" dir="ltr">"/" + name</code>. Also used as <code translate="no" dir="ltr">name_scope</code> when creating ops. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">logits_dimension</code> </td> <td> See <code translate="no" dir="ltr">base_head.Head</code> for details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss_reduction</code> </td> <td> See <code translate="no" dir="ltr">base_head.Head</code> for details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> See <code translate="no" dir="ltr">base_head.Head</code> for details. </td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="create_estimator_spec" data-text="create_estimator_spec"><code translate="no" dir="ltr">create_estimator_spec</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/base_head.py#L224-L292">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
create_estimator_spec(
    features,
    mode,
    logits,
    labels=None,
    optimizer=None,
    trainable_variables=None,
    train_op_fn=None,
    update_ops=None,
    regularization_losses=None
)
</pre> <p>Returns <code translate="no" dir="ltr">EstimatorSpec</code> that a model_fn can return.</p> <p>It is recommended to pass all args via name.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">features</code> </td> <td> Input <code translate="no" dir="ltr">dict</code> mapping string feature names to <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects containing the values for that feature in a minibatch. Often to be used to fetch example-weight tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mode</code> </td> <td> Estimator's <code translate="no" dir="ltr">ModeKeys</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">logits</code> </td> <td> Logits <code translate="no" dir="ltr">Tensor</code> to be used by the head. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">labels</code> </td> <td> Labels <code translate="no" dir="ltr">Tensor</code>, or <code translate="no" dir="ltr">dict</code> mapping string label names to <code translate="no" dir="ltr">Tensor</code> objects of the label values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">optimizer</code> </td> <td> An <a href="../keras/optimizers/optimizer.html"><code translate="no" dir="ltr">tf.keras.optimizers.Optimizer</code></a> instance to optimize the loss in TRAIN mode. Namely, sets <code translate="no" dir="ltr">train_op = optimizer.get_updates(loss, trainable_variables)</code>, which updates variables to minimize <code translate="no" dir="ltr">loss</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable_variables</code> </td> <td> A list or tuple of <code translate="no" dir="ltr">Variable</code> objects to update to minimize <code translate="no" dir="ltr">loss</code>. In Tensorflow 1.x, by default these are the list of variables collected in the graph under the key <code translate="no" dir="ltr">GraphKeys.TRAINABLE_VARIABLES</code>. As Tensorflow 2.x doesn't have collections and GraphKeys, trainable_variables need to be passed explicitly here. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">train_op_fn</code> </td> <td> Function that takes a scalar loss <code translate="no" dir="ltr">Tensor</code> and returns an op to optimize the model with the loss in TRAIN mode. Used if <code translate="no" dir="ltr">optimizer</code> is <code translate="no" dir="ltr">None</code>. Exactly one of <code translate="no" dir="ltr">train_op_fn</code> and <code translate="no" dir="ltr">optimizer</code> must be set in TRAIN mode. By default, it is <code translate="no" dir="ltr">None</code> in other modes. If you want to optimize loss yourself, you can pass <code translate="no" dir="ltr">lambda _: tf.no_op()</code> and then use <a href="estimatorspec.html#loss"><code translate="no" dir="ltr">EstimatorSpec.loss</code></a> to compute and apply gradients. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">update_ops</code> </td> <td> A list or tuple of update ops to be run at training time. For example, layers such as BatchNormalization create mean and variance update ops that need to be run at training time. In Tensorflow 1.x, these are thrown into an UPDATE_OPS collection. As Tensorflow 2.x doesn't have collections, update_ops need to be passed explicitly here. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">regularization_losses</code> </td> <td> A list of additional scalar losses to be added to the training loss, such as regularization losses. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">EstimatorSpec</code>. </td> </tr> 
</table> <h3 id="loss" data-text="loss"><code translate="no" dir="ltr">loss</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py#L203-L226">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
loss(
    labels, logits, features=None, mode=None, regularization_losses=None
)
</pre> <p>Return predictions based on keys. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h3 id="metrics" data-text="metrics"><code translate="no" dir="ltr">metrics</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py#L254-L269">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
metrics(
    regularization_losses=None
)
</pre> <p>Creates metrics. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h3 id="predictions" data-text="predictions"><code translate="no" dir="ltr">predictions</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py#L228-L252">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
predictions(
    logits
)
</pre> <p>Return predictions based on keys.</p> <p>See <code translate="no" dir="ltr">base_head.Head</code> for details.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">logits</code> </td> <td> logits <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">[D0, D1, ... DN, logits_dimension]</code>. For many applications, the shape is <code translate="no" dir="ltr">[batch_size, logits_dimension]</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A dict of predictions. </td> </tr> 
</table> <h3 id="update_metrics" data-text="update_metrics"><code translate="no" dir="ltr">update_metrics</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py#L271-L297">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
update_metrics(
    eval_metrics, features, logits, labels, regularization_losses=None
)
</pre> <p>Updates eval metrics. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/estimator/LogisticRegressionHead" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/estimator/LogisticRegressionHead</a>
  </p>
</div>
