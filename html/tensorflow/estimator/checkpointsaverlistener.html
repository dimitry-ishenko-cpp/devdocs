<h1 class="devsite-page-title">tf.estimator.CheckpointSaverListener</h1> <devsite-bookmark></devsite-bookmark>       <p>Interface for listeners that take action before or after checkpoint save.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/estimator/CheckpointSaverListener"><code translate="no" dir="ltr">tf.compat.v1.estimator.CheckpointSaverListener</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/CheckpointSaverListener"><code translate="no" dir="ltr">tf.compat.v1.train.CheckpointSaverListener</code></a></p> </section>  <p><code translate="no" dir="ltr">CheckpointSaverListener</code> triggers only in steps when <code translate="no" dir="ltr">CheckpointSaverHook</code> is triggered, and provides callbacks at the following points:</p> <ul> <li>before using the session</li> <li>before each call to <code translate="no" dir="ltr">Saver.save()</code>
</li> <li>after each call to <code translate="no" dir="ltr">Saver.save()</code>
</li> <li>at the end of session</li> </ul> <p>To use a listener, implement a class and pass the listener to a <code translate="no" dir="ltr">CheckpointSaverHook</code>, as in this example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">class ExampleCheckpointSaverListener(CheckpointSaverListener):
  def begin(self):
    # You can add ops to the graph here.
    print('Starting the session.')
    self.your_tensor = ...

  def before_save(self, session, global_step_value):
    print('About to write a checkpoint')

  def after_save(self, session, global_step_value):
    print('Done writing checkpoint.')
    if decided_to_stop_training():
      return True

  def end(self, session, global_step_value):
    print('Done with the session.')

...
listener = ExampleCheckpointSaverListener()
saver_hook = tf.estimator.CheckpointSaverHook(
    checkpoint_dir, listeners=[listener])
with
tf.compat.v1.train.MonitoredTrainingSession(chief_only_hooks=[saver_hook]):
  ...
</pre> <p>A <code translate="no" dir="ltr">CheckpointSaverListener</code> may simply take some action after every checkpoint save. It is also possible for the listener to use its own schedule to act less frequently, e.g. based on global_step_value. In this case, implementors should implement the <code translate="no" dir="ltr">end()</code> method to handle actions related to the last checkpoint save. But the listener should not act twice if <code translate="no" dir="ltr">after_save()</code> already handled this last checkpoint save.</p> <p>A <code translate="no" dir="ltr">CheckpointSaverListener</code> can request training to be stopped, by returning True in <code translate="no" dir="ltr">after_save</code>. Please note that, in replicated distributed training setting, only <code translate="no" dir="ltr">chief</code> should use this behavior. Otherwise each worker will do their own evaluation, which may be wasteful of resources.</p> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="after_save" data-text="after_save"><code translate="no" dir="ltr">after_save</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/basic_session_run_hooks.py#L517-L518">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
after_save(
    session, global_step_value
)
</pre> <h3 id="before_save" data-text="before_save"><code translate="no" dir="ltr">before_save</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/basic_session_run_hooks.py#L514-L515">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
before_save(
    session, global_step_value
)
</pre> <h3 id="begin" data-text="begin"><code translate="no" dir="ltr">begin</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/basic_session_run_hooks.py#L511-L512">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
begin()
</pre> <h3 id="end" data-text="end"><code translate="no" dir="ltr">end</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/training/basic_session_run_hooks.py#L520-L521">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
end(
    session, global_step_value
)
</pre>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/estimator/CheckpointSaverListener" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/estimator/CheckpointSaverListener</a>
  </p>
</div>
