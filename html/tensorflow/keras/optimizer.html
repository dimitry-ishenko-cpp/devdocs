<h1 class="devsite-page-title" tabindex="-1"> tf.keras.Optimizer </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.Optimizer"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="add_variable"> <meta itemprop="property" content="add_variable_from_reference"> <meta itemprop="property" content="apply"> <meta itemprop="property" content="apply_gradients"> <meta itemprop="property" content="assign"> <meta itemprop="property" content="assign_add"> <meta itemprop="property" content="assign_sub"> <meta itemprop="property" content="build"> <meta itemprop="property" content="exclude_from_weight_decay"> <meta itemprop="property" content="finalize_variable_values"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="get_config"> <meta itemprop="property" content="load_own_variables"> <meta itemprop="property" content="save_own_variables"> <meta itemprop="property" content="scale_loss"> <meta itemprop="property" content="set_weights"> <meta itemprop="property" content="stateless_apply"> <meta itemprop="property" content="update_step"> </div>   <p>A class for Tensorflow specific optimizer logic.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="optimizer.html"><code translate="no" dir="ltr">tf.keras.optimizers.Optimizer</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="optimizer.html"><code translate="no" dir="ltr">tf.compat.v1.keras.Optimizer</code></a></p> </section> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.Optimizer(
    *args, **kwargs
)
</pre></devsite-code>  <p>The major behavior change for this class is for tf.distribute.</p> <p>It will override methods from base Keras core Optimizer, which provide distribute specific functionality, e.g. variable creation, loss reduction, etc.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">learning_rate</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">variables</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="add_variable" data-text="add_variable" tabindex="-1"><code translate="no" dir="ltr">add_variable</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L181-L201">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">add_variable(
    shape,
    initializer='zeros',
    dtype=None,
    aggregation='mean',
    name=None
)
</pre></devsite-code> <h3 id="add_variable_from_reference" data-text="add_variable_from_reference" tabindex="-1"><code translate="no" dir="ltr">add_variable_from_reference</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/backend/tensorflow/optimizer.py#L25-L38">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">add_variable_from_reference(
    reference_variable, name=None, initializer='zeros'
)
</pre></devsite-code> <p>Add an all-zeros variable with the shape and dtype of a reference variable.</p> <h3 id="apply" data-text="apply" tabindex="-1"><code translate="no" dir="ltr">apply</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L286-L355">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">apply(
    grads, trainable_variables=None
)
</pre></devsite-code> <p>Update traininable variables according to provided gradient values.</p> <p><code translate="no" dir="ltr">grads</code> should be a list of gradient tensors with 1:1 mapping to the list of variables the optimizer was built with.</p> <p><code translate="no" dir="ltr">trainable_variables</code> can be provided on the first call to build the optimizer.</p> <h3 id="apply_gradients" data-text="apply_gradients" tabindex="-1"><code translate="no" dir="ltr">apply_gradients</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L280-L284">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">apply_gradients(
    grads_and_vars
)
</pre></devsite-code> <h3 id="assign" data-text="assign" tabindex="-1"><code translate="no" dir="ltr">assign</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/backend/tensorflow/optimizer.py#L48-L55">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">assign(
    variable, value
)
</pre></devsite-code> <p>Assign a value to a variable.</p> <p>This should be used in optimizers instead of <code translate="no" dir="ltr">variable.assign(value)</code> to support backend specific optimizations. Note that the variable can be a model variable or an optimizer variable; it can be a backend native variable or a Keras variable.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">variable</code> </td> <td> The variable to update. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value</code> </td> <td> The value to add to the variable. </td> </tr> </table> <h3 id="assign_add" data-text="assign_add" tabindex="-1"><code translate="no" dir="ltr">assign_add</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/backend/tensorflow/optimizer.py#L57-L64">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">assign_add(
    variable, value
)
</pre></devsite-code> <p>Add a value to a variable.</p> <p>This should be used in optimizers instead of <code translate="no" dir="ltr">variable.assign_add(value)</code> to support backend specific optimizations. Note that the variable can be a model variable or an optimizer variable; it can be a backend native variable or a Keras variable.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">variable</code> </td> <td> The variable to update. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value</code> </td> <td> The value to add to the variable. </td> </tr> </table> <h3 id="assign_sub" data-text="assign_sub" tabindex="-1"><code translate="no" dir="ltr">assign_sub</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/backend/tensorflow/optimizer.py#L66-L73">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">assign_sub(
    variable, value
)
</pre></devsite-code> <p>Subtract a value from a variable.</p> <p>This should be used in optimizers instead of <code translate="no" dir="ltr">variable.assign_sub(value)</code> to support backend specific optimizations. Note that the variable can be a model variable or an optimizer variable; it can be a backend native variable or a Keras variable.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">variable</code> </td> <td> The variable to update. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value</code> </td> <td> The value to add to the variable. </td> </tr> </table> <h3 id="build" data-text="build" tabindex="-1"><code translate="no" dir="ltr">build</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L145-L168">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">build(
    variables
)
</pre></devsite-code> <h3 id="exclude_from_weight_decay" data-text="exclude_from_weight_decay" tabindex="-1"><code translate="no" dir="ltr">exclude_from_weight_decay</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L685-L723">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">exclude_from_weight_decay(
    var_list=None, var_names=None
)
</pre></devsite-code> <p>Exclude variables from weight decay.</p> <p>This method must be called before the optimizer's <code translate="no" dir="ltr">build</code> method is called. You can set specific variables to exclude out, or set a list of strings as the anchor words, if any of which appear in a variable's name, then the variable is excluded.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">var_list</code> </td> <td> A list of <code translate="no" dir="ltr">Variable</code>s to exclude from weight decay. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">var_names</code> </td> <td> A list of strings. If any string in <code translate="no" dir="ltr">var_names</code> appear in the model variable's name, then this model variable is excluded from weight decay. For example, <code translate="no" dir="ltr">var_names=['bias']</code> excludes all bias variables from weight decay. </td> </tr> </table> <h3 id="finalize_variable_values" data-text="finalize_variable_values" tabindex="-1"><code translate="no" dir="ltr">finalize_variable_values</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L803-L816">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">finalize_variable_values(
    var_list
)
</pre></devsite-code> <p>Set the final value of model's trainable variables.</p> <p>Sometimes there are some extra steps before ending the variable updates, such as overriding the model variables with its average value.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">var_list</code> </td> <td> list of model variables. </td> </tr> </table> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L866-L888">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config, custom_objects=None
)
</pre></devsite-code> <p>Creates an optimizer from its config.</p> <p>This method is the reverse of <code translate="no" dir="ltr">get_config</code>, capable of instantiating the same optimizer from the config dictionary.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">config</code> </td> <td> A Python dictionary, typically the output of get_config. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">custom_objects</code> </td> <td> A Python dictionary mapping names to additional user-defined Python objects needed to recreate this optimizer. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> An optimizer instance. </td> </tr> 
</table> <h3 id="get_config" data-text="get_config" tabindex="-1"><code translate="no" dir="ltr">get_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L821-L864">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">get_config()
</pre></devsite-code> <p>Returns the config of the optimizer.</p> <p>An optimizer config is a Python dictionary (serializable) containing the configuration of an optimizer. The same optimizer can be reinstantiated later (without any saved state) from this configuration.</p> <p>Subclass optimizer should override this method to include other hyperparameters.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Python dictionary. </td> </tr> 
</table> <h3 id="load_own_variables" data-text="load_own_variables" tabindex="-1"><code translate="no" dir="ltr">load_own_variables</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L567-L583">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">load_own_variables(
    store
)
</pre></devsite-code> <p>Set the state of this optimizer object.</p> <h3 id="save_own_variables" data-text="save_own_variables" tabindex="-1"><code translate="no" dir="ltr">save_own_variables</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L562-L565">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">save_own_variables(
    store
)
</pre></devsite-code> <p>Get the state of this optimizer object.</p> <h3 id="scale_loss" data-text="scale_loss" tabindex="-1"><code translate="no" dir="ltr">scale_loss</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L499-L508">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">scale_loss(
    loss
)
</pre></devsite-code> <p>Scale the loss before computing gradients.</p> <p>Scales the loss before gradients are computed in a <code translate="no" dir="ltr">train_step</code>. This is primarily useful during mixed precision training to prevent numeric underflow.</p> <h3 id="set_weights" data-text="set_weights" tabindex="-1"><code translate="no" dir="ltr">set_weights</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L544-L560">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">set_weights(
    weights
)
</pre></devsite-code> <p>Set the weights of the optimizer.</p> <h3 id="stateless_apply" data-text="stateless_apply" tabindex="-1"><code translate="no" dir="ltr">stateless_apply</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/backend/tensorflow/optimizer.py#L40-L46">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_apply(
    optimizer_variables, grads, trainable_variables
)
</pre></devsite-code> <h3 id="update_step" data-text="update_step" tabindex="-1"><code translate="no" dir="ltr">update_step</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/optimizers/base_optimizer.py#L277-L278">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">update_step(
    gradient, variable, learning_rate
)
</pre></devsite-code>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Optimizer" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/Optimizer</a>
  </p>
</div>
