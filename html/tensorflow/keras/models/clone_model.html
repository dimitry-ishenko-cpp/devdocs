<h1 class="devsite-page-title" tabindex="-1"> tf.keras.models.clone_model </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.models.clone_model"> <meta itemprop="path" content="Stable"> </div>   <p>Clone a Functional or Sequential <code translate="no" dir="ltr">Model</code> instance.</p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.models.clone_model(
    model,
    input_tensors=None,
    clone_function=None,
    call_function=None,
    recursive=False,
    **kwargs
)
</pre></devsite-code> <h3 id="used-in-the-notebooks" data-text="Used in the notebooks" tabindex="-1">Used in the notebooks</h3> <table class="vertical-rules"> <thead> <tr> <th>Used in the tutorials</th> </tr> </thead> <tbody> <tr> <td> <ul> <li><a href="https://www.tensorflow.org/tutorials/optimization/compression">Scalable model compression</a></li> <li><a href="https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation">Federated Learning for Text Generation</a></li> </ul> </td> </tr> </tbody> </table> <p>Model cloning is similar to calling a model on new inputs, except that it creates new layers (and thus new weights) instead of sharing the weights of the existing layers.</p> <p>Note that <code translate="no" dir="ltr">clone_model</code> will not preserve the uniqueness of shared objects within the model (e.g. a single variable attached to two distinct layers will be restored as two separate variables).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">model</code> </td> <td> Instance of <code translate="no" dir="ltr">Model</code> (could be a Functional model or a Sequential model). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_tensors</code> </td> <td> optional list of input tensors or InputLayer objects to build the model upon. If not provided, new <code translate="no" dir="ltr">Input</code> objects will be created. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">clone_function</code> </td> <td> Callable with signature <code translate="no" dir="ltr">fn(layer)</code> to be used to clone each layer in the target model (except <code translate="no" dir="ltr">Input</code> instances). It takes as argument the layer instance to be cloned, and returns the corresponding layer instance to be used in the model copy. If unspecified, this callable defaults to the following serialization/deserialization function: <code translate="no" dir="ltr">lambda layer: layer.__class__.from_config(layer.get_config())</code>. By passing a custom callable, you can customize your copy of the model, e.g. by wrapping certain layers of interest (you might want to replace all <code translate="no" dir="ltr">LSTM</code> instances with equivalent <code translate="no" dir="ltr">Bidirectional(LSTM(...))</code> instances, for example). Defaults to <code translate="no" dir="ltr">None</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">call_function</code> </td> <td> Callable with signature <code translate="no" dir="ltr">fn(layer, *args, **kwargs)</code> to be used to call each cloned layer and a set of inputs. It takes the layer instance, the call arguments and keyword arguments, and returns the call outputs. If unspecified, this callable defaults to the regular <code translate="no" dir="ltr">__call__()</code> method: <code translate="no" dir="ltr">def fn(layer, *args, **kwargs): return layer(*args, **kwargs)</code>. By passing a custom callable, you can insert new layers before or after a given layer. Note: this argument can only be used with Functional models. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">recursive</code> </td> <td> Boolean. Whether to recursively clone any Sequential or Functional models encountered in the original Sequential/Functional model. If <code translate="no" dir="ltr">False</code>, then inner models are cloned by calling <code translate="no" dir="ltr">clone_function()</code>. If <code translate="no" dir="ltr">True</code>, then inner models are cloned by calling <code translate="no" dir="ltr">clone_model()</code> with the same <code translate="no" dir="ltr">clone_function</code>, <code translate="no" dir="ltr">call_function</code>, and <code translate="no" dir="ltr">recursive</code> arguments. Note that in this case, <code translate="no" dir="ltr">call_function</code> will not be propagated to any Sequential model (since it is not applicable to Sequential models). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> An instance of <code translate="no" dir="ltr">Model</code> reproducing the behavior of the original model, on top of new inputs tensors, using newly instantiated weights. The cloned model may behave differently from the original model if a custom <code translate="no" dir="ltr">clone_function</code> or <code translate="no" dir="ltr">call_function</code> modifies a layer or layer call. </td> </tr> 
</table> <h4 id="example" data-text="Example:" tabindex="-1">Example:</h4> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp"># Create a test Sequential model.
model = keras.Sequential([
    keras.layers.Input(shape=(728,)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid'),
])
# Create a copy of the test model (with freshly initialized weights).
new_model = clone_model(model)
</pre></devsite-code> <p>Using a <code translate="no" dir="ltr">clone_function</code> to make a model deterministic by setting the random seed everywhere:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">def clone_function(layer):
    config = layer.get_config()
    if "seed" in config:
        config["seed"] = 1337
    return layer.__class__.from_config(config)

new_model = clone_model(model)
</pre></devsite-code> <p>Using a <code translate="no" dir="ltr">call_function</code> to add a <code translate="no" dir="ltr">Dropout</code> layer after each <code translate="no" dir="ltr">Dense</code> layer (without recreating new layers):</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">def call_function(layer, *args, **kwargs):
    out = layer(*args, **kwargs)
    if isinstance(layer, keras.layers.Dense):
        out = keras.layers.Dropout(0.5)(out)
    return out

new_model = clone_model(
    model,
    clone_function=lambda x: x,  # Reuse the same layers.
    call_function=call_function,
)
</pre></devsite-code> <p>Note that subclassed models cannot be cloned by default, since their internal layer structure is not known. To achieve equivalent functionality as <code translate="no" dir="ltr">clone_model</code> in the case of a subclassed model, simply make sure that the model class implements <code translate="no" dir="ltr">get_config()</code> (and optionally <code translate="no" dir="ltr">from_config()</code>), and call:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">new_model = model.__class__.from_config(model.get_config())
</pre></devsite-code> <p>In the case of a subclassed model, you cannot using a custom <code translate="no" dir="ltr">clone_function</code>.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model</a>
  </p>
</div>
