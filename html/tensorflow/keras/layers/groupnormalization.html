<h1 class="devsite-page-title" tabindex="-1"> tf.keras.layers.GroupNormalization </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.layers.GroupNormalization"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="symbolic_call"> </div>   <p>Group normalization layer.</p> <p>Inherits From: <a href="../layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../operation.html"><code translate="no" dir="ltr">Operation</code></a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.layers.GroupNormalization(
    groups=32,
    axis=-1,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer='zeros',
    gamma_initializer='ones',
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    **kwargs
)
</pre></devsite-code>  <p>Group Normalization divides the channels into groups and computes within each group the mean and variance for normalization. Empirically, its accuracy is more stable than batch norm in a wide range of small batch sizes, if learning rate is adjusted linearly with batch sizes.</p> <p>Relation to Layer Normalization: If the number of groups is set to 1, then this operation becomes nearly identical to Layer Normalization (see Layer Normalization docs for details).</p> <p>Relation to Instance Normalization: If the number of groups is set to the input dimension (number of groups is equal to number of channels), then this operation becomes identical to Instance Normalization. You can achieve this via <code translate="no" dir="ltr">groups=-1</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">groups</code> </td> <td> Integer, the number of groups for Group Normalization. Can be in the range <code translate="no" dir="ltr">[1, N]</code> where N is the input dimension. The input dimension must be divisible by the number of groups. Defaults to 32. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">axis</code> </td> <td> Integer or List/Tuple. The axis or axes to normalize across. Typically, this is the features axis/axes. The left-out axes are typically the batch axis/axes. -1 is the last dimension in the input. Defaults to <code translate="no" dir="ltr">-1</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">epsilon</code> </td> <td> Small float added to variance to avoid dividing by zero. Defaults to 1e-3. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">center</code> </td> <td> If <code translate="no" dir="ltr">True</code>, add offset of <code translate="no" dir="ltr">beta</code> to normalized tensor. If <code translate="no" dir="ltr">False</code>, <code translate="no" dir="ltr">beta</code> is ignored. Defaults to <code translate="no" dir="ltr">True</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">scale</code> </td> <td> If <code translate="no" dir="ltr">True</code>, multiply by <code translate="no" dir="ltr">gamma</code>. If <code translate="no" dir="ltr">False</code>, <code translate="no" dir="ltr">gamma</code> is not used. When the next layer is linear (also e.g. <code translate="no" dir="ltr">relu</code>), this can be disabled since the scaling will be done by the next layer. Defaults to <code translate="no" dir="ltr">True</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">beta_initializer</code> </td> <td> Initializer for the beta weight. Defaults to zeros. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">gamma_initializer</code> </td> <td> Initializer for the gamma weight. Defaults to ones. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">beta_regularizer</code> </td> <td> Optional regularizer for the beta weight. None by default. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">gamma_regularizer</code> </td> <td> Optional regularizer for the gamma weight. None by default. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">beta_constraint</code> </td> <td> Optional constraint for the beta weight. None by default. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">gamma_constraint</code> </td> <td> Optional constraint for the gamma weight. None by default. Input shape: Arbitrary. Use the keyword argument <code translate="no" dir="ltr">input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model. Output shape: Same shape as input. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Base layer keyword arguments (e.g. <code translate="no" dir="ltr">name</code> and <code translate="no" dir="ltr">dtype</code>). </td> </tr> </table> <h4 id="reference" data-text="Reference:" tabindex="-1">Reference:</h4> <ul> <li><a href="https://arxiv.org/abs/1803.08494">Yuxin Wu &amp; Kaiming He, 2018</a></li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> Retrieves the input tensor(s) of a symbolic operation. <p>Only returns the tensor(s) corresponding to the <em>first time</em> the operation was called. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">output</code> </td> <td> Retrieves the output tensor(s) of a layer. <p>Only returns the tensor(s) corresponding to the <em>first time</em> the operation was called. </p>
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/ops/operation.py#L191-L213">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config
)
</pre></devsite-code> <p>Creates a layer from its config.</p> <p>This method is the reverse of <code translate="no" dir="ltr">get_config</code>, capable of instantiating the same layer from the config dictionary. It does not handle layer connectivity (handled by Network), nor weights (handled by <code translate="no" dir="ltr">set_weights</code>).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">config</code> </td> <td> A Python dictionary, typically the output of get_config. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A layer instance. </td> </tr> 
</table> <h3 id="symbolic_call" data-text="symbolic_call" tabindex="-1"><code translate="no" dir="ltr">symbolic_call</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/ops/operation.py#L58-L70">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">symbolic_call(
    *args, **kwargs
)
</pre></devsite-code>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization</a>
  </p>
</div>
