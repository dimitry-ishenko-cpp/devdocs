<h1 class="devsite-page-title" tabindex="-1"> tf.keras.layers.InputLayer </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.layers.InputLayer"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="symbolic_call"> </div>   <p>This is the class from which all layers inherit.</p> <p>Inherits From: <a href="../layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../operation.html"><code translate="no" dir="ltr">Operation</code></a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.layers.InputLayer(
    shape=None,
    batch_size=None,
    dtype=None,
    sparse=None,
    batch_shape=None,
    input_tensor=None,
    name=None,
    **kwargs
)
</pre></devsite-code> <h3 id="used-in-the-notebooks" data-text="Used in the notebooks" tabindex="-1">Used in the notebooks</h3> <table class="vertical-rules"> <thead> <tr> <th>Used in the guide</th> <th>Used in the tutorials</th> </tr> </thead> <tbody> <tr> <td> <ul> <li><a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_for_on_device_inference">Pruning for on-device inference w/ XNNPACK</a></li> </ul> </td> <td> <ul> <li><a href="https://www.tensorflow.org/tutorials/generative/cvae">Convolutional Variational Autoencoder</a></li> <li><a href="https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras">Multi-worker training with Keras</a></li> <li><a href="https://www.tensorflow.org/lite/performance/post_training_quant">Post-training dynamic range quantization</a></li> <li><a href="https://www.tensorflow.org/hub/tutorials/tf2_image_retraining">Retraining an Image Classifier</a></li> <li><a href="https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification">Federated Learning for Image Classification</a></li> </ul> </td> </tr> </tbody> </table> <p>A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. It involves <em>computation</em>, defined in the <code translate="no" dir="ltr">call()</code> method, and a <em>state</em> (weight variables). State can be created:</p> <ul> <li>in <code translate="no" dir="ltr">__init__()</code>, for instance via <code translate="no" dir="ltr">self.add_weight()</code>;</li> <li>in the optional <code translate="no" dir="ltr">build()</code> method, which is invoked by the first <code translate="no" dir="ltr">__call__()</code> to the layer, and supplies the shape(s) of the input(s), which may not have been known at initialization time.</li> </ul> <p>Layers are recursively composable: If you assign a Layer instance as an attribute of another Layer, the outer layer will start tracking the weights created by the inner layer. Nested layers should be instantiated in the <code translate="no" dir="ltr">__init__()</code> method or <code translate="no" dir="ltr">build()</code> method.</p> <p>Users will just instantiate a layer and then treat it as a callable.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">trainable</code> </td> <td> Boolean, whether the layer's variables should be trainable. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> String name of the layer. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> The dtype of the layer's computations and weights. Can also be a <a href="../dtypepolicy.html"><code translate="no" dir="ltr">keras.DTypePolicy</code></a>, which allows the computation and weight dtype to differ. Defaults to <code translate="no" dir="ltr">None</code>. <code translate="no" dir="ltr">None</code> means to use <a href="../config/dtype_policy.html"><code translate="no" dir="ltr">keras.config.dtype_policy()</code></a>, which is a <code translate="no" dir="ltr">float32</code> policy unless set to different value (via <a href="../config/set_dtype_policy.html"><code translate="no" dir="ltr">keras.config.set_dtype_policy()</code></a>). </td> </tr> </table> <p>We recommend that descendants of <code translate="no" dir="ltr">Layer</code> implement the following methods:</p> <ul> <li>
<code translate="no" dir="ltr">__init__()</code>: Defines custom layer attributes, and creates layer weights that do not depend on input shapes, using <code translate="no" dir="ltr">add_weight()</code>, or other state.</li> <li>
<code translate="no" dir="ltr">build(self, input_shape)</code>: This method can be used to create weights that depend on the shape(s) of the input(s), using <code translate="no" dir="ltr">add_weight()</code>, or other state. <code translate="no" dir="ltr">__call__()</code> will automatically build the layer (if it has not been built yet) by calling <code translate="no" dir="ltr">build()</code>.</li> <li>
<code translate="no" dir="ltr">call(self, *args, **kwargs)</code>: Called in <code translate="no" dir="ltr">__call__</code> after making sure <code translate="no" dir="ltr">build()</code> has been called. <code translate="no" dir="ltr">call()</code> performs the logic of applying the layer to the input arguments. Two reserved keyword arguments you can optionally use in <code translate="no" dir="ltr">call()</code> are: 1. <code translate="no" dir="ltr">training</code> (boolean, whether the call is in inference mode or training mode). 2. <code translate="no" dir="ltr">mask</code> (boolean tensor encoding masked timesteps in the input, used e.g. in RNN layers). A typical signature for this method is <code translate="no" dir="ltr">call(self, inputs)</code>, and user could optionally add <code translate="no" dir="ltr">training</code> and <code translate="no" dir="ltr">mask</code> if the layer need them.</li> <li>
<code translate="no" dir="ltr">get_config(self)</code>: Returns a dictionary containing the configuration used to initialize this layer. If the keys differ from the arguments in <code translate="no" dir="ltr">__init__()</code>, then override <code translate="no" dir="ltr">from_config(self)</code> as well. This method is used when saving the layer or a model that contains this layer.</li> </ul> <h4 id="examples" data-text="Examples:" tabindex="-1">Examples:</h4> <p>Here's a basic example: a layer with two variables, <code translate="no" dir="ltr">w</code> and <code translate="no" dir="ltr">b</code>, that returns <code translate="no" dir="ltr">y = w . x + b</code>. It shows how to implement <code translate="no" dir="ltr">build()</code> and <code translate="no" dir="ltr">call()</code>. Variables set as attributes of a layer are tracked as weights of the layers (in <code translate="no" dir="ltr">layer.weights</code>).</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">class SimpleDense(Layer):
    def __init__(self, units=32):
        super().__init__()
        self.units = units

    # Create the state of the layer (weights)
    def build(self, input_shape):
        self.kernel = self.add_weight(
            shape=(input_shape[-1], self.units),
            initializer="glorot_uniform",
            trainable=True,
            name="kernel",
        )
        self.bias = self.add_weight(
            shape=(self.units,),
            initializer="zeros",
            trainable=True,
            name="bias",
        )

    # Defines the computation
    def call(self, inputs):
        return ops.matmul(inputs, self.kernel) + self.bias

# Instantiates the layer.
linear_layer = SimpleDense(4)

# This will also call `build(input_shape)` and create the weights.
y = linear_layer(ops.ones((2, 2)))
assert len(linear_layer.weights) == 2

# These weights are trainable, so they're listed in `trainable_weights`:
assert len(linear_layer.trainable_weights) == 2
</pre></devsite-code> <p>Besides trainable weights, updated via backpropagation during training, layers can also have non-trainable weights. These weights are meant to be updated manually during <code translate="no" dir="ltr">call()</code>. Here's a example layer that computes the running sum of its inputs:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">class ComputeSum(Layer):

  def __init__(self, input_dim):
      super(ComputeSum, self).__init__()
      # Create a non-trainable weight.
      self.total = self.add_weight(
        shape=(),
        initializer="zeros",
        trainable=False,
        name="total",
      )

  def call(self, inputs):
      self.total.assign(self.total + ops.sum(inputs))
      return self.total

my_sum = ComputeSum(2)
x = ops.ones((2, 2))
y = my_sum(x)

assert my_sum.weights == [my_sum.total]
assert my_sum.non_trainable_weights == [my_sum.total]
assert my_sum.trainable_weights == []
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> The name of the layer (string). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> Dtype of the layer's weights. Alias of <code translate="no" dir="ltr">layer.variable_dtype</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">variable_dtype</code> </td> <td> Dtype of the layer's weights. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">compute_dtype</code> </td> <td> The dtype of the layer's computations. Layers automatically cast inputs to this dtype, which causes the computations and output to also be in this dtype. When mixed precision is used with a <a href="../dtypepolicy.html"><code translate="no" dir="ltr">keras.DTypePolicy</code></a>, this will be different than <code translate="no" dir="ltr">variable_dtype</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable_weights</code> </td> <td> List of variables to be included in backprop. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">non_trainable_weights</code> </td> <td> List of variables that should not be included in backprop. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">weights</code> </td> <td> The concatenation of the lists trainable_weights and non_trainable_weights (in this order). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable</code> </td> <td> Whether the layer should be trained (boolean), i.e. whether its potentially-trainable weights should be returned as part of <code translate="no" dir="ltr">layer.trainable_weights</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_spec</code> </td> <td> Optional (list of) <code translate="no" dir="ltr">InputSpec</code> object(s) specifying the constraints on inputs that can be accepted by the layer. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> Retrieves the input tensor(s) of a symbolic operation. <p>Only returns the tensor(s) corresponding to the <em>first time</em> the operation was called. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">output</code> </td> <td> Retrieves the output tensor(s) of a layer. <p>Only returns the tensor(s) corresponding to the <em>first time</em> the operation was called. </p>
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/ops/operation.py#L191-L213">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config
)
</pre></devsite-code> <p>Creates a layer from its config.</p> <p>This method is the reverse of <code translate="no" dir="ltr">get_config</code>, capable of instantiating the same layer from the config dictionary. It does not handle layer connectivity (handled by Network), nor weights (handled by <code translate="no" dir="ltr">set_weights</code>).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">config</code> </td> <td> A Python dictionary, typically the output of get_config. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A layer instance. </td> </tr> 
</table> <h3 id="symbolic_call" data-text="symbolic_call" tabindex="-1"><code translate="no" dir="ltr">symbolic_call</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/ops/operation.py#L58-L70">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">symbolic_call(
    *args, **kwargs
)
</pre></devsite-code>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer</a>
  </p>
</div>
