<h1 class="devsite-page-title" tabindex="-1"> tf.keras.layers.Bidirectional </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.layers.Bidirectional"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="reset_state"> <meta itemprop="property" content="reset_states"> <meta itemprop="property" content="symbolic_call"> </div>   <p>Bidirectional wrapper for RNNs.</p> <p>Inherits From: <a href="../layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../operation.html"><code translate="no" dir="ltr">Operation</code></a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.layers.Bidirectional(
    layer,
    merge_mode='concat',
    weights=None,
    backward_layer=None,
    **kwargs
)
</pre></devsite-code> <h3 id="used-in-the-notebooks" data-text="Used in the notebooks" tabindex="-1">Used in the notebooks</h3> <table class="vertical-rules"> <thead> <tr> <th>Used in the tutorials</th> </tr> </thead> <tbody> <tr> <td> <ul> <li><a href="https://www.tensorflow.org/text/tutorials/text_classification_rnn">Text classification with an RNN</a></li> <li><a href="https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_lstm_imdb">Graph regularization for sentiment classification using synthesized graphs</a></li> <li><a href="https://www.tensorflow.org/text/tutorials/nmt_with_attention">Neural machine translation with attention</a></li> </ul> </td> </tr> </tbody> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">layer</code> </td> <td> <a href="rnn.html"><code translate="no" dir="ltr">keras.layers.RNN</code></a> instance, such as <a href="lstm.html"><code translate="no" dir="ltr">keras.layers.LSTM</code></a> or <a href="gru.html"><code translate="no" dir="ltr">keras.layers.GRU</code></a>. It could also be a <a href="../layer.html"><code translate="no" dir="ltr">keras.layers.Layer</code></a> instance that meets the following criteria: <ol> <li>Be a sequence-processing layer (accepts 3D+ inputs).</li> <li>Have a <code translate="no" dir="ltr">go_backwards</code>, <code translate="no" dir="ltr">return_sequences</code> and <code translate="no" dir="ltr">return_state</code> attribute (with the same semantics as for the <code translate="no" dir="ltr">RNN</code> class).</li> <li>Have an <code translate="no" dir="ltr">input_spec</code> attribute.</li> <li>Implement serialization via <code translate="no" dir="ltr">get_config()</code> and <code translate="no" dir="ltr">from_config()</code>. Note that the recommended way to create new RNN layers is to write a custom RNN cell and use it with <a href="rnn.html"><code translate="no" dir="ltr">keras.layers.RNN</code></a>, instead of subclassing <a href="../layer.html"><code translate="no" dir="ltr">keras.layers.Layer</code></a> directly. When <code translate="no" dir="ltr">return_sequences</code> is <code translate="no" dir="ltr">True</code>, the output of the masked timestep will be zero regardless of the layer's original <code translate="no" dir="ltr">zero_output_for_mask</code> value. </li>
</ol>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">merge_mode</code> </td> <td> Mode by which outputs of the forward and backward RNNs will be combined. One of <code translate="no" dir="ltr">{"sum", "mul", "concat", "ave", None}</code>. If <code translate="no" dir="ltr">None</code>, the outputs will not be combined, they will be returned as a list. Defaults to <code translate="no" dir="ltr">"concat"</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">backward_layer</code> </td> <td> Optional <a href="rnn.html"><code translate="no" dir="ltr">keras.layers.RNN</code></a>, or <a href="../layer.html"><code translate="no" dir="ltr">keras.layers.Layer</code></a> instance to be used to handle backwards input processing. If <code translate="no" dir="ltr">backward_layer</code> is not provided, the layer instance passed as the <code translate="no" dir="ltr">layer</code> argument will be used to generate the backward layer automatically. Note that the provided <code translate="no" dir="ltr">backward_layer</code> layer should have properties matching those of the <code translate="no" dir="ltr">layer</code> argument, in particular it should have the same values for <code translate="no" dir="ltr">stateful</code>, <code translate="no" dir="ltr">return_states</code>, <code translate="no" dir="ltr">return_sequences</code>, etc. In addition, <code translate="no" dir="ltr">backward_layer</code> and <code translate="no" dir="ltr">layer</code> should have different <code translate="no" dir="ltr">go_backwards</code> argument values. A <code translate="no" dir="ltr">ValueError</code> will be raised if these requirements are not met. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Call arguments</th></tr> <tr class="alt"> <td colspan="2"> The call arguments for this layer are the same as those of the wrapped RNN layer. Beware that when passing the <code translate="no" dir="ltr">initial_state</code> argument during the call of this layer, the first half in the list of elements in the <code translate="no" dir="ltr">initial_state</code> list will be passed to the forward RNN call and the last half in the list of elements will be passed to the backward RNN call. </td> </tr> 
</table> <blockquote class="note">
<strong>Note:</strong><span> instantiating a <code translate="no" dir="ltr">Bidirectional</code> layer from an existing RNN layer instance will not reuse the weights state of the RNN layer instance -- the <code translate="no" dir="ltr">Bidirectional</code> layer will have freshly initialized weights.</span>
</blockquote> <h4 id="examples" data-text="Examples:" tabindex="-1">Examples:</h4> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">model = Sequential([
    Input(shape=(5, 10)),
    Bidirectional(LSTM(10, return_sequences=True),
    Bidirectional(LSTM(10)),
    Dense(5, activation="softmax"),
])
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

# With custom backward layer
forward_layer = LSTM(10, return_sequences=True)
backward_layer = LSTM(10, activation='relu', return_sequences=True,
                      go_backwards=True)
model = Sequential([
    Input(shape=(5, 10)),
    Bidirectional(forward_layer, backward_layer=backward_layer),
    Dense(5, activation="softmax"),
])
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> Retrieves the input tensor(s) of a symbolic operation. <p>Only returns the tensor(s) corresponding to the <em>first time</em> the operation was called. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">output</code> </td> <td> Retrieves the output tensor(s) of a layer. <p>Only returns the tensor(s) corresponding to the <em>first time</em> the operation was called. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">states</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/layers/rnn/bidirectional.py#L309-L326">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config, custom_objects=None
)
</pre></devsite-code> <p>Creates a layer from its config.</p> <p>This method is the reverse of <code translate="no" dir="ltr">get_config</code>, capable of instantiating the same layer from the config dictionary. It does not handle layer connectivity (handled by Network), nor weights (handled by <code translate="no" dir="ltr">set_weights</code>).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">config</code> </td> <td> A Python dictionary, typically the output of get_config. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A layer instance. </td> </tr> 
</table> <h3 id="reset_state" data-text="reset_state" tabindex="-1"><code translate="no" dir="ltr">reset_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/layers/rnn/bidirectional.py#L261-L265">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">reset_state()
</pre></devsite-code> <h3 id="reset_states" data-text="reset_states" tabindex="-1"><code translate="no" dir="ltr">reset_states</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/layers/rnn/bidirectional.py#L257-L259">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">reset_states()
</pre></devsite-code> <h3 id="symbolic_call" data-text="symbolic_call" tabindex="-1"><code translate="no" dir="ltr">symbolic_call</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/ops/operation.py#L58-L70">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">symbolic_call(
    *args, **kwargs
)
</pre></devsite-code>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional</a>
  </p>
</div>
