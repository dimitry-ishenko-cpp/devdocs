<h1 class="devsite-page-title">tf.keras.layers.experimental.EinsumDense</h1> <devsite-bookmark></devsite-bookmark>       <p>A layer that uses tf.einsum as the backing computation.</p> <p>Inherits From: <a href="../layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../module.html"><code translate="no" dir="ltr">Module</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/EinsumDense"><code translate="no" dir="ltr">tf.compat.v1.keras.layers.experimental.EinsumDense</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.layers.experimental.EinsumDense(
    equation,
    output_shape,
    activation=None,
    bias_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
</pre>  <p>This layer can perform einsum calculations of arbitrary dimensionality.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">equation</code> </td> <td> An equation describing the einsum to perform. This equation must be a valid einsum string of the form <code translate="no" dir="ltr">ab,bc-&gt;ac</code>, <code translate="no" dir="ltr">...ab,bc-&gt;...ac</code>, or <code translate="no" dir="ltr">ab...,bc-&gt;ac...</code> where 'ab', 'bc', and 'ac' can be any valid einsum axis expression sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_shape</code> </td> <td> The expected shape of the output tensor (excluding the batch dimension and any dimensions represented by ellipses). You can specify None for any dimension that is unknown or can be inferred from the input shape. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activation</code> </td> <td> Activation function to use. If you don't specify anything, no activation is applied (that is, a "linear" activation: <code translate="no" dir="ltr">a(x) = x</code>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_axes</code> </td> <td> A string containing the output dimension(s) to apply a bias to. Each character in the <code translate="no" dir="ltr">bias_axes</code> string should correspond to a character in the output portion of the <code translate="no" dir="ltr">equation</code> string. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_initializer</code> </td> <td> Initializer for the <code translate="no" dir="ltr">kernel</code> weights matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_initializer</code> </td> <td> Initializer for the bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_regularizer</code> </td> <td> Regularizer function applied to the <code translate="no" dir="ltr">kernel</code> weights matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_regularizer</code> </td> <td> Regularizer function applied to the bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activity_regularizer</code> </td> <td> Regularizer function applied to the output of the layer (its "activation").. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_constraint</code> </td> <td> Constraint function applied to the <code translate="no" dir="ltr">kernel</code> weights matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_constraint</code> </td> <td> Constraint function applied to the bias vector. </td> </tr> </table> <h4 id="examples" data-text="Examples:">Examples:</h4> <p><strong>Biased dense layer with einsums</strong></p> <p>This example shows how to instantiate a standard Keras dense layer using einsum operations. This example is equivalent to <a href="../dense.html"><code translate="no" dir="ltr">tf.keras.layers.Dense(64, use_bias=True)</code></a>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
layer = EinsumDense("ab,bc-&gt;ac", output_shape=64, bias_axes="c")
input_tensor = tf.keras.Input(shape=[32])
output_tensor = layer(input_tensor)
output_tensor
&lt;... shape=(None, 64) dtype=...&gt;
</pre> <p><strong>Applying a dense layer to a sequence</strong></p> <p>This example shows how to instantiate a layer that applies the same dense operation to every element in a sequence. Here, the 'output_shape' has two values (since there are two non-batch dimensions in the output); the first dimension in the output_shape is <code translate="no" dir="ltr">None</code>, because the sequence dimension <code translate="no" dir="ltr">b</code> has an unknown shape.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
layer = EinsumDense("abc,cd-&gt;abd",
                    output_shape=(None, 64),
                    bias_axes="d")
input_tensor = tf.keras.Input(shape=[32, 128])
output_tensor = layer(input_tensor)
output_tensor
&lt;... shape=(None, 32, 64) dtype=...&gt;
</pre> <p><strong>Applying a dense layer to a sequence using ellipses</strong></p> <p>This example shows how to instantiate a layer that applies the same dense operation to every element in a sequence, but uses the ellipsis notation instead of specifying the batch and sequence dimensions.</p> <p>Because we are using ellipsis notation and have specified only one axis, the output_shape arg is a single value. When instantiated in this way, the layer can handle any number of sequence dimensions - including the case where no sequence dimension exists.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
layer = EinsumDense("...x,xy-&gt;...y", output_shape=64, bias_axes="y")
input_tensor = tf.keras.Input(shape=[32, 128])
output_tensor = layer(input_tensor)
output_tensor
&lt;... shape=(None, 32, 64) dtype=...&gt;
</pre>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/layers/experimental/EinsumDense" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/layers/experimental/EinsumDense</a>
  </p>
</div>
