<h1 class="devsite-page-title">tf.keras.layers.TimeDistributed</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/layers/rnn/time_distributed.py#L31-L327">  View source on GitHub </a> </td> </table> <p>This wrapper allows to apply a layer to every temporal slice of an input.</p> <p>Inherits From: <a href="wrapper.html"><code translate="no" dir="ltr">Wrapper</code></a>, <a href="layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../module.html"><code translate="no" dir="ltr">Module</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed"><code translate="no" dir="ltr">tf.compat.v1.keras.layers.TimeDistributed</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.layers.TimeDistributed(
    layer, **kwargs
)
</pre>  <p>Every input should be at least 3D, and the dimension of index one of the first input will be considered to be the temporal dimension.</p> <p>Consider a batch of 32 video samples, where each sample is a 128x128 RGB image with <code translate="no" dir="ltr">channels_last</code> data format, across 10 timesteps. The batch input shape is <code translate="no" dir="ltr">(32, 10, 128, 128, 3)</code>.</p> <p>You can then use <code translate="no" dir="ltr">TimeDistributed</code> to apply the same <code translate="no" dir="ltr">Conv2D</code> layer to each of the 10 timesteps, independently:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
inputs = tf.keras.Input(shape=(10, 128, 128, 3))
conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))
outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)
outputs.shape
TensorShape([None, 10, 126, 126, 64])
</pre> <p>Because <code translate="no" dir="ltr">TimeDistributed</code> applies the same instance of <code translate="no" dir="ltr">Conv2D</code> to each of the timestamps, the same set of weights are used at each timestamp.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">layer</code> </td> <td> a <a href="layer.html"><code translate="no" dir="ltr">tf.keras.layers.Layer</code></a> instance. </td> </tr> </table> <h4 id="call_arguments" data-text="Call arguments:">Call arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">inputs</code></b>: Input tensor of shape (batch, time, ...) or nested tensors, and each of which has shape (batch, time, ...).</li> <li>
<b><code translate="no" dir="ltr">training</code></b>: Python boolean indicating whether the layer should behave in training mode or in inference mode. This argument is passed to the wrapped layer (only if the layer supports this argument).</li> <li>
<b><code translate="no" dir="ltr">mask</code></b>: Binary tensor of shape <code translate="no" dir="ltr">(samples, timesteps)</code> indicating whether a given timestep should be masked. This argument is passed to the wrapped layer (only if the layer supports this argument).</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If not initialized with a <a href="layer.html"><code translate="no" dir="ltr">tf.keras.layers.Layer</code></a> instance. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/layers/TimeDistributed" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/layers/TimeDistributed</a>
  </p>
</div>
