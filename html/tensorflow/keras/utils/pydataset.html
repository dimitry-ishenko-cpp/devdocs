<h1 class="devsite-page-title" tabindex="-1"> tf.keras.utils.PyDataset </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.utils.PyDataset"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__getitem__"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="on_epoch_end"> </div>   <p>Base class for defining a parallel dataset using Python code.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="pydataset.html"><code translate="no" dir="ltr">tf.keras.utils.Sequence</code></a></p> </section> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.utils.PyDataset(
    workers=1, use_multiprocessing=False, max_queue_size=10
)
</pre></devsite-code>  <p>Every <code translate="no" dir="ltr">PyDataset</code> must implement the <code translate="no" dir="ltr">__getitem__()</code> and the <code translate="no" dir="ltr">__len__()</code> methods. If you want to modify your dataset between epochs, you may additionally implement <code translate="no" dir="ltr">on_epoch_end()</code>. The <code translate="no" dir="ltr">__getitem__()</code> method should return a complete batch (not a single sample), and the <code translate="no" dir="ltr">__len__</code> method should return the number of batches in the dataset (rather than the number of samples).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Number of workers to use in multithreading or multiprocessing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Whether to use Python multiprocessing for parallelism. Setting this to <code translate="no" dir="ltr">True</code> means that your dataset will be replicated in multiple forked processes. This is necessary to gain compute-level (rather than I/O level) benefits from parallelism. However it can only be set to <code translate="no" dir="ltr">True</code> if your dataset can be safely pickled. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> Maximum number of batches to keep in the queue when iterating over the dataset in a multithreaded or multipricessed setting. Reduce this value to reduce the CPU memory consumption of your dataset. Defaults to 10. </td> </tr> </table> <h4 id="notes" data-text="Notes:" tabindex="-1">Notes:</h4> <ul> <li>
<code translate="no" dir="ltr">PyDataset</code> is a safer way to do multiprocessing. This structure guarantees that the model will only train once on each sample per epoch, which is not the case with Python generators.</li> <li>The arguments <code translate="no" dir="ltr">workers</code>, <code translate="no" dir="ltr">use_multiprocessing</code>, and <code translate="no" dir="ltr">max_queue_size</code> exist to configure how <code translate="no" dir="ltr">fit()</code> uses parallelism to iterate over the dataset. They are not being used by the <code translate="no" dir="ltr">PyDataset</code> class directly. When you are manually iterating over a <code translate="no" dir="ltr">PyDataset</code>, no parallelism is applied.</li> </ul> <h4 id="example" data-text="Example:" tabindex="-1">Example:</h4> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">from skimage.io import imread
from skimage.transform import resize
import numpy as np
import math

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

class CIFAR10PyDataset(keras.utils.PyDataset):

    def __init__(self, x_set, y_set, batch_size, **kwargs):
        super().__init__(**kwargs)
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        # Return number of batches.
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        # Return x, y for batch idx.
        low = idx * self.batch_size
        # Cap upper bound at array length; the last batch may be smaller
        # if the total number of items is not a multiple of batch size.
        high = min(low + self.batch_size, len(self.x))
        batch_x = self.x[low:high]
        batch_y = self.y[low:high]

        return np.array([
            resize(imread(file_name), (200, 200))
               for file_name in batch_x]), np.array(batch_y)
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_batches</code> </td> <td> Number of batches in the PyDataset. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="on_epoch_end" data-text="on_epoch_end" tabindex="-1"><code translate="no" dir="ltr">on_epoch_end</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/trainers/data_adapters/py_dataset_adapter.py#L173-L175">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">on_epoch_end()
</pre></devsite-code> <p>Method called at the end of every epoch.</p> <h3 id="__getitem__" data-text="__getitem__" tabindex="-1"><code translate="no" dir="ltr">__getitem__</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/trainers/data_adapters/py_dataset_adapter.py#L146-L155">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">__getitem__(
    index
)
</pre></devsite-code> <p>Gets batch at position <code translate="no" dir="ltr">index</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">index</code> </td> <td> position of the batch in the PyDataset. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A batch </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/PyDataset" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/utils/PyDataset</a>
  </p>
</div>
