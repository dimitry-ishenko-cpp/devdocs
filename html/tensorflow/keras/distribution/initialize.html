<h1 class="devsite-page-title" tabindex="-1"> tf.keras.distribution.initialize </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.distribution.initialize"> <meta itemprop="path" content="Stable"> </div>   <p>Initialize the distribution system for multi-host/process setting.</p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.distribution.initialize(
    job_addresses=None, num_processes=None, process_id=None
)
</pre></devsite-code>  <p>Calling <code translate="no" dir="ltr">initialize</code> will prepare the backend for execution on multi-host GPU or TPUs. It should be called before any computations.</p> <p>Note that the parameters can also be injected via environment variables, which can be better controlled by the launch script at startup time. For certain backend that also rely on the environment variables to configure, Keras will properly forward them.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">job_addresses</code> </td> <td> string. Comma separated IP addresses for all the jobs that will form the whole computation cluster. Note that for JAX backend, only the address for job 0 (coodinator) is needed. For certain runtime like cloud TPU, this value can be <code translate="no" dir="ltr">None</code>, and the backend will figure it out with the TPU environment variables. You can also config this value via environment variable <code translate="no" dir="ltr">KERAS_DISTRIBUTION_JOB_ADDRESSES</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_processes</code> </td> <td> int. The number of worker/processes that will form the whole computation cluster. For certain runtime like cloud TPU, this value can be <code translate="no" dir="ltr">None</code>, and the backend will figure it out with the TPU environment variables. You can also configure this value via environment variable <code translate="no" dir="ltr">KERAS_DISTRIBUTION_NUM_PROCESSES</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">process_id</code> </td> <td> int. The ID number of the current worker/process. The value should be ranged from <code translate="no" dir="ltr">0</code> to <code translate="no" dir="ltr">num_processes - 1</code>. <code translate="no" dir="ltr">0</code> will indicate the current worker/process is the master/coordinate job. You can also configure this value via environment variable <code translate="no" dir="ltr">KERAS_DISTRIBUTION_PROCESS_ID</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">Example</code> </td> <td> Suppose there are two GPU processes, and process 0 is running at address <code translate="no" dir="ltr">10.0.0.1:1234</code>, and process 1 is running at address <code translate="no" dir="ltr">10.0.0.2:2345</code>. To configure such cluster, you can run <p>On process 0:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">keras.distribute.initialize(
    job_addresses="10.0.0.1:1234,10.0.0.2:2345",
    num_processes=2,
    process_id=0)
</pre></devsite-code> <p>On process 1:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">keras.distribute.initialize(
    job_addresses="10.0.0.1:1234,10.0.0.2:2345",
    num_processes=2,
    process_id=1)
</pre></devsite-code> <p>or via the environment variables: On process 0:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">os.environ[
    "KERAS_DISTRIBUTION_JOB_ADDRESSES"] = "10.0.0.1:1234,10.0.0.2:2345"
os.environ["KERAS_DISTRIBUTION_NUM_PROCESSES"] = "2
os.environ["KERAS_DISTRIBUTION_PROCESS_ID"] = "0"
keras.distribute.initialize()
</pre></devsite-code> <p>On process 1:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">os.environ[
    "KERAS_DISTRIBUTION_JOB_ADDRESSES"] = "10.0.0.1:1234,10.0.0.2:2345"
os.environ["KERAS_DISTRIBUTION_NUM_PROCESSES"] = "2
os.environ["KERAS_DISTRIBUTION_PROCESS_ID"] = "1"
keras.distribute.initialize()
</pre></devsite-code> <p>Also note that for JAX backend, the <code translate="no" dir="ltr">job_addresses</code> can be further reduced to just the master/coordinator address, which is <code translate="no" dir="ltr">10.0.0.1:1234</code>. </p>
</td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/distribution/initialize" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/distribution/initialize</a>
  </p>
</div>
