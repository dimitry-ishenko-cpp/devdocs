<h1 class="devsite-page-title" tabindex="-1"> tf.keras.metrics.AUC </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.metrics.AUC"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__call__"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="add_variable"> <meta itemprop="property" content="add_weight"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="get_config"> <meta itemprop="property" content="interpolate_pr_auc"> <meta itemprop="property" content="reset_state"> <meta itemprop="property" content="result"> <meta itemprop="property" content="stateless_reset_state"> <meta itemprop="property" content="stateless_result"> <meta itemprop="property" content="stateless_update_state"> <meta itemprop="property" content="update_state"> </div>   <p>Approximates the AUC (Area under the curve) of the ROC or PR curves.</p> <p>Inherits From: <a href="../metric.html"><code translate="no" dir="ltr">Metric</code></a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.metrics.AUC(
    num_thresholds=200,
    curve='ROC',
    summation_method='interpolation',
    name=None,
    dtype=None,
    thresholds=None,
    multi_label=False,
    num_labels=None,
    label_weights=None,
    from_logits=False
)
</pre></devsite-code> <h3 id="used-in-the-notebooks" data-text="Used in the notebooks" tabindex="-1">Used in the notebooks</h3> <table class="vertical-rules"> <thead> <tr> <th>Used in the tutorials</th> </tr> </thead> <tbody> <tr> <td> <ul> <li><a href="https://www.tensorflow.org/tutorials/structured_data/imbalanced_data">Classification on imbalanced data</a></li> <li><a href="https://www.tensorflow.org/federated/tutorials/sparse_federated_learning">Client-efficient large-model federated learning via `federated_select` and sparse aggregation</a></li> </ul> </td> </tr> </tbody> </table> <p>The AUC (Area under the curve) of the ROC (Receiver operating characteristic; default) or PR (Precision Recall) curves are quality measures of binary classifiers. Unlike the accuracy, and like cross-entropy losses, ROC-AUC and PR-AUC evaluate all the operational points of a model.</p> <p>This class approximates AUCs using a Riemann sum. During the metric accumulation phrase, predictions are accumulated within predefined buckets by value. The AUC is then computed by interpolating per-bucket averages. These buckets define the evaluated operational points.</p> <p>This metric creates four local variables, <code translate="no" dir="ltr">true_positives</code>, <code translate="no" dir="ltr">true_negatives</code>, <code translate="no" dir="ltr">false_positives</code> and <code translate="no" dir="ltr">false_negatives</code> that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.</p> <p>This value is ultimately returned as <code translate="no" dir="ltr">auc</code>, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The <code translate="no" dir="ltr">num_thresholds</code> variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on <code translate="no" dir="ltr">num_thresholds</code>. The <code translate="no" dir="ltr">thresholds</code> parameter can be used to manually specify thresholds which split the predictions more evenly.</p> <p>For a best approximation of the real AUC, <code translate="no" dir="ltr">predictions</code> should be distributed approximately uniformly in the range <code translate="no" dir="ltr">[0, 1]</code> (if <code translate="no" dir="ltr">from_logits=False</code>). The quality of the AUC approximation may be poor if this is not the case. Setting <code translate="no" dir="ltr">summation_method</code> to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC.</p> <p>If <code translate="no" dir="ltr">sample_weight</code> is <code translate="no" dir="ltr">None</code>, weights default to 1. Use <code translate="no" dir="ltr">sample_weight</code> of 0 to mask values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">num_thresholds</code> </td> <td> (Optional) The number of thresholds to use when discretizing the roc curve. Values must be &gt; 1. Defaults to <code translate="no" dir="ltr">200</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">curve</code> </td> <td> (Optional) Specifies the name of the curve to be computed, <code translate="no" dir="ltr">'ROC'</code> (default) or <code translate="no" dir="ltr">'PR'</code> for the Precision-Recall-curve. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">summation_method</code> </td> <td> (Optional) Specifies the <a href="https://en.wikipedia.org/wiki/Riemann_sum">Riemann summation method</a> used. 'interpolation' (default) applies mid-point summation scheme for <code translate="no" dir="ltr">ROC</code>. For PR-AUC, interpolates (true/false) positives but not the ratio that is precision (see Davis &amp; Goadrich 2006 for details); 'minoring' applies left summation for increasing intervals and right summation for decreasing intervals; 'majoring' does the opposite. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (Optional) string name of the metric instance. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> (Optional) data type of the metric result. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">thresholds</code> </td> <td> (Optional) A list of floating point values to use as the thresholds for discretizing the curve. If set, the <code translate="no" dir="ltr">num_thresholds</code> parameter is ignored. Values should be in <code translate="no" dir="ltr">[0, 1]</code>. Endpoint thresholds equal to {<code translate="no" dir="ltr">-epsilon</code>, <code translate="no" dir="ltr">1+epsilon</code>} for a small positive epsilon value will be automatically included with these to correctly handle predictions equal to exactly 0 or 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">multi_label</code> </td> <td> boolean indicating whether multilabel data should be treated as such, wherein AUC is computed separately for each label and then averaged across labels, or (when <code translate="no" dir="ltr">False</code>) if the data should be flattened into a single label before AUC computation. In the latter case, when multilabel data is passed to AUC, each label-prediction pair is treated as an individual data point. Should be set to <code translate="no" dir="ltr">False</code> for multi-class data. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_labels</code> </td> <td> (Optional) The number of labels, used when <code translate="no" dir="ltr">multi_label</code> is True. If <code translate="no" dir="ltr">num_labels</code> is not specified, then state variables get created on the first call to <code translate="no" dir="ltr">update_state</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">label_weights</code> </td> <td> (Optional) list, array, or tensor of non-negative weights used to compute AUCs for multilabel data. When <code translate="no" dir="ltr">multi_label</code> is True, the weights are applied to the individual label AUCs when they are averaged to produce the multi-label AUC. When it's False, they are used to weight the individual label predictions in computing the confusion matrix on the flattened data. Note that this is unlike <code translate="no" dir="ltr">class_weights</code> in that <code translate="no" dir="ltr">class_weights</code> weights the example depending on the value of its label, whereas <code translate="no" dir="ltr">label_weights</code> depends only on the index of that label before flattening; therefore <code translate="no" dir="ltr">label_weights</code> should not be used for multi-class data. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">from_logits</code> </td> <td> boolean indicating whether the predictions (<code translate="no" dir="ltr">y_pred</code> in <code translate="no" dir="ltr">update_state</code>) are probabilities or sigmoid logits. As a rule of thumb, when using a keras loss, the <code translate="no" dir="ltr">from_logits</code> constructor argument of the loss should match the AUC <code translate="no" dir="ltr">from_logits</code> constructor argument. </td> </tr> </table> <h4 id="example" data-text="Example:" tabindex="-1">Example:</h4> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">m = keras.metrics.AUC(num_thresholds=3)
m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])
# threshold values are [0 - 1e-7, 0.5, 1 + 1e-7]
# tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]
# tp_rate = recall = [1, 0.5, 0], fp_rate = [1, 0, 0]
# auc = ((((1 + 0.5) / 2) * (1 - 0)) + (((0.5 + 0) / 2) * (0 - 0)))
#     = 0.75
m.result()
0.75</pre></devsite-code> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">m.reset_state()
m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9],
               sample_weight=[1, 0, 0, 1])
m.result()
1.0</pre></devsite-code> <p>Usage with <code translate="no" dir="ltr">compile()</code> API:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp"># Reports the AUC of a model outputting a probability.
model.compile(optimizer='sgd',
              loss=keras.losses.BinaryCrossentropy(),
              metrics=[keras.metrics.AUC()])

# Reports the AUC of a model outputting a logit.
model.compile(optimizer='sgd',
              loss=keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=[keras.metrics.AUC(from_logits=True)])
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">thresholds</code> </td> <td> The thresholds used for evaluating AUC. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">variables</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="add_variable" data-text="add_variable" tabindex="-1"><code translate="no" dir="ltr">add_variable</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L186-L202">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">add_variable(
    shape, initializer, dtype=None, aggregation='sum', name=None
)
</pre></devsite-code> <h3 id="add_weight" data-text="add_weight" tabindex="-1"><code translate="no" dir="ltr">add_weight</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L204-L208">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">add_weight(
    shape=(), initializer=None, dtype=None, name=None
)
</pre></devsite-code> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L226-L228">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config
)
</pre></devsite-code> <h3 id="get_config" data-text="get_config" tabindex="-1"><code translate="no" dir="ltr">get_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L1560-L1579">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">get_config()
</pre></devsite-code> <p>Return the serializable config of the metric.</p> <h3 id="interpolate_pr_auc" data-text="interpolate_pr_auc" tabindex="-1"><code translate="no" dir="ltr">interpolate_pr_auc</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L1395-L1483">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">interpolate_pr_auc()
</pre></devsite-code> <p>Interpolation formula inspired by section 4 of Davis &amp; Goadrich 2006.</p> <p><a href="https://www.biostat.wisc.edu/~page/rocpr.pdf">https://www.biostat.wisc.edu/~page/rocpr.pdf</a></p> <p>Note here we derive &amp; use a closed formula not present in the paper as follows:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">Precision = TP / (TP + FP) = TP / P
</pre></devsite-code> <p>Modeling all of TP (true positive), FP (false positive) and their sum P = TP + FP (predicted positive) as varying linearly within each interval [A, B] between successive thresholds, we get</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">Precision slope = dTP / dP
                = (TP_B - TP_A) / (P_B - P_A)
                = (TP - TP_A) / (P - P_A)
Precision = (TP_A + slope * (P - P_A)) / P
</pre></devsite-code> <p>The area within the interval is (slope / total_pos_weight) times</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">int_A^B{Precision.dP} = int_A^B{(TP_A + slope * (P - P_A)) * dP / P}
int_A^B{Precision.dP} = int_A^B{slope * dP + intercept * dP / P}
</pre></devsite-code> <p>where intercept = TP_A - slope * P_A = TP_B - slope * P_B, resulting in</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">int_A^B{Precision.dP} = TP_B - TP_A + intercept * log(P_B / P_A)
</pre></devsite-code> <p>Bringing back the factor (slope / total_pos_weight) we'd put aside, we get</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">slope * [dTP + intercept *  log(P_B / P_A)] / total_pos_weight
</pre></devsite-code> <p>where dTP == TP_B - TP_A.</p> <p>Note that when P_A == 0 the above calculation simplifies into</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">int_A^B{Precision.dTP} = int_A^B{slope * dTP}
                       = slope * (TP_B - TP_A)
</pre></devsite-code> <p>which is really equivalent to imputing constant precision throughout the first bucket having &gt;0 true positives.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> 
<tr> <td> <code translate="no" dir="ltr">pr_auc</code> </td> <td> an approximation of the area under the P-R curve. </td> </tr> </table> <h3 id="reset_state" data-text="reset_state" tabindex="-1"><code translate="no" dir="ltr">reset_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L1548-L1558">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">reset_state()
</pre></devsite-code> <p>Reset all of the metric state variables.</p> <p>This function is called between epochs/steps, when a metric is evaluated during training.</p> <h3 id="result" data-text="result" tabindex="-1"><code translate="no" dir="ltr">result</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L1485-L1546">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">result()
</pre></devsite-code> <p>Compute the current metric value.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A scalar tensor, or a dictionary of scalar tensors. </td> </tr> 
</table> <h3 id="stateless_reset_state" data-text="stateless_reset_state" tabindex="-1"><code translate="no" dir="ltr">stateless_reset_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L164-L177">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_reset_state()
</pre></devsite-code> <h3 id="stateless_result" data-text="stateless_result" tabindex="-1"><code translate="no" dir="ltr">stateless_result</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L148-L162">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_result(
    metric_variables
)
</pre></devsite-code> <h3 id="stateless_update_state" data-text="stateless_update_state" tabindex="-1"><code translate="no" dir="ltr">stateless_update_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L115-L138">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_update_state(
    metric_variables, *args, **kwargs
)
</pre></devsite-code> <h3 id="update_state" data-text="update_state" tabindex="-1"><code translate="no" dir="ltr">update_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L1338-L1393">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">update_state(
    y_true, y_pred, sample_weight=None
)
</pre></devsite-code> <p>Accumulates confusion matrix statistics.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">y_true</code> </td> <td> The ground truth values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y_pred</code> </td> <td> The predicted values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional weighting of each example. Can be a tensor whose rank is either 0, or the same rank as <code translate="no" dir="ltr">y_true</code>, and must be broadcastable to <code translate="no" dir="ltr">y_true</code>. Defaults to <code translate="no" dir="ltr">1</code>. </td> </tr> </table> <h3 id="__call__" data-text="__call__" tabindex="-1"><code translate="no" dir="ltr">__call__</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L217-L220">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">__call__(
    *args, **kwargs
)
</pre></devsite-code> <p>Call self as a function.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC</a>
  </p>
</div>
