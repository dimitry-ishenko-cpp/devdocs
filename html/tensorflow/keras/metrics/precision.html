<h1 class="devsite-page-title" tabindex="-1"> tf.keras.metrics.Precision </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.metrics.Precision"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__call__"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="add_variable"> <meta itemprop="property" content="add_weight"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="get_config"> <meta itemprop="property" content="reset_state"> <meta itemprop="property" content="result"> <meta itemprop="property" content="stateless_reset_state"> <meta itemprop="property" content="stateless_result"> <meta itemprop="property" content="stateless_update_state"> <meta itemprop="property" content="update_state"> </div>   <p>Computes the precision of the predictions with respect to the labels.</p> <p>Inherits From: <a href="../metric.html"><code translate="no" dir="ltr">Metric</code></a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.keras.metrics.Precision(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
</pre></devsite-code> <h3 id="used-in-the-notebooks" data-text="Used in the notebooks" tabindex="-1">Used in the notebooks</h3> <table class="vertical-rules"> <thead> <tr> <th>Used in the tutorials</th> </tr> </thead> <tbody> <tr> <td> <ul> <li><a href="https://www.tensorflow.org/tutorials/structured_data/imbalanced_data">Classification on imbalanced data</a></li> <li><a href="https://www.tensorflow.org/federated/tutorials/sparse_federated_learning">Client-efficient large-model federated learning via `federated_select` and sparse aggregation</a></li> </ul> </td> </tr> </tbody> </table> <p>The metric creates two local variables, <code translate="no" dir="ltr">true_positives</code> and <code translate="no" dir="ltr">false_positives</code> that are used to compute the precision. This value is ultimately returned as <code translate="no" dir="ltr">precision</code>, an idempotent operation that simply divides <code translate="no" dir="ltr">true_positives</code> by the sum of <code translate="no" dir="ltr">true_positives</code> and <code translate="no" dir="ltr">false_positives</code>.</p> <p>If <code translate="no" dir="ltr">sample_weight</code> is <code translate="no" dir="ltr">None</code>, weights default to 1. Use <code translate="no" dir="ltr">sample_weight</code> of 0 to mask values.</p> <p>If <code translate="no" dir="ltr">top_k</code> is set, we'll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.</p> <p>If <code translate="no" dir="ltr">class_id</code> is specified, we calculate precision by considering only the entries in the batch for which <code translate="no" dir="ltr">class_id</code> is above the threshold and/or in the top-k highest predictions, and computing the fraction of them for which <code translate="no" dir="ltr">class_id</code> is indeed a correct label.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">thresholds</code> </td> <td> (Optional) A float value, or a Python list/tuple of float threshold values in <code translate="no" dir="ltr">[0, 1]</code>. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is <code translate="no" dir="ltr">True</code>, below is <code translate="no" dir="ltr">False</code>). If used with a loss function that sets <code translate="no" dir="ltr">from_logits=True</code> (i.e. no sigmoid applied to predictions), <code translate="no" dir="ltr">thresholds</code> should be set to 0. One metric value is generated for each threshold value. If neither <code translate="no" dir="ltr">thresholds</code> nor <code translate="no" dir="ltr">top_k</code> are set, the default is to calculate precision with <code translate="no" dir="ltr">thresholds=0.5</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">top_k</code> </td> <td> (Optional) Unset by default. An int value specifying the top-k predictions to consider when calculating precision. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">class_id</code> </td> <td> (Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval <code translate="no" dir="ltr">[0, num_classes)</code>, where <code translate="no" dir="ltr">num_classes</code> is the last dimension of predictions. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (Optional) string name of the metric instance. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> (Optional) data type of the metric result. </td> </tr> </table> <h4 id="example" data-text="Example:" tabindex="-1">Example:</h4> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">m = keras.metrics.Precision()
m.update_state([0, 1, 1, 1], [1, 0, 1, 1])
m.result()
0.6666667</pre></devsite-code> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">m.reset_state()
m.update_state([0, 1, 1, 1], [1, 0, 1, 1], sample_weight=[0, 0, 1, 0])
m.result()
1.0</pre></devsite-code> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp"># With top_k=2, it will calculate precision over y_true[:2]
# and y_pred[:2]
m = keras.metrics.Precision(top_k=2)
m.update_state([0, 0, 1, 1], [1, 1, 1, 1])
m.result()
0.0</pre></devsite-code> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp"># With top_k=4, it will calculate precision over y_true[:4]
# and y_pred[:4]
m = keras.metrics.Precision(top_k=4)
m.update_state([0, 0, 1, 1], [1, 1, 1, 1])
m.result()
0.5</pre></devsite-code> <p>Usage with <code translate="no" dir="ltr">compile()</code> API:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">model.compile(optimizer='sgd',
              loss='binary_crossentropy',
              metrics=[keras.metrics.Precision()])
</pre></devsite-code> <p>Usage with a loss with <code translate="no" dir="ltr">from_logits=True</code>:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">model.compile(optimizer='adam',
              loss=keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=[keras.metrics.Precision(thresholds=0)])
</pre></devsite-code>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">variables</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="add_variable" data-text="add_variable" tabindex="-1"><code translate="no" dir="ltr">add_variable</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L186-L202">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">add_variable(
    shape, initializer, dtype=None, aggregation='sum', name=None
)
</pre></devsite-code> <h3 id="add_weight" data-text="add_weight" tabindex="-1"><code translate="no" dir="ltr">add_weight</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L204-L208">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">add_weight(
    shape=(), initializer=None, dtype=None, name=None
)
</pre></devsite-code> <h3 id="from_config" data-text="from_config" tabindex="-1"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L226-L228">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
from_config(
    config
)
</pre></devsite-code> <h3 id="get_config" data-text="get_config" tabindex="-1"><code translate="no" dir="ltr">get_config</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L404-L411">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">get_config()
</pre></devsite-code> <p>Return the serializable config of the metric.</p> <h3 id="reset_state" data-text="reset_state" tabindex="-1"><code translate="no" dir="ltr">reset_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L399-L402">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">reset_state()
</pre></devsite-code> <p>Reset all of the metric state variables.</p> <p>This function is called between epochs/steps, when a metric is evaluated during training.</p> <h3 id="result" data-text="result" tabindex="-1"><code translate="no" dir="ltr">result</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L392-L397">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">result()
</pre></devsite-code> <p>Compute the current metric value.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A scalar tensor, or a dictionary of scalar tensors. </td> </tr> 
</table> <h3 id="stateless_reset_state" data-text="stateless_reset_state" tabindex="-1"><code translate="no" dir="ltr">stateless_reset_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L164-L177">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_reset_state()
</pre></devsite-code> <h3 id="stateless_result" data-text="stateless_result" tabindex="-1"><code translate="no" dir="ltr">stateless_result</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L148-L162">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_result(
    metric_variables
)
</pre></devsite-code> <h3 id="stateless_update_state" data-text="stateless_update_state" tabindex="-1"><code translate="no" dir="ltr">stateless_update_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L115-L138">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">stateless_update_state(
    metric_variables, *args, **kwargs
)
</pre></devsite-code> <h3 id="update_state" data-text="update_state" tabindex="-1"><code translate="no" dir="ltr">update_state</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/confusion_metrics.py#L366-L390">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">update_state(
    y_true, y_pred, sample_weight=None
)
</pre></devsite-code> <p>Accumulates true positive and false positive statistics.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">y_true</code> </td> <td> The ground truth values, with the same dimensions as <code translate="no" dir="ltr">y_pred</code>. Will be cast to <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y_pred</code> </td> <td> The predicted values. Each element must be in the range <code translate="no" dir="ltr">[0, 1]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional weighting of each example. Defaults to <code translate="no" dir="ltr">1</code>. Can be a tensor whose rank is either 0, or the same rank as <code translate="no" dir="ltr">y_true</code>, and must be broadcastable to <code translate="no" dir="ltr">y_true</code>. </td> </tr> </table> <h3 id="__call__" data-text="__call__" tabindex="-1"><code translate="no" dir="ltr">__call__</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L217-L220">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">__call__(
    *args, **kwargs
)
</pre></devsite-code> <p>Call self as a function.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision</a>
  </p>
</div>
