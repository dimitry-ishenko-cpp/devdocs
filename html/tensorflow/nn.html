<h1 class="devsite-page-title" tabindex="-1"> Module: tf.nn </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.nn"> <meta itemprop="path" content="Stable"> </div>   <p>Public API for tf._api.v2.nn namespace</p> <h2 id="modules" data-text="Modules" tabindex="-1">Modules</h2> <p><a href="nn/experimental.html"><code translate="no" dir="ltr">experimental</code></a> module: Public API for tf._api.v2.nn.experimental namespace</p> <h2 id="classes" data-text="Classes" tabindex="-1">Classes</h2> <p><a href="nn/rnncelldevicewrapper.html"><code translate="no" dir="ltr">class RNNCellDeviceWrapper</code></a>: Operator that ensures an RNNCell runs on a particular device. (deprecated)</p> <p><a href="nn/rnncelldropoutwrapper.html"><code translate="no" dir="ltr">class RNNCellDropoutWrapper</code></a>: Operator adding dropout to inputs and outputs of the given cell. (deprecated)</p> <p><a href="nn/rnncellresidualwrapper.html"><code translate="no" dir="ltr">class RNNCellResidualWrapper</code></a>: RNNCell wrapper that ensures cell inputs are added to the outputs. (deprecated)</p> <h2 id="functions" data-text="Functions" tabindex="-1">Functions</h2> <p><a href="random/all_candidate_sampler.html"><code translate="no" dir="ltr">all_candidate_sampler(...)</code></a>: Generate the set of all classes.</p> <p><a href="math/approx_max_k.html"><code translate="no" dir="ltr">approx_max_k(...)</code></a>: Returns max <code translate="no" dir="ltr">k</code> values and their indices of the input <code translate="no" dir="ltr">operand</code> in an approximate manner.</p> <p><a href="math/approx_min_k.html"><code translate="no" dir="ltr">approx_min_k(...)</code></a>: Returns min <code translate="no" dir="ltr">k</code> values and their indices of the input <code translate="no" dir="ltr">operand</code> in an approximate manner.</p> <p><a href="nn/atrous_conv2d.html"><code translate="no" dir="ltr">atrous_conv2d(...)</code></a>: Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p> <p><a href="nn/atrous_conv2d_transpose.html"><code translate="no" dir="ltr">atrous_conv2d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">atrous_conv2d</code>.</p> <p><a href="nn/avg_pool.html"><code translate="no" dir="ltr">avg_pool(...)</code></a>: Performs the avg pooling on the input.</p> <p><a href="nn/avg_pool1d.html"><code translate="no" dir="ltr">avg_pool1d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/avg_pool2d.html"><code translate="no" dir="ltr">avg_pool2d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/avg_pool3d.html"><code translate="no" dir="ltr">avg_pool3d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/batch_norm_with_global_normalization.html"><code translate="no" dir="ltr">batch_norm_with_global_normalization(...)</code></a>: Batch normalization.</p> <p><a href="nn/batch_normalization.html"><code translate="no" dir="ltr">batch_normalization(...)</code></a>: Batch normalization.</p> <p><a href="nn/bias_add.html"><code translate="no" dir="ltr">bias_add(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="nn/collapse_repeated.html"><code translate="no" dir="ltr">collapse_repeated(...)</code></a>: Merge repeated labels into single labels.</p> <p><a href="nn/compute_accidental_hits.html"><code translate="no" dir="ltr">compute_accidental_hits(...)</code></a>: Compute the position ids in <code translate="no" dir="ltr">sampled_candidates</code> matching <code translate="no" dir="ltr">true_classes</code>.</p> <p><a href="nn/compute_average_loss.html"><code translate="no" dir="ltr">compute_average_loss(...)</code></a>: Scales per-example losses with sample_weights and computes their average.</p> <p><a href="nn/conv1d.html"><code translate="no" dir="ltr">conv1d(...)</code></a>: Computes a 1-D convolution given 3-D input and filter tensors.</p> <p><a href="nn/conv1d_transpose.html"><code translate="no" dir="ltr">conv1d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv1d</code>.</p> <p><a href="nn/conv2d.html"><code translate="no" dir="ltr">conv2d(...)</code></a>: Computes a 2-D convolution given <code translate="no" dir="ltr">input</code> and 4-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/conv2d_transpose.html"><code translate="no" dir="ltr">conv2d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv2d</code>.</p> <p><a href="nn/conv3d.html"><code translate="no" dir="ltr">conv3d(...)</code></a>: Computes a 3-D convolution given 5-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/conv3d_transpose.html"><code translate="no" dir="ltr">conv3d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv3d</code>.</p> <p><a href="nn/conv_transpose.html"><code translate="no" dir="ltr">conv_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">convolution</code>.</p> <p><a href="nn/convolution.html"><code translate="no" dir="ltr">convolution(...)</code></a>: Computes sums of N-D convolutions (actually cross-correlation).</p> <p><a href="nn/crelu.html"><code translate="no" dir="ltr">crelu(...)</code></a>: Computes Concatenated ReLU.</p> <p><a href="nn/ctc_beam_search_decoder.html"><code translate="no" dir="ltr">ctc_beam_search_decoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p> <p><a href="nn/ctc_greedy_decoder.html"><code translate="no" dir="ltr">ctc_greedy_decoder(...)</code></a>: Performs greedy decoding on the logits given in input (best path).</p> <p><a href="nn/ctc_loss.html"><code translate="no" dir="ltr">ctc_loss(...)</code></a>: Computes CTC (Connectionist Temporal Classification) loss.</p> <p><a href="nn/ctc_unique_labels.html"><code translate="no" dir="ltr">ctc_unique_labels(...)</code></a>: Get unique labels and indices for batched labels for <a href="nn/ctc_loss.html"><code translate="no" dir="ltr">tf.nn.ctc_loss</code></a>.</p> <p><a href="nn/depth_to_space.html"><code translate="no" dir="ltr">depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="nn/depthwise_conv2d.html"><code translate="no" dir="ltr">depthwise_conv2d(...)</code></a>: Depthwise 2-D convolution.</p> <p><a href="nn/depthwise_conv2d_backprop_filter.html"><code translate="no" dir="ltr">depthwise_conv2d_backprop_filter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p> <p><a href="nn/depthwise_conv2d_backprop_input.html"><code translate="no" dir="ltr">depthwise_conv2d_backprop_input(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p> <p><a href="nn/dilation2d.html"><code translate="no" dir="ltr">dilation2d(...)</code></a>: Computes the grayscale dilation of 4-D <code translate="no" dir="ltr">input</code> and 3-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/dropout.html"><code translate="no" dir="ltr">dropout(...)</code></a>: Computes dropout: randomly sets elements to zero to prevent overfitting.</p> <p><a href="nn/elu.html"><code translate="no" dir="ltr">elu(...)</code></a>: Computes the exponential linear function.</p> <p><a href="nn/embedding_lookup.html"><code translate="no" dir="ltr">embedding_lookup(...)</code></a>: Looks up embeddings for the given <code translate="no" dir="ltr">ids</code> from a list of tensors.</p> <p><a href="nn/embedding_lookup_sparse.html"><code translate="no" dir="ltr">embedding_lookup_sparse(...)</code></a>: Looks up embeddings for the given ids and weights from a list of tensors.</p> <p><a href="nn/erosion2d.html"><code translate="no" dir="ltr">erosion2d(...)</code></a>: Computes the grayscale erosion of 4-D <code translate="no" dir="ltr">value</code> and 3-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="random/fixed_unigram_candidate_sampler.html"><code translate="no" dir="ltr">fixed_unigram_candidate_sampler(...)</code></a>: Samples a set of classes using the provided (fixed) base distribution.</p> <p><a href="nn/fractional_avg_pool.html"><code translate="no" dir="ltr">fractional_avg_pool(...)</code></a>: Performs fractional average pooling on the input.</p> <p><a href="nn/fractional_max_pool.html"><code translate="no" dir="ltr">fractional_max_pool(...)</code></a>: Performs fractional max pooling on the input.</p> <p><a href="nn/gelu.html"><code translate="no" dir="ltr">gelu(...)</code></a>: Compute the Gaussian Error Linear Unit (GELU) activation function.</p> <p><a href="math/in_top_k.html"><code translate="no" dir="ltr">in_top_k(...)</code></a>: Outputs whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="nn/isotonic_regression.html"><code translate="no" dir="ltr">isotonic_regression(...)</code></a>: Solves isotonic regression problems along the given axis.</p> <p><a href="nn/l2_loss.html"><code translate="no" dir="ltr">l2_loss(...)</code></a>: L2 Loss.</p> <p><a href="math/l2_normalize.html"><code translate="no" dir="ltr">l2_normalize(...)</code></a>: Normalizes along dimension <code translate="no" dir="ltr">axis</code> using an L2 norm. (deprecated arguments)</p> <p><a href="nn/leaky_relu.html"><code translate="no" dir="ltr">leaky_relu(...)</code></a>: Compute the Leaky ReLU activation function.</p> <p><a href="random/learned_unigram_candidate_sampler.html"><code translate="no" dir="ltr">learned_unigram_candidate_sampler(...)</code></a>: Samples a set of classes from a distribution learned during training.</p> <p><a href="nn/local_response_normalization.html"><code translate="no" dir="ltr">local_response_normalization(...)</code></a>: Local Response Normalization.</p> <p><a href="nn/log_poisson_loss.html"><code translate="no" dir="ltr">log_poisson_loss(...)</code></a>: Computes log Poisson loss given <code translate="no" dir="ltr">log_input</code>.</p> <p><a href="nn/log_softmax.html"><code translate="no" dir="ltr">log_softmax(...)</code></a>: Computes log softmax activations.</p> <p><a href="nn/local_response_normalization.html"><code translate="no" dir="ltr">lrn(...)</code></a>: Local Response Normalization.</p> <p><a href="nn/max_pool.html"><code translate="no" dir="ltr">max_pool(...)</code></a>: Performs max pooling on the input.</p> <p><a href="nn/max_pool1d.html"><code translate="no" dir="ltr">max_pool1d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool2d.html"><code translate="no" dir="ltr">max_pool2d(...)</code></a>: Performs max pooling on 2D spatial data such as images.</p> <p><a href="nn/max_pool3d.html"><code translate="no" dir="ltr">max_pool3d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool_with_argmax.html"><code translate="no" dir="ltr">max_pool_with_argmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p> <p><a href="nn/moments.html"><code translate="no" dir="ltr">moments(...)</code></a>: Calculates the mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/nce_loss.html"><code translate="no" dir="ltr">nce_loss(...)</code></a>: Computes and returns the noise-contrastive estimation training loss.</p> <p><a href="nn/normalize_moments.html"><code translate="no" dir="ltr">normalize_moments(...)</code></a>: Calculate the mean and variance of based on the sufficient statistics.</p> <p><a href="nn/pool.html"><code translate="no" dir="ltr">pool(...)</code></a>: Performs an N-D pooling operation.</p> <p><a href="nn/relu.html"><code translate="no" dir="ltr">relu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, 0)</code>.</p> <p><a href="nn/relu6.html"><code translate="no" dir="ltr">relu6(...)</code></a>: Computes Rectified Linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code>.</p> <p><a href="nn/safe_embedding_lookup_sparse.html"><code translate="no" dir="ltr">safe_embedding_lookup_sparse(...)</code></a>: Lookup embedding results, accounting for invalid IDs and empty features.</p> <p><a href="nn/sampled_softmax_loss.html"><code translate="no" dir="ltr">sampled_softmax_loss(...)</code></a>: Computes and returns the sampled softmax training loss.</p> <p><a href="nn/scale_regularization_loss.html"><code translate="no" dir="ltr">scale_regularization_loss(...)</code></a>: Scales the sum of the given regularization losses by number of replicas.</p> <p><a href="nn/selu.html"><code translate="no" dir="ltr">selu(...)</code></a>: Computes scaled exponential linear: <code translate="no" dir="ltr">scale * alpha * (exp(features) - 1)</code></p> <p><a href="nn/separable_conv2d.html"><code translate="no" dir="ltr">separable_conv2d(...)</code></a>: 2-D convolution with separable filters.</p> <p><a href="math/sigmoid.html"><code translate="no" dir="ltr">sigmoid(...)</code></a>: Computes sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="nn/sigmoid_cross_entropy_with_logits.html"><code translate="no" dir="ltr">sigmoid_cross_entropy_with_logits(...)</code></a>: Computes sigmoid cross entropy given <code translate="no" dir="ltr">logits</code>.</p> <p><a href="nn/silu.html"><code translate="no" dir="ltr">silu(...)</code></a>: Computes the SiLU or Swish activation function: <code translate="no" dir="ltr">x * sigmoid(beta * x)</code>.</p> <p><a href="nn/softmax.html"><code translate="no" dir="ltr">softmax(...)</code></a>: Computes softmax activations.</p> <p><a href="nn/softmax_cross_entropy_with_logits.html"><code translate="no" dir="ltr">softmax_cross_entropy_with_logits(...)</code></a>: Computes softmax cross entropy between <code translate="no" dir="ltr">logits</code> and <code translate="no" dir="ltr">labels</code>.</p> <p><a href="math/softplus.html"><code translate="no" dir="ltr">softplus(...)</code></a>: Computes elementwise softplus: <code translate="no" dir="ltr">softplus(x) = log(exp(x) + 1)</code>.</p> <p><a href="nn/softsign.html"><code translate="no" dir="ltr">softsign(...)</code></a>: Computes softsign: <code translate="no" dir="ltr">features / (abs(features) + 1)</code>.</p> <p><a href="space_to_batch.html"><code translate="no" dir="ltr">space_to_batch(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="nn/space_to_depth.html"><code translate="no" dir="ltr">space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="nn/sparse_softmax_cross_entropy_with_logits.html"><code translate="no" dir="ltr">sparse_softmax_cross_entropy_with_logits(...)</code></a>: Computes sparse softmax cross entropy between <code translate="no" dir="ltr">logits</code> and <code translate="no" dir="ltr">labels</code>.</p> <p><a href="nn/sufficient_statistics.html"><code translate="no" dir="ltr">sufficient_statistics(...)</code></a>: Calculate the sufficient statistics for the mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/silu.html"><code translate="no" dir="ltr">swish(...)</code></a>: Computes the SiLU or Swish activation function: <code translate="no" dir="ltr">x * sigmoid(beta * x)</code>.</p> <p><a href="math/tanh.html"><code translate="no" dir="ltr">tanh(...)</code></a>: Computes hyperbolic tangent of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="math/top_k.html"><code translate="no" dir="ltr">top_k(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest entries for the last dimension.</p> <p><a href="nn/weighted_cross_entropy_with_logits.html"><code translate="no" dir="ltr">weighted_cross_entropy_with_logits(...)</code></a>: Computes a weighted cross entropy.</p> <p><a href="nn/weighted_moments.html"><code translate="no" dir="ltr">weighted_moments(...)</code></a>: Returns the frequency-weighted mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/with_space_to_batch.html"><code translate="no" dir="ltr">with_space_to_batch(...)</code></a>: Performs <code translate="no" dir="ltr">op</code> on the space-to-batch representation of <code translate="no" dir="ltr">input</code>.</p> <p><a href="math/zero_fraction.html"><code translate="no" dir="ltr">zero_fraction(...)</code></a>: Returns the fraction of zeros in <code translate="no" dir="ltr">value</code>.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/nn" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/nn</a>
  </p>
</div>
