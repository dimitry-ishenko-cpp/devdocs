<h1 class="devsite-page-title">tf.test.Benchmark</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/platform/benchmark.py#L305-L437">  View source on GitHub </a> </td> </table> <p>Abstract class that provides helpers for TensorFlow benchmarks.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/test/Benchmark"><code translate="no" dir="ltr">tf.compat.v1.test.Benchmark</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.test.Benchmark()
</pre>  <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="evaluate" data-text="evaluate"><code translate="no" dir="ltr">evaluate</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/platform/benchmark.py#L427-L437">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
evaluate(
    tensors
)
</pre> <p>Evaluates tensors and returns numpy values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensors</code> </td> <td> A Tensor or a nested list/tuple of Tensors. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> tensors numpy values. </td> </tr> 
</table> <h3 id="is_abstract" data-text="is_abstract"><code translate="no" dir="ltr">is_abstract</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/platform/benchmark.py#L314-L318">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
is_abstract()
</pre> <h3 id="report_benchmark" data-text="report_benchmark"><code translate="no" dir="ltr">report_benchmark</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/platform/benchmark.py#L259-L288">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
report_benchmark(
    iters=None,
    cpu_time=None,
    wall_time=None,
    throughput=None,
    extras=None,
    name=None,
    metrics=None
)
</pre> <p>Report a benchmark.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">iters</code> </td> <td> (optional) How many iterations were run </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cpu_time</code> </td> <td> (optional) Median or mean cpu time in seconds. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wall_time</code> </td> <td> (optional) Median or mean wall time in seconds. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">throughput</code> </td> <td> (optional) Throughput (in MB/s) </td> </tr>
<tr> <td> <code translate="no" dir="ltr">extras</code> </td> <td> (optional) Dict mapping string keys to additional benchmark info. Values may be either floats or values that are convertible to strings. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (optional) Override the BenchmarkEntry name with <code translate="no" dir="ltr">name</code>. Otherwise it is inferred from the top-level method name. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">metrics</code> </td> <td> (optional) A list of dict, where each dict has the keys below name (required), string, metric name value (required), double, metric value min_value (optional), double, minimum acceptable metric value max_value (optional), double, maximum acceptable metric value </td> </tr> </table> <h3 id="run_op_benchmark" data-text="run_op_benchmark"><code translate="no" dir="ltr">run_op_benchmark</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/platform/benchmark.py#L320-L425">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
run_op_benchmark(
    sess,
    op_or_tensor,
    feed_dict=None,
    burn_iters=2,
    min_iters=10,
    store_trace=False,
    store_memory_usage=True,
    name=None,
    extras=None,
    mbs=0
)
</pre> <p>Run an op or tensor in the given session. Report the results.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">sess</code> </td> <td> <code translate="no" dir="ltr">Session</code> object to use for timing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">op_or_tensor</code> </td> <td> <code translate="no" dir="ltr">Operation</code> or <code translate="no" dir="ltr">Tensor</code> to benchmark. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">feed_dict</code> </td> <td> A <code translate="no" dir="ltr">dict</code> of values to feed for each op iteration (see the <code translate="no" dir="ltr">feed_dict</code> parameter of <code translate="no" dir="ltr">Session.run</code>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">burn_iters</code> </td> <td> Number of burn-in iterations to run. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">min_iters</code> </td> <td> Minimum number of iterations to use for timing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">store_trace</code> </td> <td> Boolean, whether to run an extra untimed iteration and store the trace of iteration in returned extras. The trace will be stored as a string in Google Chrome trace format in the extras field "full_trace_chrome_format". Note that trace will not be stored in test_log_pb2.TestResults proto. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">store_memory_usage</code> </td> <td> Boolean, whether to run an extra untimed iteration, calculate memory usage, and store that in extras fields. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (optional) Override the BenchmarkEntry name with <code translate="no" dir="ltr">name</code>. Otherwise it is inferred from the top-level method name. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">extras</code> </td> <td> (optional) Dict mapping string keys to additional benchmark info. Values may be either floats or values that are convertible to strings. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mbs</code> </td> <td> (optional) The number of megabytes moved by this op, used to calculate the ops throughput. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">dict</code> containing the key-value pairs that were passed to <code translate="no" dir="ltr">report_benchmark</code>. If <code translate="no" dir="ltr">store_trace</code> option is used, then <code translate="no" dir="ltr">full_chrome_trace_format</code> will be included in return dictionary even though it is not passed to <code translate="no" dir="ltr">report_benchmark</code> with <code translate="no" dir="ltr">extras</code>. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/test/Benchmark" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/test/Benchmark</a>
  </p>
</div>
