<h1 class="devsite-page-title" tabindex="-1"> tf.test.Benchmark </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.test.Benchmark"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="evaluate"> <meta itemprop="property" content="is_abstract"> <meta itemprop="property" content="report_benchmark"> <meta itemprop="property" content="run_op_benchmark"> </div>   <p>Abstract class that provides helpers for TensorFlow benchmarks.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="benchmark.html"><code translate="no" dir="ltr">tf.compat.v1.test.Benchmark</code></a></p> </section> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.test.Benchmark()
</pre></devsite-code>  <h2 id="methods" data-text="Methods" tabindex="-1">Methods</h2> <h3 id="evaluate" data-text="evaluate" tabindex="-1"><code translate="no" dir="ltr">evaluate</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/platform/benchmark.py#L410-L420">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">evaluate(
    tensors
)
</pre></devsite-code> <p>Evaluates tensors and returns numpy values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensors</code> </td> <td> A Tensor or a nested list/tuple of Tensors. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> tensors numpy values. </td> </tr> 
</table> <h3 id="is_abstract" data-text="is_abstract" tabindex="-1"><code translate="no" dir="ltr">is_abstract</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/platform/benchmark.py#L297-L301">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">@classmethod
is_abstract()
</pre></devsite-code> <h3 id="report_benchmark" data-text="report_benchmark" tabindex="-1"><code translate="no" dir="ltr">report_benchmark</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/platform/benchmark.py#L242-L271">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">report_benchmark(
    iters=None,
    cpu_time=None,
    wall_time=None,
    throughput=None,
    extras=None,
    name=None,
    metrics=None
)
</pre></devsite-code> <p>Report a benchmark.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">iters</code> </td> <td> (optional) How many iterations were run </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cpu_time</code> </td> <td> (optional) Median or mean cpu time in seconds. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wall_time</code> </td> <td> (optional) Median or mean wall time in seconds. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">throughput</code> </td> <td> (optional) Throughput (in MB/s) </td> </tr>
<tr> <td> <code translate="no" dir="ltr">extras</code> </td> <td> (optional) Dict mapping string keys to additional benchmark info. Values may be either floats or values that are convertible to strings. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (optional) Override the BenchmarkEntry name with <code translate="no" dir="ltr">name</code>. Otherwise it is inferred from the top-level method name. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">metrics</code> </td> <td> (optional) A list of dict, where each dict has the keys below name (required), string, metric name value (required), double, metric value min_value (optional), double, minimum acceptable metric value max_value (optional), double, maximum acceptable metric value </td> </tr> </table> <h3 id="run_op_benchmark" data-text="run_op_benchmark" tabindex="-1"><code translate="no" dir="ltr">run_op_benchmark</code></h3> <p><a target="_blank" class="external" href="https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/platform/benchmark.py#L303-L408">View source</a></p> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">run_op_benchmark(
    sess,
    op_or_tensor,
    feed_dict=None,
    burn_iters=2,
    min_iters=10,
    store_trace=False,
    store_memory_usage=True,
    name=None,
    extras=None,
    mbs=0
)
</pre></devsite-code> <p>Run an op or tensor in the given session. Report the results.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">sess</code> </td> <td> <code translate="no" dir="ltr">Session</code> object to use for timing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">op_or_tensor</code> </td> <td> <code translate="no" dir="ltr">Operation</code> or <code translate="no" dir="ltr">Tensor</code> to benchmark. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">feed_dict</code> </td> <td> A <code translate="no" dir="ltr">dict</code> of values to feed for each op iteration (see the <code translate="no" dir="ltr">feed_dict</code> parameter of <code translate="no" dir="ltr">Session.run</code>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">burn_iters</code> </td> <td> Number of burn-in iterations to run. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">min_iters</code> </td> <td> Minimum number of iterations to use for timing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">store_trace</code> </td> <td> Boolean, whether to run an extra untimed iteration and store the trace of iteration in returned extras. The trace will be stored as a string in Google Chrome trace format in the extras field "full_trace_chrome_format". Note that trace will not be stored in test_log_pb2.TestResults proto. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">store_memory_usage</code> </td> <td> Boolean, whether to run an extra untimed iteration, calculate memory usage, and store that in extras fields. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (optional) Override the BenchmarkEntry name with <code translate="no" dir="ltr">name</code>. Otherwise it is inferred from the top-level method name. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">extras</code> </td> <td> (optional) Dict mapping string keys to additional benchmark info. Values may be either floats or values that are convertible to strings. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mbs</code> </td> <td> (optional) The number of megabytes moved by this op, used to calculate the ops throughput. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">dict</code> containing the key-value pairs that were passed to <code translate="no" dir="ltr">report_benchmark</code>. If <code translate="no" dir="ltr">store_trace</code> option is used, then <code translate="no" dir="ltr">full_chrome_trace_format</code> will be included in return dictionary even though it is not passed to <code translate="no" dir="ltr">report_benchmark</code> with <code translate="no" dir="ltr">extras</code>. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/test/Benchmark" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/test/Benchmark</a>
  </p>
</div>
