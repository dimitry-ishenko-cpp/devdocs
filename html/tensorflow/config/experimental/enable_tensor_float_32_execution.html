<h1 class="devsite-page-title" tabindex="-1"> tf.config.experimental.enable_tensor_float_32_execution </h1> <devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip nocontent" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it">    </devsite-feature-tooltip> <div class="devsite-page-title-meta"><devsite-view-release-notes></devsite-view-release-notes></div>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.config.experimental.enable_tensor_float_32_execution"> <meta itemprop="path" content="Stable"> </div>   <p>Enable or disable the use of TensorFloat-32 on supported hardware.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="-1">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="enable_tensor_float_32_execution.html"><code translate="no" dir="ltr">tf.compat.v1.config.experimental.enable_tensor_float_32_execution</code></a></p> </section> 
<devsite-code><pre class="devsite-click-to-copy tfo-signature-link" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">tf.config.experimental.enable_tensor_float_32_execution(
    enabled
)
</pre></devsite-code>  <p><a href="https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format">TensorFloat-32</a>, or TF32 for short, is a math mode for NVIDIA Ampere GPUs and above. TensorFloat-32 execution causes certain float32 ops, such as matrix multiplications and convolutions, to run much faster on such GPUs but with reduced precision. This reduced precision should not impact convergence of deep learning models in practice.</p> <p>TensorFloat-32 is enabled by default. TensorFloat-32 is only supported on NVIDIA GPUs starting with the Ampere generation, so older NVIDIA GPUs will use the full float32 precision regardless of whether TensorFloat-32 is enabled or not. If you want to use the full float32 precision on all GPUs, you can disable TensorFloat-32 execution with this function. For example:</p> 
<devsite-code><pre class="devsite-click-to-copy" translate="no" dir="ltr" is-upgraded syntax="Python" data-language="cpp">x = tf.fill((1024, 1024), 1.0001)
y = tf.fill((1024, 1024), 1.)
# TensorFloat-32 is enabled, so matmul is run with reduced precision
print(tf.linalg.matmul(x, y)[0, 0])  # 1024.0
tf.config.experimental.enable_tensor_float_32_execution(False)
# Matmul is run with full precision
print(tf.linalg.matmul(x, y)[0, 0])  # ~1024.1
</pre></devsite-code> <p>To check whether TensorFloat-32 execution is currently enabled, use <a href="tensor_float_32_execution_enabled.html"><code translate="no" dir="ltr">tf.config.experimental.tensor_float_32_execution_enabled</code></a>.</p> <p>If TensorFloat-32 is enabled, float32 inputs of supported ops, such as <a href="../../linalg/matmul.html"><code translate="no" dir="ltr">tf.linalg.matmul</code></a>, will be rounded from 23 bits of precision to 10 bits of precision in most cases. This allows the ops to execute much faster by utilizing the GPU's tensor cores. TensorFloat-32 has the same dynamic range as float32, meaning it is no more likely to underflow or overflow than float32. Ops still use float32 accumulation when TensorFloat-32 is enabled. Enabling or disabling TensorFloat-32 only affects Ampere GPUs and above.</p> <p>Note TensorFloat-32 is not always used in supported ops, as only inputs of certain shapes are supported. Support for more input shapes and more ops may be added in the future. As a result, precision of float32 ops may decrease in minor versions of TensorFlow.</p> <p>TensorFloat-32 is also used for some complex64 ops. Currently, TensorFloat-32 is used in fewer cases for complex64 as it is for float32.</p> <p>Simiarly to GPUs, TPUs also run certain float32 ops, like matrix multiplications and convolutions, with lower precision by default. Unlike GPUs, TPUs use bfloat16 precision instead of TensorFloat-32 precision for such ops. Disabling TensorFloat-32 with this function also causes TPUs to run float32 ops with the full float32 precision but with lower performance.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">enabled</code> </td> <td> Bool indicating whether to enable TensorFloat-32 execution. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_tensor_float_32_execution" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_tensor_float_32_execution</a>
  </p>
</div>
