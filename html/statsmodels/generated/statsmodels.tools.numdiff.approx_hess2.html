<h1 id="statsmodels-tools-numdiff-approx-hess2">statsmodels.tools.numdiff.approx_hess2</h1> <dl class="function"> <dt id="statsmodels.tools.numdiff.approx_hess2">
<code>statsmodels.tools.numdiff.approx_hess2(x, f, epsilon=None, args=(), kwargs={}, return_grad=False)</code> <a class="reference internal" href="http://www.statsmodels.org/stable/_modules/statsmodels/tools/numdiff.html#approx_hess2"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate Hessian with finite difference derivative approximation</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<ul class="first simple"> <li>
<strong>x</strong> (<em>array_like</em>) – value at which function derivative is evaluated</li> <li>
<strong>f</strong> (<em>function</em>) – function of one array f(x, <code>*args</code>, <code>**kwargs</code>)</li> <li>
<strong>epsilon</strong> (<em>float</em><em> or </em><em>array-like</em><em>, </em><em>optional</em>) – Stepsize used, if None, then stepsize is automatically chosen according to EPS**(1/3)*x.</li> <li>
<strong>args</strong> (<em>tuple</em>) – Arguments for function <code>f</code>.</li> <li>
<strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.2/library/stdtypes.html#dict" title="(in Python v3.2)">dict</a>) – Keyword arguments for function <code>f</code>.</li> <li>
<strong>return_grad</strong> (<em>bool</em>) – Whether or not to also return the gradient</li> </ul> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">

<ul class="simple"> <li>
<strong>hess</strong> (<em>ndarray</em>) – array of partial second derivatives, Hessian</li> <li>
<strong>grad</strong> (<em>nparray</em>) – Gradient if return_grad == True</li> </ul> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>Equation (8) in Ridout. Computes the Hessian as:</p> <pre data-language="python">1/(2*d_j*d_k) * ((f(x + d[j]*e[j] + d[k]*e[k]) - f(x + d[j]*e[j])) -
           (f(x + d[k]*e[k]) - f(x)) +
           (f(x - d[j]*e[j] - d[k]*e[k]) - f(x + d[j]*e[j])) -
           (f(x - d[k]*e[k]) - f(x)))
</pre> <p>where e[j] is a vector with element j == 1 and the rest are zero and d[i] is epsilon[i].</p> <h4 class="rubric">References</h4> <dl class="docutils"> <dt>Ridout, M.S. (2009) Statistical applications of the complex-step method</dt> <dd>of numerical differentiation. The American Statistician, 63, 66-74</dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2009&ndash;2012 Statsmodels Developers<br>&copy; 2006&ndash;2008 Scipy Developers<br>&copy; 2006 Jonathan E. Taylor<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://www.statsmodels.org/stable/generated/statsmodels.tools.numdiff.approx_hess2.html" class="_attribution-link">http://www.statsmodels.org/stable/generated/statsmodels.tools.numdiff.approx_hess2.html</a>
  </p>
</div>
