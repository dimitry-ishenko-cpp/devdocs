<h1 id="getting-started">Getting started</h1> <p>This very simple case-study is designed to get you up-and-running quickly with <code>statsmodels</code>. Starting from raw data, we will show the steps needed to estimate a statistical model and to draw a diagnostic plot. We will only use functions provided by <code>statsmodels</code> or its <code>pandas</code> and <code>patsy</code> dependencies.</p>  <h2 id="loading-modules-and-functions">Loading modules and functions</h2> <p>After <a class="reference external" href="install.html">installing statsmodels and its dependencies</a>, we load a few modules and functions:</p> <pre data-language="python">In [1]: from __future__ import print_function

In [2]: import statsmodels.api as sm

In [3]: import pandas

In [4]: from patsy import dmatrices
</pre> <p><a class="reference external" href="http://pandas.pydata.org/">pandas</a> builds on <code>numpy</code> arrays to provide rich data structures and data analysis tools. The <code>pandas.DataFrame</code> function provides labelled arrays of (potentially heterogenous) data, similar to the <code>R</code> “data.frame”. The <code>pandas.read_csv</code> function can be used to convert a comma-separated values file to a <code>DataFrame</code> object.</p> <p><a class="reference external" href="https://github.com/pydata/patsy">patsy</a> is a Python library for describing statistical models and building <a class="reference external" href="https://en.wikipedia.org/wiki/Design_matrix">Design Matrices</a> using <code>R</code>-like formulas.</p>   <h2 id="data">Data</h2> <p>We download the <a class="reference external" href="http://vincentarelbundock.github.io/Rdatasets/doc/HistData/Guerry.html">Guerry dataset</a>, a collection of historical data used in support of Andre-Michel Guerry’s 1833 <em>Essay on the Moral Statistics of France</em>. The data set is hosted online in comma-separated values format (CSV) by the <a class="reference external" href="http://vincentarelbundock.github.io/Rdatasets/">Rdatasets</a> repository. We could download the file locally and then load it using <code>read_csv</code>, but <code>pandas</code> takes care of all of this automatically for us:</p> <pre data-language="python">In [5]: df = sm.datasets.get_rdataset("Guerry", "HistData").data
</pre> <p>The <a class="reference external" href="iolib.html">Input/Output doc page</a> shows how to import from various other formats.</p> <p>We select the variables of interest and look at the bottom 5 rows:</p> <pre data-language="python">In [6]: vars = ['Department', 'Lottery', 'Literacy', 'Wealth', 'Region']

In [7]: df = df[vars]

In [8]: df[-5:]
Out[8]: 
      Department  Lottery  Literacy  Wealth Region
81        Vienne       40        25      68      W
82  Haute-Vienne       55        13      67      C
83        Vosges       14        62      82      E
84         Yonne       51        47      30      C
85         Corse       83        49      37    NaN
</pre> <p>Notice that there is one missing observation in the <em>Region</em> column. We eliminate it using a <code>DataFrame</code> method provided by <code>pandas</code>:</p> <pre data-language="python">In [9]: df = df.dropna()

In [10]: df[-5:]
Out[10]: 
      Department  Lottery  Literacy  Wealth Region
80        Vendee       68        28      56      W
81        Vienne       40        25      68      W
82  Haute-Vienne       55        13      67      C
83        Vosges       14        62      82      E
84         Yonne       51        47      30      C
</pre>   <h2 id="substantive-motivation-and-model">Substantive motivation and model</h2> <p>We want to know whether literacy rates in the 86 French departments are associated with per capita wagers on the Royal Lottery in the 1820s. We need to control for the level of wealth in each department, and we also want to include a series of dummy variables on the right-hand side of our regression equation to control for unobserved heterogeneity due to regional effects. The model is estimated using ordinary least squares regression (OLS).</p>   <h2 id="design-matrices-endog-exog">Design matrices (<em>endog</em> &amp; <em>exog</em>)</h2> <p>To fit most of the models covered by <code>statsmodels</code>, you will need to create two design matrices. The first is a matrix of endogenous variable(s) (i.e. dependent, response, regressand, etc.). The second is a matrix of exogenous variable(s) (i.e. independent, predictor, regressor, etc.). The OLS coefficient estimates are calculated as usual:</p> <div class="math notranslate nohighlight"> \[\hat{\beta} = (X'X)^{-1} X'y\]</div> <p>where <span class="math notranslate nohighlight">\(y\)</span> is an <span class="math notranslate nohighlight">\(N \times 1\)</span> column of data on lottery wagers per capita (<em>Lottery</em>). <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(N \times 7\)</span> with an intercept, the <em>Literacy</em> and <em>Wealth</em> variables, and 4 region binary variables.</p> <p>The <code>patsy</code> module provides a convenient function to prepare design matrices using <code>R</code>-like formulas. You can find more information <a class="reference external" href="http://patsy.readthedocs.io/en/latest/">here</a>.</p> <p>We use <code>patsy</code>’s <code>dmatrices</code> function to create design matrices:</p> <pre data-language="python">In [11]: y, X = dmatrices('Lottery ~ Literacy + Wealth + Region', data=df, return_type='dataframe')
</pre> <p>The resulting matrices/data frames look like this:</p> <pre data-language="python">In [12]: y[:3]
Out[12]: 
   Lottery
0     41.0
1     38.0
2     66.0

In [13]: X[:3]
</pre><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2009&ndash;2012 Statsmodels Developers<br>&copy; 2006&ndash;2008 Scipy Developers<br>&copy; 2006 Jonathan E. Taylor<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://www.statsmodels.org/stable/gettingstarted.html" class="_attribution-link">http://www.statsmodels.org/stable/gettingstarted.html</a>
  </p>
</div>
