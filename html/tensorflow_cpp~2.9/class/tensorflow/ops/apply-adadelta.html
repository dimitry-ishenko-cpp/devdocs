<devsite-bookmark></devsite-bookmark>    <h1 id="tensorflow::ops::applyadadelta" data-text="tensorflow::ops::ApplyAdadelta">tensorflow::ops::ApplyAdadelta</h1> <p><code translate="no" dir="ltr">#include &lt;training_ops.h&gt;</code></p> <p>Update '*var' according to the adadelta scheme. </p> <h2 id="summary" data-text="Summary">Summary</h2> <p>accum = rho() * accum + (1 - rho()) * grad.square(); update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad; update_accum = rho() * update_accum + (1 - rho()) * update.square(); var -= update;</p> <p>Args:</p>
<ul> <li>scope: A <a href="../scope.html#classtensorflow_1_1_scope">Scope</a> object</li> <li>var: Should be from a Variable().</li> <li>accum: Should be from a Variable().</li> <li>accum_update: Should be from a Variable().</li> <li>lr: Scaling factor. Must be a scalar.</li> <li>rho: Decay factor. Must be a scalar.</li> <li>epsilon: Constant factor. Must be a scalar.</li> <li>grad: The gradient.</li> </ul> <p>Optional attributes (see <code translate="no" dir="ltr"><a href="../../../struct/tensorflow/ops/apply-adadelta/attrs.html#structtensorflow_1_1ops_1_1_apply_adadelta_1_1_attrs">Attrs</a></code>):</p>
<ul> <li>use_locking: If True, updating of the var, accum and update_accum tensors will be protected by a lock; otherwise the behavior is undefined, but may exhibit less contention.</li> </ul> <p>Returns:</p>
<ul> <li>
<code translate="no" dir="ltr"><a href="../output.html#classtensorflow_1_1_output">Output</a></code>: Same as "var". </li> </ul> <table class="constructors responsive"> <tr> <th colspan="2"> Constructors and Destructors </th> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1aa28344b035c47c459fd0afca95547d97">ApplyAdadelta</a>(const ::<a href="../scope.html#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> var, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> accum, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> accum_update, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> lr, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> rho, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> epsilon, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> grad)</code> <br> </td> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1a08f5d27287a3064abb5e3b83fadbe887">ApplyAdadelta</a>(const ::<a href="../scope.html#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> var, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> accum, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> accum_update, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> lr, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> rho, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> epsilon, ::<a href="../input.html#classtensorflow_1_1_input">tensorflow::Input</a> grad, const <a href="../../../struct/tensorflow/ops/apply-adadelta/attrs.html#structtensorflow_1_1ops_1_1_apply_adadelta_1_1_attrs">ApplyAdadelta::Attrs</a> &amp; attrs)</code> <br> </td> </tr> </table> <table class="properties responsive"> <tr> <th colspan="2"> Public attributes </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1a4bcd49cd72b4103e0041a1231ad7cbfb">operation</a></code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../operation.html#classtensorflow_1_1_operation">Operation</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1aaa46dd79340e6999dac483165b45499d">out</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output.html#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> </table> <table class="methods responsive"> <tr> <th colspan="2"> Public functions </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1a7ab3d73516eacd84efdba9d4c8bb31dd">node</a>() const </code> </td> <td> <div> <code translate="no" dir="ltr">::tensorflow::Node *</code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1aa0992e4c234bd33403c057425829457c">operator::tensorflow::Input</a>() const </code> </td> <td>  </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1a0d01185e91e72c289949de8ca852c923">operator::tensorflow::Output</a>() const </code> </td> <td>  </td> </tr> </table> <table class="methods responsive"> <tr> <th colspan="2"> Public static functions </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_apply_adadelta_1a8545cc26c688935679d0a732a1407986">UseLocking</a>(bool x)</code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../../../struct/tensorflow/ops/apply-adadelta/attrs.html#structtensorflow_1_1ops_1_1_apply_adadelta_1_1_attrs">Attrs</a></code> </div> </td> </tr> </table> <table class="constants responsive"> <tr> <th colspan="2"> Structs </th> </tr> <tr> <td> <a href="../../../struct/tensorflow/ops/apply-adadelta/attrs.html">tensorflow::ops::ApplyAdadelta::Attrs</a> </td> <td> <p>Optional attribute setters for <a href="apply-adadelta.html#classtensorflow_1_1ops_1_1_apply_adadelta">ApplyAdadelta</a>. </p> </td> </tr> </table> <h2 id="public-attributes_1" data-text="Public attributes">Public attributes</h2> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1a4bcd49cd72b4103e0041a1231ad7cbfb"> <h3 id="operation" data-text="operation">operation</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">Operation operation</pre>  </div> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1aaa46dd79340e6999dac483165b45499d"> <h3 id="out" data-text="out">out</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">::tensorflow::Output out</pre>  </div> <h2 id="public-functions_1" data-text="Public functions">Public functions</h2> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1aa28344b035c47c459fd0afca95547d97"> <h3 id="applyadadelta" data-text="ApplyAdadelta">ApplyAdadelta</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp"> ApplyAdadelta(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input var,
  ::tensorflow::Input accum,
  ::tensorflow::Input accum_update,
  ::tensorflow::Input lr,
  ::tensorflow::Input rho,
  ::tensorflow::Input epsilon,
  ::tensorflow::Input grad
)</pre>  </div> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1a08f5d27287a3064abb5e3b83fadbe887"> <h3 id="applyadadelta_1" data-text="ApplyAdadelta">ApplyAdadelta</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp"> ApplyAdadelta(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input var,
  ::tensorflow::Input accum,
  ::tensorflow::Input accum_update,
  ::tensorflow::Input lr,
  ::tensorflow::Input rho,
  ::tensorflow::Input epsilon,
  ::tensorflow::Input grad,
  const ApplyAdadelta::Attrs &amp; attrs
)</pre>  </div> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1a7ab3d73516eacd84efdba9d4c8bb31dd"> <h3 id="node" data-text="node">node</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">::tensorflow::Node * node() const </pre>  </div> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1aa0992e4c234bd33403c057425829457c"> <h3 id="operator::tensorflow::input" data-text="operator::tensorflow::Input">operator::tensorflow::Input</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">operator::tensorflow::Input() const </pre>  </div> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1a0d01185e91e72c289949de8ca852c923"> <h3 id="operator::tensorflow::output" data-text="operator::tensorflow::Output">operator::tensorflow::Output</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">operator::tensorflow::Output() const </pre>  </div> <h2 id="public-static-functions_1" data-text="Public static functions">Public static functions</h2> <div id="classtensorflow_1_1ops_1_1_apply_adadelta_1a8545cc26c688935679d0a732a1407986"> <h3 id="uselocking" data-text="UseLocking">UseLocking</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">Attrs UseLocking(
  bool x
)</pre>  </div>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/cc/class/tensorflow/ops/apply-adadelta" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/cc/class/tensorflow/ops/apply-adadelta</a>
  </p>
</div>
