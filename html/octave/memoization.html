<div class="section" id="Memoization">   <h1 class="section">19.5 Memoization</h1> <p>Memoization is a technique to cache the results of slow function calls and return the cached value when the function is called with the same inputs again, instead of reevaluating it. It is very common to replace function calls with lookup tables if the same inputs are happening over and over again in a known, predictable way. Memoization is, at its core, an extension of this practice where the lookup table is extended even during runtime for new arguments not seen previously. A basic theoretical background can be found on Wikipedia or any undergraduate-level computer science textbook. </p> <p>Octave’s <code>memoize</code> function provides drop-in memoization functionality for any user function or Octave function, including compiled functions. </p> <dl class="def"> <dt id="index-memoize">
<span class="category">: </span><span><em><var>mem_fcn_handle</var> =</em> <strong>memoize</strong> <em>(<var>fcn_handle</var>)</em><a href="#index-memoize" class="copiable-anchor"> ¶</a></span>
</dt> <dd> <p>Create a memoized version <var>mem_fcn_handle</var> of function <var>fcn_handle</var>. </p> <p>Each call to the memoized version <var>mem_fcn_handle</var> checks the inputs against an internally maintained table, and if the inputs have occurred previously, then the result of the function call is returned from the table itself instead of evaluating the full function again. This speeds up the execution of functions that are called with the same inputs multiple times. </p> <p>For example, here we take a slow user-written function named <code>slow_fcn</code> and memoize it to a new handle <code>cyc</code>. The first executions of both versions take the same time, but the subsequent executions of the memoized version returns the previously computed value, thus reducing 2.4 seconds of runtime to only 2.4 milliseconds. The final check verifies that the same result was returned from both versions. </p> <pre class="example" data-language="matlab">&gt;&gt; tic; p = slow_fcn (5040); toc
Elapsed time is 2.41244 seconds.
&gt;&gt; tic; p = slow_fcn (5040); toc
Elapsed time is 2.41542 seconds.

&gt;&gt; cyc = memoize (@slow_fcn);
&gt;&gt; tic; r = cyc (5040); toc
Elapsed time is 2.42609 seconds.
&gt;&gt; tic; r = cyc (5040); toc
Elapsed time is 0.00236511 seconds.

&gt;&gt; all (p == r)
ans = 1</pre> <p><strong>See also:</strong> <a href="#XREFclearAllMemoizedCaches">clearAllMemoizedCaches</a>. </p>
</dd>
</dl> <p>To memoize a function <code>z = foo(x, y)</code>, use this general pattern: </p> <pre class="example" data-language="matlab">foo2 = memoize (@(x, y) foo(x, y));
z = foo2 (x, y);</pre> <p>In the above example, the first line creates a memoized version <code>foo2</code> of the function <code>foo</code>. For simple functions with only trivial wrapping, this line can also be shortened to: </p> <pre class="example" data-language="matlab">foo2 = memoize (@foo);</pre> <p>The second line <code>z = foo2 (x, y);</code> calls that memoized version <code>foo2</code> instead of the original function, allowing <code>memoize</code> to intercept the call and replace it with a looked-up value from a table if the inputs have occurred before, instead of evaluating the original function again. </p> <p>Note that this will not accelerate the <em>first</em> call to the function but only subsequent calls. </p> <p>Note that due to the overhead incurred by <code>memoize</code> to create and manage the lookup tables for each function, this technique is useful only for functions that take at least a couple of seconds to execute. Such functions can be replaced by table lookups taking only a millisecond or so, but if the original function itself was taking only milliseconds, memoizing it will not speed it up. </p> <p>Recursive functions can be memoized as well, using a pattern like: </p> <pre class="example" data-language="matlab">function z = foo (x, y)
  persistent foo2 = memoize (@foo);
  foo2.CacheSize = 1e6;

  ## Call the memoized version when recursing
  z = foo2 (x, y);
endfunction</pre> <p>The <code>CacheSize</code> can be optionally increased in anticipation of a large number of function calls, such as from inside a recursive function. If <code>CacheSize</code> is exceeded, the memoization tables are resized, causing a slowdown. Increasing the <code>CacheSize</code> thus works like preallocation to speed up execution. </p> <p>The function <code>clearAllMemoizedCaches</code> clears the memoization tables when they are no longer needed. </p> <dl class="def"> <dt id="index-clearAllMemoizedCaches">
<span class="category">: </span><span> <strong>clearAllMemoizedCaches</strong> <em>()</em><a href="#index-clearAllMemoizedCaches" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Clear all memoized caches. </p> <p>Memoization maintains internal tables of which functions have been called with which inputs. This function clears those tables to free memory, or for a fresh start. </p> <p><strong>See also:</strong> <a href="#XREFmemoize">memoize</a>. </p>
</dd>
</dl> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 1996–2023 The Octave Project Developers<br>Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.<br/>Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.</br>Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions.<br>
    <a href="https://docs.octave.org/v8.1.0/Memoization.html" class="_attribution-link">https://docs.octave.org/v8.1.0/Memoization.html</a>
  </p>
</div>
