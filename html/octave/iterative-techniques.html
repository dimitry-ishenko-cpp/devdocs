<div class="section-level-extent" id="Iterative-Techniques"> <div class="nav-panel"> <p> Next: <a href="real-life-example.html" accesskey="n" rel="next">Real Life Example using Sparse Matrices</a>, Previous: <a href="sparse-linear-algebra.html" accesskey="p" rel="prev">Linear Algebra on Sparse Matrices</a>, Up: <a href="sparse-matrices.html" accesskey="u" rel="up">Sparse Matrices</a> [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="concept-index.html" title="Index" rel="index">Index</a>]</p> </div>  <h1 class="section" id="Iterative-Techniques-Applied-to-Sparse-Matrices"><span>22.3 Iterative Techniques Applied to Sparse Matrices<a class="copiable-link" href="#Iterative-Techniques-Applied-to-Sparse-Matrices"> ¶</a></span></h1> <p>The left division <code class="code">\</code> and right division <code class="code">/</code> operators, discussed in the previous section, use direct solvers to resolve a linear equation of the form <code class="code"><var class="var">x</var> = <var class="var">A</var> \ <var class="var">b</var></code> or <code class="code"><var class="var">x</var> = <var class="var">b</var> / <var class="var">A</var></code>. Octave also includes a number of functions to solve sparse linear equations using iterative techniques. </p>  <dl class="first-deftypefn"> <dt class="deftypefn" id="index-pcg">
<span class="category-def">: </span><span><code class="def-type"><var class="var">x</var> =</code> <strong class="def-name">pcg</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, <var class="var">tol</var>, <var class="var">maxit</var>, <var class="var">m1</var>, <var class="var">m2</var>, <var class="var">x0</var>, …)</code><a class="copiable-link" href="#index-pcg"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-pcg-1">
<span class="category-def">: </span><span><code class="def-type"><var class="var">x</var> =</code> <strong class="def-name">pcg</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, <var class="var">tol</var>, <var class="var">maxit</var>, <var class="var">M</var>, [], <var class="var">x0</var>, …)</code><a class="copiable-link" href="#index-pcg-1"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-pcg-2">
<span class="category-def">: </span><span><code class="def-type">[<var class="var">x</var>, <var class="var">flag</var>, <var class="var">relres</var>, <var class="var">iter</var>, <var class="var">resvec</var>, <var class="var">eigest</var>] =</code> <strong class="def-name">pcg</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, …)</code><a class="copiable-link" href="#index-pcg-2"> ¶</a></span>
</dt> <dd> <p>Solve the linear system of equations <code class="code"><var class="var">A</var> * <var class="var">x</var> = <var class="var">b</var></code> by means of the Preconditioned Conjugate Gradient iterative method. </p> <p>The input arguments are: </p> <ul class="itemize mark-bullet"> <li>
<var class="var">A</var> is the matrix of the linear system and it must be square. <var class="var">A</var> can be passed as a matrix, function handle, or inline function <code class="code">Afcn</code> such that <code class="code">Afcn(x) = A * x</code>. Additional parameters to <code class="code">Afcn</code> may be passed after <var class="var">x0</var>. <p><var class="var">A</var> has to be Hermitian and Positive Definite (HPD). If <code class="code">pcg</code> detects <var class="var">A</var> not to be positive definite, a warning is printed and the <var class="var">flag</var> output is set. </p> </li>
<li>
<var class="var">b</var> is the right-hand side vector. </li>
<li>
<var class="var">tol</var> is the required relative tolerance for the residual error, <code class="code"><var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var></code>. The iteration stops if <code class="code">norm (<var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var>)</code> ≤ <code class="code"><var class="var">tol</var> * norm (<var class="var">b</var>)</code>. If <var class="var">tol</var> is omitted or empty, then a tolerance of 1e-6 is used. </li>
<li>
<var class="var">maxit</var> is the maximum allowed number of iterations; if <var class="var">maxit</var> is omitted or empty then a value of 20 is used. </li>
<li>
<var class="var">m</var> is a HPD preconditioning matrix. For any decomposition <code class="code"><var class="var">m</var> = <var class="var">p1</var> * <var class="var">p2</var></code> such that <code class="code">inv (<var class="var">p1</var>) * <var class="var">A</var> * inv (<var class="var">p2</var>)</code> is HPD, the conjugate gradient method is formally applied to the linear system <code class="code">inv (<var class="var">p1</var>) * <var class="var">A</var> * inv (<var class="var">p2</var>) * <var class="var">y</var> = inv (<var class="var">p1</var>) * <var class="var">b</var></code>, with <code class="code"><var class="var">x</var> = inv (<var class="var">p2</var>) * <var class="var">y</var></code> (split preconditioning). In practice, at each iteration of the conjugate gradient method a linear system with matrix <var class="var">m</var> is solved with <code class="code">mldivide</code>. If a particular factorization <code class="code"><var class="var">m</var> = <var class="var">m1</var> * <var class="var">m2</var></code> is available (for instance, an incomplete Cholesky factorization of <var class="var">a</var>), the two matrices <var class="var">m1</var> and <var class="var">m2</var> can be passed and the relative linear systems are solved with the <code class="code">mldivide</code> operator. Note that a proper choice of the preconditioner may dramatically improve the overall performance of the method. Instead of matrices <var class="var">m1</var> and <var class="var">m2</var>, the user may pass two functions which return the results of applying the inverse of <var class="var">m1</var> and <var class="var">m2</var> to a vector. If <var class="var">m1</var> is omitted or empty <code class="code">[]</code>, then no preconditioning is applied. If no factorization of <var class="var">m</var> is available, <var class="var">m2</var> can be omitted or left [], and the input variable <var class="var">m1</var> can be used to pass the preconditioner <var class="var">m</var>. </li>
<li>
<var class="var">x0</var> is the initial guess. If <var class="var">x0</var> is omitted or empty then the function sets <var class="var">x0</var> to a zero vector by default. </li>
</ul> <p>The arguments which follow <var class="var">x0</var> are treated as parameters, and passed in an appropriate manner to any of the functions (<var class="var">A</var> or <var class="var">m1</var> or <var class="var">m2</var>) that have been given to <code class="code">pcg</code>. See the examples below for further details. </p> <p>The output arguments are: </p> <ul class="itemize mark-bullet"> <li>
<var class="var">x</var> is the computed approximation to the solution of <code class="code"><var class="var">A</var> * <var class="var">x</var> = <var class="var">b</var></code>. If the algorithm did not converge, then <var class="var">x</var> is the iteration which has the minimum residual. </li>
<li>
<var class="var">flag</var> reports on the convergence: <ul class="itemize mark-bullet"> <li>0: The algorithm converged to within the prescribed tolerance. </li>
<li>1: The algorithm did not converge and it reached the maximum number of iterations. </li>
<li>2: The preconditioner matrix is singular. </li>
<li>3: The algorithm stagnated, i.e., the absolute value of the difference between the current iteration <var class="var">x</var> and the previous is less than <code class="code"><var class="var">eps</var> * norm (<var class="var">x</var>,2)</code>. </li>
<li>4: The algorithm detects that the input (preconditioned) matrix is not HPD. </li>
</ul> </li>
<li>
<var class="var">relres</var> is the ratio of the final residual to its initial value, measured in the Euclidean norm. </li>
<li>
<var class="var">iter</var> indicates the iteration of <var class="var">x</var> which it was computed. Since the output <var class="var">x</var> corresponds to the minimal residual solution, the total number of iterations that the method performed is given by <code class="code">length(resvec) - 1</code>. </li>
<li>
<var class="var">resvec</var> describes the convergence history of the method. <code class="code"><var class="var">resvec</var> (<var class="var">i</var>, 1)</code> is the Euclidean norm of the residual, and <code class="code"><var class="var">resvec</var> (<var class="var">i</var>, 2)</code> is the preconditioned residual norm, after the (<var class="var">i</var>-1)-th iteration, <code class="code"><var class="var">i</var> = 1, 2, …, <var class="var">iter</var>+1</code>. The preconditioned residual norm is defined as <code class="code"><var class="var">r</var>' * (<var class="var">m</var> \ <var class="var">r</var>)</code> where <code class="code"><var class="var">r</var> = <var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var></code>, see also the description of <var class="var">m</var>. If <var class="var">eigest</var> is not required, only <code class="code"><var class="var">resvec</var> (:, 1)</code> is returned. </li>
<li>
<var class="var">eigest</var> returns the estimate for the smallest <code class="code"><var class="var">eigest</var>(1)</code> and largest <code class="code"><var class="var">eigest</var>(2)</code> eigenvalues of the preconditioned matrix <code class="code"><var class="var">P</var> = <var class="var">m</var> \ <var class="var">A</var></code>. In particular, if no preconditioning is used, the estimates for the extreme eigenvalues of <var class="var">A</var> are returned. <code class="code"><var class="var">eigest</var>(1)</code> is an overestimate and <code class="code"><var class="var">eigest</var>(2)</code> is an underestimate, so that <code class="code"><var class="var">eigest</var>(2) / <var class="var">eigest</var>(1)</code> is a lower bound for <code class="code">cond (<var class="var">P</var>, 2)</code>, which nevertheless in the limit should theoretically be equal to the actual value of the condition number. </li>
</ul> <p>Let us consider a trivial problem with a tridiagonal matrix </p> <pre class="example" data-language="matlab">n = 10;
A = toeplitz (sparse ([1, 1], [1, 2], [2, 1], 1, n));
b = A * ones (n, 1);
M1 = ichol (A); # in this tridiagonal case it corresponds to chol (A)'
M2 = M1';
M = M1 * M2;
Afcn = @(x) A * x;
Mfcn = @(x) M \ x;
M1fcn = @(x) M1 \ x;
M2fcn = @(x) M2 \ x;</pre> <p><small class="sc">EXAMPLE 1:</small> Simplest use of <code class="code">pcg</code> </p> <pre class="example" data-language="matlab">x = pcg (A, b)</pre> <p><small class="sc">EXAMPLE 2:</small> <code class="code">pcg</code> with a function which computes <code class="code"><var class="var">A</var> * <var class="var">x</var></code> </p> <pre class="example" data-language="matlab">x = pcg (Afcn, b)</pre> <p><small class="sc">EXAMPLE 3:</small> <code class="code">pcg</code> with a preconditioner matrix <var class="var">M</var> </p> <pre class="example" data-language="matlab">x = pcg (A, b, 1e-06, 100, M)</pre> <p><small class="sc">EXAMPLE 4:</small> <code class="code">pcg</code> with a function as preconditioner </p> <pre class="example" data-language="matlab">x = pcg (Afcn, b, 1e-6, 100, Mfcn)</pre> <p><small class="sc">EXAMPLE 5:</small> <code class="code">pcg</code> with preconditioner matrices <var class="var">M1</var> and <var class="var">M2</var> </p> <pre class="example" data-language="matlab">x = pcg (A, b, 1e-6, 100, M1, M2)</pre> <p><small class="sc">EXAMPLE 6:</small> <code class="code">pcg</code> with functions as preconditioners </p> <pre class="example" data-language="matlab">x = pcg (Afcn, b, 1e-6, 100, M1fcn, M2fcn)</pre> <p><small class="sc">EXAMPLE 7:</small> <code class="code">pcg</code> with as input a function requiring an argument </p> <pre class="example" data-language="matlab">function y = Ap (A, x, p) # compute A^p * x
     y = x;
     for i = 1:p
       y = A * y;
     endfor
  endfunction
Apfcn = @(x, p) Ap (A, x, p);
x = pcg (Apfcn, b, [], [], [], [], [], 2);</pre> <p><small class="sc">EXAMPLE 8:</small> explicit example to show that <code class="code">pcg</code> uses a split preconditioner </p> <pre class="example" data-language="matlab">M1 = ichol (A + 0.1 * eye (n)); # factorization of A perturbed
M2 = M1';
M = M1 * M2;

## reference solution computed by pcg after two iterations
[x_ref, fl] = pcg (A, b, [], 2, M)

## split preconditioning
[y, fl] = pcg ((M1 \ A) / M2, M1 \ b, [], 2)
x = M2 \ y # compare x and x_ref</pre> <p>References: </p> <ol class="enumerate"> <li> C.T. Kelley, <cite class="cite">Iterative Methods for Linear and Nonlinear Equations</cite>, SIAM, 1995. (the base PCG algorithm) </li>
<li> Y. Saad, <cite class="cite">Iterative Methods for Sparse Linear Systems</cite>, PWS 1996. (condition number estimate from PCG) Revised version of this book is available online at <a class="url" href="https://www-users.cs.umn.edu/~saad/books.html">https://www-users.cs.umn.edu/~saad/books.html</a> </li>
</ol> <p><strong class="strong">See also:</strong> <a class="ref" href="creating-sparse-matrices.html#XREFsparse">sparse</a>, <a class="ref" href="#XREFpcr">pcr</a>, <a class="ref" href="specialized-solvers.html#XREFgmres">gmres</a>, <a class="ref" href="specialized-solvers.html#XREFbicg">bicg</a>, <a class="ref" href="specialized-solvers.html#XREFbicgstab">bicgstab</a>, <a class="ref" href="specialized-solvers.html#XREFcgs">cgs</a>. </p>
</dd>
</dl>  <dl class="first-deftypefn"> <dt class="deftypefn" id="index-pcr">
<span class="category-def">: </span><span><code class="def-type"><var class="var">x</var> =</code> <strong class="def-name">pcr</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, <var class="var">tol</var>, <var class="var">maxit</var>, <var class="var">m</var>, <var class="var">x0</var>, …)</code><a class="copiable-link" href="#index-pcr"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-pcr-1">
<span class="category-def">: </span><span><code class="def-type">[<var class="var">x</var>, <var class="var">flag</var>, <var class="var">relres</var>, <var class="var">iter</var>, <var class="var">resvec</var>] =</code> <strong class="def-name">pcr</strong> <code class="def-code-arguments">(…)</code><a class="copiable-link" href="#index-pcr-1"> ¶</a></span>
</dt> <dd> <p>Solve the linear system of equations <code class="code"><var class="var">A</var> * <var class="var">x</var> = <var class="var">b</var></code> by means of the Preconditioned Conjugate Residuals iterative method. </p> <p>The input arguments are </p> <ul class="itemize mark-bullet"> <li>
<var class="var">A</var> can be either a square (preferably sparse) matrix or a function handle, inline function or string containing the name of a function which computes <code class="code"><var class="var">A</var> * <var class="var">x</var></code>. In principle <var class="var">A</var> should be symmetric and non-singular; if <code class="code">pcr</code> finds <var class="var">A</var> to be numerically singular, you will get a warning message and the <var class="var">flag</var> output parameter will be set. </li>
<li>
<var class="var">b</var> is the right hand side vector. </li>
<li>
<var class="var">tol</var> is the required relative tolerance for the residual error, <code class="code"><var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var></code>. The iteration stops if <code class="code">norm (<var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var>) &lt;=
<var class="var">tol</var> * norm (<var class="var">b</var> - <var class="var">A</var> * <var class="var">x0</var>)</code>. If <var class="var">tol</var> is empty or is omitted, the function sets <code class="code"><var class="var">tol</var> = 1e-6</code> by default. </li>
<li>
<var class="var">maxit</var> is the maximum allowable number of iterations; if <code class="code">[]</code> is supplied for <var class="var">maxit</var>, or <code class="code">pcr</code> has less arguments, a default value equal to 20 is used. </li>
<li>
<var class="var">m</var> is the (left) preconditioning matrix, so that the iteration is (theoretically) equivalent to solving by <code class="code">pcr</code> <code class="code"><var class="var">P</var> * <var class="var">x</var> = <var class="var">m</var> \ <var class="var">b</var></code>, with <code class="code"><var class="var">P</var> = <var class="var">m</var> \ <var class="var">A</var></code>. Note that a proper choice of the preconditioner may dramatically improve the overall performance of the method. Instead of matrix <var class="var">m</var>, the user may pass a function which returns the results of applying the inverse of <var class="var">m</var> to a vector (usually this is the preferred way of using the preconditioner). If <code class="code">[]</code> is supplied for <var class="var">m</var>, or <var class="var">m</var> is omitted, no preconditioning is applied. </li>
<li>
<var class="var">x0</var> is the initial guess. If <var class="var">x0</var> is empty or omitted, the function sets <var class="var">x0</var> to a zero vector by default. </li>
</ul> <p>The arguments which follow <var class="var">x0</var> are treated as parameters, and passed in a proper way to any of the functions (<var class="var">A</var> or <var class="var">m</var>) which are passed to <code class="code">pcr</code>. See the examples below for further details. </p> <p>The output arguments are </p> <ul class="itemize mark-bullet"> <li>
<var class="var">x</var> is the computed approximation to the solution of <code class="code"><var class="var">A</var> * <var class="var">x</var> = <var class="var">b</var></code>. </li>
<li>
<var class="var">flag</var> reports on the convergence. <code class="code"><var class="var">flag</var> = 0</code> means the solution converged and the tolerance criterion given by <var class="var">tol</var> is satisfied. <code class="code"><var class="var">flag</var> = 1</code> means that the <var class="var">maxit</var> limit for the iteration count was reached. <code class="code"><var class="var">flag</var> = 3</code> reports a <code class="code">pcr</code> breakdown, see [1] for details. </li>
<li>
<var class="var">relres</var> is the ratio of the final residual to its initial value, measured in the Euclidean norm. </li>
<li>
<var class="var">iter</var> is the actual number of iterations performed. </li>
<li>
<var class="var">resvec</var> describes the convergence history of the method, so that <code class="code"><var class="var">resvec</var> (i)</code> contains the Euclidean norms of the residual after the (<var class="var">i</var>-1)-th iteration, <code class="code"><var class="var">i</var> = 1,2, …, <var class="var">iter</var>+1</code>. </li>
</ul> <p>Let us consider a trivial problem with a diagonal matrix (we exploit the sparsity of A) </p> <pre class="example" data-language="matlab">n = 10;
A = sparse (diag (1:n));
b = rand (N, 1);</pre> <p><small class="sc">EXAMPLE 1:</small> Simplest use of <code class="code">pcr</code> </p> <pre class="example" data-language="matlab">x = pcr (A, b)</pre> <p><small class="sc">EXAMPLE 2:</small> <code class="code">pcr</code> with a function which computes <code class="code"><var class="var">A</var> * <var class="var">x</var></code>. </p> <pre class="example" data-language="matlab">function y = apply_a (x)
  y = [1:10]' .* x;
endfunction

x = pcr ("apply_a", b)</pre> <p><small class="sc">EXAMPLE 3:</small> Preconditioned iteration, with full diagnostics. The preconditioner (quite strange, because even the original matrix <var class="var">A</var> is trivial) is defined as a function </p> <pre class="example" data-language="matlab">function y = apply_m (x)
  k = floor (length (x) - 2);
  y = x;
  y(1:k) = x(1:k) ./ [1:k]';
endfunction

[x, flag, relres, iter, resvec] = ...
                   pcr (A, b, [], [], "apply_m")
semilogy ([1:iter+1], resvec);</pre> <p><small class="sc">EXAMPLE 4:</small> Finally, a preconditioner which depends on a parameter <var class="var">k</var>. </p> <pre class="example" data-language="matlab">function y = apply_m (x, varargin)
  k = varargin{1};
  y = x;
  y(1:k) = x(1:k) ./ [1:k]';
endfunction

[x, flag, relres, iter, resvec] = ...
                   pcr (A, b, [], [], "apply_m"', [], 3)</pre> <p>Reference: </p> <p>W. Hackbusch, <cite class="cite">Iterative Solution of Large Sparse Systems of Equations</cite>, section 9.5.4; Springer, 1994 </p> <p><strong class="strong">See also:</strong> <a class="ref" href="creating-sparse-matrices.html#XREFsparse">sparse</a>, <a class="ref" href="#XREFpcg">pcg</a>. </p>
</dd>
</dl> <p>The speed with which an iterative solver converges to a solution can be accelerated with the use of a pre-conditioning matrix <var class="var">M</var>. In this case the linear equation <code class="code"><var class="var">M</var>^-1 * <var class="var">x</var> = <var class="var">M</var>^-1 *
<var class="var">A</var> \ <var class="var">b</var></code> is solved instead. Typical pre-conditioning matrices are partial factorizations of the original matrix. </p>  <dl class="first-deftypefn"> <dt class="deftypefn" id="index-ichol">
<span class="category-def">: </span><span><code class="def-type"><var class="var">L</var> =</code> <strong class="def-name">ichol</strong> <code class="def-code-arguments">(<var class="var">A</var>)</code><a class="copiable-link" href="#index-ichol"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-ichol-1">
<span class="category-def">: </span><span><code class="def-type"><var class="var">L</var> =</code> <strong class="def-name">ichol</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">opts</var>)</code><a class="copiable-link" href="#index-ichol-1"> ¶</a></span>
</dt> <dd> <p>Compute the incomplete Cholesky factorization of the sparse square matrix <var class="var">A</var>. </p> <p>By default, <code class="code">ichol</code> uses only the lower triangle of <var class="var">A</var> and produces a lower triangular factor <var class="var">L</var> such that <code class="code">L*L'</code> approximates <var class="var">A</var>. </p> <p>The factor given by this routine may be useful as a preconditioner for a system of linear equations being solved by iterative methods such as PCG (Preconditioned Conjugate Gradient). </p> <p>The factorization may be modified by passing options in a structure <var class="var">opts</var>. The option name is a field of the structure and the setting is the value of field. Names and specifiers are case sensitive. </p> <dl class="table"> <dt>type</dt> <dd>
<p>Type of factorization. </p> <dl class="table"> <dt>
<code class="code">"nofill"</code> (default)</dt> <dd>
<p>Incomplete Cholesky factorization with no fill-in (IC(0)). </p> </dd> <dt><code class="code">"ict"</code></dt> <dd><p>Incomplete Cholesky factorization with threshold dropping (ICT). </p></dd> </dl> </dd> <dt>diagcomp</dt> <dd>
<p>A non-negative scalar <var class="var">alpha</var> for incomplete Cholesky factorization of <code class="code"><var class="var">A</var> + <var class="var">alpha</var> * diag (diag (<var class="var">A</var>))</code> instead of <var class="var">A</var>. This can be useful when <var class="var">A</var> is not positive definite. The default value is 0. </p> </dd> <dt>droptol</dt> <dd>
<p>A non-negative scalar specifying the drop tolerance for factorization if performing ICT. The default value is 0 which produces the complete Cholesky factorization. </p> <p>Non-diagonal entries of <var class="var">L</var> are set to 0 unless </p> <p><code class="code">abs (<var class="var">L</var>(i,j)) &gt;= droptol * norm (<var class="var">A</var>(j:end, j), 1)</code>. </p> </dd> <dt>michol</dt> <dd>
<p>Modified incomplete Cholesky factorization: </p> <dl class="table"> <dt>
<code class="code">"off"</code> (default)</dt> <dd>
<p>Row and column sums are not necessarily preserved. </p> </dd> <dt><code class="code">"on"</code></dt> <dd><p>The diagonal of <var class="var">L</var> is modified so that row (and column) sums are preserved even when elements have been dropped during the factorization. The relationship preserved is: <code class="code"><var class="var">A</var> * e = <var class="var">L</var> * <var class="var">L</var>' * e</code>, where e is a vector of ones. </p></dd> </dl> </dd> <dt>shape</dt> <dd> <dl class="table"> <dt>
<code class="code">"lower"</code> (default)</dt> <dd>
<p>Use only the lower triangle of <var class="var">A</var> and return a lower triangular factor <var class="var">L</var> such that <code class="code">L*L'</code> approximates <var class="var">A</var>. </p> </dd> <dt><code class="code">"upper"</code></dt> <dd><p>Use only the upper triangle of <var class="var">A</var> and return an upper triangular factor <var class="var">U</var> such that <code class="code">U'*U</code> approximates <var class="var">A</var>. </p></dd> </dl> </dd> </dl> <p>EXAMPLES </p> <p>The following problem demonstrates how to factorize a sample symmetric positive definite matrix with the full Cholesky decomposition and with the incomplete one. </p> <pre class="example" data-language="matlab">A = [ 0.37, -0.05,  -0.05,  -0.07;
     -0.05,  0.116,  0.0,   -0.05;
     -0.05,  0.0,    0.116, -0.05;
     -0.07, -0.05,  -0.05,   0.202];
A = sparse (A);
nnz (tril (A))
ans =  9
L = chol (A, "lower");
nnz (L)
ans =  10
norm (A - L * L', "fro") / norm (A, "fro")
ans =  1.1993e-16
opts.type = "nofill";
L = ichol (A, opts);
nnz (L)
ans =  9
norm (A - L * L', "fro") / norm (A, "fro")
ans =  0.019736</pre> <p>Another example for decomposition is a finite difference matrix used to solve a boundary value problem on the unit square. </p> <pre class="example" data-language="matlab">nx = 400; ny = 200;
hx = 1 / (nx + 1); hy = 1 / (ny + 1);
Dxx = spdiags ([ones(nx, 1), -2*ones(nx, 1), ones(nx, 1)],
               [-1 0 1 ], nx, nx) / (hx ^ 2);
Dyy = spdiags ([ones(ny, 1), -2*ones(ny, 1), ones(ny, 1)],
               [-1 0 1 ], ny, ny) / (hy ^ 2);
A = -kron (Dxx, speye (ny)) - kron (speye (nx), Dyy);
nnz (tril (A))
ans =  239400
opts.type = "nofill";
L = ichol (A, opts);
nnz (tril (A))
ans =  239400
norm (A - L * L', "fro") / norm (A, "fro")
ans =  0.062327</pre> <p>References for implemented algorithms: </p> <p>[1] Y. Saad. "Preconditioning Techniques." <cite class="cite">Iterative Methods for Sparse Linear Systems</cite>, PWS Publishing Company, 1996. </p> <p>[2] M. Jones, P. Plassmann: <cite class="cite">An Improved Incomplete Cholesky Factorization</cite>, 1992. </p> <p><strong class="strong">See also:</strong> <a class="ref" href="matrix-factorizations.html#XREFchol">chol</a>, <a class="ref" href="#XREFilu">ilu</a>, <a class="ref" href="#XREFpcg">pcg</a>. </p>
</dd>
</dl>  <dl class="first-deftypefn"> <dt class="deftypefn" id="index-ilu">
<span class="category-def">: </span><span><code class="def-type"><var class="var">LUA</var> =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(<var class="var">A</var>)</code><a class="copiable-link" href="#index-ilu"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-ilu-1">
<span class="category-def">: </span><span><code class="def-type"><var class="var">LUA</var> =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">opts</var>)</code><a class="copiable-link" href="#index-ilu-1"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-ilu-2">
<span class="category-def">: </span><span><code class="def-type">[<var class="var">L</var>, <var class="var">U</var>] =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(…)</code><a class="copiable-link" href="#index-ilu-2"> ¶</a></span>
</dt> <dt class="deftypefnx def-cmd-deftypefn" id="index-ilu-3">
<span class="category-def">: </span><span><code class="def-type">[<var class="var">L</var>, <var class="var">U</var>, <var class="var">P</var>] =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(…)</code><a class="copiable-link" href="#index-ilu-3"> ¶</a></span>
</dt> <dd> <p>Compute the incomplete LU factorization of the sparse square matrix <var class="var">A</var>. </p> <p><code class="code">ilu</code> returns a unit lower triangular matrix <var class="var">L</var>, an upper triangular matrix <var class="var">U</var>, and optionally a permutation matrix <var class="var">P</var>, such that <code class="code"><var class="var">L</var>*<var class="var">U</var></code> approximates <code class="code"><var class="var">P</var>*<var class="var">A</var></code>. </p> <p>The factors given by this routine may be useful as preconditioners for a system of linear equations being solved by iterative methods such as BICG (BiConjugate Gradients) or GMRES (Generalized Minimum Residual Method). </p> <p>The factorization may be modified by passing options in a structure <var class="var">opts</var>. The option name is a field of the structure and the setting is the value of field. Names and specifiers are case sensitive. </p> <dl class="table"> <dt><code class="code">type</code></dt> <dd>
<p>Type of factorization. </p> <dl class="table"> <dt>
<code class="code">"nofill"</code> (default)</dt> <dd>
<p>ILU factorization with no fill-in (ILU(0)). </p> <p>Additional supported options: <code class="code">milu</code>. </p> </dd> <dt><code class="code">"crout"</code></dt> <dd>
<p>Crout version of ILU factorization (ILUC). </p> <p>Additional supported options: <code class="code">milu</code>, <code class="code">droptol</code>. </p> </dd> <dt><code class="code">"ilutp"</code></dt> <dd>
<p>ILU factorization with threshold and pivoting. </p> <p>Additional supported options: <code class="code">milu</code>, <code class="code">droptol</code>, <code class="code">udiag</code>, <code class="code">thresh</code>. </p>
</dd> </dl> </dd> <dt><code class="code">droptol</code></dt> <dd>
<p>A non-negative scalar specifying the drop tolerance for factorization. The default value is 0 which produces the complete LU factorization. </p> <p>Non-diagonal entries of <var class="var">U</var> are set to 0 unless </p> <p><code class="code">abs (<var class="var">U</var>(i,j)) &gt;= droptol * norm (<var class="var">A</var>(:,j))</code>. </p> <p>Non-diagonal entries of <var class="var">L</var> are set to 0 unless </p> <p><code class="code">abs (<var class="var">L</var>(i,j)) &gt;= droptol * norm (<var class="var">A</var>(:,j))/<var class="var">U</var>(j,j)</code>. </p> </dd> <dt><code class="code">milu</code></dt> <dd>
<p>Modified incomplete LU factorization: </p> <dl class="table"> <dt><code class="code">"row"</code></dt> <dd>
<p>Row-sum modified incomplete LU factorization. The factorization preserves row sums: <code class="code"><var class="var">A</var> * e = <var class="var">L</var> * <var class="var">U</var> * e</code>, where e is a vector of ones. </p> </dd> <dt><code class="code">"col"</code></dt> <dd>
<p>Column-sum modified incomplete LU factorization. The factorization preserves column sums: <code class="code">e' * <var class="var">A</var> = e' * <var class="var">L</var> * <var class="var">U</var></code>. </p> </dd> <dt>
<code class="code">"off"</code> (default)</dt> <dd><p>Row and column sums are not necessarily preserved. </p></dd> </dl> </dd> <dt><code class="code">udiag</code></dt> <dd>
<p>If true, any zeros on the diagonal of the upper triangular factor are replaced by the local drop tolerance <code class="code">droptol * norm (<var class="var">A</var>(:,j))/<var class="var">U</var>(j,j)</code>. The default is false. </p> </dd> <dt><code class="code">thresh</code></dt> <dd><p>Pivot threshold for factorization. It can range between 0 (diagonal pivoting) and 1 (default), where the maximum magnitude entry in the column is chosen to be the pivot. </p></dd> </dl> <p>If <code class="code">ilu</code> is called with just one output, the returned matrix is <code class="code"><var class="var">L</var> + <var class="var">U</var> - speye (size (<var class="var">A</var>))</code>, where <var class="var">L</var> is unit lower triangular and <var class="var">U</var> is upper triangular. </p> <p>With two outputs, <code class="code">ilu</code> returns a unit lower triangular matrix <var class="var">L</var> and an upper triangular matrix <var class="var">U</var>. For <var class="var">opts</var>.type == <code class="code">"ilutp"</code>, one of the factors is permuted based on the value of <var class="var">opts</var>.milu. When <var class="var">opts</var>.milu == <code class="code">"row"</code>, <var class="var">U</var> is a column permuted upper triangular factor. Otherwise, <var class="var">L</var> is a row-permuted unit lower triangular factor. </p> <p>If there are three named outputs and <var class="var">opts</var>.milu != <code class="code">"row"</code>, <var class="var">P</var> is returned such that <var class="var">L</var> and <var class="var">U</var> are incomplete factors of <code class="code"><var class="var">P</var>*<var class="var">A</var></code>. When <var class="var">opts</var>.milu == <code class="code">"row"</code>, <var class="var">P</var> is returned such that <var class="var">L</var> and <var class="var">U</var> are incomplete factors of <code class="code"><var class="var">A</var>*<var class="var">P</var></code>. </p> <p>EXAMPLES </p> <pre class="example" data-language="matlab">A = gallery ("neumann", 1600) + speye (1600);
opts.type = "nofill";
nnz (A)
ans = 7840

nnz (lu (A))
ans = 126478

nnz (ilu (A, opts))
ans = 7840</pre> <p>This shows that <var class="var">A</var> has 7,840 nonzeros, the complete LU factorization has 126,478 nonzeros, and the incomplete LU factorization, with 0 level of fill-in, has 7,840 nonzeros, the same amount as <var class="var">A</var>. Taken from: <a class="url" href="https://www.mathworks.com/help/matlab/ref/ilu.html">https://www.mathworks.com/help/matlab/ref/ilu.html</a> </p> <pre class="example" data-language="matlab">A = gallery ("wathen", 10, 10);
b = sum (A, 2);
tol = 1e-8;
maxit = 50;
opts.type = "crout";
opts.droptol = 1e-4;
[L, U] = ilu (A, opts);
x = bicg (A, b, tol, maxit, L, U);
norm (A * x - b, inf)</pre> <p>This example uses ILU as preconditioner for a random FEM-Matrix, which has a large condition number. Without <var class="var">L</var> and <var class="var">U</var> BICG would not converge. </p> <p><strong class="strong">See also:</strong> <a class="ref" href="matrix-factorizations.html#XREFlu">lu</a>, <a class="ref" href="#XREFichol">ichol</a>, <a class="ref" href="specialized-solvers.html#XREFbicg">bicg</a>, <a class="ref" href="specialized-solvers.html#XREFgmres">gmres</a>. </p>
</dd>
</dl> </div>  <div class="nav-panel"> <p> Next: <a href="real-life-example.html">Real Life Example using Sparse Matrices</a>, Previous: <a href="sparse-linear-algebra.html">Linear Algebra on Sparse Matrices</a>, Up: <a href="sparse-matrices.html">Sparse Matrices</a> [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="concept-index.html" title="Index" rel="index">Index</a>]</p> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 1996–2023 The Octave Project Developers<br>Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.<br/>Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.</br>Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions.<br>
    <a href="https://docs.octave.org/v9.2.0/Iterative-Techniques.html" class="_attribution-link">https://docs.octave.org/v9.2.0/Iterative-Techniques.html</a>
  </p>
</div>
