<div class="section" id="Matrix-Factorizations">   <h1 class="section">18.3 Matrix Factorizations</h1>  <dl class="def"> <dt id="index-chol">
<span class="category">: </span><span><em><var>R</var> =</em> <strong>chol</strong> <em>(<var>A</var>)</em><a href="#index-chol" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-chol-1">
<span class="category">: </span><span><em>[<var>R</var>, <var>p</var>] =</em> <strong>chol</strong> <em>(<var>A</var>)</em><a href="#index-chol-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-chol-2">
<span class="category">: </span><span><em>[<var>R</var>, <var>p</var>, <var>Q</var>] =</em> <strong>chol</strong> <em>(<var>A</var>)</em><a href="#index-chol-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-chol-3">
<span class="category">: </span><span><em>[<var>R</var>, <var>p</var>, <var>Q</var>] =</em> <strong>chol</strong> <em>(<var>A</var>, "vector")</em><a href="#index-chol-3" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-chol-4">
<span class="category">: </span><span><em>[<var>L</var>, …] =</em> <strong>chol</strong> <em>(…, "lower")</em><a href="#index-chol-4" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-chol-5">
<span class="category">: </span><span><em>[<var>R</var>, …] =</em> <strong>chol</strong> <em>(…, "upper")</em><a href="#index-chol-5" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
 <p>Compute the upper Cholesky factor, <var>R</var>, of the real symmetric or complex Hermitian positive definite matrix <var>A</var>. </p> <p>The upper Cholesky factor <var>R</var> is computed by using the upper triangular part of matrix <var>A</var> and is defined by </p> <pre class="example" data-language="matlab">R' * R = A.</pre> <p>Calling <code>chol</code> using the optional <code>"upper"</code> flag has the same behavior. In contrast, using the optional <code>"lower"</code> flag, <code>chol</code> returns the lower triangular factorization, computed by using the lower triangular part of matrix <var>A</var>, such that </p> <pre class="example" data-language="matlab">L * L' = A.</pre> <p>Called with one output argument <code>chol</code> fails if matrix <var>A</var> is not positive definite. Note that if matrix <var>A</var> is not real symmetric or complex Hermitian then the lower triangular part is considered to be the (complex conjugate) transpose of the upper triangular part, or vice versa, given the <code>"lower"</code> flag. </p> <p>Called with two or more output arguments <var>p</var> flags whether the matrix <var>A</var> was positive definite and <code>chol</code> does not fail. A zero value of <var>p</var> indicates that matrix <var>A</var> is positive definite and <var>R</var> gives the factorization. Otherwise, <var>p</var> will have a positive value. </p> <p>If called with three output arguments matrix <var>A</var> must be sparse and a sparsity preserving row/column permutation is applied to matrix <var>A</var> prior to the factorization. That is <var>R</var> is the factorization of <code><var>A</var>(<var>Q</var>,<var>Q</var>)</code> such that </p> <pre class="example" data-language="matlab">R' * R = Q' * A * Q.</pre> <p>The sparsity preserving permutation is generally returned as a matrix. However, given the optional flag <code>"vector"</code>, <var>Q</var> will be returned as a vector such that </p> <pre class="example" data-language="matlab">R' * R = A(Q, Q).</pre> <p>In general the lower triangular factorization is significantly faster for sparse matrices. </p> <p><strong>See also:</strong> <a href="#XREFhess">hess</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>, <a href="iterative-techniques.html#XREFichol">ichol</a>, <a href="#XREFcholinv">cholinv</a>, <a href="#XREFchol2inv">chol2inv</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholdelete">choldelete</a>, <a href="#XREFcholshift">cholshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-cholinv">
<span class="category">: </span><span><em><var>Ainv</var> =</em> <strong>cholinv</strong> <em>(<var>A</var>)</em><a href="#index-cholinv" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Compute the inverse of the symmetric positive definite matrix <var>A</var> using the Cholesky factorization. </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFchol2inv">chol2inv</a>, <a href="basic-matrix-functions.html#XREFinv">inv</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-chol2inv">
<span class="category">: </span><span><em><var>Ainv</var> =</em> <strong>chol2inv</strong> <em>(<var>R</var>)</em><a href="#index-chol2inv" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Invert a symmetric, positive definite square matrix from its Cholesky decomposition, <var>R</var>. </p> <p>Note that <var>R</var> should be an upper-triangular matrix with positive diagonal elements. <code>chol2inv (<var>U</var>)</code> provides <code>inv (<var>R</var>'*<var>R</var>)</code> but is much faster than using <code>inv</code>. </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholinv">cholinv</a>, <a href="basic-matrix-functions.html#XREFinv">inv</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-cholupdate">
<span class="category">: </span><span><em>[<var>R1</var>, <var>info</var>] =</em> <strong>cholupdate</strong> <em>(<var>R</var>, <var>u</var>, <var>op</var>)</em><a href="#index-cholupdate" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update or downdate a Cholesky factorization. </p> <p>Given an upper triangular matrix <var>R</var> and a column vector <var>u</var>, attempt to determine another upper triangular matrix <var>R1</var> such that </p> <ul> <li> <var>R1</var>’*<var>R1</var> = <var>R</var>’*<var>R</var> + <var>u</var>*<var>u</var>’ if <var>op</var> is <code>"+"</code> </li>
<li> <var>R1</var>’*<var>R1</var> = <var>R</var>’*<var>R</var> - <var>u</var>*<var>u</var>’ if <var>op</var> is <code>"-"</code> </li>
</ul> <p>If <var>op</var> is <code>"-"</code>, <var>info</var> is set to </p> <ul> <li> 0 if the downdate was successful, </li>
<li> 1 if <var>R</var>’*<var>R</var> - <var>u</var>*<var>u</var>’ is not positive definite, </li>
<li> 2 if <var>R</var> is singular. </li>
</ul> <p>If <var>info</var> is not present, an error message is printed in cases 1 and 2. </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholdelete">choldelete</a>, <a href="#XREFcholshift">cholshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-cholinsert">
<span class="category">: </span><span><em><var>R1</var> =</em> <strong>cholinsert</strong> <em>(<var>R</var>, <var>j</var>, <var>u</var>)</em><a href="#index-cholinsert" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-cholinsert-1">
<span class="category">: </span><span><em>[<var>R1</var>, <var>info</var>] =</em> <strong>cholinsert</strong> <em>(<var>R</var>, <var>j</var>, <var>u</var>)</em><a href="#index-cholinsert-1" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a Cholesky factorization given a row or column to insert in the original factored matrix. </p> <p>Given a Cholesky factorization of a real symmetric or complex Hermitian positive definite matrix <var>A</var> = <var>R</var>’*<var>R</var>, <var>R</var> upper triangular, return the Cholesky factorization of <var>A1</var>, where A1(p,p) = A, A1(:,j) = A1(j,:)’ = u and p = <span class="nolinebreak">[1:j-1,j+1:n+1]</span>. u(j) should be positive. </p> <p>On return, <var>info</var> is set to </p> <ul> <li> 0 if the insertion was successful, </li>
<li> 1 if <var>A1</var> is not positive definite, </li>
<li> 2 if <var>R</var> is singular. </li>
</ul> <p>If <var>info</var> is not present, an error message is printed in cases 1 and 2. </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholdelete">choldelete</a>, <a href="#XREFcholshift">cholshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-choldelete">
<span class="category">: </span><span><em><var>R1</var> =</em> <strong>choldelete</strong> <em>(<var>R</var>, <var>j</var>)</em><a href="#index-choldelete" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a Cholesky factorization given a row or column to delete from the original factored matrix. </p> <p>Given a Cholesky factorization of a real symmetric or complex Hermitian positive definite matrix <var>A</var> = <var>R</var>’*<var>R</var>, <var>R</var> upper triangular, return the Cholesky factorization of A(p,p), where p = <span class="nolinebreak">[1:j-1,j+1:n+1]</span>. </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholshift">cholshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-cholshift">
<span class="category">: </span><span><em><var>R1</var> =</em> <strong>cholshift</strong> <em>(<var>R</var>, <var>i</var>, <var>j</var>)</em><a href="#index-cholshift" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a Cholesky factorization given a range of columns to shift in the original factored matrix. </p> <p>Given a Cholesky factorization of a real symmetric or complex Hermitian positive definite matrix <var>A</var> = <var>R</var>’*<var>R</var>, <var>R</var> upper triangular, return the Cholesky factorization of <var>A</var>(p,p), where p is the permutation <br> <code>p = [1:i-1, shift(i:j, 1), j+1:n]</code> if <var>i</var> &lt; <var>j</var> <br> or <br> <code>p = [1:j-1, shift(j:i,-1), i+1:n]</code> if <var>j</var> &lt; <var>i</var>. <br> </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholdelete">choldelete</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-hess">
<span class="category">: </span><span><em><var>H</var> =</em> <strong>hess</strong> <em>(<var>A</var>)</em><a href="#index-hess" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-hess-1">
<span class="category">: </span><span><em>[<var>P</var>, <var>H</var>] =</em> <strong>hess</strong> <em>(<var>A</var>)</em><a href="#index-hess-1" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
 <p>Compute the Hessenberg decomposition of the matrix <var>A</var>. </p> <p>The Hessenberg decomposition is <code><var>P</var> * <var>H</var> * <var>P</var>' = <var>A</var></code> where <var>P</var> is a square unitary matrix (<code><var>P</var>' * <var>P</var> = I</code>, using complex-conjugate transposition) and <var>H</var> is upper Hessenberg (<code><var>H</var>(i, j) = 0 forall i &gt; j+1)</code>. </p> <p>The Hessenberg decomposition is usually used as the first step in an eigenvalue computation, but has other applications as well (see Golub, Nash, and Van Loan, IEEE Transactions on Automatic Control, 1979). </p> <p><strong>See also:</strong> <a href="basic-matrix-functions.html#XREFeig">eig</a>, <a href="#XREFchol">chol</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-lu">
<span class="category">: </span><span><em>[<var>L</var>, <var>U</var>] =</em> <strong>lu</strong> <em>(<var>A</var>)</em><a href="#index-lu" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-lu-1">
<span class="category">: </span><span><em>[<var>L</var>, <var>U</var>, <var>P</var>] =</em> <strong>lu</strong> <em>(<var>A</var>)</em><a href="#index-lu-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-lu-2">
<span class="category">: </span><span><em>[<var>L</var>, <var>U</var>, <var>P</var>, <var>Q</var>] =</em> <strong>lu</strong> <em>(<var>S</var>)</em><a href="#index-lu-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-lu-3">
<span class="category">: </span><span><em>[<var>L</var>, <var>U</var>, <var>P</var>, <var>Q</var>, <var>R</var>] =</em> <strong>lu</strong> <em>(<var>S</var>)</em><a href="#index-lu-3" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-lu-4">
<span class="category">: </span><span><em>[…] =</em> <strong>lu</strong> <em>(<var>S</var>, <var>thresh</var>)</em><a href="#index-lu-4" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-lu-5">
<span class="category">: </span><span><em><var>y</var> =</em> <strong>lu</strong> <em>(…)</em><a href="#index-lu-5" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-lu-6">
<span class="category">: </span><span><em>[…] =</em> <strong>lu</strong> <em>(…, "vector")</em><a href="#index-lu-6" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
 <p>Compute the LU decomposition of <var>A</var>. </p> <p>If <var>A</var> is full then subroutines from <small>LAPACK</small> are used, and if <var>A</var> is sparse then <small>UMFPACK</small> is used. </p> <p>The result is returned in a permuted form, according to the optional return value <var>P</var>. For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>, </p> <pre class="example" data-language="matlab">[L, U, P] = lu (A)</pre> <p>returns </p> <pre class="example" data-language="matlab">L =

  1.00000  0.00000
  0.33333  1.00000

U =

  3.00000  4.00000
  0.00000  0.66667

P =

  0  1
  1  0</pre> <p>The matrix is not required to be square. </p> <p>When called with two or three output arguments and a sparse input matrix, <code>lu</code> does not attempt to perform sparsity preserving column permutations. Called with a fourth output argument, the sparsity preserving column transformation <var>Q</var> is returned, such that <code><var>P</var> * <var>A</var> * <var>Q</var> = <var>L</var> * <var>U</var></code>. This is the <strong>preferred</strong> way to call <code>lu</code> with sparse input matrices. </p> <p>Called with a fifth output argument and a sparse input matrix, <code>lu</code> attempts to use a scaling factor <var>R</var> on the input matrix such that <code><var>P</var> * (<var>R</var> \ <var>A</var>) * <var>Q</var> = <var>L</var> * <var>U</var></code>. This typically leads to a sparser and more stable factorization. </p> <p>An additional input argument <var>thresh</var> that defines the pivoting threshold can be given. <var>thresh</var> can be a scalar, in which case it defines the <small>UMFPACK</small> pivoting tolerance for both symmetric and unsymmetric cases. If <var>thresh</var> is a 2-element vector, then the first element defines the pivoting tolerance for the unsymmetric <small>UMFPACK</small> pivoting strategy and the second for the symmetric strategy. By default, the values defined by <code>spparms</code> are used ([0.1, 0.001]). </p> <p>Given the string argument <code>"vector"</code>, <code>lu</code> returns the values of <var>P</var> and <var>Q</var> as vector values, such that for full matrix, <code><var>A</var>(<var>P</var>,:) = <var>L</var> * <var>U</var></code>, and <code><var>R</var>(<var>P</var>,:)
* <var>A</var>(:,<var>Q</var>) = <var>L</var> * <var>U</var></code>. </p> <p>With two output arguments, returns the permuted forms of the upper and lower triangular matrices, such that <code><var>A</var> = <var>L</var> * <var>U</var></code>. With one output argument <var>y</var>, then the matrix returned by the <small>LAPACK</small> routines is returned. If the input matrix is sparse then the matrix <var>L</var> is embedded into <var>U</var> to give a return value similar to the full case. For both full and sparse matrices, <code>lu</code> loses the permutation information. </p> <p><strong>See also:</strong> <a href="#XREFluupdate">luupdate</a>, <a href="iterative-techniques.html#XREFilu">ilu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-luupdate">
<span class="category">: </span><span><em>[<var>L</var>, <var>U</var>] =</em> <strong>luupdate</strong> <em>(<var>L</var>, <var>U</var>, <var>x</var>, <var>y</var>)</em><a href="#index-luupdate" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-luupdate-1">
<span class="category">: </span><span><em>[<var>L</var>, <var>U</var>, <var>P</var>] =</em> <strong>luupdate</strong> <em>(<var>L</var>, <var>U</var>, <var>P</var>, <var>x</var>, <var>y</var>)</em><a href="#index-luupdate-1" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Given an LU factorization of a real or complex matrix <var>A</var> = <var>L</var>*<var>U</var>, <var>L</var> lower unit trapezoidal and <var>U</var> upper trapezoidal, return the LU factorization of <var>A</var> + <var>x</var>*<var>y</var>.’, where <var>x</var> and <var>y</var> are column vectors (rank-1 update) or matrices with equal number of columns (rank-k update). </p> <p>Optionally, row-pivoted updating can be used by supplying a row permutation (pivoting) matrix <var>P</var>; in that case, an updated permutation matrix is returned. Note that if <var>L</var>, <var>U</var>, <var>P</var> is a pivoted LU factorization as obtained by <code>lu</code>: </p> <pre class="example" data-language="matlab">[L, U, P] = lu (A);</pre> <p>then a factorization of <code><var>A</var>+<var>x</var>*<var>y</var>.'</code> can be obtained either as </p> <pre class="example" data-language="matlab">[L1, U1] = lu (L, U, P*x, y)</pre> <p>or </p> <pre class="example" data-language="matlab">[L1, U1, P1] = lu (L, U, P, x, y)</pre> <p>The first form uses the unpivoted algorithm, which is faster, but less stable. The second form uses a slower pivoted algorithm, which is more stable. </p> <p>The matrix case is done as a sequence of rank-1 updates; thus, for large enough k, it will be both faster and more accurate to recompute the factorization from scratch. </p> <p><strong>See also:</strong> <a href="#XREFlu">lu</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFqrupdate">qrupdate</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qr">
<span class="category">: </span><span><em>[<var>Q</var>, <var>R</var>] =</em> <strong>qr</strong> <em>(<var>A</var>)</em><a href="#index-qr" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-1">
<span class="category">: </span><span><em>[<var>Q</var>, <var>R</var>, <var>P</var>] =</em> <strong>qr</strong> <em>(<var>A</var>)</em><a href="#index-qr-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-2">
<span class="category">: </span><span><em><var>X</var> =</em> <strong>qr</strong> <em>(<var>A</var>) # non-sparse A</em><a href="#index-qr-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-3">
<span class="category">: </span><span><em><var>R</var> =</em> <strong>qr</strong> <em>(<var>A</var>) # sparse A</em><a href="#index-qr-3" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-4">
<span class="category">: </span><span><em><var>X</var> =</em> <strong>qr</strong> <em>(<var>A</var>, <var>B</var>) # sparse A</em><a href="#index-qr-4" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-5">
<span class="category">: </span><span><em>[<var>C</var>, <var>R</var>] =</em> <strong>qr</strong> <em>(<var>A</var>, <var>B</var>)</em><a href="#index-qr-5" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-6">
<span class="category">: </span><span><em>[…] =</em> <strong>qr</strong> <em>(…, 0)</em><a href="#index-qr-6" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-7">
<span class="category">: </span><span><em>[…] =</em> <strong>qr</strong> <em>(…, "econ")</em><a href="#index-qr-7" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-8">
<span class="category">: </span><span><em>[…] =</em> <strong>qr</strong> <em>(…, "vector")</em><a href="#index-qr-8" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qr-9">
<span class="category">: </span><span><em>[…] =</em> <strong>qr</strong> <em>(…, "matrix")</em><a href="#index-qr-9" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
 <p>Compute the QR factorization of <var>A</var>, using standard <small>LAPACK</small> subroutines. </p> <p>The QR factorization is </p> <pre class="example" data-language="matlab">Q * R = A</pre> <p>where <var>Q</var> is an orthogonal matrix and <var>R</var> is upper triangular. </p> <p>For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>, </p> <pre class="example" data-language="matlab">[Q, R] = qr (A)</pre> <p>returns </p> <pre class="example" data-language="matlab">Q =

  -0.31623  -0.94868
  -0.94868   0.31623

R =

  -3.16228  -4.42719
   0.00000  -0.63246</pre> <p>which multiplied together return the original matrix </p> <pre class="example" data-language="matlab">Q * R
  ⇒
     1.0000   2.0000
     3.0000   4.0000</pre> <p>If just a single return value is requested then it is either <var>R</var>, if <var>A</var> is sparse, or <var>X</var>, such that <code><var>R</var> = triu (<var>X</var>)</code> if <var>A</var> is full. (Note: unlike most commands, the single return value is not the first return value when multiple values are requested.) </p> <p>If a third output <var>P</var> is requested, then <code>qr</code> calculates the permuted QR factorization </p> <pre class="example" data-language="matlab">Q * R = A * P</pre> <p>where <var>Q</var> is an orthogonal matrix, <var>R</var> is upper triangular, and <var>P</var> is a permutation matrix. </p> <p>If <var>A</var> is dense, the permuted QR factorization has the additional property that the diagonal entries of <var>R</var> are ordered by decreasing magnitude. In other words, <code>abs (diag (<var>R</var>))</code> will be ordered from largest to smallest. </p> <p>If <var>A</var> is sparse, <var>P</var> is a fill-reducing ordering of the columns of <var>A</var>. In that case, the diagonal entries of <var>R</var> are not ordered by decreasing magnitude. </p> <p>For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>, </p> <pre class="example" data-language="matlab">[Q, R, P] = qr (A)</pre> <p>returns </p> <pre class="example" data-language="matlab">Q =

  -0.44721  -0.89443
  -0.89443   0.44721

R =

  -4.47214  -3.13050
   0.00000   0.44721

P =

   0  1
   1  0</pre> <p>If the input matrix <var>A</var> is sparse, the sparse QR factorization is computed by using <small>SPQR</small> or <small>CXSPARSE</small> (e.g., if <small>SPQR</small> is not available). Because the matrix <var>Q</var> is, in general, a full matrix, it is recommended to request only one return value <var>R</var>. In that case, the computation avoids the construction of <var>Q</var> and returns a sparse <var>R</var> such that <code><var>R</var> = chol (<var>A</var>' * <var>A</var>)</code>. </p> <p>If <var>A</var> is dense, an additional matrix <var>B</var> is supplied and two return values are requested, then <code>qr</code> returns <var>C</var>, where <code><var>C</var> = <var>Q</var>' * <var>B</var></code>. This allows the least squares approximation of <code><var>A</var> \ <var>B</var></code> to be calculated as </p> <pre class="example" data-language="matlab">[C, R] = qr (A, B)
X = R \ C</pre> <p>If <var>A</var> is a sparse MxN matrix and an additional matrix <var>B</var> is supplied, one or two return values are possible. If one return value <var>X</var> is requested and M &lt; N, then <var>X</var> is the minimum 2-norm solution of <code><var>A</var> \ <var>B</var></code>. If M &gt;= N, <var>X</var> is the least squares approximation of <code><var>A</var> \ <var>B</var></code>. If two return values are requested, <var>C</var> and <var>R</var> have the same meaning as in the dense case (<var>C</var> is dense and <var>R</var> is sparse). The version with one return parameter should be preferred because it uses less memory and can handle rank-deficient matrices better. </p> <p>If the final argument is the string <code>"vector"</code> then <var>P</var> is a permutation vector (of the columns of <var>A</var>) instead of a permutation matrix. In this case, the defining relationship is: </p> <pre class="example" data-language="matlab">Q * R = A(:, P)</pre> <p>The default, however, is to return a permutation matrix and this may be explicitly specified by using a final argument of <code>"matrix"</code>. </p> <p>If the final argument is the scalar 0 or the string <code>"econ"</code>, an economy factorization is returned. If the original matrix <var>A</var> has size MxN and M &gt; N, then the economy factorization will calculate just N rows in <var>R</var> and N columns in <var>Q</var> and omit the zeros in <var>R</var>. If M ≤ N, there is no difference between the economy and standard factorizations. When calculating an economy factorization and <var>A</var> is dense, the output <var>P</var> is always a vector rather than a matrix. If <var>A</var> is sparse, output <var>P</var> is a sparse permutation matrix. </p> <p>Background: The QR factorization has applications in the solution of least squares problems </p> <pre class="example" data-language="matlab">min norm (A*x - b)</pre> <p>for overdetermined systems of equations (i.e., <var>A</var> is a tall, thin matrix). </p> <p>The permuted QR factorization <code>[<var>Q</var>, <var>R</var>, <var>P</var>] = qr (<var>A</var>)</code> allows the construction of an orthogonal basis of <code>span (A)</code>. </p> <p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrdelete">qrdelete</a>, <a href="#XREFqrshift">qrshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qrupdate">
<span class="category">: </span><span><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrupdate</strong> <em>(<var>Q</var>, <var>R</var>, <var>u</var>, <var>v</var>)</em><a href="#index-qrupdate" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a QR factorization given update vectors or matrices. </p> <p>Given a QR factorization of a real or complex matrix <var>A</var> = <var>Q</var>*<var>R</var>, <var>Q</var> unitary and <var>R</var> upper trapezoidal, return the QR factorization of <var>A</var> + <var>u</var>*<var>v</var>’, where <var>u</var> and <var>v</var> are column vectors (rank-1 update) or matrices with equal number of columns (rank-k update). Notice that the latter case is done as a sequence of rank-1 updates; thus, for k large enough, it will be both faster and more accurate to recompute the factorization from scratch. </p> <p>The QR factorization supplied may be either full (Q is square) or economized (R is square). </p> <p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrdelete">qrdelete</a>, <a href="#XREFqrshift">qrshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qrinsert">
<span class="category">: </span><span><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrinsert</strong> <em>(<var>Q</var>, <var>R</var>, <var>j</var>, <var>x</var>, <var>orient</var>)</em><a href="#index-qrinsert" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a QR factorization given a row or column to insert in the original factored matrix. </p> <p>Given a QR factorization of a real or complex matrix <var>A</var> = <var>Q</var>*<var>R</var>, <var>Q</var> unitary and <var>R</var> upper trapezoidal, return the QR factorization of <span class="nolinebreak">[A(:,1:j-1)</span> x A(:,j:n)], where <var>u</var> is a column vector to be inserted into <var>A</var> (if <var>orient</var> is <code>"col"</code>), or the QR factorization of <span class="nolinebreak">[A(1:j-1,:);x;A(:,j:n)]</span>, where <var>x</var> is a row vector to be inserted into <var>A</var> (if <var>orient</var> is <code>"row"</code>). </p> <p>The default value of <var>orient</var> is <code>"col"</code>. If <var>orient</var> is <code>"col"</code>, <var>u</var> may be a matrix and <var>j</var> an index vector resulting in the QR factorization of a matrix <var>B</var> such that B(:,<var>j</var>) gives <var>u</var> and B(:,<var>j</var>) = [] gives <var>A</var>. Notice that the latter case is done as a sequence of k insertions; thus, for k large enough, it will be both faster and more accurate to recompute the factorization from scratch. </p> <p>If <var>orient</var> is <code>"col"</code>, the QR factorization supplied may be either full (Q is square) or economized (R is square). </p> <p>If <var>orient</var> is <code>"row"</code>, full factorization is needed. </p> <p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrdelete">qrdelete</a>, <a href="#XREFqrshift">qrshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qrdelete">
<span class="category">: </span><span><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrdelete</strong> <em>(<var>Q</var>, <var>R</var>, <var>j</var>, <var>orient</var>)</em><a href="#index-qrdelete" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a QR factorization given a row or column to delete from the original factored matrix. </p> <p>Given a QR factorization of a real or complex matrix <var>A</var> = <var>Q</var>*<var>R</var>, <var>Q</var> unitary and <var>R</var> upper trapezoidal, return the QR factorization of <span class="nolinebreak">[A(:,1:j-1),</span> U, A(:,j:n)], where <var>u</var> is a column vector to be inserted into <var>A</var> (if <var>orient</var> is <code>"col"</code>), or the QR factorization of <span class="nolinebreak">[A(1:j-1,:);X;A(:,j:n)]</span>, where <var>x</var> is a row <var>orient</var> is <code>"row"</code>). The default value of <var>orient</var> is <code>"col"</code>. </p> <p>If <var>orient</var> is <code>"col"</code>, <var>j</var> may be an index vector resulting in the QR factorization of a matrix <var>B</var> such that A(:,<var>j</var>) = [] gives <var>B</var>. Notice that the latter case is done as a sequence of k deletions; thus, for k large enough, it will be both faster and more accurate to recompute the factorization from scratch. </p> <p>If <var>orient</var> is <code>"col"</code>, the QR factorization supplied may be either full (Q is square) or economized (R is square). </p> <p>If <var>orient</var> is <code>"row"</code>, full factorization is needed. </p> <p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrshift">qrshift</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qrshift">
<span class="category">: </span><span><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrshift</strong> <em>(<var>Q</var>, <var>R</var>, <var>i</var>, <var>j</var>)</em><a href="#index-qrshift" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Update a QR factorization given a range of columns to shift in the original factored matrix. </p> <p>Given a QR factorization of a real or complex matrix <var>A</var> = <var>Q</var>*<var>R</var>, <var>Q</var> unitary and <var>R</var> upper trapezoidal, return the QR factorization of <var>A</var>(:,p), where p is the permutation <br> <code>p = [1:i-1, shift(i:j, 1), j+1:n]</code> if <var>i</var> &lt; <var>j</var> <br> or <br> <code>p = [1:j-1, shift(j:i,-1), i+1:n]</code> if <var>j</var> &lt; <var>i</var>. <br> </p> <p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrdelete">qrdelete</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qz">
<span class="category">: </span><span><em><var>lambda</var> =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>)</em><a href="#index-qz" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qz-1">
<span class="category">: </span><span><em>[<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>, <var>V</var>, <var>W</var>, <var>lambda</var>] =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>)</em><a href="#index-qz-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qz-2">
<span class="category">: </span><span><em>[<var>AA</var>, <var>BB</var>, <var>Z</var>] =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>, <var>opt</var>)</em><a href="#index-qz-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-qz-3">
<span class="category">: </span><span><em>[<var>AA</var>, <var>BB</var>, <var>Z</var>, <var>lambda</var>] =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>, <var>opt</var>)</em><a href="#index-qz-3" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Compute the QZ decomposition of a generalized eigenvalue problem. </p> <p>The generalized eigenvalue problem is defined as </p> <p><em class="math">A x = <var>lambda</var> B x</em> </p> <p>There are three calling forms of the function: </p> <ol> <li> <code><var>lambda</var> = qz (<var>A</var>, <var>B</var>)</code> <p>Compute the generalized eigenvalues <var>lambda</var>. </p> </li>
<li> <code>[<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>, <var>V</var>, <var>W</var>, <var>lambda</var>] = qz (<var>A</var>, <var>B</var>)</code> <p>Compute QZ decomposition, generalized eigenvectors, and generalized eigenvalues. </p> <pre class="example" data-language="matlab">AA = Q * A * Z, BB = Q * B * Z
A * V = B * V * diag (lambda)
W' * A = diag (lambda) * W' * B</pre> <p>with <var>Q</var> and <var>Z</var> orthogonal (unitary for complex case). </p> </li>
<li> <code>[<var>AA</var>, <var>BB</var>, <var>Z</var> {, <var>lambda</var>}] = qz (<var>A</var>, <var>B</var>, <var>opt</var>)</code> <p>As in form 2 above, but allows ordering of generalized eigenpairs for, e.g., solution of discrete time algebraic Riccati equations. Form 3 is not available for complex matrices, and does not compute the generalized eigenvectors <var>V</var>, <var>W</var>, nor the orthogonal matrix <var>Q</var>. </p> <dl compact> <dt><span><var>opt</var></span></dt> <dd>
<p>for ordering eigenvalues of the GEP pencil. The leading block of the revised pencil contains all eigenvalues that satisfy: </p> <dl compact> <dt><span><code>"N"</code></span></dt> <dd>
<p>unordered (default) </p> </dd> <dt><span><code>"S"</code></span></dt> <dd>
<p>small: leading block has all |<var>lambda</var>| &lt; 1 </p> </dd> <dt><span><code>"B"</code></span></dt> <dd>
<p>big: leading block has all |<var>lambda</var>| ≥ 1 </p> </dd> <dt><span><code>"-"</code></span></dt> <dd>
<p>negative real part: leading block has all eigenvalues in the open left half-plane </p> </dd> <dt><span><code>"+"</code></span></dt> <dd><p>non-negative real part: leading block has all eigenvalues in the closed right half-plane </p></dd> </dl> </dd> </dl> </li>
</ol> <p>Note: <code>qz</code> performs permutation balancing, but not scaling (see <a href="basic-matrix-functions.html#XREFbalance"><code>balance</code></a>), which may be lead to less accurate results than <code>eig</code>. The order of output arguments was selected for compatibility with <small>MATLAB</small>. </p> <p><strong>See also:</strong> <a href="basic-matrix-functions.html#XREFeig">eig</a>, <a href="basic-matrix-functions.html#XREFgsvd">gsvd</a>, <a href="basic-matrix-functions.html#XREFbalance">balance</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqzhess">qzhess</a>, <a href="#XREFschur">schur</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-qzhess">
<span class="category">: </span><span><em>[<var>aa</var>, <var>bb</var>, <var>q</var>, <var>z</var>] =</em> <strong>qzhess</strong> <em>(<var>A</var>, <var>B</var>)</em><a href="#index-qzhess" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Compute the Hessenberg-triangular decomposition of the matrix pencil <code>(<var>A</var>, <var>B</var>)</code>, returning <code><var>aa</var> = <var>q</var> * <var>A</var> * <var>z</var></code>, <code><var>bb</var> = <var>q</var> * <var>B</var> * <var>z</var></code>, with <var>q</var> and <var>z</var> orthogonal. </p> <p>For example: </p> <pre class="example" data-language="matlab">[aa, bb, q, z] = qzhess ([1, 2; 3, 4], [5, 6; 7, 8])
  ⇒ aa =
      -3.02244  -4.41741
       0.92998   0.69749
  ⇒ bb =
      -8.60233  -9.99730
       0.00000  -0.23250
  ⇒ q =
      -0.58124  -0.81373
      -0.81373   0.58124
  ⇒ z =
     Diagonal Matrix
       1   0
       0   1</pre> <p>The Hessenberg-triangular decomposition is the first step in Moler and Stewart’s QZ decomposition algorithm. </p> <p>Algorithm taken from Golub and Van Loan, <cite>Matrix Computations, 2nd edition</cite>. </p> <p><strong>See also:</strong> <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-schur">
<span class="category">: </span><span><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>)</em><a href="#index-schur" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-schur-1">
<span class="category">: </span><span><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>, "real")</em><a href="#index-schur-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-schur-2">
<span class="category">: </span><span><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>, "complex")</em><a href="#index-schur-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-schur-3">
<span class="category">: </span><span><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>, <var>opt</var>)</em><a href="#index-schur-3" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-schur-4">
<span class="category">: </span><span><em>[<var>U</var>, <var>S</var>] =</em> <strong>schur</strong> <em>(…)</em><a href="#index-schur-4" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
 <p>Compute the Schur decomposition of <var>A</var>. </p> <p>The Schur decomposition of a square matrix <var>A</var> is defined as </p> <pre class="example" data-language="matlab">S = U' * A * U</pre> <p>where <var>U</var> is a unitary matrix (<code><var>U</var>'* <var>U</var></code> is identity) and <var>S</var> is upper triangular. The eigenvalues of <var>A</var> (and <var>S</var>) are the diagonal elements of <var>S</var>. If the matrix <var>A</var> is real, then the real Schur decomposition is computed, in which the matrix <var>U</var> is orthogonal and <var>S</var> is block upper triangular with blocks of size at most <code>2 x 2</code> along the diagonal. </p> <p>The default for real matrices is a real Schur decomposition. A complex decomposition may be forced by passing the flag <code>"complex"</code>. </p> <p>The eigenvalues are optionally ordered along the diagonal according to the value of <var>opt</var>: </p> <dl compact> <dt><span><code><var>opt</var> = "a"</code></span></dt> <dd>
<p>Move eigenvalues with negative real parts to the leading block of <var>S</var>. Mnemonic: <code>"a"</code> for Algebraic Riccati Equations, where this ordering is useful. </p> </dd> <dt><span><code><var>opt</var> = "d"</code></span></dt> <dd>
<p>Move eigenvalues with magnitude less than one to the leading block of <var>S</var>. Mnemonic: <code>"d"</code> for Discrete Algebraic Riccati Equations, where this ordering is useful. </p> </dd> <dt><span><code><var>opt</var> = "u"</code></span></dt> <dd><p>Unordered. No particular ordering of eigenvalues (default). </p></dd> </dl> <p>The leading <var>k</var> columns of <var>U</var> always span the <var>A</var>-invariant subspace corresponding to the <var>k</var> leading eigenvalues of <var>S</var>. </p> <p><strong>See also:</strong> <a href="#XREFrsf2csf">rsf2csf</a>, <a href="#XREFordschur">ordschur</a>, <a href="#XREFordeig">ordeig</a>, <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFsvd">svd</a>, <a href="basic-matrix-functions.html#XREFeig">eig</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-rsf2csf">
<span class="category">: </span><span><em>[<var>U</var>, <var>T</var>] =</em> <strong>rsf2csf</strong> <em>(<var>UR</var>, <var>TR</var>)</em><a href="#index-rsf2csf" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Convert a real, upper quasi-triangular Schur form <var>TR</var> to a complex, upper triangular Schur form <var>T</var>. </p> <p>Note that the following relations hold: </p> <p><code><var>UR</var> * <var>TR</var> * <var>UR</var>' = <var>U</var> * <var>T</var> * <var>U</var>'</code> and <code><var>U</var>' * <var>U</var></code> is the identity matrix I. </p> <p>Note also that <var>U</var> and <var>T</var> are not unique. </p> <p><strong>See also:</strong> <a href="#XREFschur">schur</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-ordschur">
<span class="category">: </span><span><em>[<var>UR</var>, <var>SR</var>] =</em> <strong>ordschur</strong> <em>(<var>U</var>, <var>S</var>, <var>select</var>)</em><a href="#index-ordschur" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Reorder the real Schur factorization (<var>U</var>,<var>S</var>) obtained with the <code>schur</code> function, so that selected eigenvalues appear in the upper left diagonal blocks of the quasi triangular Schur matrix. </p> <p>The logical vector <var>select</var> specifies the selected eigenvalues as they appear along <var>S</var>’s diagonal. </p> <p>For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>, and its Schur decomposition </p> <pre class="example" data-language="matlab">[U, S] = schur (A)</pre> <p>which returns </p> <pre class="example" data-language="matlab">U =

  -0.82456  -0.56577
   0.56577  -0.82456

S =

  -0.37228  -1.00000
   0.00000   5.37228</pre> <p>It is possible to reorder the decomposition so that the positive eigenvalue is in the upper left corner, by doing: </p> <pre class="example" data-language="matlab">[U, S] = ordschur (U, S, [0,1])</pre> <p><strong>See also:</strong> <a href="#XREFschur">schur</a>, <a href="#XREFordeig">ordeig</a>, <a href="#XREFordqz">ordqz</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-ordqz">
<span class="category">: </span><span><em>[<var>AR</var>, <var>BR</var>, <var>QR</var>, <var>ZR</var>] =</em> <strong>ordqz</strong> <em>(<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>, <var>keyword</var>)</em><a href="#index-ordqz" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-ordqz-1">
<span class="category">: </span><span><em>[<var>AR</var>, <var>BR</var>, <var>QR</var>, <var>ZR</var>] =</em> <strong>ordqz</strong> <em>(<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>, <var>select</var>)</em><a href="#index-ordqz-1" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Reorder the QZ decomposition of a generalized eigenvalue problem. </p> <p>The generalized eigenvalue problem is defined as </p> <p><em class="math">A x = <var>lambda</var> B x</em> </p> <p>Its generalized Schur decomposition is computed using the <code>qz</code> algorithm: </p> <p><code>[<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>] = qz (<var>A</var>, <var>B</var>)</code> </p> <p>where <var>AA</var>, <var>BB</var>, <var>Q</var>, and <var>Z</var> fulfill </p> <pre class="example" data-language="matlab">AA = Q * A * Z, BB = Q * B * Z</pre> <p>The <code>ordqz</code> function computes a unitary transformation <var>QR</var> and <var>ZR</var> such that the order of the eigenvalue on the diagonal of <var>AA</var> and <var>BB</var> is changed. The resulting reordered matrices <var>AR</var> and <var>BR</var> fulfill: </p> <pre class="example" data-language="matlab">AR = QR * A * ZR, BR = QR * B * ZR</pre> <p>The function can either be called with the <var>keyword</var> argument which selects the eigenvalues in the top left block of <var>AR</var> and <var>BR</var> in the following way: </p> <dl compact> <dt><span><code>"S"</code>, <code>"udi"</code></span></dt> <dd>
<p>small: leading block has all |<var>lambda</var>| &lt; 1 </p> </dd> <dt><span><code>"B"</code>, <code>"udo"</code></span></dt> <dd>
<p>big: leading block has all |<var>lambda</var>| ≥ 1 </p> </dd> <dt><span><code>"-"</code>, <code>"lhp"</code></span></dt> <dd>
<p>negative real part: leading block has all eigenvalues in the open left half-plane </p> </dd> <dt><span><code>"+"</code>, <code>"rhp"</code></span></dt> <dd><p>non-negative real part: leading block has all eigenvalues in the closed right half-plane </p></dd> </dl> <p>If a logical vector <var>select</var> is given instead of a keyword the <code>ordqz</code> function reorders all eigenvalues <code>k</code> to the left block for which <code>select(k)</code> is true. </p> <p>Note: The keywords are compatible with the ones from <code>qr</code>. </p> <p><strong>See also:</strong> <a href="basic-matrix-functions.html#XREFeig">eig</a>, <a href="#XREFordeig">ordeig</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFordschur">ordschur</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-ordeig">
<span class="category">: </span><span><em><var>lambda</var> =</em> <strong>ordeig</strong> <em>(<var>A</var>)</em><a href="#index-ordeig" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-ordeig-1">
<span class="category">: </span><span><em><var>lambda</var> =</em> <strong>ordeig</strong> <em>(<var>A</var>, <var>B</var>)</em><a href="#index-ordeig-1" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Return the eigenvalues of quasi-triangular matrices in their order of appearance in the matrix <var>A</var>. </p> <p>The quasi-triangular matrix <var>A</var> is usually the result of a Schur factorization. If called with a second input <var>B</var> then the generalized eigenvalues of the pair <var>A</var>, <var>B</var> are returned in the order of appearance of the matrix <code><var>A</var>-<var>lambda</var>*<var>B</var></code>. The pair <var>A</var>, <var>B</var> is usually the result of a QZ decomposition. </p> <p><strong>See also:</strong> <a href="#XREFordschur">ordschur</a>, <a href="#XREFordqz">ordqz</a>, <a href="basic-matrix-functions.html#XREFeig">eig</a>, <a href="#XREFschur">schur</a>, <a href="#XREFqz">qz</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-subspace">
<span class="category">: </span><span><em><var>angle</var> =</em> <strong>subspace</strong> <em>(<var>A</var>, <var>B</var>)</em><a href="#index-subspace" class="copiable-anchor"> ¶</a></span>
</dt> <dd><p>Determine the largest principal angle between two subspaces spanned by the columns of matrices <var>A</var> and <var>B</var>. </p></dd>
</dl> <dl class="def"> <dt id="index-svd">
<span class="category">: </span><span><em><var>s</var> =</em> <strong>svd</strong> <em>(<var>A</var>)</em><a href="#index-svd" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-svd-1">
<span class="category">: </span><span><em>[<var>U</var>, <var>S</var>, <var>V</var>] =</em> <strong>svd</strong> <em>(<var>A</var>)</em><a href="#index-svd-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-svd-2">
<span class="category">: </span><span><em>[<var>U</var>, <var>S</var>, <var>V</var>] =</em> <strong>svd</strong> <em>(<var>A</var>, "econ")</em><a href="#index-svd-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-svd-3">
<span class="category">: </span><span><em>[<var>U</var>, <var>S</var>, <var>V</var>] =</em> <strong>svd</strong> <em>(<var>A</var>, 0)</em><a href="#index-svd-3" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
 <p>Compute the singular value decomposition of <var>A</var>. </p> <p>The singular value decomposition is defined by the relation </p> <pre class="example" data-language="matlab">A = U*S*V'</pre> <p>The function <code>svd</code> normally returns only the vector of singular values. When called with three return values, it computes <var>U</var>, <var>S</var>, and <var>V</var>. For example, </p> <pre class="example" data-language="matlab">svd (hilb (3))</pre> <p>returns </p> <pre class="example" data-language="matlab">ans =

  1.4083189
  0.1223271
  0.0026873</pre> <p>and </p> <pre class="example" data-language="matlab">[u, s, v] = svd (hilb (3))</pre> <p>returns </p> <pre class="example" data-language="matlab">u =

  -0.82704   0.54745   0.12766
  -0.45986  -0.52829  -0.71375
  -0.32330  -0.64901   0.68867

s =

  1.40832  0.00000  0.00000
  0.00000  0.12233  0.00000
  0.00000  0.00000  0.00269

v =

  -0.82704   0.54745   0.12766
  -0.45986  -0.52829  -0.71375
  -0.32330  -0.64901   0.68867</pre> <p>When given a second argument that is not 0, <code>svd</code> returns an economy-sized decomposition, eliminating the unnecessary rows or columns of <var>U</var> or <var>V</var>. </p> <p>If the second argument is exactly 0, then the choice of decomposition is based on the matrix <var>A</var>. If <var>A</var> has more rows than columns then an economy-sized decomposition is returned, otherwise a regular decomposition is calculated. </p> <p>Algorithm Notes: When calculating the full decomposition (left and right singular matrices in addition to singular values) there is a choice of two routines in <small>LAPACK</small>. The default routine used by Octave is <code>gesvd</code>. The alternative is <code>gesdd</code> which is 5X faster, but may use more memory and may be inaccurate for some input matrices. There is a third routine <code>gejsv</code>, suitable for better accuracy at extreme scale. See the documentation for <code>svd_driver</code> for more information on choosing a driver. </p> <p><strong>See also:</strong> <a href="#XREFsvd_005fdriver">svd_driver</a>, <a href="sparse-linear-algebra.html#XREFsvds">svds</a>, <a href="basic-matrix-functions.html#XREFeig">eig</a>, <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-svd_005fdriver">
<span class="category">: </span><span><em><var>val</var> =</em> <strong>svd_driver</strong> <em>()</em><a href="#index-svd_005fdriver" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-svd_005fdriver-1">
<span class="category">: </span><span><em><var>old_val</var> =</em> <strong>svd_driver</strong> <em>(<var>new_val</var>)</em><a href="#index-svd_005fdriver-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-svd_005fdriver-2">
<span class="category">: </span><span><em><var>old_val</var> =</em> <strong>svd_driver</strong> <em>(<var>new_val</var>, "local")</em><a href="#index-svd_005fdriver-2" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Query or set the underlying <small>LAPACK</small> driver used by <code>svd</code>. </p> <p>Currently recognized values are <code>"gesdd"</code>, <code>"gesvd"</code>, and <code>"gejsv"</code>. The default is <code>"gesvd"</code>. </p> <p>When called from inside a function with the <code>"local"</code> option, the variable is changed locally for the function and any subroutines it calls. The original variable value is restored when exiting the function. </p> <p>Algorithm Notes: The <small>LAPACK</small> library routines <code>gesvd</code> and <code>gesdd</code> are different only when calculating the full singular value decomposition (left and right singular matrices as well as singular values). When calculating just the singular values the following discussion is not relevant. </p> <p>The newer <code>gesdd</code> routine is based on a Divide-and-Conquer algorithm that is 5X faster than the alternative <code>gesvd</code>, which is based on QR factorization. However, the new algorithm can use significantly more memory. For an MxN input matrix the memory usage is of order O(min(M,N) ^ 2), whereas the alternative is of order O(max(M,N)). </p> <p>The routine <code>gejsv</code> uses a preconditioned Jacobi SVD algorithm. Unlike <code>gesvd</code> and <code>gesdd</code>, in <code>gejsv</code>, there is no bidiagonalization step that could contaminate accuracy in some extreme cases. Also, <code>gejsv</code> is known to be optimally accurate in some sense. However, the speed is slower (single threaded at its core) and uses more memory (O(min(M,N) ^ 2 + M + N)). </p> <p>Beyond speed and memory issues, there have been instances where some input matrices were not accurately decomposed by <code>gesdd</code>. See currently active bug <a href="https://savannah.gnu.org/bugs/?55564">https://savannah.gnu.org/bugs/?55564</a>. Until these accuracy issues are resolved in a new version of the <small>LAPACK</small> library, the default driver in Octave has been set to <code>"gesvd"</code>. </p> <p><strong>See also:</strong> <a href="#XREFsvd">svd</a>. </p>
</dd>
</dl> <dl class="def"> <dt id="index-housh">
<span class="category">: </span><span><em>[<var>housv</var>, <var>beta</var>, <var>zer</var>] =</em> <strong>housh</strong> <em>(<var>x</var>, <var>j</var>, <var>z</var>)</em><a href="#index-housh" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Compute Householder reflection vector <var>housv</var> to reflect <var>x</var> to be the j-th column of identity, i.e., </p> <pre class="example" data-language="matlab">(I - beta*housv*housv')x =  norm (x)*e(j) if x(j) &lt; 0,
(I - beta*housv*housv')x = -norm (x)*e(j) if x(j) &gt;= 0</pre> <p>Inputs </p> <dl compact> <dt><span><var>x</var></span></dt> <dd>
<p>vector </p> </dd> <dt><span><var>j</var></span></dt> <dd>
<p>index into vector </p> </dd> <dt><span><var>z</var></span></dt> <dd><p>threshold for zero (usually should be the number 0) </p></dd> </dl> <p>Outputs (see Golub and Van Loan): </p> <dl compact> <dt><span><var>beta</var></span></dt> <dd>
<p>If beta = 0, then no reflection need be applied (zer set to 0) </p> </dd> <dt><span><var>housv</var></span></dt> <dd><p>householder vector </p></dd> </dl> </dd>
</dl> <dl class="def"> <dt id="index-krylov">
<span class="category">: </span><span><em>[<var>u</var>, <var>h</var>, <var>nu</var>] =</em> <strong>krylov</strong> <em>(<var>A</var>, <var>V</var>, <var>k</var>, <var>eps1</var>, <var>pflg</var>)</em><a href="#index-krylov" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Construct an orthogonal basis <var>u</var> of a block Krylov subspace. </p> <p>The block Krylov subspace has the following form: </p> <pre class="example" data-language="matlab">[v a*v a^2*v … a^(k+1)*v]</pre> <p>The construction is made with Householder reflections to guard against loss of orthogonality. </p> <p>If <var>V</var> is a vector, then <var>h</var> contains the Hessenberg matrix such that <code>a*u == u*h+rk*ek'</code>, in which <code>rk = a*u(:,k)-u*h(:,k)</code>, and <code>ek'</code> is the vector <code>[0, 0, …, 1]</code> of length <var>k</var>. Otherwise, <var>h</var> is meaningless. </p> <p>If <var>V</var> is a vector and <var>k</var> is greater than <code>length (A) - 1</code>, then <var>h</var> contains the Hessenberg matrix such that <code>a*u == u*h</code>. </p> <p>The value of <var>nu</var> is the dimension of the span of the Krylov subspace (based on <var>eps1</var>). </p> <p>If <var>b</var> is a vector and <var>k</var> is greater than <var>m-1</var>, then <var>h</var> contains the Hessenberg decomposition of <var>A</var>. </p> <p>The optional parameter <var>eps1</var> is the threshold for zero. The default value is 1e-12. </p> <p>If the optional parameter <var>pflg</var> is nonzero, row pivoting is used to improve numerical behavior. The default value is 0. </p> <p>Reference: A. Hodel, P. Misra, <cite>Partial Pivoting in the Computation of Krylov Subspaces of Large Sparse Systems</cite>, Proceedings of the 42nd IEEE Conference on Decision and Control, December 2003. </p>
</dd>
</dl> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 1996–2023 The Octave Project Developers<br>Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.<br/>Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.</br>Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions.<br>
    <a href="https://docs.octave.org/v8.1.0/Matrix-Factorizations.html" class="_attribution-link">https://docs.octave.org/v8.1.0/Matrix-Factorizations.html</a>
  </p>
</div>
