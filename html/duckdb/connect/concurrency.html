<h1 class="title">Concurrency</h1>  <h2 id="handling-concurrency"> <a style="text-decoration: none;" href="#handling-concurrency">Handling Concurrency</a> </h2> <p>DuckDB has two configurable options for concurrency:</p> <ol> <li>One process can both read and write to the database.</li> <li>Multiple processes can read from the database, but no processes can write (<a href="../configuration/overview.html#configuration-reference.html"><code class="language-plaintext highlighter-rouge">access_mode = 'READ_ONLY'</code></a>).</li> </ol> <p>When using option 1, DuckDB supports multiple writer threads using a combination of <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC (Multi-Version Concurrency Control)</a> and optimistic concurrency control (see <a href="#concurrency-within-a-single-process">Concurrency within a Single Process</a>), but all within that single writer process. The reason for this concurrency model is to allow for the caching of data in RAM for faster analytical queries, rather than going back and forth to disk during each query. It also allows the caching of functions pointers, the database catalog, and other items so that subsequent queries on the same connection are faster.</p> <blockquote> <p>DuckDB is optimized for bulk operations, so executing many small transactions is not a primary design goal.</p> </blockquote> <h2 id="concurrency-within-a-single-process"> <a style="text-decoration: none;" href="#concurrency-within-a-single-process">Concurrency within a Single Process</a> </h2> <p>DuckDB supports concurrency within a single process according to the following rules. As long as there are no write conflicts, multiple concurrent writes will succeed. Appends will never conflict, even on the same table. Multiple threads can also simultaneously update separate tables or separate subsets of the same table. Optimistic concurrency control comes into play when two threads attempt to edit (update or delete) the same row at the same time. In that situation, the second thread to attempt the edit will fail with a conflict error.</p> <h2 id="writing-to-duckdb-from-multiple-processes"> <a style="text-decoration: none;" href="#writing-to-duckdb-from-multiple-processes">Writing to DuckDB from Multiple Processes</a> </h2> <p>Writing to DuckDB from multiple processes is not supported automatically and is not a primary design goal (see <a href="#handling-concurrency">Handling Concurrency</a>).</p> <p>If multiple processes must write to the same file, several design patterns are possible, but would need to be implemented in application logic. For example, each process could acquire a cross-process mutex lock, then open the database in read/write mode and close it when the query is complete. Instead of using a mutex lock, each process could instead retry the connection if another process is already connected to the database (being sure to close the connection upon query completion). Another alternative would be to do multi-process transactions on a MySQL, PostgreSQL, or SQLite database, and use DuckDB's <a href="../extensions/mysql.html">MySQL</a>, <a href="../extensions/postgres.html">PostgreSQL</a>, or <a href="../extensions/sqlite.html">SQLite</a> extensions to execute analytical queries on that data periodically.</p> <p>Additional options include writing data to Parquet files and using DuckDB's ability to <a href="../data/parquet/overview.html">read multiple Parquet files</a>, taking a similar approach with <a href="../data/csv/overview.html">CSV files</a>, or creating a web server to receive requests and manage reads and writes to DuckDB.</p> <h2 id="optimistic-concurrency-control"> <a style="text-decoration: none;" href="#optimistic-concurrency-control">Optimistic Concurrency Control</a> </h2> <p>DuckDB uses <a href="https://en.wikipedia.org/wiki/Optimistic_concurrency_control">optimistic concurrency control</a>, an approach generally considered to be the best fit for read-intensive analytical database systems as it speeds up read query processing. As a result any transactions that modify the same rows at the same time will cause a transaction conflict error:</p> <pre class="language-console highlighter-rouge" data-language="console">Transaction conflict: cannot update a table that has been altered!</pre> <blockquote> <p>Tip A common workaround when a transaction conflict is encountered is to rerun the transaction.</p> </blockquote><div class="_attribution">
  <p class="_attribution-p">
    &copy; Copyright 2018&ndash;2024 Stichting DuckDB Foundation<br>Licensed under the MIT License.<br>
    <a href="https://duckdb.org/docs/connect/concurrency.html" class="_attribution-link">https://duckdb.org/docs/connect/concurrency.html</a>
  </p>
</div>
