<h1 id="module:FindCUDA">FindCUDA</h1> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p><em>Deprecated since version 3.10.</em></p> </div> <p>It is no longer necessary to use this module or call <code>find_package(CUDA)</code> for compiling CUDA code. Instead, list <code>CUDA</code> among the languages named in the top-level call to the <a class="reference internal" href="../command/project.html#command:project" title="project" id="index-0-command:project"><code>project()</code></a> command, or call the <a class="reference internal" href="../command/enable_language.html#command:enable_language" title="enable_language" id="index-0-command:enable_language"><code>enable_language()</code></a> command with <code>CUDA</code>. Then one can add CUDA (<code>.cu</code>) sources directly to targets similar to other languages.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.17: </span>To find and use the CUDA toolkit libraries manually, use the <a class="reference internal" href="findcudatoolkit.html#module:FindCUDAToolkit" title="FindCUDAToolkit" id="index-0-module:FindCUDAToolkit"><code>FindCUDAToolkit</code></a> module instead. It works regardless of the <code>CUDA</code> language being enabled.</p> </div>  <h2>Documentation of Deprecated Usage</h2> <p>Tools for building CUDA C files: libraries and build dependencies.</p> <p>This script locates the NVIDIA CUDA C tools. It should work on Linux, Windows, and macOS and should be reasonably up to date with CUDA C releases.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.19: </span>QNX support.</p> </div> <p>This script makes use of the standard <a class="reference internal" href="../command/find_package.html#command:find_package" title="find_package" id="index-0-command:find_package"><code>find_package()</code></a> arguments of <code>&lt;VERSION&gt;</code>, <code>REQUIRED</code> and <code>QUIET</code>. <code>CUDA_FOUND</code> will report if an acceptable version of CUDA was found.</p> <p>The script will prompt the user to specify <code>CUDA_TOOLKIT_ROOT_DIR</code> if the prefix cannot be determined by the location of nvcc in the system path and <code>REQUIRED</code> is specified to <a class="reference internal" href="../command/find_package.html#command:find_package" title="find_package" id="index-1-command:find_package"><code>find_package()</code></a>. To use a different installed version of the toolkit set the environment variable <code>CUDA_BIN_PATH</code> before running cmake (e.g. <code>CUDA_BIN_PATH=/usr/local/cuda1.0</code> instead of the default <code>/usr/local/cuda</code>) or set <code>CUDA_TOOLKIT_ROOT_DIR</code> after configuring. If you change the value of <code>CUDA_TOOLKIT_ROOT_DIR</code>, various components that depend on the path will be relocated.</p> <p>It might be necessary to set <code>CUDA_TOOLKIT_ROOT_DIR</code> manually on certain platforms, or to use a CUDA runtime not installed in the default location. In newer versions of the toolkit the CUDA library is included with the graphics driver -- be sure that the driver version matches what is needed by the CUDA runtime version.</p>  <h3>Input Variables</h3> <p>The following variables affect the behavior of the macros in the script (in alphabetical order). Note that any of these flags can be changed multiple times in the same directory before calling <code>cuda_add_executable()</code>, <code>cuda_add_library()</code>, <code>cuda_compile()</code>, <code>cuda_compile_ptx()</code>, <code>cuda_compile_fatbin()</code>, <code>cuda_compile_cubin()</code> or <code>cuda_wrap_srcs()</code>:</p> <dl> <dt>
<code>CUDA_64_BIT_DEVICE_CODE (Default: host bit size)</code> </dt>
<dd>
<p>Set to <code>ON</code> to compile for 64 bit device code, OFF for 32 bit device code. Note that making this different from the host code when generating object or C files from CUDA code just won't work, because size_t gets defined by nvcc in the generated source. If you compile to PTX and then load the file yourself, you can mix bit sizes between device and host.</p> </dd> <dt>
<code>CUDA_ATTACH_VS_BUILD_RULE_TO_CUDA_FILE (Default: ON)</code> </dt>
<dd>
<p>Set to <code>ON</code> if you want the custom build rule to be attached to the source file in Visual Studio. Turn OFF if you add the same cuda file to multiple targets.</p> <p>This allows the user to build the target from the CUDA file; however, bad things can happen if the CUDA source file is added to multiple targets. When performing parallel builds it is possible for the custom build command to be run more than once and in parallel causing cryptic build errors. VS runs the rules for every source file in the target, and a source can have only one rule no matter how many projects it is added to. When the rule is run from multiple targets race conditions can occur on the generated file. Eventually everything will get built, but if the user is unaware of this behavior, there may be confusion. It would be nice if this script could detect the reuse of source files across multiple targets and turn the option off for the user, but no good solution could be found.</p> </dd> <dt>
<code>CUDA_BUILD_CUBIN (Default: OFF)</code> </dt>
<dd>
<p>Set to <code>ON</code> to enable and extra compilation pass with the <code>-cubin</code> option in Device mode. The output is parsed and register, shared memory usage is printed during build.</p> </dd> <dt>
<code>CUDA_BUILD_EMULATION (Default: OFF for device mode)</code> </dt>
<dd>
<p>Set to <code>ON</code> for Emulation mode. <code>-D_DEVICEEMU</code> is defined for CUDA C files when <code>CUDA_BUILD_EMULATION</code> is <code>TRUE</code>.</p> </dd> <dt>
<code>CUDA_LINK_LIBRARIES_KEYWORD (Default: "")</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.9.</span></p> </div> <p>The <code>&lt;PRIVATE|PUBLIC|INTERFACE&gt;</code> keyword to use for internal <a class="reference internal" href="../command/target_link_libraries.html#command:target_link_libraries" title="target_link_libraries" id="index-0-command:target_link_libraries"><code>target_link_libraries()</code></a> calls. The default is to use no keyword which uses the old "plain" form of <a class="reference internal" href="../command/target_link_libraries.html#command:target_link_libraries" title="target_link_libraries" id="index-1-command:target_link_libraries"><code>target_link_libraries()</code></a>. Note that is matters because whatever is used inside the <code>FindCUDA</code> module must also be used outside - the two forms of <a class="reference internal" href="../command/target_link_libraries.html#command:target_link_libraries" title="target_link_libraries" id="index-2-command:target_link_libraries"><code>target_link_libraries()</code></a> cannot be mixed.</p> </dd> <dt>
<code>CUDA_GENERATED_OUTPUT_DIR (Default: CMAKE_CURRENT_BINARY_DIR)</code> </dt>
<dd>
<p>Set to the path you wish to have the generated files placed. If it is blank output files will be placed in <a class="reference internal" href="../variable/cmake_current_binary_dir.html#variable:CMAKE_CURRENT_BINARY_DIR" title="CMAKE_CURRENT_BINARY_DIR" id="index-1-variable:CMAKE_CURRENT_BINARY_DIR"><code>CMAKE_CURRENT_BINARY_DIR</code></a>. Intermediate files will always be placed in <code>CMAKE_CURRENT_BINARY_DIR/CMakeFiles</code>.</p> </dd> <dt>
<code>CUDA_HOST_COMPILATION_CPP (Default: ON)</code> </dt>
<dd>
<p>Set to <code>OFF</code> for C compilation of host code.</p> </dd> <dt>
<code>CUDA_HOST_COMPILER (Default: CMAKE_C_COMPILER)</code> </dt>
<dd>
<p>Set the host compiler to be used by nvcc. Ignored if <code>-ccbin</code> or <code>--compiler-bindir</code> is already present in the <code>CUDA_NVCC_FLAGS</code> or <code>CUDA_NVCC_FLAGS_&lt;CONFIG&gt;</code> variables. For Visual Studio targets, the host compiler is constructed with one or more visual studio macros such as <code>$(VCInstallDir)</code>, that expands out to the path when the command is run from within VS.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.13: </span>If the <a class="reference internal" href="../envvar/cudahostcxx.html#envvar:CUDAHOSTCXX" title="CUDAHOSTCXX" id="index-0-envvar:CUDAHOSTCXX"><code>CUDAHOSTCXX</code></a> environment variable is set it will be used as the default.</p> </div> </dd> <dt>
<code>CUDA_NVCC_FLAGS, CUDA_NVCC_FLAGS_&lt;CONFIG&gt;</code> </dt>
<dd>
<p>Additional NVCC command line arguments. NOTE: multiple arguments must be semi-colon delimited (e.g. <code>--compiler-options;-Wall</code>)</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.6: </span>Contents of these variables may use <a class="reference internal" href="../manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7)" title="cmake-generator-expressions(7)" id="index-0-manual:cmake-generator-expressions(7)"><code>generator expressions</code></a>.</p> </div> </dd> <dt>
<code>CUDA_PROPAGATE_HOST_FLAGS (Default: ON)</code> </dt>
<dd>
<p>Set to <code>ON</code> to propagate <a class="reference internal" href="#" title="CMAKE_&lt;LANG&gt;_FLAGS" id="index-0-variable:CMAKE_&lt;LANG&gt;_FLAGS"><code>CMAKE_{C,CXX}_FLAGS</code></a> and their configuration dependent counterparts (e.g. <code>CMAKE_C_FLAGS_DEBUG</code>) automatically to the host compiler through nvcc's <code>-Xcompiler</code> flag. This helps make the generated host code match the rest of the system better. Sometimes certain flags give nvcc problems, and this will help you turn the flag propagation off. This does not affect the flags supplied directly to nvcc via <code>CUDA_NVCC_FLAGS</code> or through the <code>OPTION</code> flags specified through <code>cuda_add_library()</code>, <code>cuda_add_executable()</code>, or <code>cuda_wrap_srcs()</code>. Flags used for shared library compilation are not affected by this flag.</p> </dd> <dt>
<code>CUDA_SEPARABLE_COMPILATION (Default: OFF)</code> </dt>
<dd>
<p>If set this will enable separable compilation for all CUDA runtime object files. If used outside of <code>cuda_add_executable()</code> and <code>cuda_add_library()</code> (e.g. calling <code>cuda_wrap_srcs()</code> directly), <code>cuda_compute_separable_compilation_object_file_name()</code> and <code>cuda_link_separable_compilation_objects()</code> should be called.</p> </dd> <dt>
<code>CUDA_SOURCE_PROPERTY_FORMAT</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.3.</span></p> </div> <p>If this source file property is set, it can override the format specified to <code>cuda_wrap_srcs()</code> (<code>OBJ</code>, <code>PTX</code>, <code>CUBIN</code>, or <code>FATBIN</code>). If an input source file is not a <code>.cu</code> file, setting this file will cause it to be treated as a <code>.cu</code> file. See documentation for set_source_files_properties on how to set this property.</p> </dd> <dt>
<code>CUDA_USE_STATIC_CUDA_RUNTIME (Default: ON)</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.3.</span></p> </div> <p>When enabled the static version of the CUDA runtime library will be used in <code>CUDA_LIBRARIES</code>. If the version of CUDA configured doesn't support this option, then it will be silently disabled.</p> </dd> <dt>
<code>CUDA_VERBOSE_BUILD (Default: OFF)</code> </dt>
<dd>
<p>Set to <code>ON</code> to see all the commands used when building the CUDA file. When using a Makefile generator the value defaults to <code>VERBOSE</code> (run <code>make VERBOSE=1</code> to see output), although setting <code>CUDA_VERBOSE_BUILD</code> to <code>ON</code> will always print the output.</p> </dd> </dl>   <h3>Commands</h3> <p>The script creates the following functions and macros (in alphabetical order):</p> <pre data-language="cmake">cuda_add_cufft_to_target(&lt;cuda_target&gt;)
</pre> <p>Adds the cufft library to the target (can be any target). Handles whether you are in emulation mode or not.</p> <pre data-language="cmake">cuda_add_cublas_to_target(&lt;cuda_target&gt;)
</pre> <p>Adds the cublas library to the target (can be any target). Handles whether you are in emulation mode or not.</p> <pre data-language="cmake">cuda_add_executable(&lt;cuda_target&gt; &lt;file&gt;...
                    [WIN32] [MACOSX_BUNDLE] [EXCLUDE_FROM_ALL] [OPTIONS ...])
</pre> <p>Creates an executable <code>&lt;cuda_target&gt;</code> which is made up of the files specified. All of the non CUDA C files are compiled using the standard build rules specified by CMake and the CUDA files are compiled to object files using nvcc and the host compiler. In addition <code>CUDA_INCLUDE_DIRS</code> is added automatically to <a class="reference internal" href="../command/include_directories.html#command:include_directories" title="include_directories" id="index-0-command:include_directories"><code>include_directories()</code></a>. Some standard CMake target calls can be used on the target after calling this macro (e.g. <a class="reference internal" href="../command/set_target_properties.html#command:set_target_properties" title="set_target_properties" id="index-0-command:set_target_properties"><code>set_target_properties()</code></a> and <a class="reference internal" href="../command/target_link_libraries.html#command:target_link_libraries" title="target_link_libraries" id="index-3-command:target_link_libraries"><code>target_link_libraries()</code></a>), but setting properties that adjust compilation flags will not affect code compiled by nvcc. Such flags should be modified before calling <code>cuda_add_executable()</code>, <code>cuda_add_library()</code> or <code>cuda_wrap_srcs()</code>.</p> <pre data-language="cmake">cuda_add_library(&lt;cuda_target&gt; &lt;file&gt;...
                 [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] [OPTIONS ...])
</pre> <p>Same as <code>cuda_add_executable()</code> except that a library is created.</p> <pre data-language="cmake">cuda_build_clean_target()
</pre> <p>Creates a convenience target that deletes all the dependency files generated. You should make clean after running this target to ensure the dependency files get regenerated.</p> <pre data-language="cmake">cuda_compile(&lt;generated_files&gt; &lt;file&gt;... [STATIC | SHARED | MODULE]
             [OPTIONS ...])
</pre> <p>Returns a list of generated files from the input source files to be used with <a class="reference internal" href="../command/add_library.html#command:add_library" title="add_library" id="index-0-command:add_library"><code>add_library()</code></a> or <a class="reference internal" href="../command/add_executable.html#command:add_executable" title="add_executable" id="index-0-command:add_executable"><code>add_executable()</code></a>.</p> <pre data-language="cmake">cuda_compile_ptx(&lt;generated_files&gt; &lt;file&gt;... [OPTIONS ...])
</pre> <p>Returns a list of <code>PTX</code> files generated from the input source files.</p> <pre data-language="cmake">cuda_compile_fatbin(&lt;generated_files&gt; &lt;file&gt;... [OPTIONS ...])
</pre> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.1.</span></p> </div> <p>Returns a list of <code>FATBIN</code> files generated from the input source files.</p> <pre data-language="cmake">cuda_compile_cubin(&lt;generated_files&gt; &lt;file&gt;... [OPTIONS ...])
</pre> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.1.</span></p> </div> <p>Returns a list of <code>CUBIN</code> files generated from the input source files.</p> <pre data-language="cmake">cuda_compute_separable_compilation_object_file_name(&lt;output_file_var&gt;
                                                    &lt;cuda_target&gt;
                                                    &lt;object_files&gt;)
</pre> <p>Compute the name of the intermediate link file used for separable compilation. This file name is typically passed into <code>CUDA_LINK_SEPARABLE_COMPILATION_OBJECTS</code>. output_file_var is produced based on cuda_target the list of objects files that need separable compilation as specified by <code>&lt;object_files&gt;</code>. If the <code>&lt;object_files&gt;</code> list is empty, then <code>&lt;output_file_var&gt;</code> will be empty. This function is called automatically for <code>cuda_add_library()</code> and <code>cuda_add_executable()</code>. Note that this is a function and not a macro.</p> <pre data-language="cmake">cuda_include_directories(path0 path1 ...)
</pre> <p>Sets the directories that should be passed to nvcc (e.g. <code>nvcc -Ipath0 -Ipath1 ...</code>). These paths usually contain other <code>.cu</code> files.</p> <pre data-language="cmake">cuda_link_separable_compilation_objects(&lt;output_file_var&gt; &lt;cuda_target&gt;
                                        &lt;nvcc_flags&gt; &lt;object_files&gt;)
</pre> <p>Generates the link object required by separable compilation from the given object files. This is called automatically for <code>cuda_add_executable()</code> and <code>cuda_add_library()</code>, but can be called manually when using <code>cuda_wrap_srcs()</code> directly. When called from <code>cuda_add_library()</code> or <code>cuda_add_executable()</code> the <code>&lt;nvcc_flags&gt;</code> passed in are the same as the flags passed in via the <code>OPTIONS</code> argument. The only nvcc flag added automatically is the bitness flag as specified by <code>CUDA_64_BIT_DEVICE_CODE</code>. Note that this is a function instead of a macro.</p> <pre data-language="cmake">cuda_select_nvcc_arch_flags(&lt;out_variable&gt; [&lt;target_CUDA_architecture&gt; ...])
</pre> <p>Selects GPU arch flags for nvcc based on <code>target_CUDA_architecture</code>.</p> <p>Values for <code>target_CUDA_architecture</code>:</p> <ul class="simple"> <li>
<code>Auto</code>: detects local machine GPU compute arch at runtime.</li> <li>
<code>Common</code> and <code>All</code>: cover common and entire subsets of architectures.</li> <li>
<code>&lt;name&gt;</code>: one of <code>Fermi</code>, <code>Kepler</code>, <code>Maxwell</code>, <code>Kepler+Tegra</code>, <code>Kepler+Tesla</code>, <code>Maxwell+Tegra</code>, <code>Pascal</code>.</li> <li>
<code>&lt;ver&gt;</code>, <code>&lt;ver&gt;(&lt;ver&gt;)</code>, <code>&lt;ver&gt;+PTX</code>, where <code>&lt;ver&gt;</code> is one of <code>2.0</code>, <code>2.1</code>, <code>3.0</code>, <code>3.2</code>, <code>3.5</code>, <code>3.7</code>, <code>5.0</code>, <code>5.2</code>, <code>5.3</code>, <code>6.0</code>, <code>6.2</code>.</li> </ul> <p>Returns list of flags to be added to <code>CUDA_NVCC_FLAGS</code> in <code>&lt;out_variable&gt;</code>. Additionally, sets <code>&lt;out_variable&gt;_readable</code> to the resulting numeric list.</p> <p>Example:</p> <pre data-language="none">cuda_select_nvcc_arch_flags(ARCH_FLAGS 3.0 3.5+PTX 5.2(5.0) Maxwell)
list(APPEND CUDA_NVCC_FLAGS ${ARCH_FLAGS})
</pre> <p>More info on CUDA architectures: <a class="reference external" href="https://en.wikipedia.org/wiki/CUDA">https://en.wikipedia.org/wiki/CUDA</a>. Note that this is a function instead of a macro.</p> <pre data-language="cmake">cuda_wrap_srcs(&lt;cuda_target&gt; &lt;format&gt; &lt;generated_files&gt; &lt;file&gt;...
               [STATIC | SHARED | MODULE] [OPTIONS ...])
</pre> <p>This is where all the magic happens. <code>cuda_add_executable()</code>, <code>cuda_add_library()</code>, <code>cuda_compile()</code>, and <code>cuda_compile_ptx()</code> all call this function under the hood.</p> <p>Given the list of files <code>&lt;file&gt;...</code> this macro generates custom commands that generate either PTX or linkable objects (use <code>PTX</code> or <code>OBJ</code> for the <code>&lt;format&gt;</code> argument to switch). Files that don't end with <code>.cu</code> or have the <code>HEADER_FILE_ONLY</code> property are ignored.</p> <p>The arguments passed in after <code>OPTIONS</code> are extra command line options to give to nvcc. You can also specify per configuration options by specifying the name of the configuration followed by the options. General options must precede configuration specific options. Not all configurations need to be specified, only the ones provided will be used. For example:</p> <pre data-language="cmake">cuda_add_executable(...
  OPTIONS -DFLAG=2 "-DFLAG_OTHER=space in flag"
  DEBUG -g
  RELEASE --use_fast_math
  RELWITHDEBINFO --use_fast_math;-g
  MINSIZEREL --use_fast_math)
</pre> <p>For certain configurations (namely VS generating object files with <code>CUDA_ATTACH_VS_BUILD_RULE_TO_CUDA_FILE</code> set to <code>ON</code>), no generated file will be produced for the given cuda file. This is because when you add the cuda file to Visual Studio it knows that this file produces an object file and will link in the resulting object file automatically.</p> <p>This script will also generate a separate cmake script that is used at build time to invoke nvcc. This is for several reasons:</p> <ul class="simple"> <li>nvcc can return negative numbers as return values which confuses Visual Studio into thinking that the command succeeded. The script now checks the error codes and produces errors when there was a problem.</li> <li>nvcc has been known to not delete incomplete results when it encounters problems. This confuses build systems into thinking the target was generated when in fact an unusable file exists. The script now deletes the output files if there was an error.</li> <li>By putting all the options that affect the build into a file and then make the build rule dependent on the file, the output files will be regenerated when the options change.</li> </ul> <p>This script also looks at optional arguments <code>STATIC</code>, <code>SHARED</code>, or <code>MODULE</code> to determine when to target the object compilation for a shared library. <a class="reference internal" href="../variable/build_shared_libs.html#variable:BUILD_SHARED_LIBS" title="BUILD_SHARED_LIBS" id="index-0-variable:BUILD_SHARED_LIBS"><code>BUILD_SHARED_LIBS</code></a> is ignored in <code>cuda_wrap_srcs()</code>, but it is respected in <code>cuda_add_library()</code>. On some systems special flags are added for building objects intended for shared libraries. A preprocessor macro, <code>&lt;target_name&gt;_EXPORTS</code> is defined when a shared library compilation is detected.</p> <p>Flags passed into add_definitions with <code>-D</code> or <code>/D</code> are passed along to nvcc.</p>   <h3>Result Variables</h3> <p>The script defines the following variables:</p> <dl> <dt>
<code>CUDA_VERSION_MAJOR</code> </dt>
<dd>
<p>The major version of cuda as reported by nvcc.</p> </dd> <dt>
<code>CUDA_VERSION_MINOR</code> </dt>
<dd>
<p>The minor version.</p> </dd> <dt>
<code>CUDA_VERSION, CUDA_VERSION_STRING</code> </dt>
<dd>
<p>Full version in the <code>X.Y</code> format.</p> </dd> <dt>
<code>CUDA_HAS_FP16</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.6: </span>Whether a short float (<code>float16</code>, <code>fp16</code>) is supported.</p> </div> </dd> <dt>
<code>CUDA_TOOLKIT_ROOT_DIR</code> </dt>
<dd>
<p>Path to the CUDA Toolkit (defined if not set).</p> </dd> <dt>
<code>CUDA_SDK_ROOT_DIR</code> </dt>
<dd>
<p>Path to the CUDA SDK. Use this to find files in the SDK. This script will not directly support finding specific libraries or headers, as that isn't supported by NVIDIA. If you want to change libraries when the path changes see the <code>FindCUDA.cmake</code> script for an example of how to clear these variables. There are also examples of how to use the <code>CUDA_SDK_ROOT_DIR</code> to locate headers or libraries, if you so choose (at your own risk).</p> </dd> <dt>
<code>CUDA_INCLUDE_DIRS</code> </dt>
<dd>
<p>Include directory for cuda headers. Added automatically for <code>cuda_add_executable()</code> and <code>cuda_add_library()</code>.</p> </dd> <dt>
<code>CUDA_LIBRARIES</code> </dt>
<dd>
<p>Cuda RT library.</p> </dd> <dt>
<code>CUDA_CUFFT_LIBRARIES</code> </dt>
<dd>
<p>Device or emulation library for the Cuda FFT implementation (alternative to <code>cuda_add_cufft_to_target()</code> macro)</p> </dd> <dt>
<code>CUDA_CUBLAS_LIBRARIES</code> </dt>
<dd>
<p>Device or emulation library for the Cuda BLAS implementation (alternative to <code>cuda_add_cublas_to_target()</code> macro).</p> </dd> <dt>
<code>CUDA_cudart_static_LIBRARY</code> </dt>
<dd>
<p>Statically linkable cuda runtime library. Only available for CUDA version 5.5+.</p> </dd> <dt>
<code>CUDA_cudadevrt_LIBRARY</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.7: </span>Device runtime library. Required for separable compilation.</p> </div> </dd> <dt>
<code>CUDA_cupti_LIBRARY</code> </dt>
<dd>
<p>CUDA Profiling Tools Interface library. Only available for CUDA version 4.0+.</p> </dd> <dt>
<code>CUDA_curand_LIBRARY</code> </dt>
<dd>
<p>CUDA Random Number Generation library. Only available for CUDA version 3.2+.</p> </dd> <dt>
<code>CUDA_cusolver_LIBRARY</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.2: </span>CUDA Direct Solver library. Only available for CUDA version 7.0+.</p> </div> </dd> <dt>
<code>CUDA_cusparse_LIBRARY</code> </dt>
<dd>
<p>CUDA Sparse Matrix library. Only available for CUDA version 3.2+.</p> </dd> <dt>
<code>CUDA_npp_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib. Only available for CUDA version 4.0+.</p> </dd> <dt>
<code>CUDA_nppc_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (core). Only available for CUDA version 5.5+.</p> </dd> <dt>
<code>CUDA_nppi_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 5.5 - 8.0.</p> </dd> <dt>
<code>CUDA_nppial_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppicc_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppicom_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0 - 10.2. Replaced by nvjpeg.</p> </dd> <dt>
<code>CUDA_nppidei_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppif_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppig_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppim_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppist_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppisu_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_nppitc_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (image processing). Only available for CUDA version 9.0.</p> </dd> <dt>
<code>CUDA_npps_LIBRARY</code> </dt>
<dd>
<p>NVIDIA Performance Primitives lib (signal processing). Only available for CUDA version 5.5+.</p> </dd> <dt>
<code>CUDA_nvcuvenc_LIBRARY</code> </dt>
<dd>
<p>CUDA Video Encoder library. Only available for CUDA version 3.2+. Windows only.</p> </dd> <dt>
<code>CUDA_nvcuvid_LIBRARY</code> </dt>
<dd>
<p>CUDA Video Decoder library. Only available for CUDA version 3.2+. Windows only.</p> </dd> <dt>
<code>CUDA_nvToolsExt_LIBRARY</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.16: </span>NVIDA CUDA Tools Extension library. Available for CUDA version 5+.</p> </div> </dd> <dt>
<code>CUDA_OpenCL_LIBRARY</code> </dt>
<dd>
<div class="versionadded"> <p><span class="versionmodified added">New in version 3.16: </span>NVIDA CUDA OpenCL library. Available for CUDA version 5+.</p> </div> </dd> </dl>    <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2000&ndash;2023 Kitware, Inc. and Contributors<br>Licensed under the BSD 3-clause License.<br>
    <a href="https://cmake.org/cmake/help/v3.26/module/FindCUDA.html" class="_attribution-link">https://cmake.org/cmake/help/v3.26/module/FindCUDA.html</a>
  </p>
</div>
