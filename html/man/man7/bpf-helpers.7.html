<h1>bpf-helpers(7) — Linux manual page</h1>   <pre>
<span class="headline"><i>BPF-HELPERS</i>(7)      Miscellaneous Information Manual      <i>BPF-HELPERS</i>(7)</span>
</pre> <h2>
NAME </h2>
<pre>
       BPF-HELPERS - list of eBPF helper functions
</pre> <h2>
DESCRIPTION </h2>
<pre>
       The extended Berkeley Packet Filter (eBPF) subsystem consists in
       programs written in a pseudo-assembly language, then attached to
       one of the several kernel hooks and run in reaction of specific
       events. This framework differs from the older, "classic" BPF (or
       "cBPF") in several aspects, one of them being the ability to call
       special functions (or "helpers") from within a program.  These
       functions are restricted to a white-list of helpers defined in
       the kernel.

       These helpers are used by eBPF programs to interact with the
       system, or with the context in which they work. For instance,
       they can be used to print debugging messages, to get the time
       since the system was booted, to interact with eBPF maps, or to
       manipulate network packets. Since there are several eBPF program
       types, and that they do not run in the same context, each program
       type can only call a subset of those helpers.

       Due to eBPF conventions, a helper can not have more than five
       arguments.

       Internally, eBPF programs call directly into the compiled helper
       functions without requiring any foreign-function interface. As a
       result, calling helpers introduces no overhead, thus offering
       excellent performance.

       This document is an attempt to list and document the helpers
       available to eBPF developers. They are sorted by chronological
       order (the oldest helpers in the kernel at the top).
</pre> <h2>
HELPERS </h2>
<pre>
       <b>void *bpf_map_lookup_elem(struct bpf_map *</b><i>map</i><b>, const void *</b><i>key</i><b>)</b>

              <b>Description</b>
                     Perform a lookup in <i>map</i> for an entry associated to
                     <i>key</i>.

              <b>Return </b>Map value associated to <i>key</i>, or <b>NULL </b>if no entry
                     was found.

       <b>long bpf_map_update_elem(struct bpf_map *</b><i>map</i><b>, const void *</b><i>key</i><b>,</b>
       <b>const void *</b><i>value</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Add or update the value of the entry associated to
                     <i>key</i> in <i>map</i> with <i>value</i>. <i>flags</i> is one of:

                     <b>BPF_NOEXIST</b>
                            The entry for <i>key</i> must not exist in the map.

                     <b>BPF_EXIST</b>
                            The entry for <i>key</i> must already exist in the
                            map.

                     <b>BPF_ANY</b>
                            No condition on the existence of the entry
                            for <i>key</i>.

                     Flag value <b>BPF_NOEXIST </b>cannot be used for maps of
                     types <b>BPF_MAP_TYPE_ARRAY </b>or
                     <b>BPF_MAP_TYPE_PERCPU_ARRAY  </b>(all elements always
                     exist), the helper would return an error.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_map_delete_elem(struct bpf_map *</b><i>map</i><b>, const void *</b><i>key</i><b>)</b>

              <b>Description</b>
                     Delete entry with <i>key</i> from <i>map</i>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_probe_read(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void *</b><i>unsafe_ptr</i><b>)</b>

              <b>Description</b>
                     For tracing programs, safely attempt to read <i>size</i>
                     bytes from kernel space address <i>unsafe_ptr</i> and
                     store the data in <i>dst</i>.

                     Generally, use <b>bpf_probe_read_user</b>() or
                     <b>bpf_probe_read_kernel</b>() instead.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>u64 bpf_ktime_get_ns(void)</b>

              <b>Description</b>
                     Return the time elapsed since system boot, in
                     nanoseconds.  Does not include time the system was
                     suspended.  See: <b>clock_gettime</b>(<b>CLOCK_MONOTONIC</b>)

              <b>Return </b>Current <i>ktime</i>.

       <b>long bpf_trace_printk(const char *</b><i>fmt</i><b>, u32 </b><i>fmt_size</i><b>, ...)</b>

              <b>Description</b>
                     This helper is a "printk()-like" facility for
                     debugging. It prints a message defined by format
                     <i>fmt</i> (of size <i>fmt_size</i>) to file
                     <i>/sys/kernel/tracing/trace</i> from TraceFS, if
                     available. It can take up to three additional <b>u64</b>
                     arguments (as an eBPF helpers, the total number of
                     arguments is limited to five).

                     Each time the helper is called, it appends a line
                     to the trace.  Lines are discarded while
                     <i>/sys/kernel/tracing/trace</i> is open, use
                     <i>/sys/kernel/tracing/trace_pipe</i> to avoid this.  The
                     format of the trace is customizable, and the exact
                     output one will get depends on the options set in
                     <i>/sys/kernel/tracing/trace_options</i> (see also the
                     <i>README</i> file under the same directory). However, it
                     usually defaults to something like:

                        telnet-470   [001] .N.. 419421.045894: 0x00000001: &lt;formatted msg&gt;

                     In the above:

                        • <b>telnet </b>is the name of the current task.

                        • <b>470 </b>is the PID of the current task.

                        • <b>001 </b>is the CPU number on which the task is
                          running.

                        • In <b>.N..</b>, each character refers to a set of
                          options (whether irqs are enabled, scheduling
                          options, whether hard/softirqs are running,
                          level of preempt_disabled respectively). <b>N</b>
                          means that <b>TIF_NEED_RESCHED </b>and
                          <b>PREEMPT_NEED_RESCHED </b>are set.

                        • <b>419421.045894 </b>is a timestamp.

                        • <b>0x00000001 </b>is a fake value used by BPF for the
                          instruction pointer register.

                        • <b>&lt;formatted msg&gt; </b>is the message formatted with
                          <i>fmt</i>.

                     The conversion specifiers supported by <i>fmt</i> are
                     similar, but more limited than for printk(). They
                     are <b>%d</b>, <b>%i</b>, <b>%u</b>, <b>%x</b>, <b>%ld</b>, <b>%li</b>, <b>%lu</b>, <b>%lx</b>, <b>%lld</b>, <b>%lli</b>,
                     <b>%llu</b>, <b>%llx</b>, <b>%p</b>, <b>%s</b>. No modifier (size of field,
                     padding with zeroes, etc.) is available, and the
                     helper will return <b>-EINVAL </b>(but print nothing) if
                     it encounters an unknown specifier.

                     Also, note that <b>bpf_trace_printk</b>() is slow, and
                     should only be used for debugging purposes. For
                     this reason, a notice block (spanning several
                     lines) is printed to kernel logs and states that
                     the helper should not be used "for production use"
                     the first time this helper is used (or more
                     precisely, when <b>trace_printk</b>() buffers are
                     allocated). For passing values to user space, perf
                     events should be preferred.

              <b>Return </b>The number of bytes written to the buffer, or a
                     negative error in case of failure.

       <b>u32 bpf_get_prandom_u32(void)</b>

              <b>Description</b>
                     Get a pseudo-random number.

                     From a security point of view, this helper uses its
                     own pseudo-random internal state, and cannot be
                     used to infer the seed of other random functions in
                     the kernel. However, it is essential to note that
                     the generator used by the helper is not
                     cryptographically secure.

              <b>Return </b>A random 32-bit unsigned value.

       <b>u32 bpf_get_smp_processor_id(void)</b>

              <b>Description</b>
                     Get the SMP (symmetric multiprocessing) processor
                     id. Note that all programs run with migration
                     disabled, which means that the SMP processor id is
                     stable during all the execution of the program.

              <b>Return </b>The SMP id of the processor running the program.

       <b>long bpf_skb_store_bytes(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>offset</i><b>, const</b>
       <b>void *</b><i>from</i><b>, u32 </b><i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Store <i>len</i> bytes from address <i>from</i> into the packet
                     associated to <i>skb</i>, at <i>offset</i>. <i>flags</i> are a
                     combination of <b>BPF_F_RECOMPUTE_CSUM </b>(automatically
                     recompute the checksum for the packet after storing
                     the bytes) and <b>BPF_F_INVALIDATE_HASH </b>(set
                     <i>skb</i><b>-&gt;hash</b>, <i>skb</i><b>-&gt;swhash </b>and <i>skb</i><b>-&gt;l4hash </b>to 0).

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_l3_csum_replace(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>offset</i><b>, u64</b>
       <i>from</i><b>, u64 </b><i>to</i><b>, u64 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Recompute the layer 3 (e.g. IP) checksum for the
                     packet associated to <i>skb</i>. Computation is
                     incremental, so the helper must know the former
                     value of the header field that was modified (<i>from</i>),
                     the new value of this field (<i>to</i>), and the number of
                     bytes (2 or 4) for this field, stored in <i>size</i>.
                     Alternatively, it is possible to store the
                     difference between the previous and the new values
                     of the header field in <i>to</i>, by setting <i>from</i> and <i>size</i>
                     to 0. For both methods, <i>offset</i> indicates the
                     location of the IP checksum within the packet.

                     This helper works in combination with
                     <b>bpf_csum_diff</b>(), which does not update the checksum
                     in-place, but offers more flexibility and can
                     handle sizes larger than 2 or 4 for the checksum to
                     update.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_l4_csum_replace(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>offset</i><b>, u64</b>
       <i>from</i><b>, u64 </b><i>to</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Recompute the layer 4 (e.g. TCP, UDP or ICMP)
                     checksum for the packet associated to <i>skb</i>.
                     Computation is incremental, so the helper must know
                     the former value of the header field that was
                     modified (<i>from</i>), the new value of this field (<i>to</i>),
                     and the number of bytes (2 or 4) for this field,
                     stored on the lowest four bits of <i>flags</i>.
                     Alternatively, it is possible to store the
                     difference between the previous and the new values
                     of the header field in <i>to</i>, by setting <i>from</i> and the
                     four lowest bits of <i>flags</i> to 0. For both methods,
                     <i>offset</i> indicates the location of the IP checksum
                     within the packet. In addition to the size of the
                     field, <i>flags</i> can be added (bitwise OR) actual
                     flags. With <b>BPF_F_MARK_MANGLED_0</b>, a null checksum
                     is left untouched (unless <b>BPF_F_MARK_ENFORCE </b>is
                     added as well), and for updates resulting in a null
                     checksum the value is set to <b>CSUM_MANGLED_0</b>
                     instead. Flag <b>BPF_F_PSEUDO_HDR </b>indicates the
                     checksum is to be computed against a pseudo-header.

                     This helper works in combination with
                     <b>bpf_csum_diff</b>(), which does not update the checksum
                     in-place, but offers more flexibility and can
                     handle sizes larger than 2 or 4 for the checksum to
                     update.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_tail_call(void *</b><i>ctx</i><b>, struct bpf_map *</b><i>prog_array_map</i><b>, u32</b>
       <i>index</i><b>)</b>

              <b>Description</b>
                     This special helper is used to trigger a "tail
                     call", or in other words, to jump into another eBPF
                     program. The same stack frame is used (but values
                     on stack and in registers for the caller are not
                     accessible to the callee). This mechanism allows
                     for program chaining, either for raising the
                     maximum number of available eBPF instructions, or
                     to execute given programs in conditional blocks.
                     For security reasons, there is an upper limit to
                     the number of successive tail calls that can be
                     performed.

                     Upon call of this helper, the program attempts to
                     jump into a program referenced at index <i>index</i> in
                     <i>prog_array_map</i>, a special map of type
                     <b>BPF_MAP_TYPE_PROG_ARRAY</b>, and passes <i>ctx</i>, a pointer
                     to the context.

                     If the call succeeds, the kernel immediately runs
                     the first instruction of the new program. This is
                     not a function call, and it never returns to the
                     previous program. If the call fails, then the
                     helper has no effect, and the caller continues to
                     run its subsequent instructions. A call can fail if
                     the destination program for the jump does not exist
                     (i.e. <i>index</i> is superior to the number of entries in
                     <i>prog_array_map</i>), or if the maximum number of tail
                     calls has been reached for this chain of programs.
                     This limit is defined in the kernel by the macro
                     <b>MAX_TAIL_CALL_CNT </b>(not accessible to user space),
                     which is currently set to 33.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_clone_redirect(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>ifindex</i><b>, u64</b>
       <i>flags</i><b>)</b>

              <b>Description</b>
                     Clone and redirect the packet associated to <i>skb</i> to
                     another net device of index <i>ifindex</i>. Both ingress
                     and egress interfaces can be used for redirection.
                     The <b>BPF_F_INGRESS </b>value in <i>flags</i> is used to make
                     the distinction (ingress path is selected if the
                     flag is present, egress path otherwise).  This is
                     the only flag supported for now.

                     In comparison with <b>bpf_redirect</b>() helper,
                     <b>bpf_clone_redirect</b>() has the associated cost of
                     duplicating the packet buffer, but this can be
                     executed out of the eBPF program. Conversely,
                     <b>bpf_redirect</b>() is more efficient, but it is handled
                     through an action code where the redirection
                     happens only after the eBPF program has returned.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure. Positive error indicates a potential drop
                     or congestion in the target device. The particular
                     positive error codes are not defined.

       <b>u64 bpf_get_current_pid_tgid(void)</b>

              <b>Description</b>
                     Get the current pid and tgid.

              <b>Return </b>A 64-bit integer containing the current tgid and
                     pid, and created as such: <i>current_task</i><b>-&gt;tgid &lt;&lt; 32</b>
                     <b>| </b><i>current_task</i><b>-&gt;pid</b>.

       <b>u64 bpf_get_current_uid_gid(void)</b>

              <b>Description</b>
                     Get the current uid and gid.

              <b>Return </b>A 64-bit integer containing the current GID and
                     UID, and created as such: <i>current_gid</i> <b>&lt;&lt; 32 |</b>
                     <i>current_uid</i>.

       <b>long bpf_get_current_comm(void *</b><i>buf</i><b>, u32 </b><i>size_of_buf</i><b>)</b>

              <b>Description</b>
                     Copy the <b>comm </b>attribute of the current task into
                     <i>buf</i> of <i>size_of_buf</i>. The <b>comm </b>attribute contains the
                     name of the executable (excluding the path) for the
                     current task. The <i>size_of_buf</i> must be strictly
                     positive. On success, the helper makes sure that
                     the <i>buf</i> is NUL-terminated. On failure, it is filled
                     with zeroes.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>u32 bpf_get_cgroup_classid(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Retrieve the classid for the current task, i.e. for
                     the net_cls cgroup to which <i>skb</i> belongs.

                     This helper can be used on TC egress path, but not
                     on ingress.

                     The net_cls cgroup provides an interface to tag
                     network packets based on a user-provided identifier
                     for all traffic coming from the tasks belonging to
                     the related cgroup. See also the related kernel
                     documentation, available from the Linux sources in
                     file
                     <i>Documentation/admin-guide/cgroup-v1/net_cls.rst</i>.

                     The Linux kernel has two versions for cgroups:
                     there are cgroups v1 and cgroups v2. Both are
                     available to users, who can use a mixture of them,
                     but note that the net_cls cgroup is for cgroup v1
                     only. This makes it incompatible with BPF programs
                     run on cgroups, which is a cgroup-v2-only feature
                     (a socket can only hold data for one version of
                     cgroups at a time).

                     This helper is only available is the kernel was
                     compiled with the <b>CONFIG_CGROUP_NET_CLASSID</b>
                     configuration option set to "<b>y</b>" or to "<b>m</b>".

              <b>Return </b>The classid, or 0 for the default unconfigured
                     classid.

       <b>long bpf_skb_vlan_push(struct sk_buff *</b><i>skb</i><b>, __be16 </b><i>vlan_proto</i><b>,</b>
       <b>u16 </b><i>vlan_tci</i><b>)</b>

              <b>Description</b>
                     Push a <i>vlan_tci</i> (VLAN tag control information) of
                     protocol <i>vlan_proto</i> to the packet associated to
                     <i>skb</i>, then update the checksum. Note that if
                     <i>vlan_proto</i> is different from <b>ETH_P_8021Q </b>and
                     <b>ETH_P_8021AD</b>, it is considered to be <b>ETH_P_8021Q</b>.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_vlan_pop(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Pop a VLAN header from the packet associated to
                     <i>skb</i>.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_get_tunnel_key(struct sk_buff *</b><i>skb</i><b>, struct</b>
       <b>bpf_tunnel_key *</b><i>key</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get tunnel metadata. This helper takes a pointer
                     <i>key</i> to an empty <b>struct bpf_tunnel_key </b>of <b>size</b>, that
                     will be filled with tunnel metadata for the packet
                     associated to <i>skb</i>.  The <i>flags</i> can be set to
                     <b>BPF_F_TUNINFO_IPV6</b>, which indicates that the tunnel
                     is based on IPv6 protocol instead of IPv4.

                     The <b>struct bpf_tunnel_key </b>is an object that
                     generalizes the principal parameters used by
                     various tunneling protocols into a single struct.
                     This way, it can be used to easily make a decision
                     based on the contents of the encapsulation header,
                     "summarized" in this struct. In particular, it
                     holds the IP address of the remote end (IPv4 or
                     IPv6, depending on the case) in <i>key</i><b>-&gt;remote_ipv4 </b>or
                     <i>key</i><b>-&gt;remote_ipv6</b>. Also, this struct exposes the
                     <i>key</i><b>-&gt;tunnel_id</b>, which is generally mapped to a VNI
                     (Virtual Network Identifier), making it
                     programmable together with the
                     <b>bpf_skb_set_tunnel_key</b>() helper.

                     Let's imagine that the following code is part of a
                     program attached to the TC ingress interface, on
                     one end of a GRE tunnel, and is supposed to filter
                     out all messages coming from remote ends with IPv4
                     address other than 10.0.0.1:

                        int ret;
                        struct bpf_tunnel_key key = {};

                        ret = bpf_skb_get_tunnel_key(skb, &amp;key, sizeof(key), 0);
                        if (ret &lt; 0)
                                return TC_ACT_SHOT;     // drop packet

                        if (key.remote_ipv4 != 0x0a000001)
                                return TC_ACT_SHOT;     // drop packet

                        return TC_ACT_OK;               // accept packet

                     This interface can also be used with all
                     encapsulation devices that can operate in "collect
                     metadata" mode: instead of having one network
                     device per specific configuration, the "collect
                     metadata" mode only requires a single device where
                     the configuration can be extracted from this
                     helper.

                     This can be used together with various tunnels such
                     as VXLan, Geneve, GRE or IP in IP (IPIP).

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_set_tunnel_key(struct sk_buff *</b><i>skb</i><b>, struct</b>
       <b>bpf_tunnel_key *</b><i>key</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Populate tunnel metadata for packet associated to
                     <i>skb.</i> The tunnel metadata is set to the contents of
                     <i>key</i>, of <i>size</i>. The <i>flags</i> can be set to a combination
                     of the following values:

                     <b>BPF_F_TUNINFO_IPV6</b>
                            Indicate that the tunnel is based on IPv6
                            protocol instead of IPv4.

                     <b>BPF_F_ZERO_CSUM_TX</b>
                            For IPv4 packets, add a flag to tunnel
                            metadata indicating that checksum
                            computation should be skipped and checksum
                            set to zeroes.

                     <b>BPF_F_DONT_FRAGMENT</b>
                            Add a flag to tunnel metadata indicating
                            that the packet should not be fragmented.

                     <b>BPF_F_SEQ_NUMBER</b>
                            Add a flag to tunnel metadata indicating
                            that a sequence number should be added to
                            tunnel header before sending the packet.
                            This flag was added for GRE encapsulation,
                            but might be used with other protocols as
                            well in the future.

                     <b>BPF_F_NO_TUNNEL_KEY</b>
                            Add a flag to tunnel metadata indicating
                            that no tunnel key should be set in the
                            resulting tunnel header.

                     Here is a typical usage on the transmit path:

                        struct bpf_tunnel_key key;
                             populate key ...
                        bpf_skb_set_tunnel_key(skb, &amp;key, sizeof(key), 0);
                        bpf_clone_redirect(skb, vxlan_dev_ifindex, 0);

                     See also the description of the
                     <b>bpf_skb_get_tunnel_key</b>() helper for additional
                     information.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>u64 bpf_perf_event_read(struct bpf_map *</b><i>map</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Read the value of a perf event counter. This helper
                     relies on a <i>map</i> of type
                     <b>BPF_MAP_TYPE_PERF_EVENT_ARRAY</b>. The nature of the
                     perf event counter is selected when <i>map</i> is updated
                     with perf event file descriptors. The <i>map</i> is an
                     array whose size is the number of available CPUs,
                     and each cell contains a value relative to one CPU.
                     The value to retrieve is indicated by <i>flags</i>, that
                     contains the index of the CPU to look up, masked
                     with <b>BPF_F_INDEX_MASK</b>. Alternatively, <i>flags</i> can be
                     set to <b>BPF_F_CURRENT_CPU </b>to indicate that the value
                     for the current CPU should be retrieved.

                     Note that before Linux 4.13, only hardware perf
                     event can be retrieved.

                     Also, be aware that the newer helper
                     <b>bpf_perf_event_read_value</b>() is recommended over
                     <b>bpf_perf_event_read</b>() in general. The latter has
                     some ABI quirks where error and counter value are
                     used as a return code (which is wrong to do since
                     ranges may overlap). This issue is fixed with
                     <b>bpf_perf_event_read_value</b>(), which at the same time
                     provides more features over the
                     <b>bpf_perf_event_read</b>() interface. Please refer to
                     the description of <b>bpf_perf_event_read_value</b>() for
                     details.

              <b>Return </b>The value of the perf event counter read from the
                     map, or a negative error code in case of failure.

       <b>long bpf_redirect(u32 </b><i>ifindex</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Redirect the packet to another net device of index
                     <i>ifindex</i>.  This helper is somewhat similar to
                     <b>bpf_clone_redirect</b>(), except that the packet is not
                     cloned, which provides increased performance.

                     Except for XDP, both ingress and egress interfaces
                     can be used for redirection. The <b>BPF_F_INGRESS</b>
                     value in <i>flags</i> is used to make the distinction
                     (ingress path is selected if the flag is present,
                     egress path otherwise). Currently, XDP only
                     supports redirection to the egress interface, and
                     accepts no flag at all.

                     The same effect can also be attained with the more
                     generic <b>bpf_redirect_map</b>(), which uses a BPF map to
                     store the redirect target instead of providing it
                     directly to the helper.

              <b>Return </b>For XDP, the helper returns <b>XDP_REDIRECT </b>on success
                     or <b>XDP_ABORTED </b>on error. For other program types,
                     the values are <b>TC_ACT_REDIRECT </b>on success or
                     <b>TC_ACT_SHOT </b>on error.

       <b>u32 bpf_get_route_realm(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Retrieve the realm or the route, that is to say the
                     <b>tclassid </b>field of the destination for the <i>skb</i>. The
                     identifier retrieved is a user-provided tag,
                     similar to the one used with the net_cls cgroup
                     (see description for <b>bpf_get_cgroup_classid</b>()
                     helper), but here this tag is held by a route (a
                     destination entry), not by a task.

                     Retrieving this identifier works with the clsact TC
                     egress hook (see also <a href="../man8/tc-bpf.8.html">tc-bpf(8)</a>), or alternatively
                     on conventional classful egress qdiscs, but not on
                     TC ingress path. In case of clsact TC egress hook,
                     this has the advantage that, internally, the
                     destination entry has not been dropped yet in the
                     transmit path. Therefore, the destination entry
                     does not need to be artificially held via
                     <b>netif_keep_dst</b>() for a classful qdisc until the <i>skb</i>
                     is freed.

                     This helper is available only if the kernel was
                     compiled with <b>CONFIG_IP_ROUTE_CLASSID </b>configuration
                     option.

              <b>Return </b>The realm of the route for the packet associated to
                     <i>skb</i>, or 0 if none was found.

       <b>long bpf_perf_event_output(void *</b><i>ctx</i><b>, struct bpf_map *</b><i>map</i><b>, u64</b>
       <i>flags</i><b>, void *</b><i>data</i><b>, u64 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Write raw <i>data</i> blob into a special BPF perf event
                     held by <i>map</i> of type <b>BPF_MAP_TYPE_PERF_EVENT_ARRAY</b>.
                     This perf event must have the following attributes:
                     <b>PERF_SAMPLE_RAW </b>as <b>sample_type</b>, <b>PERF_TYPE_SOFTWARE</b>
                     as <b>type</b>, and <b>PERF_COUNT_SW_BPF_OUTPUT </b>as <b>config</b>.

                     The <i>flags</i> are used to indicate the index in <i>map</i> for
                     which the value must be put, masked with
                     <b>BPF_F_INDEX_MASK</b>.  Alternatively, <i>flags</i> can be set
                     to <b>BPF_F_CURRENT_CPU </b>to indicate that the index of
                     the current CPU core should be used.

                     The value to write, of <i>size</i>, is passed through eBPF
                     stack and pointed by <i>data</i>.

                     The context of the program <i>ctx</i> needs also be passed
                     to the helper.

                     On user space, a program willing to read the values
                     needs to call <b>perf_event_open</b>() on the perf event
                     (either for one or for all CPUs) and to store the
                     file descriptor into the <i>map</i>. This must be done
                     before the eBPF program can send data into it. An
                     example is available in file
                     <i>samples/bpf/trace_output_user.c</i> in the Linux kernel
                     source tree (the eBPF program counterpart is in
                     <i>samples/bpf/trace_output_kern.c</i>).

                     <b>bpf_perf_event_output</b>() achieves better performance
                     than <b>bpf_trace_printk</b>() for sharing data with user
                     space, and is much better suitable for streaming
                     data from eBPF programs.

                     Note that this helper is not restricted to tracing
                     use cases and can be used with programs attached to
                     TC or XDP as well, where it allows for passing data
                     to user space listeners. Data can be:

                     • Only custom structs,

                     • Only the packet payload, or

                     • A combination of both.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_load_bytes(const void *</b><i>skb</i><b>, u32 </b><i>offset</i><b>, void *</b><i>to</i><b>,</b>
       <b>u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     This helper was provided as an easy way to load
                     data from a packet. It can be used to load <i>len</i>
                     bytes from <i>offset</i> from the packet associated to
                     <i>skb</i>, into the buffer pointed by <i>to</i>.

                     Since Linux 4.7, usage of this helper has mostly
                     been replaced by "direct packet access", enabling
                     packet data to be manipulated with <i>skb</i><b>-&gt;data </b>and
                     <i>skb</i><b>-&gt;data_end </b>pointing respectively to the first
                     byte of packet data and to the byte after the last
                     byte of packet data. However, it remains useful if
                     one wishes to read large quantities of data at once
                     from a packet into the eBPF stack.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_get_stackid(void *</b><i>ctx</i><b>, struct bpf_map *</b><i>map</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Walk a user or a kernel stack and return its id. To
                     achieve this, the helper needs <i>ctx</i>, which is a
                     pointer to the context on which the tracing program
                     is executed, and a pointer to a <i>map</i> of type
                     <b>BPF_MAP_TYPE_STACK_TRACE</b>.

                     The last argument, <i>flags</i>, holds the number of stack
                     frames to skip (from 0 to 255), masked with
                     <b>BPF_F_SKIP_FIELD_MASK</b>. The next bits can be used to
                     set a combination of the following flags:

                     <b>BPF_F_USER_STACK</b>
                            Collect a user space stack instead of a
                            kernel stack.

                     <b>BPF_F_FAST_STACK_CMP</b>
                            Compare stacks by hash only.

                     <b>BPF_F_REUSE_STACKID</b>
                            If two different stacks hash into the same
                            <i>stackid</i>, discard the old one.

                     The stack id retrieved is a 32 bit long integer
                     handle which can be further combined with other
                     data (including other stack ids) and used as a key
                     into maps. This can be useful for generating a
                     variety of graphs (such as flame graphs or off-cpu
                     graphs).

                     For walking a stack, this helper is an improvement
                     over <b>bpf_probe_read</b>(), which can be used with
                     unrolled loops but is not efficient and consumes a
                     lot of eBPF instructions.  Instead,
                     <b>bpf_get_stackid</b>() can collect up to
                     <b>PERF_MAX_STACK_DEPTH </b>both kernel and user frames.
                     Note that this limit can be controlled with the
                     <b>sysctl </b>program, and that it should be manually
                     increased in order to profile long user stacks
                     (such as stacks for Java programs). To do so, use:

                        # sysctl kernel.perf_event_max_stack=&lt;new value&gt;

              <b>Return </b>The positive or null stack id on success, or a
                     negative error in case of failure.

       <b>s64 bpf_csum_diff(__be32 *</b><i>from</i><b>, u32 </b><i>from_size</i><b>, __be32 *</b><i>to</i><b>, u32</b>
       <i>to_size</i><b>, __wsum </b><i>seed</i><b>)</b>

              <b>Description</b>
                     Compute a checksum difference, from the raw buffer
                     pointed by <i>from</i>, of length <i>from_size</i> (that must be
                     a multiple of 4), towards the raw buffer pointed by
                     <i>to</i>, of size <i>to_size</i> (same remark). An optional <i>seed</i>
                     can be added to the value (this can be cascaded,
                     the seed may come from a previous call to the
                     helper).

                     This is flexible enough to be used in several ways:

                     • With <i>from_size</i> == 0, <i>to_size</i> &gt; 0 and <i>seed</i> set to
                       checksum, it can be used when pushing new data.

                     • With <i>from_size</i> &gt; 0, <i>to_size</i> == 0 and <i>seed</i> set to
                       checksum, it can be used when removing data from
                       a packet.

                     • With <i>from_size</i> &gt; 0, <i>to_size</i> &gt; 0 and <i>seed</i> set to
                       0, it can be used to compute a diff. Note that
                       <i>from_size</i> and <i>to_size</i> do not need to be equal.

                     This helper can be used in combination with
                     <b>bpf_l3_csum_replace</b>() and <b>bpf_l4_csum_replace</b>(), to
                     which one can feed in the difference computed with
                     <b>bpf_csum_diff</b>().

              <b>Return </b>The checksum result, or a negative error code in
                     case of failure.

       <b>long bpf_skb_get_tunnel_opt(struct sk_buff *</b><i>skb</i><b>, void *</b><i>opt</i><b>, u32</b>
       <i>size</i><b>)</b>

              <b>Description</b>
                     Retrieve tunnel options metadata for the packet
                     associated to <i>skb</i>, and store the raw tunnel option
                     data to the buffer <i>opt</i> of <i>size</i>.

                     This helper can be used with encapsulation devices
                     that can operate in "collect metadata" mode (please
                     refer to the related note in the description of
                     <b>bpf_skb_get_tunnel_key</b>() for more details). A
                     particular example where this can be used is in
                     combination with the Geneve encapsulation protocol,
                     where it allows for pushing (with
                     <b>bpf_skb_get_tunnel_opt</b>() helper) and retrieving
                     arbitrary TLVs (Type-Length-Value headers) from the
                     eBPF program. This allows for full customization of
                     these headers.

              <b>Return </b>The size of the option data retrieved.

       <b>long bpf_skb_set_tunnel_opt(struct sk_buff *</b><i>skb</i><b>, void *</b><i>opt</i><b>, u32</b>
       <i>size</i><b>)</b>

              <b>Description</b>
                     Set tunnel options metadata for the packet
                     associated to <i>skb</i> to the option data contained in
                     the raw buffer <i>opt</i> of <i>size</i>.

                     See also the description of the
                     <b>bpf_skb_get_tunnel_opt</b>() helper for additional
                     information.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_change_proto(struct sk_buff *</b><i>skb</i><b>, __be16 </b><i>proto</i><b>, u64</b>
       <i>flags</i><b>)</b>

              <b>Description</b>
                     Change the protocol of the <i>skb</i> to <i>proto</i>. Currently
                     supported are transition from IPv4 to IPv6, and
                     from IPv6 to IPv4. The helper takes care of the
                     groundwork for the transition, including resizing
                     the socket buffer. The eBPF program is expected to
                     fill the new headers, if any, via <b>skb_store_bytes</b>()
                     and to recompute the checksums with
                     <b>bpf_l3_csum_replace</b>() and <b>bpf_l4_csum_replace</b>().
                     The main case for this helper is to perform NAT64
                     operations out of an eBPF program.

                     Internally, the GSO type is marked as dodgy so that
                     headers are checked and segments are recalculated
                     by the GSO/GRO engine.  The size for GSO target is
                     adapted as well.

                     All values for <i>flags</i> are reserved for future usage,
                     and must be left at zero.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_change_type(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>type</i><b>)</b>

              <b>Description</b>
                     Change the packet type for the packet associated to
                     <i>skb</i>. This comes down to setting <i>skb</i><b>-&gt;pkt_type </b>to
                     <i>type</i>, except the eBPF program does not have a write
                     access to <i>skb</i><b>-&gt;pkt_type </b>beside this helper. Using a
                     helper here allows for graceful handling of errors.

                     The major use case is to change incoming <i>skb*s to</i>
                     <i>**PACKET_HOST*</i> in a programmatic way instead of
                     having to recirculate via <b>redirect</b>(...,
                     <b>BPF_F_INGRESS</b>), for example.

                     Note that <i>type</i> only allows certain values. At this
                     time, they are:

                     <b>PACKET_HOST</b>
                            Packet is for us.

                     <b>PACKET_BROADCAST</b>
                            Send packet to all.

                     <b>PACKET_MULTICAST</b>
                            Send packet to group.

                     <b>PACKET_OTHERHOST</b>
                            Send packet to someone else.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_under_cgroup(struct sk_buff *</b><i>skb</i><b>, struct bpf_map</b>
       <b>*</b><i>map</i><b>, u32 </b><i>index</i><b>)</b>

              <b>Description</b>
                     Check whether <i>skb</i> is a descendant of the cgroup2
                     held by <i>map</i> of type <b>BPF_MAP_TYPE_CGROUP_ARRAY</b>, at
                     <i>index</i>.

              <b>Return </b>The return value depends on the result of the test,
                     and can be:

                     • 0, if the <i>skb</i> failed the cgroup2 descendant test.

                     • 1, if the <i>skb</i> succeeded the cgroup2 descendant
                       test.

                     • A negative error code, if an error occurred.

       <b>u32 bpf_get_hash_recalc(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Retrieve the hash of the packet, <i>skb</i><b>-&gt;hash</b>. If it
                     is not set, in particular if the hash was cleared
                     due to mangling, recompute this hash. Later
                     accesses to the hash can be done directly with
                     <i>skb</i><b>-&gt;hash</b>.

                     Calling <b>bpf_set_hash_invalid</b>(), changing a packet
                     prototype with <b>bpf_skb_change_proto</b>(), or calling
                     <b>bpf_skb_store_bytes</b>() with the
                     <b>BPF_F_INVALIDATE_HASH </b>are actions susceptible to
                     clear the hash and to trigger a new computation for
                     the next call to <b>bpf_get_hash_recalc</b>().

              <b>Return </b>The 32-bit hash.

       <b>u64 bpf_get_current_task(void)</b>

              <b>Description</b>
                     Get the current task.

              <b>Return </b>A pointer to the current task struct.

       <b>long bpf_probe_write_user(void *</b><i>dst</i><b>, const void *</b><i>src</i><b>, u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     Attempt in a safe way to write <i>len</i> bytes from the
                     buffer <i>src</i> to <i>dst</i> in memory. It only works for
                     threads that are in user context, and <i>dst</i> must be a
                     valid user space address.

                     This helper should not be used to implement any
                     kind of security mechanism because of TOC-TOU
                     attacks, but rather to debug, divert, and
                     manipulate execution of semi-cooperative processes.

                     Keep in mind that this feature is meant for
                     experiments, and it has a risk of crashing the
                     system and running programs.  Therefore, when an
                     eBPF program using this helper is attached, a
                     warning including PID and process name is printed
                     to kernel logs.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_current_task_under_cgroup(struct bpf_map *</b><i>map</i><b>, u32</b>
       <i>index</i><b>)</b>

              <b>Description</b>
                     Check whether the probe is being run is the context
                     of a given subset of the cgroup2 hierarchy. The
                     cgroup2 to test is held by <i>map</i> of type
                     <b>BPF_MAP_TYPE_CGROUP_ARRAY</b>, at <i>index</i>.

              <b>Return </b>The return value depends on the result of the test,
                     and can be:

                     • 1, if current task belongs to the cgroup2.

                     • 0, if current task does not belong to the
                       cgroup2.

                     • A negative error code, if an error occurred.

       <b>long bpf_skb_change_tail(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Resize (trim or grow) the packet associated to <i>skb</i>
                     to the new <i>len</i>. The <i>flags</i> are reserved for future
                     usage, and must be left at zero.

                     The basic idea is that the helper performs the
                     needed work to change the size of the packet, then
                     the eBPF program rewrites the rest via helpers like
                     <b>bpf_skb_store_bytes</b>(), <b>bpf_l3_csum_replace</b>(),
                     <b>bpf_l3_csum_replace</b>() and others. This helper is a
                     slow path utility intended for replies with control
                     messages. And because it is targeted for slow path,
                     the helper itself can afford to be slow: it
                     implicitly linearizes, unclones and drops offloads
                     from the <i>skb</i>.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_pull_data(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     Pull in non-linear data in case the <i>skb</i> is
                     non-linear and not all of <i>len</i> are part of the
                     linear section. Make <i>len</i> bytes from <i>skb</i> readable
                     and writable. If a zero value is passed for <i>len</i>,
                     then all bytes in the linear part of <i>skb</i> will be
                     made readable and writable.

                     This helper is only needed for reading and writing
                     with direct packet access.

                     For direct packet access, testing that offsets to
                     access are within packet boundaries (test on
                     <i>skb</i><b>-&gt;data_end</b>) is susceptible to fail if offsets
                     are invalid, or if the requested data is in
                     non-linear parts of the <i>skb</i>. On failure the program
                     can just bail out, or in the case of a non-linear
                     buffer, use a helper to make the data available.
                     The <b>bpf_skb_load_bytes</b>() helper is a first solution
                     to access the data. Another one consists in using
                     <b>bpf_skb_pull_data </b>to pull in once the non-linear
                     parts, then retesting and eventually access the
                     data.

                     At the same time, this also makes sure the <i>skb</i> is
                     uncloned, which is a necessary condition for direct
                     write. As this needs to be an invariant for the
                     write part only, the verifier detects writes and
                     adds a prologue that is calling <b>bpf_skb_pull_data()</b>
                     to effectively unclone the <i>skb</i> from the very
                     beginning in case it is indeed cloned.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>s64 bpf_csum_update(struct sk_buff *</b><i>skb</i><b>, __wsum </b><i>csum</i><b>)</b>

              <b>Description</b>
                     Add the checksum <i>csum</i> into <i>skb</i><b>-&gt;csum </b>in case the
                     driver has supplied a checksum for the entire
                     packet into that field. Return an error otherwise.
                     This helper is intended to be used in combination
                     with <b>bpf_csum_diff</b>(), in particular when the
                     checksum needs to be updated after data has been
                     written into the packet through direct packet
                     access.

              <b>Return </b>The checksum on success, or a negative error code
                     in case of failure.

       <b>void bpf_set_hash_invalid(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Invalidate the current <i>skb</i><b>-&gt;hash</b>. It can be used
                     after mangling on headers through direct packet
                     access, in order to indicate that the hash is
                     outdated and to trigger a recalculation the next
                     time the kernel tries to access this hash or when
                     the <b>bpf_get_hash_recalc</b>() helper is called.

              <b>Return </b>void.

       <b>long bpf_get_numa_node_id(void)</b>

              <b>Description</b>
                     Return the id of the current NUMA node. The primary
                     use case for this helper is the selection of
                     sockets for the local NUMA node, when the program
                     is attached to sockets using the
                     <b>SO_ATTACH_REUSEPORT_EBPF </b>option (see also
                     <a href="socket.7.html">socket(7)</a>), but the helper is also available to
                     other eBPF program types, similarly to
                     <b>bpf_get_smp_processor_id</b>().

              <b>Return </b>The id of current NUMA node.

       <b>long bpf_skb_change_head(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Grows headroom of packet associated to <i>skb</i> and
                     adjusts the offset of the MAC header accordingly,
                     adding <i>len</i> bytes of space. It automatically extends
                     and reallocates memory as required.

                     This helper can be used on a layer 3 <i>skb</i> to push a
                     MAC header for redirection into a layer 2 device.

                     All values for <i>flags</i> are reserved for future usage,
                     and must be left at zero.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_xdp_adjust_head(struct xdp_buff *</b><i>xdp_md</i><b>, int </b><i>delta</i><b>)</b>

              <b>Description</b>
                     Adjust (move) <i>xdp_md</i><b>-&gt;data </b>by <i>delta</i> bytes. Note
                     that it is possible to use a negative value for
                     <i>delta</i>. This helper can be used to prepare the
                     packet for pushing or popping headers.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_probe_read_str(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>unsafe_ptr</i><b>)</b>

              <b>Description</b>
                     Copy a NUL terminated string from an unsafe kernel
                     address <i>unsafe_ptr</i> to <i>dst</i>. See
                     <b>bpf_probe_read_kernel_str</b>() for more details.

                     Generally, use <b>bpf_probe_read_user_str</b>() or
                     <b>bpf_probe_read_kernel_str</b>() instead.

              <b>Return </b>On success, the strictly positive length of the
                     string, including the trailing NUL character. On
                     error, a negative value.

       <b>u64 bpf_get_socket_cookie(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     If the <b>struct sk_buff </b>pointed by <i>skb</i> has a known
                     socket, retrieve the cookie (generated by the
                     kernel) of this socket.  If no cookie has been set
                     yet, generate a new cookie. Once generated, the
                     socket cookie remains stable for the life of the
                     socket. This helper can be useful for monitoring
                     per socket networking traffic statistics as it
                     provides a global socket identifier that can be
                     assumed unique.

              <b>Return </b>A 8-byte long unique number on success, or 0 if the
                     socket field is missing inside <i>skb</i>.

       <b>u64 bpf_get_socket_cookie(struct bpf_sock_addr *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     Equivalent to bpf_get_socket_cookie() helper that
                     accepts <i>skb</i>, but gets socket from <b>struct</b>
                     <b>bpf_sock_addr </b>context.

              <b>Return </b>A 8-byte long unique number.

       <b>u64 bpf_get_socket_cookie(struct bpf_sock_ops *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     Equivalent to <b>bpf_get_socket_cookie</b>() helper that
                     accepts <i>skb</i>, but gets socket from <b>struct</b>
                     <b>bpf_sock_ops </b>context.

              <b>Return </b>A 8-byte long unique number.

       <b>u64 bpf_get_socket_cookie(struct sock *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Equivalent to <b>bpf_get_socket_cookie</b>() helper that
                     accepts <i>sk</i>, but gets socket from a BTF <b>struct sock</b>.
                     This helper also works for sleepable programs.

              <b>Return </b>A 8-byte long unique number or 0 if <i>sk</i> is NULL.

       <b>u32 bpf_get_socket_uid(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Get the owner UID of the socked associated to <i>skb</i>.

              <b>Return </b>The owner UID of the socket associated to <i>skb</i>. If
                     the socket is <b>NULL</b>, or if it is not a full socket
                     (i.e. if it is a time-wait or a request socket
                     instead), <b>overflowuid </b>value is returned (note that
                     <b>overflowuid </b>might also be the actual UID value for
                     the socket).

       <b>long bpf_set_hash(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>hash</i><b>)</b>

              <b>Description</b>
                     Set the full hash for <i>skb</i> (set the field <i>skb</i><b>-&gt;hash</b>)
                     to value <i>hash</i>.

              <b>Return </b>0

       <b>long bpf_setsockopt(void *</b><i>bpf_socket</i><b>, int </b><i>level</i><b>, int </b><i>optname</i><b>,</b>
       <b>void *</b><i>optval</i><b>, int </b><i>optlen</i><b>)</b>

              <b>Description</b>
                     Emulate a call to <b>setsockopt() </b>on the socket
                     associated to <i>bpf_socket</i>, which must be a full
                     socket. The <i>level</i> at which the option resides and
                     the name <i>optname</i> of the option must be specified,
                     see <a href="../man2/setsockopt.2.html">setsockopt(2)</a> for more information.  The option
                     value of length <i>optlen</i> is pointed by <i>optval</i>.

                     <i>bpf_socket</i> should be one of the following:

                     • <b>struct bpf_sock_ops </b>for <b>BPF_PROG_TYPE_SOCK_OPS</b>.

                     • <b>struct bpf_sock_addr </b>for
                       <b>BPF_CGROUP_INET4_CONNECT</b>,
                       <b>BPF_CGROUP_INET6_CONNECT </b>and
                       <b>BPF_CGROUP_UNIX_CONNECT</b>.

                     This helper actually implements a subset of
                     <b>setsockopt()</b>.  It supports the following <i>level</i>s:

                     • <b>SOL_SOCKET</b>, which supports the following
                       <i>optname</i>s: <b>SO_RCVBUF</b>, <b>SO_SNDBUF</b>,
                       <b>SO_MAX_PACING_RATE</b>, <b>SO_PRIORITY</b>, <b>SO_RCVLOWAT</b>,
                       <b>SO_MARK</b>, <b>SO_BINDTODEVICE</b>, <b>SO_KEEPALIVE</b>,
                       <b>SO_REUSEADDR</b>, <b>SO_REUSEPORT</b>, <b>SO_BINDTOIFINDEX</b>,
                       <b>SO_TXREHASH</b>.

                     • <b>IPPROTO_TCP</b>, which supports the following
                       <i>optname</i>s: <b>TCP_CONGESTION</b>, <b>TCP_BPF_IW</b>,
                       <b>TCP_BPF_SNDCWND_CLAMP</b>, <b>TCP_SAVE_SYN</b>,
                       <b>TCP_KEEPIDLE</b>, <b>TCP_KEEPINTVL</b>, <b>TCP_KEEPCNT</b>,
                       <b>TCP_SYNCNT</b>, <b>TCP_USER_TIMEOUT</b>, <b>TCP_NOTSENT_LOWAT</b>,
                       <b>TCP_NODELAY</b>, <b>TCP_MAXSEG</b>, <b>TCP_WINDOW_CLAMP</b>,
                       <b>TCP_THIN_LINEAR_TIMEOUTS</b>, <b>TCP_BPF_DELACK_MAX</b>,
                       <b>TCP_BPF_RTO_MIN</b>.

                     • <b>IPPROTO_IP</b>, which supports <i>optname</i> <b>IP_TOS</b>.

                     • <b>IPPROTO_IPV6</b>, which supports the following
                       <i>optname</i>s: <b>IPV6_TCLASS</b>, <b>IPV6_AUTOFLOWLABEL</b>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_adjust_room(struct sk_buff *</b><i>skb</i><b>, s32 </b><i>len_diff</i><b>, u32</b>
       <i>mode</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Grow or shrink the room for data in the packet
                     associated to <i>skb</i> by <i>len_diff</i>, and according to the
                     selected <i>mode</i>.

                     By default, the helper will reset any offloaded
                     checksum indicator of the skb to CHECKSUM_NONE.
                     This can be avoided by the following flag:

                     • <b>BPF_F_ADJ_ROOM_NO_CSUM_RESET</b>: Do not reset
                       offloaded checksum data of the skb to
                       CHECKSUM_NONE.

                     There are two supported modes at this time:

                     • <b>BPF_ADJ_ROOM_MAC</b>: Adjust room at the mac layer
                       (room space is added or removed between the layer
                       2 and layer 3 headers).

                     • <b>BPF_ADJ_ROOM_NET</b>: Adjust room at the network
                       layer (room space is added or removed between the
                       layer 3 and layer 4 headers).

                     The following flags are supported at this time:

                     • <b>BPF_F_ADJ_ROOM_FIXED_GSO</b>: Do not adjust gso_size.
                       Adjusting mss in this way is not allowed for
                       datagrams.

                     • <b>BPF_F_ADJ_ROOM_ENCAP_L3_IPV4</b>,
                       <b>BPF_F_ADJ_ROOM_ENCAP_L3_IPV6</b>: Any new space is
                       reserved to hold a tunnel header.  Configure skb
                       offsets and other fields accordingly.

                     • <b>BPF_F_ADJ_ROOM_ENCAP_L4_GRE</b>,
                       <b>BPF_F_ADJ_ROOM_ENCAP_L4_UDP</b>: Use with ENCAP_L3
                       flags to further specify the tunnel type.

                     • <b>BPF_F_ADJ_ROOM_ENCAP_L2</b>(<i>len</i>): Use with
                       ENCAP_L3/L4 flags to further specify the tunnel
                       type; <i>len</i> is the length of the inner MAC header.

                     • <b>BPF_F_ADJ_ROOM_ENCAP_L2_ETH</b>: Use with
                       BPF_F_ADJ_ROOM_ENCAP_L2 flag to further specify
                       the L2 type as Ethernet.

                     • <b>BPF_F_ADJ_ROOM_DECAP_L3_IPV4</b>,
                       <b>BPF_F_ADJ_ROOM_DECAP_L3_IPV6</b>: Indicate the new IP
                       header version after decapsulating the outer IP
                       header. Used when the inner and outer IP versions
                       are different.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_redirect_map(struct bpf_map *</b><i>map</i><b>, u64 </b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Redirect the packet to the endpoint referenced by
                     <i>map</i> at index <i>key</i>. Depending on its type, this <i>map</i>
                     can contain references to net devices (for
                     forwarding packets through other ports), or to CPUs
                     (for redirecting XDP frames to another CPU; but
                     this is only implemented for native XDP (with
                     driver support) as of this writing).

                     The lower two bits of <i>flags</i> are used as the return
                     code if the map lookup fails. This is so that the
                     return value can be one of the XDP program return
                     codes up to <b>XDP_TX</b>, as chosen by the caller. The
                     higher bits of <i>flags</i> can be set to BPF_F_BROADCAST
                     or BPF_F_EXCLUDE_INGRESS as defined below.

                     With BPF_F_BROADCAST the packet will be broadcasted
                     to all the interfaces in the map, with
                     BPF_F_EXCLUDE_INGRESS the ingress interface will be
                     excluded when do broadcasting.

                     See also <b>bpf_redirect</b>(), which only supports
                     redirecting to an ifindex, but doesn't require a
                     map to do so.

              <b>Return XDP_REDIRECT </b>on success, or the value of the two
                     lower bits of the <i>flags</i> argument on error.

       <b>long bpf_sk_redirect_map(struct sk_buff *</b><i>skb</i><b>, struct bpf_map</b>
       <b>*</b><i>map</i><b>, u32 </b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Redirect the packet to the socket referenced by <i>map</i>
                     (of type <b>BPF_MAP_TYPE_SOCKMAP</b>) at index <i>key</i>. Both
                     ingress and egress interfaces can be used for
                     redirection. The <b>BPF_F_INGRESS </b>value in <i>flags</i> is
                     used to make the distinction (ingress path is
                     selected if the flag is present, egress path
                     otherwise). This is the only flag supported for
                     now.

              <b>Return SK_PASS </b>on success, or <b>SK_DROP </b>on error.

       <b>long bpf_sock_map_update(struct bpf_sock_ops *</b><i>skops</i><b>, struct</b>
       <b>bpf_map *</b><i>map</i><b>, void *</b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Add an entry to, or update a <i>map</i> referencing
                     sockets. The <i>skops</i> is used as a new value for the
                     entry associated to <i>key</i>. <i>flags</i> is one of:

                     <b>BPF_NOEXIST</b>
                            The entry for <i>key</i> must not exist in the map.

                     <b>BPF_EXIST</b>
                            The entry for <i>key</i> must already exist in the
                            map.

                     <b>BPF_ANY</b>
                            No condition on the existence of the entry
                            for <i>key</i>.

                     If the <i>map</i> has eBPF programs (parser and verdict),
                     those will be inherited by the socket being added.
                     If the socket is already attached to eBPF programs,
                     this results in an error.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_xdp_adjust_meta(struct xdp_buff *</b><i>xdp_md</i><b>, int </b><i>delta</i><b>)</b>

              <b>Description</b>
                     Adjust the address pointed by <i>xdp_md</i><b>-&gt;data_meta </b>by
                     <i>delta</i> (which can be positive or negative). Note
                     that this operation modifies the address stored in
                     <i>xdp_md</i><b>-&gt;data</b>, so the latter must be loaded only
                     after the helper has been called.

                     The use of <i>xdp_md</i><b>-&gt;data_meta </b>is optional and
                     programs are not required to use it. The rationale
                     is that when the packet is processed with XDP (e.g.
                     as DoS filter), it is possible to push further meta
                     data along with it before passing to the stack, and
                     to give the guarantee that an ingress eBPF program
                     attached as a TC classifier on the same device can
                     pick this up for further post-processing. Since TC
                     works with socket buffers, it remains possible to
                     set from XDP the <b>mark </b>or <b>priority </b>pointers, or
                     other pointers for the socket buffer.  Having this
                     scratch space generic and programmable allows for
                     more flexibility as the user is free to store
                     whatever meta data they need.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_perf_event_read_value(struct bpf_map *</b><i>map</i><b>, u64 </b><i>flags</i><b>,</b>
       <b>struct bpf_perf_event_value *</b><i>buf</i><b>, u32 </b><i>buf_size</i><b>)</b>

              <b>Description</b>
                     Read the value of a perf event counter, and store
                     it into <i>buf</i> of size <i>buf_size</i>. This helper relies on
                     a <i>map</i> of type <b>BPF_MAP_TYPE_PERF_EVENT_ARRAY</b>. The
                     nature of the perf event counter is selected when
                     <i>map</i> is updated with perf event file descriptors.
                     The <i>map</i> is an array whose size is the number of
                     available CPUs, and each cell contains a value
                     relative to one CPU. The value to retrieve is
                     indicated by <i>flags</i>, that contains the index of the
                     CPU to look up, masked with <b>BPF_F_INDEX_MASK</b>.
                     Alternatively, <i>flags</i> can be set to
                     <b>BPF_F_CURRENT_CPU </b>to indicate that the value for
                     the current CPU should be retrieved.

                     This helper behaves in a way close to
                     <b>bpf_perf_event_read</b>() helper, save that instead of
                     just returning the value observed, it fills the <i>buf</i>
                     structure. This allows for additional data to be
                     retrieved: in particular, the enabled and running
                     times (in <i>buf</i><b>-&gt;enabled </b>and <i>buf</i><b>-&gt;running</b>,
                     respectively) are copied. In general,
                     <b>bpf_perf_event_read_value</b>() is recommended over
                     <b>bpf_perf_event_read</b>(), which has some ABI issues
                     and provides fewer functionalities.

                     These values are interesting, because hardware PMU
                     (Performance Monitoring Unit) counters are limited
                     resources. When there are more PMU based perf
                     events opened than available counters, kernel will
                     multiplex these events so each event gets certain
                     percentage (but not all) of the PMU time. In case
                     that multiplexing happens, the number of samples or
                     counter value will not reflect the case compared to
                     when no multiplexing occurs. This makes comparison
                     between different runs difficult.  Typically, the
                     counter value should be normalized before comparing
                     to other experiments. The usual normalization is
                     done as follows.

                        normalized_counter = counter * t_enabled / t_running

                     Where t_enabled is the time enabled for event and
                     t_running is the time running for event since last
                     normalization. The enabled and running times are
                     accumulated since the perf event open. To achieve
                     scaling factor between two invocations of an eBPF
                     program, users can use CPU id as the key (which is
                     typical for perf array usage model) to remember the
                     previous value and do the calculation inside the
                     eBPF program.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_perf_prog_read_value(struct bpf_perf_event_data *</b><i>ctx</i><b>,</b>
       <b>struct bpf_perf_event_value *</b><i>buf</i><b>, u32 </b><i>buf_size</i><b>)</b>

              <b>Description</b>
                     For an eBPF program attached to a perf event,
                     retrieve the value of the event counter associated
                     to <i>ctx</i> and store it in the structure pointed by <i>buf</i>
                     and of size <i>buf_size</i>. Enabled and running times are
                     also stored in the structure (see description of
                     helper <b>bpf_perf_event_read_value</b>() for more
                     details).

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_getsockopt(void *</b><i>bpf_socket</i><b>, int </b><i>level</i><b>, int </b><i>optname</i><b>,</b>
       <b>void *</b><i>optval</i><b>, int </b><i>optlen</i><b>)</b>

              <b>Description</b>
                     Emulate a call to <b>getsockopt() </b>on the socket
                     associated to <i>bpf_socket</i>, which must be a full
                     socket. The <i>level</i> at which the option resides and
                     the name <i>optname</i> of the option must be specified,
                     see <a href="../man2/getsockopt.2.html">getsockopt(2)</a> for more information.  The
                     retrieved value is stored in the structure pointed
                     by <i>opval</i> and of length <i>optlen</i>.

                     <i>bpf_socket</i> should be one of the following:

                     • <b>struct bpf_sock_ops </b>for <b>BPF_PROG_TYPE_SOCK_OPS</b>.

                     • <b>struct bpf_sock_addr </b>for
                       <b>BPF_CGROUP_INET4_CONNECT</b>,
                       <b>BPF_CGROUP_INET6_CONNECT </b>and
                       <b>BPF_CGROUP_UNIX_CONNECT</b>.

                     This helper actually implements a subset of
                     <b>getsockopt()</b>.  It supports the same set of <i>optname</i>s
                     that is supported by the <b>bpf_setsockopt</b>() helper.
                     The exceptions are <b>TCP_BPF_* </b>is <b>bpf_setsockopt</b>()
                     only and <b>TCP_SAVED_SYN </b>is <b>bpf_getsockopt</b>() only.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_override_return(struct pt_regs *</b><i>regs</i><b>, u64 </b><i>rc</i><b>)</b>

              <b>Description</b>
                     Used for error injection, this helper uses kprobes
                     to override the return value of the probed
                     function, and to set it to <i>rc</i>.  The first argument
                     is the context <i>regs</i> on which the kprobe works.

                     This helper works by setting the PC (program
                     counter) to an override function which is run in
                     place of the original probed function. This means
                     the probed function is not run at all. The
                     replacement function just returns with the required
                     value.

                     This helper has security implications, and thus is
                     subject to restrictions. It is only available if
                     the kernel was compiled with the
                     <b>CONFIG_BPF_KPROBE_OVERRIDE </b>configuration option,
                     and in this case it only works on functions tagged
                     with <b>ALLOW_ERROR_INJECTION </b>in the kernel code.

                     Also, the helper is only available for the
                     architectures having the
                     CONFIG_FUNCTION_ERROR_INJECTION option. As of this
                     writing, x86 architecture is the only one to
                     support this feature.

              <b>Return </b>0

       <b>long bpf_sock_ops_cb_flags_set(struct bpf_sock_ops *</b><i>bpf_sock</i><b>, int</b>
       <i>argval</i><b>)</b>

              <b>Description</b>
                     Attempt to set the value of the
                     <b>bpf_sock_ops_cb_flags </b>field for the full TCP socket
                     associated to <i>bpf_sock_ops</i> to <i>argval</i>.

                     The primary use of this field is to determine if
                     there should be calls to eBPF programs of type
                     <b>BPF_PROG_TYPE_SOCK_OPS </b>at various points in the TCP
                     code. A program of the same type can change its
                     value, per connection and as necessary, when the
                     connection is established. This field is directly
                     accessible for reading, but this helper must be
                     used for updates in order to return an error if an
                     eBPF program tries to set a callback that is not
                     supported in the current kernel.

                     <i>argval</i> is a flag array which can combine these
                     flags:

                     • <b>BPF_SOCK_OPS_RTO_CB_FLAG </b>(retransmission time
                       out)

                     • <b>BPF_SOCK_OPS_RETRANS_CB_FLAG </b>(retransmission)

                     • <b>BPF_SOCK_OPS_STATE_CB_FLAG </b>(TCP state change)

                     • <b>BPF_SOCK_OPS_RTT_CB_FLAG </b>(every RTT)

                     Therefore, this function can be used to clear a
                     callback flag by setting the appropriate bit to
                     zero. e.g. to disable the RTO callback:

                     <b>bpf_sock_ops_cb_flags_set(bpf_sock,</b>
                            <b>bpf_sock-&gt;bpf_sock_ops_cb_flags &amp;</b>
                            <b>~BPF_SOCK_OPS_RTO_CB_FLAG)</b>

                     Here are some examples of where one could call such
                     eBPF program:

                     • When RTO fires.

                     • When a packet is retransmitted.

                     • When the connection terminates.

                     • When a packet is sent.

                     • When a packet is received.

              <b>Return </b>Code <b>-EINVAL </b>if the socket is not a full TCP
                     socket; otherwise, a positive number containing the
                     bits that could not be set is returned (which comes
                     down to 0 if all bits were set as required).

       <b>long bpf_msg_redirect_map(struct sk_msg_buff *</b><i>msg</i><b>, struct bpf_map</b>
       <b>*</b><i>map</i><b>, u32 </b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     This helper is used in programs implementing
                     policies at the socket level. If the message <i>msg</i> is
                     allowed to pass (i.e. if the verdict eBPF program
                     returns <b>SK_PASS</b>), redirect it to the socket
                     referenced by <i>map</i> (of type <b>BPF_MAP_TYPE_SOCKMAP</b>) at
                     index <i>key</i>. Both ingress and egress interfaces can
                     be used for redirection. The <b>BPF_F_INGRESS </b>value in
                     <i>flags</i> is used to make the distinction (ingress path
                     is selected if the flag is present, egress path
                     otherwise). This is the only flag supported for
                     now.

              <b>Return SK_PASS </b>on success, or <b>SK_DROP </b>on error.

       <b>long bpf_msg_apply_bytes(struct sk_msg_buff *</b><i>msg</i><b>, u32 </b><i>bytes</i><b>)</b>

              <b>Description</b>
                     For socket policies, apply the verdict of the eBPF
                     program to the next <i>bytes</i> (number of bytes) of
                     message <i>msg</i>.

                     For example, this helper can be used in the
                     following cases:

                     • A single <b>sendmsg</b>() or <b>sendfile</b>() system call
                       contains multiple logical messages that the eBPF
                       program is supposed to read and for which it
                       should apply a verdict.

                     • An eBPF program only cares to read the first
                       <i>bytes</i> of a <i>msg</i>. If the message has a large
                       payload, then setting up and calling the eBPF
                       program repeatedly for all bytes, even though the
                       verdict is already known, would create
                       unnecessary overhead.

                     When called from within an eBPF program, the helper
                     sets a counter internal to the BPF infrastructure,
                     that is used to apply the last verdict to the next
                     <i>bytes</i>. If <i>bytes</i> is smaller than the current data
                     being processed from a <b>sendmsg</b>() or <b>sendfile</b>()
                     system call, the first <i>bytes</i> will be sent and the
                     eBPF program will be re-run with the pointer for
                     start of data pointing to byte number <i>bytes</i> <b>+ 1</b>. If
                     <i>bytes</i> is larger than the current data being
                     processed, then the eBPF verdict will be applied to
                     multiple <b>sendmsg</b>() or <b>sendfile</b>() calls until <i>bytes</i>
                     are consumed.

                     Note that if a socket closes with the internal
                     counter holding a non-zero value, this is not a
                     problem because data is not being buffered for
                     <i>bytes</i> and is sent as it is received.

              <b>Return </b>0

       <b>long bpf_msg_cork_bytes(struct sk_msg_buff *</b><i>msg</i><b>, u32 </b><i>bytes</i><b>)</b>

              <b>Description</b>
                     For socket policies, prevent the execution of the
                     verdict eBPF program for message <i>msg</i> until <i>bytes</i>
                     (byte number) have been accumulated.

                     This can be used when one needs a specific number
                     of bytes before a verdict can be assigned, even if
                     the data spans multiple <b>sendmsg</b>() or <b>sendfile</b>()
                     calls. The extreme case would be a user calling
                     <b>sendmsg</b>() repeatedly with 1-byte long message
                     segments. Obviously, this is bad for performance,
                     but it is still valid. If the eBPF program needs
                     <i>bytes</i> bytes to validate a header, this helper can
                     be used to prevent the eBPF program to be called
                     again until <i>bytes</i> have been accumulated.

              <b>Return </b>0

       <b>long bpf_msg_pull_data(struct sk_msg_buff *</b><i>msg</i><b>, u32 </b><i>start</i><b>, u32</b>
       <i>end</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     For socket policies, pull in non-linear data from
                     user space for <i>msg</i> and set pointers <i>msg</i><b>-&gt;data </b>and
                     <i>msg</i><b>-&gt;data_end </b>to <i>start</i> and <i>end</i> bytes offsets into
                     <i>msg</i>, respectively.

                     If a program of type <b>BPF_PROG_TYPE_SK_MSG </b>is run on
                     a <i>msg</i> it can only parse data that the (<b>data</b>,
                     <b>data_end</b>) pointers have already consumed. For
                     <b>sendmsg</b>() hooks this is likely the first
                     scatterlist element. But for calls relying on the
                     <b>sendpage </b>handler (e.g. <b>sendfile</b>()) this will be the
                     range (<b>0</b>, <b>0</b>) because the data is shared with user
                     space and by default the objective is to avoid
                     allowing user space to modify data while (or after)
                     eBPF verdict is being decided. This helper can be
                     used to pull in data and to set the start and end
                     pointer to given values. Data will be copied if
                     necessary (i.e. if data was not linear and if start
                     and end pointers do not point to the same chunk).

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

                     All values for <i>flags</i> are reserved for future usage,
                     and must be left at zero.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_bind(struct bpf_sock_addr *</b><i>ctx</i><b>, struct sockaddr *</b><i>addr</i><b>,</b>
       <b>int </b><i>addr_len</i><b>)</b>

              <b>Description</b>
                     Bind the socket associated to <i>ctx</i> to the address
                     pointed by <i>addr</i>, of length <i>addr_len</i>. This allows
                     for making outgoing connection from the desired IP
                     address, which can be useful for example when all
                     processes inside a cgroup should use one single IP
                     address on a host that has multiple IP configured.

                     This helper works for IPv4 and IPv6, TCP and UDP
                     sockets. The domain (<i>addr</i><b>-&gt;sa_family</b>) must be
                     <b>AF_INET </b>(or <b>AF_INET6</b>). It's advised to pass zero
                     port (<b>sin_port </b>or <b>sin6_port</b>) which triggers
                     IP_BIND_ADDRESS_NO_PORT-like behavior and lets the
                     kernel efficiently pick up an unused port as long
                     as 4-tuple is unique. Passing non-zero port might
                     lead to degraded performance.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_xdp_adjust_tail(struct xdp_buff *</b><i>xdp_md</i><b>, int </b><i>delta</i><b>)</b>

              <b>Description</b>
                     Adjust (move) <i>xdp_md</i><b>-&gt;data_end </b>by <i>delta</i> bytes. It
                     is possible to both shrink and grow the packet
                     tail.  Shrink done via <i>delta</i> being a negative
                     integer.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_skb_get_xfrm_state(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>index</i><b>,</b>
       <b>struct bpf_xfrm_state *</b><i>xfrm_state</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Retrieve the XFRM state (IP transform framework,
                     see also <a href="../man8/ip-xfrm.8.html">ip-xfrm(8)</a>) at <i>index</i> in XFRM "security
                     path" for <i>skb</i>.

                     The retrieved value is stored in the <b>struct</b>
                     <b>bpf_xfrm_state </b>pointed by <i>xfrm_state</i> and of length
                     <i>size</i>.

                     All values for <i>flags</i> are reserved for future usage,
                     and must be left at zero.

                     This helper is available only if the kernel was
                     compiled with <b>CONFIG_XFRM </b>configuration option.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_get_stack(void *</b><i>ctx</i><b>, void *</b><i>buf</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Return a user or a kernel stack in bpf program
                     provided buffer.  To achieve this, the helper needs
                     <i>ctx</i>, which is a pointer to the context on which the
                     tracing program is executed.  To store the
                     stacktrace, the bpf program provides <i>buf</i> with a
                     nonnegative <i>size</i>.

                     The last argument, <i>flags</i>, holds the number of stack
                     frames to skip (from 0 to 255), masked with
                     <b>BPF_F_SKIP_FIELD_MASK</b>. The next bits can be used to
                     set the following flags:

                     <b>BPF_F_USER_STACK</b>
                            Collect a user space stack instead of a
                            kernel stack.

                     <b>BPF_F_USER_BUILD_ID</b>
                            Collect (build_id, file_offset) instead of
                            ips for user stack, only valid if
                            <b>BPF_F_USER_STACK </b>is also specified.

                            <i>file_offset</i> is an offset relative to the
                            beginning of the executable or shared object
                            file backing the vma which the <i>ip</i> falls in.
                            It is <i>not</i> an offset relative to that
                            object's base address. Accordingly, it must
                            be adjusted by adding (sh_addr - sh_offset),
                            where sh_{addr,offset} correspond to the
                            executable section containing <i>file_offset</i> in
                            the object, for comparisons to symbols'
                            st_value to be valid.

                     <b>bpf_get_stack</b>() can collect up to
                     <b>PERF_MAX_STACK_DEPTH </b>both kernel and user frames,
                     subject to sufficient large buffer size. Note that
                     this limit can be controlled with the <b>sysctl</b>
                     program, and that it should be manually increased
                     in order to profile long user stacks (such as
                     stacks for Java programs). To do so, use:

                        # sysctl kernel.perf_event_max_stack=&lt;new value&gt;

              <b>Return </b>The non-negative copied <i>buf</i> length equal to or less
                     than <i>size</i> on success, or a negative error in case
                     of failure.

       <b>long bpf_skb_load_bytes_relative(const void *</b><i>skb</i><b>, u32 </b><i>offset</i><b>,</b>
       <b>void *</b><i>to</i><b>, u32 </b><i>len</i><b>, u32 </b><i>start_header</i><b>)</b>

              <b>Description</b>
                     This helper is similar to <b>bpf_skb_load_bytes</b>() in
                     that it provides an easy way to load <i>len</i> bytes from
                     <i>offset</i> from the packet associated to <i>skb</i>, into the
                     buffer pointed by <i>to</i>. The difference to
                     <b>bpf_skb_load_bytes</b>() is that a fifth argument
                     <i>start_header</i> exists in order to select a base
                     offset to start from. <i>start_header</i> can be one of:

                     <b>BPF_HDR_START_MAC</b>
                            Base offset to load data from is <i>skb</i>'s mac
                            header.

                     <b>BPF_HDR_START_NET</b>
                            Base offset to load data from is <i>skb</i>'s
                            network header.

                     In general, "direct packet access" is the preferred
                     method to access packet data, however, this helper
                     is in particular useful in socket filters where
                     <i>skb</i><b>-&gt;data </b>does not always point to the start of the
                     mac header and where "direct packet access" is not
                     available.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_fib_lookup(void *</b><i>ctx</i><b>, struct bpf_fib_lookup *</b><i>params</i><b>, int</b>
       <i>plen</i><b>, u32 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Do FIB lookup in kernel tables using parameters in
                     <i>params</i>.  If lookup is successful and result shows
                     packet is to be forwarded, the neighbor tables are
                     searched for the nexthop.  If successful (ie., FIB
                     lookup shows forwarding and nexthop is resolved),
                     the nexthop address is returned in ipv4_dst or
                     ipv6_dst based on family, smac is set to mac
                     address of egress device, dmac is set to nexthop
                     mac address, rt_metric is set to metric from route
                     (IPv4/IPv6 only), and ifindex is set to the device
                     index of the nexthop from the FIB lookup.

                     <i>plen</i> argument is the size of the passed in struct.
                     <i>flags</i> argument can be a combination of one or more
                     of the following values:

                     <b>BPF_FIB_LOOKUP_DIRECT</b>
                            Do a direct table lookup vs full lookup
                            using FIB rules.

                     <b>BPF_FIB_LOOKUP_TBID</b>
                            Used with BPF_FIB_LOOKUP_DIRECT.  Use the
                            routing table ID present in <i>params</i>-&gt;tbid for
                            the fib lookup.

                     <b>BPF_FIB_LOOKUP_OUTPUT</b>
                            Perform lookup from an egress perspective
                            (default is ingress).

                     <b>BPF_FIB_LOOKUP_SKIP_NEIGH</b>
                            Skip the neighbour table lookup.
                            <i>params</i>-&gt;dmac and <i>params</i>-&gt;smac will not be
                            set as output. A common use case is to call
                            <b>bpf_redirect_neigh</b>() after doing
                            <b>bpf_fib_lookup</b>().

                     <b>BPF_FIB_LOOKUP_SRC</b>
                            Derive and set source IP addr in
                            <i>params</i>-&gt;ipv{4,6}_src for the nexthop. If the
                            src addr cannot be derived,
                            <b>BPF_FIB_LKUP_RET_NO_SRC_ADDR </b>is returned. In
                            this case, <i>params</i>-&gt;dmac and <i>params</i>-&gt;smac are
                            not set either.

                     <i>ctx</i> is either <b>struct xdp_md </b>for XDP programs or
                     <b>struct sk_buff </b>tc cls_act programs.

              <b>Return</b>

                     • &lt; 0 if any input argument is invalid

                     • 0 on success (packet is forwarded, nexthop
                       neighbor exists)

                     • &gt; 0 one of <b>BPF_FIB_LKUP_RET_ </b>codes explaining why
                       the packet is not forwarded or needs assist from
                       full stack

                     If lookup fails with BPF_FIB_LKUP_RET_FRAG_NEEDED,
                     then the MTU was exceeded and output
                     params-&gt;mtu_result contains the MTU.

       <b>long bpf_sock_hash_update(struct bpf_sock_ops *</b><i>skops</i><b>, struct</b>
       <b>bpf_map *</b><i>map</i><b>, void *</b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Add an entry to, or update a sockhash <i>map</i>
                     referencing sockets.  The <i>skops</i> is used as a new
                     value for the entry associated to <i>key</i>. <i>flags</i> is one
                     of:

                     <b>BPF_NOEXIST</b>
                            The entry for <i>key</i> must not exist in the map.

                     <b>BPF_EXIST</b>
                            The entry for <i>key</i> must already exist in the
                            map.

                     <b>BPF_ANY</b>
                            No condition on the existence of the entry
                            for <i>key</i>.

                     If the <i>map</i> has eBPF programs (parser and verdict),
                     those will be inherited by the socket being added.
                     If the socket is already attached to eBPF programs,
                     this results in an error.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_msg_redirect_hash(struct sk_msg_buff *</b><i>msg</i><b>, struct</b>
       <b>bpf_map *</b><i>map</i><b>, void *</b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     This helper is used in programs implementing
                     policies at the socket level. If the message <i>msg</i> is
                     allowed to pass (i.e. if the verdict eBPF program
                     returns <b>SK_PASS</b>), redirect it to the socket
                     referenced by <i>map</i> (of type <b>BPF_MAP_TYPE_SOCKHASH</b>)
                     using hash <i>key</i>. Both ingress and egress interfaces
                     can be used for redirection. The <b>BPF_F_INGRESS</b>
                     value in <i>flags</i> is used to make the distinction
                     (ingress path is selected if the flag is present,
                     egress path otherwise). This is the only flag
                     supported for now.

              <b>Return SK_PASS </b>on success, or <b>SK_DROP </b>on error.

       <b>long bpf_sk_redirect_hash(struct sk_buff *</b><i>skb</i><b>, struct bpf_map</b>
       <b>*</b><i>map</i><b>, void *</b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     This helper is used in programs implementing
                     policies at the skb socket level. If the sk_buff
                     <i>skb</i> is allowed to pass (i.e.  if the verdict eBPF
                     program returns <b>SK_PASS</b>), redirect it to the socket
                     referenced by <i>map</i> (of type <b>BPF_MAP_TYPE_SOCKHASH</b>)
                     using hash <i>key</i>. Both ingress and egress interfaces
                     can be used for redirection. The <b>BPF_F_INGRESS</b>
                     value in <i>flags</i> is used to make the distinction
                     (ingress path is selected if the flag is present,
                     egress otherwise). This is the only flag supported
                     for now.

              <b>Return SK_PASS </b>on success, or <b>SK_DROP </b>on error.

       <b>long bpf_lwt_push_encap(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>type</i><b>, void *</b><i>hdr</i><b>,</b>
       <b>u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     Encapsulate the packet associated to <i>skb</i> within a
                     Layer 3 protocol header. This header is provided in
                     the buffer at address <i>hdr</i>, with <i>len</i> its size in
                     bytes. <i>type</i> indicates the protocol of the header
                     and can be one of:

                     <b>BPF_LWT_ENCAP_SEG6</b>
                            IPv6 encapsulation with Segment Routing
                            Header (<b>struct ipv6_sr_hdr</b>). <i>hdr</i> only
                            contains the SRH, the IPv6 header is
                            computed by the kernel.

                     <b>BPF_LWT_ENCAP_SEG6_INLINE</b>
                            Only works if <i>skb</i> contains an IPv6 packet.
                            Insert a Segment Routing Header (<b>struct</b>
                            <b>ipv6_sr_hdr</b>) inside the IPv6 header.

                     <b>BPF_LWT_ENCAP_IP</b>
                            IP encapsulation (GRE/GUE/IPIP/etc). The
                            outer header must be IPv4 or IPv6, followed
                            by zero or more additional headers, up to
                            <b>LWT_BPF_MAX_HEADROOM </b>total bytes in all
                            prepended headers. Please note that if
                            <b>skb_is_gso</b>(<i>skb</i>) is true, no more than two
                            headers can be prepended, and the inner
                            header, if present, should be either GRE or
                            UDP/GUE.

                     <b>BPF_LWT_ENCAP_SEG6</b>* types can be called by BPF
                     programs of type <b>BPF_PROG_TYPE_LWT_IN</b>;
                     <b>BPF_LWT_ENCAP_IP </b>type can be called by bpf programs
                     of types <b>BPF_PROG_TYPE_LWT_IN </b>and
                     <b>BPF_PROG_TYPE_LWT_XMIT</b>.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_lwt_seg6_store_bytes(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>offset</i><b>,</b>
       <b>const void *</b><i>from</i><b>, u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     Store <i>len</i> bytes from address <i>from</i> into the packet
                     associated to <i>skb</i>, at <i>offset</i>. Only the flags, tag
                     and TLVs inside the outermost IPv6 Segment Routing
                     Header can be modified through this helper.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_lwt_seg6_adjust_srh(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>offset</i><b>, s32</b>
       <i>delta</i><b>)</b>

              <b>Description</b>
                     Adjust the size allocated to TLVs in the outermost
                     IPv6 Segment Routing Header contained in the packet
                     associated to <i>skb</i>, at position <i>offset</i> by <i>delta</i>
                     bytes. Only offsets after the segments are
                     accepted. <i>delta</i> can be as well positive (growing)
                     as negative (shrinking).

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_lwt_seg6_action(struct sk_buff *</b><i>skb</i><b>, u32 </b><i>action</i><b>, void</b>
       <b>*</b><i>param</i><b>, u32 </b><i>param_len</i><b>)</b>

              <b>Description</b>
                     Apply an IPv6 Segment Routing action of type <i>action</i>
                     to the packet associated to <i>skb</i>. Each action takes
                     a parameter contained at address <i>param</i>, and of
                     length <i>param_len</i> bytes.  <i>action</i> can be one of:

                     <b>SEG6_LOCAL_ACTION_END_X</b>
                            End.X action: Endpoint with Layer-3
                            cross-connect.  Type of <i>param</i>: <b>struct</b>
                            <b>in6_addr</b>.

                     <b>SEG6_LOCAL_ACTION_END_T</b>
                            End.T action: Endpoint with specific IPv6
                            table lookup.  Type of <i>param</i>: <b>int</b>.

                     <b>SEG6_LOCAL_ACTION_END_B6</b>
                            End.B6 action: Endpoint bound to an SRv6
                            policy.  Type of <i>param</i>: <b>struct ipv6_sr_hdr</b>.

                     <b>SEG6_LOCAL_ACTION_END_B6_ENCAP</b>
                            End.B6.Encap action: Endpoint bound to an
                            SRv6 encapsulation policy.  Type of <i>param</i>:
                            <b>struct ipv6_sr_hdr</b>.

                     A call to this helper is susceptible to change the
                     underlying packet buffer. Therefore, at load time,
                     all checks on pointers previously done by the
                     verifier are invalidated and must be performed
                     again, if the helper is used in combination with
                     direct packet access.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_rc_repeat(void *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     This helper is used in programs implementing IR
                     decoding, to report a successfully decoded repeat
                     key message. This delays the generation of a key up
                     event for previously generated key down event.

                     Some IR protocols like NEC have a special IR
                     message for repeating last button, for when a
                     button is held down.

                     The <i>ctx</i> should point to the lirc sample as passed
                     into the program.

                     This helper is only available is the kernel was
                     compiled with the <b>CONFIG_BPF_LIRC_MODE2</b>
                     configuration option set to "<b>y</b>".

              <b>Return </b>0

       <b>long bpf_rc_keydown(void *</b><i>ctx</i><b>, u32 </b><i>protocol</i><b>, u64 </b><i>scancode</i><b>, u32</b>
       <i>toggle</i><b>)</b>

              <b>Description</b>
                     This helper is used in programs implementing IR
                     decoding, to report a successfully decoded key
                     press with <i>scancode</i>, <i>toggle</i> value in the given
                     <i>protocol</i>. The scancode will be translated to a
                     keycode using the rc keymap, and reported as an
                     input key down event. After a period a key up event
                     is generated. This period can be extended by
                     calling either <b>bpf_rc_keydown</b>() again with the same
                     values, or calling <b>bpf_rc_repeat</b>().

                     Some protocols include a toggle bit, in case the
                     button was released and pressed again between
                     consecutive scancodes.

                     The <i>ctx</i> should point to the lirc sample as passed
                     into the program.

                     The <i>protocol</i> is the decoded protocol number (see
                     <b>enum rc_proto </b>for some predefined values).

                     This helper is only available is the kernel was
                     compiled with the <b>CONFIG_BPF_LIRC_MODE2</b>
                     configuration option set to "<b>y</b>".

              <b>Return </b>0

       <b>u64 bpf_skb_cgroup_id(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Return the cgroup v2 id of the socket associated
                     with the <i>skb</i>.  This is roughly similar to the
                     <b>bpf_get_cgroup_classid</b>() helper for cgroup v1 by
                     providing a tag resp. identifier that can be
                     matched on or used for map lookups e.g. to
                     implement policy. The cgroup v2 id of a given path
                     in the hierarchy is exposed in user space through
                     the f_handle API in order to get to the same 64-bit
                     id.

                     This helper can be used on TC egress path, but not
                     on ingress, and is available only if the kernel was
                     compiled with the <b>CONFIG_SOCK_CGROUP_DATA</b>
                     configuration option.

              <b>Return </b>The id is returned or 0 in case the id could not be
                     retrieved.

       <b>u64 bpf_get_current_cgroup_id(void)</b>

              <b>Description</b>
                     Get the current cgroup id based on the cgroup
                     within which the current task is running.

              <b>Return </b>A 64-bit integer containing the current cgroup id
                     based on the cgroup within which the current task
                     is running.

       <b>void *bpf_get_local_storage(void *</b><i>map</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get the pointer to the local storage area.  The
                     type and the size of the local storage is defined
                     by the <i>map</i> argument.  The <i>flags</i> meaning is specific
                     for each map type, and has to be 0 for cgroup local
                     storage.

                     Depending on the BPF program type, a local storage
                     area can be shared between multiple instances of
                     the BPF program, running simultaneously.

                     A user should care about the synchronization by
                     himself.  For example, by using the <b>BPF_ATOMIC</b>
                     instructions to alter the shared data.

              <b>Return </b>A pointer to the local storage area.

       <b>long bpf_sk_select_reuseport(struct sk_reuseport_md *</b><i>reuse</i><b>,</b>
       <b>struct bpf_map *</b><i>map</i><b>, void *</b><i>key</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Select a <b>SO_REUSEPORT </b>socket from a
                     <b>BPF_MAP_TYPE_REUSEPORT_SOCKARRAY </b><i>map</i>.  It checks
                     the selected socket is matching the incoming
                     request in the socket buffer.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>u64 bpf_skb_ancestor_cgroup_id(struct sk_buff *</b><i>skb</i><b>, int</b>
       <i>ancestor_level</i><b>)</b>

              <b>Description</b>
                     Return id of cgroup v2 that is ancestor of cgroup
                     associated with the <i>skb</i> at the <i>ancestor_level</i>.  The
                     root cgroup is at <i>ancestor_level</i> zero and each step
                     down the hierarchy increments the level. If
                     <i>ancestor_level</i> == level of cgroup associated with
                     <i>skb</i>, then return value will be same as that of
                     <b>bpf_skb_cgroup_id</b>().

                     The helper is useful to implement policies based on
                     cgroups that are upper in hierarchy than immediate
                     cgroup associated with <i>skb</i>.

                     The format of returned id and helper limitations
                     are same as in <b>bpf_skb_cgroup_id</b>().

              <b>Return </b>The id is returned or 0 in case the id could not be
                     retrieved.

       <b>struct bpf_sock *bpf_sk_lookup_tcp(void *</b><i>ctx</i><b>, struct</b>
       <b>bpf_sock_tuple *</b><i>tuple</i><b>, u32 </b><i>tuple_size</i><b>, u64 </b><i>netns</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Look for TCP socket matching <i>tuple</i>, optionally in a
                     child network namespace <i>netns</i>. The return value
                     must be checked, and if non-<b>NULL</b>, released via
                     <b>bpf_sk_release</b>().

                     The <i>ctx</i> should point to the context of the program,
                     such as the skb or socket (depending on the hook in
                     use). This is used to determine the base network
                     namespace for the lookup.

                     <i>tuple_size</i> must be one of:

                     <b>sizeof(</b><i>tuple</i><b>-&gt;ipv4)</b>
                            Look for an IPv4 socket.

                     <b>sizeof(</b><i>tuple</i><b>-&gt;ipv6)</b>
                            Look for an IPv6 socket.

                     If the <i>netns</i> is a negative signed 32-bit integer,
                     then the socket lookup table in the netns
                     associated with the <i>ctx</i> will be used. For the TC
                     hooks, this is the netns of the device in the skb.
                     For socket hooks, this is the netns of the socket.
                     If <i>netns</i> is any other signed 32-bit value greater
                     than or equal to zero then it specifies the ID of
                     the netns relative to the netns associated with the
                     <i>ctx</i>. <i>netns</i> values beyond the range of 32-bit
                     integers are reserved for future use.

                     All values for <i>flags</i> are reserved for future usage,
                     and must be left at zero.

                     This helper is available only if the kernel was
                     compiled with <b>CONFIG_NET </b>configuration option.

              <b>Return </b>Pointer to <b>struct bpf_sock</b>, or <b>NULL </b>in case of
                     failure.  For sockets with reuseport option, the
                     <b>struct bpf_sock </b>result is from <i>reuse</i><b>-&gt;socks</b>[] using
                     the hash of the tuple.

       <b>struct bpf_sock *bpf_sk_lookup_udp(void *</b><i>ctx</i><b>, struct</b>
       <b>bpf_sock_tuple *</b><i>tuple</i><b>, u32 </b><i>tuple_size</i><b>, u64 </b><i>netns</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Look for UDP socket matching <i>tuple</i>, optionally in a
                     child network namespace <i>netns</i>. The return value
                     must be checked, and if non-<b>NULL</b>, released via
                     <b>bpf_sk_release</b>().

                     The <i>ctx</i> should point to the context of the program,
                     such as the skb or socket (depending on the hook in
                     use). This is used to determine the base network
                     namespace for the lookup.

                     <i>tuple_size</i> must be one of:

                     <b>sizeof(</b><i>tuple</i><b>-&gt;ipv4)</b>
                            Look for an IPv4 socket.

                     <b>sizeof(</b><i>tuple</i><b>-&gt;ipv6)</b>
                            Look for an IPv6 socket.

                     If the <i>netns</i> is a negative signed 32-bit integer,
                     then the socket lookup table in the netns
                     associated with the <i>ctx</i> will be used. For the TC
                     hooks, this is the netns of the device in the skb.
                     For socket hooks, this is the netns of the socket.
                     If <i>netns</i> is any other signed 32-bit value greater
                     than or equal to zero then it specifies the ID of
                     the netns relative to the netns associated with the
                     <i>ctx</i>. <i>netns</i> values beyond the range of 32-bit
                     integers are reserved for future use.

                     All values for <i>flags</i> are reserved for future usage,
                     and must be left at zero.

                     This helper is available only if the kernel was
                     compiled with <b>CONFIG_NET </b>configuration option.

              <b>Return </b>Pointer to <b>struct bpf_sock</b>, or <b>NULL </b>in case of
                     failure.  For sockets with reuseport option, the
                     <b>struct bpf_sock </b>result is from <i>reuse</i><b>-&gt;socks</b>[] using
                     the hash of the tuple.

       <b>long bpf_sk_release(void *</b><i>sock</i><b>)</b>

              <b>Description</b>
                     Release the reference held by <i>sock</i>. <i>sock</i> must be a
                     non-<b>NULL </b>pointer that was returned from
                     <b>bpf_sk_lookup_xxx</b>().

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_map_push_elem(struct bpf_map *</b><i>map</i><b>, const void *</b><i>value</i><b>,</b>
       <b>u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Push an element <i>value</i> in <i>map</i>. <i>flags</i> is one of:

                     <b>BPF_EXIST</b>
                            If the queue/stack is full, the oldest
                            element is removed to make room for this.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_map_pop_elem(struct bpf_map *</b><i>map</i><b>, void *</b><i>value</i><b>)</b>

              <b>Description</b>
                     Pop an element from <i>map</i>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_map_peek_elem(struct bpf_map *</b><i>map</i><b>, void *</b><i>value</i><b>)</b>

              <b>Description</b>
                     Get an element from <i>map</i> without removing it.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_msg_push_data(struct sk_msg_buff *</b><i>msg</i><b>, u32 </b><i>start</i><b>, u32</b>
       <i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     For socket policies, insert <i>len</i> bytes into <i>msg</i> at
                     offset <i>start</i>.

                     If a program of type <b>BPF_PROG_TYPE_SK_MSG </b>is run on
                     a <i>msg</i> it may want to insert metadata or options
                     into the <i>msg</i>.  This can later be read and used by
                     any of the lower layer BPF hooks.

                     This helper may fail if under memory pressure (a
                     malloc fails) in these cases BPF programs will get
                     an appropriate error and BPF programs will need to
                     handle them.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_msg_pop_data(struct sk_msg_buff *</b><i>msg</i><b>, u32 </b><i>start</i><b>, u32</b>
       <i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Will remove <i>len</i> bytes from a <i>msg</i> starting at byte
                     <i>start</i>.  This may result in <b>ENOMEM </b>errors under
                     certain situations if an allocation and copy are
                     required due to a full ring buffer.  However, the
                     helper will try to avoid doing the allocation if
                     possible. Other errors can occur if input
                     parameters are invalid either due to <i>start</i> byte not
                     being valid part of <i>msg</i> payload and/or <i>pop</i> value
                     being to large.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_rc_pointer_rel(void *</b><i>ctx</i><b>, s32 </b><i>rel_x</i><b>, s32 </b><i>rel_y</i><b>)</b>

              <b>Description</b>
                     This helper is used in programs implementing IR
                     decoding, to report a successfully decoded pointer
                     movement.

                     The <i>ctx</i> should point to the lirc sample as passed
                     into the program.

                     This helper is only available is the kernel was
                     compiled with the <b>CONFIG_BPF_LIRC_MODE2</b>
                     configuration option set to "<b>y</b>".

              <b>Return </b>0

       <b>long bpf_spin_lock(struct bpf_spin_lock *</b><i>lock</i><b>)</b>

              <b>Description</b>
                     Acquire a spinlock represented by the pointer <i>lock</i>,
                     which is stored as part of a value of a map. Taking
                     the lock allows to safely update the rest of the
                     fields in that value. The spinlock can (and must)
                     later be released with a call to
                     <b>bpf_spin_unlock</b>(<i>lock</i>).

                     Spinlocks in BPF programs come with a number of
                     restrictions and constraints:

                     • <b>bpf_spin_lock </b>objects are only allowed inside
                       maps of types <b>BPF_MAP_TYPE_HASH </b>and
                       <b>BPF_MAP_TYPE_ARRAY </b>(this list could be extended
                       in the future).

                     • BTF description of the map is mandatory.

                     • The BPF program can take ONE lock at a time,
                       since taking two or more could cause dead locks.

                     • Only one <b>struct bpf_spin_lock </b>is allowed per map
                       element.

                     • When the lock is taken, calls (either BPF to BPF
                       or helpers) are not allowed.

                     • The <b>BPF_LD_ABS </b>and <b>BPF_LD_IND </b>instructions are
                       not allowed inside a spinlock-ed region.

                     • The BPF program MUST call <b>bpf_spin_unlock</b>() to
                       release the lock, on all execution paths, before
                       it returns.

                     • The BPF program can access <b>struct bpf_spin_lock</b>
                       only via the <b>bpf_spin_lock</b>() and
                       <b>bpf_spin_unlock</b>() helpers. Loading or storing
                       data into the <b>struct bpf_spin_lock </b><i>lock</i><b>; </b>field of
                       a map is not allowed.

                     • To use the <b>bpf_spin_lock</b>() helper, the BTF
                       description of the map value must be a struct and
                       have <b>struct bpf_spin_lock </b><i>anyname</i><b>; </b>field at the
                       top level.  Nested lock inside another struct is
                       not allowed.

                     • The <b>struct bpf_spin_lock </b><i>lock</i> field in a map
                       value must be aligned on a multiple of 4 bytes in
                       that value.

                     • Syscall with command <b>BPF_MAP_LOOKUP_ELEM </b>does not
                       copy the <b>bpf_spin_lock </b>field to user space.

                     • Syscall with command <b>BPF_MAP_UPDATE_ELEM</b>, or
                       update from a BPF program, do not update the
                       <b>bpf_spin_lock </b>field.

                     • <b>bpf_spin_lock </b>cannot be on the stack or inside a
                       networking packet (it can only be inside of a map
                       values).

                     • <b>bpf_spin_lock </b>is available to root only.

                     • Tracing programs and socket filter programs
                       cannot use <b>bpf_spin_lock</b>() due to insufficient
                       preemption checks (but this may change in the
                       future).

                     • <b>bpf_spin_lock </b>is not allowed in inner maps of
                       map-in-map.

              <b>Return </b>0

       <b>long bpf_spin_unlock(struct bpf_spin_lock *</b><i>lock</i><b>)</b>

              <b>Description</b>
                     Release the <i>lock</i> previously locked by a call to
                     <b>bpf_spin_lock</b>(<i>lock</i>).

              <b>Return </b>0

       <b>struct bpf_sock *bpf_sk_fullsock(struct bpf_sock *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     This helper gets a <b>struct bpf_sock </b>pointer such
                     that all the fields in this <b>bpf_sock </b>can be
                     accessed.

              <b>Return </b>A <b>struct bpf_sock </b>pointer on success, or <b>NULL </b>in
                     case of failure.

       <b>struct bpf_tcp_sock *bpf_tcp_sock(struct bpf_sock *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     This helper gets a <b>struct bpf_tcp_sock </b>pointer from
                     a <b>struct bpf_sock </b>pointer.

              <b>Return </b>A <b>struct bpf_tcp_sock </b>pointer on success, or <b>NULL</b>
                     in case of failure.

       <b>long bpf_skb_ecn_set_ce(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     Set ECN (Explicit Congestion Notification) field of
                     IP header to <b>CE </b>(Congestion Encountered) if current
                     value is <b>ECT </b>(ECN Capable Transport). Otherwise, do
                     nothing. Works with IPv6 and IPv4.

              <b>Return </b>1 if the <b>CE </b>flag is set (either by the current
                     helper call or because it was already present), 0
                     if it is not set.

       <b>struct bpf_sock *bpf_get_listener_sock(struct bpf_sock *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Return a <b>struct bpf_sock </b>pointer in <b>TCP_LISTEN</b>
                     state.  <b>bpf_sk_release</b>() is unnecessary and not
                     allowed.

              <b>Return </b>A <b>struct bpf_sock </b>pointer on success, or <b>NULL </b>in
                     case of failure.

       <b>struct bpf_sock *bpf_skc_lookup_tcp(void *</b><i>ctx</i><b>, struct</b>
       <b>bpf_sock_tuple *</b><i>tuple</i><b>, u32 </b><i>tuple_size</i><b>, u64 </b><i>netns</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Look for TCP socket matching <i>tuple</i>, optionally in a
                     child network namespace <i>netns</i>. The return value
                     must be checked, and if non-<b>NULL</b>, released via
                     <b>bpf_sk_release</b>().

                     This function is identical to <b>bpf_sk_lookup_tcp</b>(),
                     except that it also returns timewait or request
                     sockets. Use <b>bpf_sk_fullsock</b>() or <b>bpf_tcp_sock</b>() to
                     access the full structure.

                     This helper is available only if the kernel was
                     compiled with <b>CONFIG_NET </b>configuration option.

              <b>Return </b>Pointer to <b>struct bpf_sock</b>, or <b>NULL </b>in case of
                     failure.  For sockets with reuseport option, the
                     <b>struct bpf_sock </b>result is from <i>reuse</i><b>-&gt;socks</b>[] using
                     the hash of the tuple.

       <b>long bpf_tcp_check_syncookie(void *</b><i>sk</i><b>, void *</b><i>iph</i><b>, u32 </b><i>iph_len</i><b>,</b>
       <b>struct tcphdr *</b><i>th</i><b>, u32 </b><i>th_len</i><b>)</b>

              <b>Description</b>
                     Check whether <i>iph</i> and <i>th</i> contain a valid SYN cookie
                     ACK for the listening socket in <i>sk</i>.

                     <i>iph</i> points to the start of the IPv4 or IPv6 header,
                     while <i>iph_len</i> contains <b>sizeof</b>(<b>struct iphdr</b>) or
                     <b>sizeof</b>(<b>struct ipv6hdr</b>).

                     <i>th</i> points to the start of the TCP header, while
                     <i>th_len</i> contains the length of the TCP header (at
                     least <b>sizeof</b>(<b>struct tcphdr</b>)).

              <b>Return </b>0 if <i>iph</i> and <i>th</i> are a valid SYN cookie ACK, or a
                     negative error otherwise.

       <b>long bpf_sysctl_get_name(struct bpf_sysctl *</b><i>ctx</i><b>, char *</b><i>buf</i><b>,</b>
       <b>size_t </b><i>buf_len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get name of sysctl in /proc/sys/ and copy it into
                     provided by program buffer <i>buf</i> of size <i>buf_len</i>.

                     The buffer is always NUL terminated, unless it's
                     zero-sized.

                     If <i>flags</i> is zero, full name (e.g.
                     "net/ipv4/tcp_mem") is copied. Use
                     <b>BPF_F_SYSCTL_BASE_NAME </b>flag to copy base name only
                     (e.g. "tcp_mem").

              <b>Return </b>Number of character copied (not including the
                     trailing NUL).

                     <b>-E2BIG </b>if the buffer wasn't big enough (<i>buf</i> will
                     contain truncated name in this case).

       <b>long bpf_sysctl_get_current_value(struct bpf_sysctl *</b><i>ctx</i><b>, char</b>
       <b>*</b><i>buf</i><b>, size_t </b><i>buf_len</i><b>)</b>

              <b>Description</b>
                     Get current value of sysctl as it is presented in
                     /proc/sys (incl. newline, etc), and copy it as a
                     string into provided by program buffer <i>buf</i> of size
                     <i>buf_len</i>.

                     The whole value is copied, no matter what file
                     position user space issued e.g. sys_read at.

                     The buffer is always NUL terminated, unless it's
                     zero-sized.

              <b>Return </b>Number of character copied (not including the
                     trailing NUL).

                     <b>-E2BIG </b>if the buffer wasn't big enough (<i>buf</i> will
                     contain truncated name in this case).

                     <b>-EINVAL </b>if current value was unavailable, e.g.
                     because sysctl is uninitialized and read returns
                     -EIO for it.

       <b>long bpf_sysctl_get_new_value(struct bpf_sysctl *</b><i>ctx</i><b>, char *</b><i>buf</i><b>,</b>
       <b>size_t </b><i>buf_len</i><b>)</b>

              <b>Description</b>
                     Get new value being written by user space to sysctl
                     (before the actual write happens) and copy it as a
                     string into provided by program buffer <i>buf</i> of size
                     <i>buf_len</i>.

                     User space may write new value at file position &gt;
                     0.

                     The buffer is always NUL terminated, unless it's
                     zero-sized.

              <b>Return </b>Number of character copied (not including the
                     trailing NUL).

                     <b>-E2BIG </b>if the buffer wasn't big enough (<i>buf</i> will
                     contain truncated name in this case).

                     <b>-EINVAL </b>if sysctl is being read.

       <b>long bpf_sysctl_set_new_value(struct bpf_sysctl *</b><i>ctx</i><b>, const char</b>
       <b>*</b><i>buf</i><b>, size_t </b><i>buf_len</i><b>)</b>

              <b>Description</b>
                     Override new value being written by user space to
                     sysctl with value provided by program in buffer <i>buf</i>
                     of size <i>buf_len</i>.

                     <i>buf</i> should contain a string in same form as
                     provided by user space on sysctl write.

                     User space may write new value at file position &gt;
                     0. To override the whole sysctl value file position
                     should be set to zero.

              <b>Return </b>0 on success.

                     <b>-E2BIG </b>if the <i>buf_len</i> is too big.

                     <b>-EINVAL </b>if sysctl is being read.

       <b>long bpf_strtol(const char *</b><i>buf</i><b>, size_t </b><i>buf_len</i><b>, u64 </b><i>flags</i><b>, long</b>
       <b>*</b><i>res</i><b>)</b>

              <b>Description</b>
                     Convert the initial part of the string from buffer
                     <i>buf</i> of size <i>buf_len</i> to a long integer according to
                     the given base and save the result in <i>res</i>.

                     The string may begin with an arbitrary amount of
                     white space (as determined by <a href="../man3/isspace.3.html">isspace(3)</a>) followed
                     by a single optional '<b>-</b>' sign.

                     Five least significant bits of <i>flags</i> encode base,
                     other bits are currently unused.

                     Base must be either 8, 10, 16 or 0 to detect it
                     automatically similar to user space <a href="../man3/strtol.3.html">strtol(3)</a>.

              <b>Return </b>Number of characters consumed on success. Must be
                     positive but no more than <i>buf_len</i>.

                     <b>-EINVAL </b>if no valid digits were found or
                     unsupported base was provided.

                     <b>-ERANGE </b>if resulting value was out of range.

       <b>long bpf_strtoul(const char *</b><i>buf</i><b>, size_t </b><i>buf_len</i><b>, u64 </b><i>flags</i><b>,</b>
       <b>unsigned long *</b><i>res</i><b>)</b>

              <b>Description</b>
                     Convert the initial part of the string from buffer
                     <i>buf</i> of size <i>buf_len</i> to an unsigned long integer
                     according to the given base and save the result in
                     <i>res</i>.

                     The string may begin with an arbitrary amount of
                     white space (as determined by <a href="../man3/isspace.3.html">isspace(3)</a>).

                     Five least significant bits of <i>flags</i> encode base,
                     other bits are currently unused.

                     Base must be either 8, 10, 16 or 0 to detect it
                     automatically similar to user space <a href="../man3/strtoul.3.html">strtoul(3)</a>.

              <b>Return </b>Number of characters consumed on success. Must be
                     positive but no more than <i>buf_len</i>.

                     <b>-EINVAL </b>if no valid digits were found or
                     unsupported base was provided.

                     <b>-ERANGE </b>if resulting value was out of range.

       <b>void *bpf_sk_storage_get(struct bpf_map *</b><i>map</i><b>, void *</b><i>sk</i><b>, void</b>
       <b>*</b><i>value</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get a bpf-local-storage from a <i>sk</i>.

                     Logically, it could be thought of getting the value
                     from a <i>map</i> with <i>sk</i> as the <b>key</b>.  From this
                     perspective,  the usage is not much different from
                     <b>bpf_map_lookup_elem</b>(<i>map</i>, <b>&amp;</b><i>sk</i>) except this helper
                     enforces the key must be a full socket and the map
                     must be a <b>BPF_MAP_TYPE_SK_STORAGE </b>also.

                     Underneath, the value is stored locally at <i>sk</i>
                     instead of the <i>map</i>.  The <i>map</i> is used as the
                     bpf-local-storage "type". The bpf-local-storage
                     "type" (i.e. the <i>map</i>) is searched against all
                     bpf-local-storages residing at <i>sk</i>.

                     <i>sk</i> is a kernel <b>struct sock </b>pointer for LSM program.
                     <i>sk</i> is a <b>struct bpf_sock </b>pointer for other program
                     types.

                     An optional <i>flags</i> (<b>BPF_SK_STORAGE_GET_F_CREATE</b>) can
                     be used such that a new bpf-local-storage will be
                     created if one does not exist.  <i>value</i> can be used
                     together with <b>BPF_SK_STORAGE_GET_F_CREATE </b>to
                     specify the initial value of a bpf-local-storage.
                     If <i>value</i> is <b>NULL</b>, the new bpf-local-storage will be
                     zero initialized.

              <b>Return </b>A bpf-local-storage pointer is returned on success.

                     <b>NULL </b>if not found or there was an error in adding a
                     new bpf-local-storage.

       <b>long bpf_sk_storage_delete(struct bpf_map *</b><i>map</i><b>, void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Delete a bpf-local-storage from a <i>sk</i>.

              <b>Return </b>0 on success.

                     <b>-ENOENT </b>if the bpf-local-storage cannot be found.
                     <b>-EINVAL </b>if sk is not a fullsock (e.g. a
                     request_sock).

       <b>long bpf_send_signal(u32 </b><i>sig</i><b>)</b>

              <b>Description</b>
                     Send signal <i>sig</i> to the process of the current task.
                     The signal may be delivered to any of this
                     process's threads.

              <b>Return </b>0 on success or successfully queued.

                     <b>-EBUSY </b>if work queue under nmi is full.

                     <b>-EINVAL </b>if <i>sig</i> is invalid.

                     <b>-EPERM </b>if no permission to send the <i>sig</i>.

                     <b>-EAGAIN </b>if bpf program can try again.

       <b>s64 bpf_tcp_gen_syncookie(void *</b><i>sk</i><b>, void *</b><i>iph</i><b>, u32 </b><i>iph_len</i><b>,</b>
       <b>struct tcphdr *</b><i>th</i><b>, u32 </b><i>th_len</i><b>)</b>

              <b>Description</b>
                     Try to issue a SYN cookie for the packet with
                     corresponding IP/TCP headers, <i>iph</i> and <i>th</i>, on the
                     listening socket in <i>sk</i>.

                     <i>iph</i> points to the start of the IPv4 or IPv6 header,
                     while <i>iph_len</i> contains <b>sizeof</b>(<b>struct iphdr</b>) or
                     <b>sizeof</b>(<b>struct ipv6hdr</b>).

                     <i>th</i> points to the start of the TCP header, while
                     <i>th_len</i> contains the length of the TCP header with
                     options (at least <b>sizeof</b>(<b>struct tcphdr</b>)).

              <b>Return </b>On success, lower 32 bits hold the generated SYN
                     cookie in followed by 16 bits which hold the MSS
                     value for that cookie, and the top 16 bits are
                     unused.

                     On failure, the returned value is one of the
                     following:

                     <b>-EINVAL </b>SYN cookie cannot be issued due to error

                     <b>-ENOENT </b>SYN cookie should not be issued (no SYN
                     flood)

                     <b>-EOPNOTSUPP </b>kernel configuration does not enable
                     SYN cookies

                     <b>-EPROTONOSUPPORT </b>IP packet version is not 4 or 6

       <b>long bpf_skb_output(void *</b><i>ctx</i><b>, struct bpf_map *</b><i>map</i><b>, u64 </b><i>flags</i><b>,</b>
       <b>void *</b><i>data</i><b>, u64 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Write raw <i>data</i> blob into a special BPF perf event
                     held by <i>map</i> of type <b>BPF_MAP_TYPE_PERF_EVENT_ARRAY</b>.
                     This perf event must have the following attributes:
                     <b>PERF_SAMPLE_RAW </b>as <b>sample_type</b>, <b>PERF_TYPE_SOFTWARE</b>
                     as <b>type</b>, and <b>PERF_COUNT_SW_BPF_OUTPUT </b>as <b>config</b>.

                     The <i>flags</i> are used to indicate the index in <i>map</i> for
                     which the value must be put, masked with
                     <b>BPF_F_INDEX_MASK</b>.  Alternatively, <i>flags</i> can be set
                     to <b>BPF_F_CURRENT_CPU </b>to indicate that the index of
                     the current CPU core should be used.

                     The value to write, of <i>size</i>, is passed through eBPF
                     stack and pointed by <i>data</i>.

                     <i>ctx</i> is a pointer to in-kernel struct sk_buff.

                     This helper is similar to <b>bpf_perf_event_output</b>()
                     but restricted to raw_tracepoint bpf programs.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_probe_read_user(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>unsafe_ptr</i><b>)</b>

              <b>Description</b>
                     Safely attempt to read <i>size</i> bytes from user space
                     address <i>unsafe_ptr</i> and store the data in <i>dst</i>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_probe_read_kernel(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>unsafe_ptr</i><b>)</b>

              <b>Description</b>
                     Safely attempt to read <i>size</i> bytes from kernel space
                     address <i>unsafe_ptr</i> and store the data in <i>dst</i>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_probe_read_user_str(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>unsafe_ptr</i><b>)</b>

              <b>Description</b>
                     Copy a NUL terminated string from an unsafe user
                     address <i>unsafe_ptr</i> to <i>dst</i>. The <i>size</i> should include
                     the terminating NUL byte. In case the string length
                     is smaller than <i>size</i>, the target is not padded with
                     further NUL bytes. If the string length is larger
                     than <i>size</i>, just <i>size</i>-1 bytes are copied and the
                     last byte is set to NUL.

                     On success, returns the number of bytes that were
                     written, including the terminal NUL. This makes
                     this helper useful in tracing programs for reading
                     strings, and more importantly to get its length at
                     runtime. See the following snippet:

                        SEC("kprobe/sys_open")
                        void bpf_sys_open(struct pt_regs *ctx)
                        {
                                char buf[PATHLEN]; // PATHLEN is defined to 256
                                int res = bpf_probe_read_user_str(buf, sizeof(buf),
                                                                  ctx-&gt;di);

                                // Consume buf, for example push it to
                                // userspace via bpf_perf_event_output(); we
                                // can use res (the string length) as event
                                // size, after checking its boundaries.
                        }

                     In comparison, using <b>bpf_probe_read_user</b>() helper
                     here instead to read the string would require to
                     estimate the length at compile time, and would
                     often result in copying more memory than necessary.

                     Another useful use case is when parsing individual
                     process arguments or individual environment
                     variables navigating <i>current</i><b>-&gt;mm-&gt;arg_start </b>and
                     <i>current</i><b>-&gt;mm-&gt;env_start</b>: using this helper and the
                     return value, one can quickly iterate at the right
                     offset of the memory area.

              <b>Return </b>On success, the strictly positive length of the
                     output string, including the trailing NUL
                     character. On error, a negative value.

       <b>long bpf_probe_read_kernel_str(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>unsafe_ptr</i><b>)</b>

              <b>Description</b>
                     Copy a NUL terminated string from an unsafe kernel
                     address <i>unsafe_ptr</i> to <i>dst</i>. Same semantics as with
                     <b>bpf_probe_read_user_str</b>() apply.

              <b>Return </b>On success, the strictly positive length of the
                     string, including the trailing NUL character. On
                     error, a negative value.

       <b>long bpf_tcp_send_ack(void *</b><i>tp</i><b>, u32 </b><i>rcv_nxt</i><b>)</b>

              <b>Description</b>
                     Send out a tcp-ack. <i>tp</i> is the in-kernel struct
                     <b>tcp_sock</b>.  <i>rcv_nxt</i> is the ack_seq to be sent out.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_send_signal_thread(u32 </b><i>sig</i><b>)</b>

              <b>Description</b>
                     Send signal <i>sig</i> to the thread corresponding to the
                     current task.

              <b>Return </b>0 on success or successfully queued.

                     <b>-EBUSY </b>if work queue under nmi is full.

                     <b>-EINVAL </b>if <i>sig</i> is invalid.

                     <b>-EPERM </b>if no permission to send the <i>sig</i>.

                     <b>-EAGAIN </b>if bpf program can try again.

       <b>u64 bpf_jiffies64(void)</b>

              <b>Description</b>
                     Obtain the 64bit jiffies

              <b>Return </b>The 64 bit jiffies

       <b>long bpf_read_branch_records(struct bpf_perf_event_data *</b><i>ctx</i><b>,</b>
       <b>void *</b><i>buf</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     For an eBPF program attached to a perf event,
                     retrieve the branch records (<b>struct</b>
                     <b>perf_branch_entry</b>) associated to <i>ctx</i> and store it
                     in the buffer pointed by <i>buf</i> up to size <i>size</i> bytes.

              <b>Return </b>On success, number of bytes written to <i>buf</i>. On
                     error, a negative value.

                     The <i>flags</i> can be set to
                     <b>BPF_F_GET_BRANCH_RECORDS_SIZE </b>to instead return the
                     number of bytes required to store all the branch
                     entries. If this flag is set, <i>buf</i> may be NULL.

                     <b>-EINVAL </b>if arguments invalid or <b>size </b>not a multiple
                     of <b>sizeof</b>(<b>struct perf_branch_entry</b>).

                     <b>-ENOENT </b>if architecture does not support branch
                     records.

       <b>long bpf_get_ns_current_pid_tgid(u64 </b><i>dev</i><b>, u64 </b><i>ino</i><b>, struct</b>
       <b>bpf_pidns_info *</b><i>nsdata</i><b>, u32 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Returns 0 on success, values for <i>pid</i> and <i>tgid</i> as
                     seen from the current <i>namespace</i> will be returned in
                     <i>nsdata</i>.

              <b>Return </b>0 on success, or one of the following in case of
                     failure:

                     <b>-EINVAL </b>if dev and inum supplied don't match dev_t
                     and inode number with nsfs of current task, or if
                     dev conversion to dev_t lost high bits.

                     <b>-ENOENT </b>if pidns does not exists for the current
                     task.

       <b>long bpf_xdp_output(void *</b><i>ctx</i><b>, struct bpf_map *</b><i>map</i><b>, u64 </b><i>flags</i><b>,</b>
       <b>void *</b><i>data</i><b>, u64 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Write raw <i>data</i> blob into a special BPF perf event
                     held by <i>map</i> of type <b>BPF_MAP_TYPE_PERF_EVENT_ARRAY</b>.
                     This perf event must have the following attributes:
                     <b>PERF_SAMPLE_RAW </b>as <b>sample_type</b>, <b>PERF_TYPE_SOFTWARE</b>
                     as <b>type</b>, and <b>PERF_COUNT_SW_BPF_OUTPUT </b>as <b>config</b>.

                     The <i>flags</i> are used to indicate the index in <i>map</i> for
                     which the value must be put, masked with
                     <b>BPF_F_INDEX_MASK</b>.  Alternatively, <i>flags</i> can be set
                     to <b>BPF_F_CURRENT_CPU </b>to indicate that the index of
                     the current CPU core should be used.

                     The value to write, of <i>size</i>, is passed through eBPF
                     stack and pointed by <i>data</i>.

                     <i>ctx</i> is a pointer to in-kernel struct xdp_buff.

                     This helper is similar to <b>bpf_perf_eventoutput</b>()
                     but restricted to raw_tracepoint bpf programs.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>u64 bpf_get_netns_cookie(void *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     Retrieve the cookie (generated by the kernel) of
                     the network namespace the input <i>ctx</i> is associated
                     with. The network namespace cookie remains stable
                     for its lifetime and provides a global identifier
                     that can be assumed unique. If <i>ctx</i> is NULL, then
                     the helper returns the cookie for the initial
                     network namespace. The cookie itself is very
                     similar to that of <b>bpf_get_socket_cookie</b>() helper,
                     but for network namespaces instead of sockets.

              <b>Return </b>A 8-byte long opaque number.

       <b>u64 bpf_get_current_ancestor_cgroup_id(int </b><i>ancestor_level</i><b>)</b>

              <b>Description</b>
                     Return id of cgroup v2 that is ancestor of the
                     cgroup associated with the current task at the
                     <i>ancestor_level</i>. The root cgroup is at
                     <i>ancestor_level</i> zero and each step down the
                     hierarchy increments the level. If <i>ancestor_level</i>
                     == level of cgroup associated with the current
                     task, then return value will be the same as that of
                     <b>bpf_get_current_cgroup_id</b>().

                     The helper is useful to implement policies based on
                     cgroups that are upper in hierarchy than immediate
                     cgroup associated with the current task.

                     The format of returned id and helper limitations
                     are same as in <b>bpf_get_current_cgroup_id</b>().

              <b>Return </b>The id is returned or 0 in case the id could not be
                     retrieved.

       <b>long bpf_sk_assign(struct sk_buff *</b><i>skb</i><b>, void *</b><i>sk</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Helper is overloaded depending on BPF program type.
                     This description applies to <b>BPF_PROG_TYPE_SCHED_CLS</b>
                     and <b>BPF_PROG_TYPE_SCHED_ACT </b>programs.

                     Assign the <i>sk</i> to the <i>skb</i>. When combined with
                     appropriate routing configuration to receive the
                     packet towards the socket, will cause <i>skb</i> to be
                     delivered to the specified socket.  Subsequent
                     redirection of <i>skb</i> via  <b>bpf_redirect</b>(),
                     <b>bpf_clone_redirect</b>() or other methods outside of
                     BPF may interfere with successful delivery to the
                     socket.

                     This operation is only valid from TC ingress path.

                     The <i>flags</i> argument must be zero.

              <b>Return </b>0 on success, or a negative error in case of
                     failure:

                     <b>-EINVAL </b>if specified <i>flags</i> are not supported.

                     <b>-ENOENT </b>if the socket is unavailable for
                     assignment.

                     <b>-ENETUNREACH </b>if the socket is unreachable (wrong
                     netns).

                     <b>-EOPNOTSUPP </b>if the operation is not supported, for
                     example a call from outside of TC ingress.

       <b>long bpf_sk_assign(struct bpf_sk_lookup *</b><i>ctx</i><b>, struct bpf_sock</b>
       <b>*</b><i>sk</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Helper is overloaded depending on BPF program type.
                     This description applies to <b>BPF_PROG_TYPE_SK_LOOKUP</b>
                     programs.

                     Select the <i>sk</i> as a result of a socket lookup.

                     For the operation to succeed passed socket must be
                     compatible with the packet description provided by
                     the <i>ctx</i> object.

                     L4 protocol (<b>IPPROTO_TCP </b>or <b>IPPROTO_UDP</b>) must be an
                     exact match. While IP family (<b>AF_INET </b>or <b>AF_INET6</b>)
                     must be compatible, that is IPv6 sockets that are
                     not v6-only can be selected for IPv4 packets.

                     Only TCP listeners and UDP unconnected sockets can
                     be selected. <i>sk</i> can also be NULL to reset any
                     previous selection.

                     <i>flags</i> argument can combination of following values:

                     • <b>BPF_SK_LOOKUP_F_REPLACE </b>to override the previous
                       socket selection, potentially done by a BPF
                       program that ran before us.

                     • <b>BPF_SK_LOOKUP_F_NO_REUSEPORT </b>to skip
                       load-balancing within reuseport group for the
                       socket being selected.

                     On success <i>ctx-&gt;sk</i> will point to the selected
                     socket.

              <b>Return </b>0 on success, or a negative errno in case of
                     failure.

                     • <b>-EAFNOSUPPORT </b>if socket family (<i>sk-&gt;family</i>) is
                       not compatible with packet family (<i>ctx-&gt;family</i>).

                     • <b>-EEXIST </b>if socket has been already selected,
                       potentially by another program, and
                       <b>BPF_SK_LOOKUP_F_REPLACE </b>flag was not specified.

                     • <b>-EINVAL </b>if unsupported flags were specified.

                     • <b>-EPROTOTYPE </b>if socket L4 protocol (<i>sk-&gt;protocol</i>)
                       doesn't match packet protocol (<i>ctx-&gt;protocol</i>).

                     • <b>-ESOCKTNOSUPPORT </b>if socket is not in allowed
                       state (TCP listening or UDP unconnected).

       <b>u64 bpf_ktime_get_boot_ns(void)</b>

              <b>Description</b>
                     Return the time elapsed since system boot, in
                     nanoseconds.  Does include the time the system was
                     suspended.  See: <b>clock_gettime</b>(<b>CLOCK_BOOTTIME</b>)

              <b>Return </b>Current <i>ktime</i>.

       <b>long bpf_seq_printf(struct seq_file *</b><i>m</i><b>, const char *</b><i>fmt</i><b>, u32</b>
       <i>fmt_size</i><b>, const void *</b><i>data</i><b>, u32 </b><i>data_len</i><b>)</b>

              <b>Description</b>
                     <b>bpf_seq_printf</b>() uses seq_file <b>seq_printf</b>() to
                     print out the format string.  The <i>m</i> represents the
                     seq_file. The <i>fmt</i> and <i>fmt_size</i> are for the format
                     string itself. The <i>data</i> and <i>data_len</i> are format
                     string arguments. The <i>data</i> are a <b>u64 </b>array and
                     corresponding format string values are stored in
                     the array. For strings and pointers where pointees
                     are accessed, only the pointer values are stored in
                     the <i>data</i> array.  The <i>data_len</i> is the size of <i>data</i>
                     in bytes - must be a multiple of 8.

                     Formats <b>%s</b>, <b>%p{i,I}{4,6} </b>requires to read kernel
                     memory.  Reading kernel memory may fail due to
                     either invalid address or valid address but
                     requiring a major memory fault. If reading kernel
                     memory fails, the string for <b>%s </b>will be an empty
                     string, and the ip address for <b>%p{i,I}{4,6} </b>will be
                     0. Not returning error to bpf program is consistent
                     with what <b>bpf_trace_printk</b>() does for now.

              <b>Return </b>0 on success, or a negative error in case of
                     failure:

                     <b>-EBUSY </b>if per-CPU memory copy buffer is busy, can
                     try again by returning 1 from bpf program.

                     <b>-EINVAL </b>if arguments are invalid, or if <i>fmt</i> is
                     invalid/unsupported.

                     <b>-E2BIG </b>if <i>fmt</i> contains too many format specifiers.

                     <b>-EOVERFLOW </b>if an overflow happened: The same object
                     will be tried again.

       <b>long bpf_seq_write(struct seq_file *</b><i>m</i><b>, const void *</b><i>data</i><b>, u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     <b>bpf_seq_write</b>() uses seq_file <b>seq_write</b>() to write
                     the data.  The <i>m</i> represents the seq_file. The <i>data</i>
                     and <i>len</i> represent the data to write in bytes.

              <b>Return </b>0 on success, or a negative error in case of
                     failure:

                     <b>-EOVERFLOW </b>if an overflow happened: The same object
                     will be tried again.

       <b>u64 bpf_sk_cgroup_id(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Return the cgroup v2 id of the socket <i>sk</i>.

                     <i>sk</i> must be a non-<b>NULL </b>pointer to a socket, e.g. one
                     returned from <b>bpf_sk_lookup_xxx</b>(),
                     <b>bpf_sk_fullsock</b>(), etc. The format of returned id
                     is same as in <b>bpf_skb_cgroup_id</b>().

                     This helper is available only if the kernel was
                     compiled with the <b>CONFIG_SOCK_CGROUP_DATA</b>
                     configuration option.

              <b>Return </b>The id is returned or 0 in case the id could not be
                     retrieved.

       <b>u64 bpf_sk_ancestor_cgroup_id(void *</b><i>sk</i><b>, int </b><i>ancestor_level</i><b>)</b>

              <b>Description</b>
                     Return id of cgroup v2 that is ancestor of cgroup
                     associated with the <i>sk</i> at the <i>ancestor_level</i>.  The
                     root cgroup is at <i>ancestor_level</i> zero and each step
                     down the hierarchy increments the level. If
                     <i>ancestor_level</i> == level of cgroup associated with
                     <i>sk</i>, then return value will be same as that of
                     <b>bpf_sk_cgroup_id</b>().

                     The helper is useful to implement policies based on
                     cgroups that are upper in hierarchy than immediate
                     cgroup associated with <i>sk</i>.

                     The format of returned id and helper limitations
                     are same as in <b>bpf_sk_cgroup_id</b>().

              <b>Return </b>The id is returned or 0 in case the id could not be
                     retrieved.

       <b>long bpf_ringbuf_output(void *</b><i>ringbuf</i><b>, void *</b><i>data</i><b>, u64 </b><i>size</i><b>, u64</b>
       <i>flags</i><b>)</b>

              <b>Description</b>
                     Copy <i>size</i> bytes from <i>data</i> into a ring buffer
                     <i>ringbuf</i>.  If <b>BPF_RB_NO_WAKEUP </b>is specified in
                     <i>flags</i>, no notification of new data availability is
                     sent.  If <b>BPF_RB_FORCE_WAKEUP </b>is specified in
                     <i>flags</i>, notification of new data availability is
                     sent unconditionally.  If <b>0 </b>is specified in <i>flags</i>,
                     an adaptive notification of new data availability
                     is sent.

                     An adaptive notification is a notification sent
                     whenever the user-space process has caught up and
                     consumed all available payloads. In case the
                     user-space process is still processing a previous
                     payload, then no notification is needed as it will
                     process the newly added payload automatically.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>void *bpf_ringbuf_reserve(void *</b><i>ringbuf</i><b>, u64 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Reserve <i>size</i> bytes of payload in a ring buffer
                     <i>ringbuf</i>.  <i>flags</i> must be 0.

              <b>Return </b>Valid pointer with <i>size</i> bytes of memory available;
                     NULL, otherwise.

       <b>void bpf_ringbuf_submit(void *</b><i>data</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Submit reserved ring buffer sample, pointed to by
                     <i>data</i>.  If <b>BPF_RB_NO_WAKEUP </b>is specified in <i>flags</i>,
                     no notification of new data availability is sent.
                     If <b>BPF_RB_FORCE_WAKEUP </b>is specified in <i>flags</i>,
                     notification of new data availability is sent
                     unconditionally.  If <b>0 </b>is specified in <i>flags</i>, an
                     adaptive notification of new data availability is
                     sent.

                     See 'bpf_ringbuf_output()' for the definition of
                     adaptive notification.

              <b>Return </b>Nothing. Always succeeds.

       <b>void bpf_ringbuf_discard(void *</b><i>data</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Discard reserved ring buffer sample, pointed to by
                     <i>data</i>.  If <b>BPF_RB_NO_WAKEUP </b>is specified in <i>flags</i>,
                     no notification of new data availability is sent.
                     If <b>BPF_RB_FORCE_WAKEUP </b>is specified in <i>flags</i>,
                     notification of new data availability is sent
                     unconditionally.  If <b>0 </b>is specified in <i>flags</i>, an
                     adaptive notification of new data availability is
                     sent.

                     See 'bpf_ringbuf_output()' for the definition of
                     adaptive notification.

              <b>Return </b>Nothing. Always succeeds.

       <b>u64 bpf_ringbuf_query(void *</b><i>ringbuf</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Query various characteristics of provided ring
                     buffer. What exactly is queries is determined by
                     <i>flags</i>:

                     • <b>BPF_RB_AVAIL_DATA</b>: Amount of data not yet
                       consumed.

                     • <b>BPF_RB_RING_SIZE</b>: The size of ring buffer.

                     • <b>BPF_RB_CONS_POS</b>: Consumer position (can wrap
                       around).

                     • <b>BPF_RB_PROD_POS</b>: Producer(s) position (can wrap
                       around).

                     Data returned is just a momentary snapshot of
                     actual values and could be inaccurate, so this
                     facility should be used to power heuristics and for
                     reporting, not to make 100% correct calculation.

              <b>Return </b>Requested value, or 0, if <i>flags</i> are not recognized.

       <b>long bpf_csum_level(struct sk_buff *</b><i>skb</i><b>, u64 </b><i>level</i><b>)</b>

              <b>Description</b>
                     Change the skbs checksum level by one layer up or
                     down, or reset it entirely to none in order to have
                     the stack perform checksum validation. The level is
                     applicable to the following protocols: TCP, UDP,
                     GRE, SCTP, FCOE. For example, a decap of | ETH | IP
                     | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
                     through <b>bpf_skb_adjust_room</b>() helper with passing
                     in <b>BPF_F_ADJ_ROOM_NO_CSUM_RESET </b>flag would require
                     one call to <b>bpf_csum_level</b>() with
                     <b>BPF_CSUM_LEVEL_DEC </b>since the UDP header is removed.
                     Similarly, an encap of the latter into the former
                     could be accompanied by a helper call to
                     <b>bpf_csum_level</b>() with <b>BPF_CSUM_LEVEL_INC </b>if the skb
                     is still intended to be processed in higher layers
                     of the stack instead of just egressing at tc.

                     There are three supported level settings at this
                     time:

                     • <b>BPF_CSUM_LEVEL_INC</b>: Increases skb-&gt;csum_level for
                       skbs with CHECKSUM_UNNECESSARY.

                     • <b>BPF_CSUM_LEVEL_DEC</b>: Decreases skb-&gt;csum_level for
                       skbs with CHECKSUM_UNNECESSARY.

                     • <b>BPF_CSUM_LEVEL_RESET</b>: Resets skb-&gt;csum_level to 0
                       and sets CHECKSUM_NONE to force checksum
                       validation by the stack.

                     • <b>BPF_CSUM_LEVEL_QUERY</b>: No-op, returns the current
                       skb-&gt;csum_level.

              <b>Return </b>0 on success, or a negative error in case of
                     failure. In the case of <b>BPF_CSUM_LEVEL_QUERY</b>, the
                     current skb-&gt;csum_level is returned or the error
                     code -EACCES in case the skb is not subject to
                     CHECKSUM_UNNECESSARY.

       <b>struct tcp6_sock *bpf_skc_to_tcp6_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a <i>tcp6_sock</i>
                     pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>struct tcp_sock *bpf_skc_to_tcp_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a <i>tcp_sock</i>
                     pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>struct tcp_timewait_sock *bpf_skc_to_tcp_timewait_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a
                     <i>tcp_timewait_sock</i> pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>struct tcp_request_sock *bpf_skc_to_tcp_request_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a <i>tcp_request_sock</i>
                     pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>struct udp6_sock *bpf_skc_to_udp6_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a <i>udp6_sock</i>
                     pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>long bpf_get_task_stack(struct task_struct *</b><i>task</i><b>, void *</b><i>buf</i><b>, u32</b>
       <i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Return a user or a kernel stack in bpf program
                     provided buffer.  Note: the user stack will only be
                     populated if the <i>task</i> is the current task; all
                     other tasks will return -EOPNOTSUPP.  To achieve
                     this, the helper needs <i>task</i>, which is a valid
                     pointer to <b>struct task_struct</b>. To store the
                     stacktrace, the bpf program provides <i>buf</i> with a
                     nonnegative <i>size</i>.

                     The last argument, <i>flags</i>, holds the number of stack
                     frames to skip (from 0 to 255), masked with
                     <b>BPF_F_SKIP_FIELD_MASK</b>. The next bits can be used to
                     set the following flags:

                     <b>BPF_F_USER_STACK</b>
                            Collect a user space stack instead of a
                            kernel stack.  The <i>task</i> must be the current
                            task.

                     <b>BPF_F_USER_BUILD_ID</b>
                            Collect buildid+offset instead of ips for
                            user stack, only valid if <b>BPF_F_USER_STACK</b>
                            is also specified.

                     <b>bpf_get_task_stack</b>() can collect up to
                     <b>PERF_MAX_STACK_DEPTH </b>both kernel and user frames,
                     subject to sufficient large buffer size. Note that
                     this limit can be controlled with the <b>sysctl</b>
                     program, and that it should be manually increased
                     in order to profile long user stacks (such as
                     stacks for Java programs). To do so, use:

                        # sysctl kernel.perf_event_max_stack=&lt;new value&gt;

              <b>Return </b>The non-negative copied <i>buf</i> length equal to or less
                     than <i>size</i> on success, or a negative error in case
                     of failure.

       <b>long bpf_load_hdr_opt(struct bpf_sock_ops *</b><i>skops</i><b>, void</b>
       <b>*</b><i>searchby_res</i><b>, u32 </b><i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Load header option.  Support reading a particular
                     TCP header option for bpf program
                     (<b>BPF_PROG_TYPE_SOCK_OPS</b>).

                     If <i>flags</i> is 0, it will search the option from the
                     <i>skops</i><b>-&gt;skb_data</b>.  The comment in <b>struct</b>
                     <b>bpf_sock_ops </b>has details on what skb_data contains
                     under different <i>skops</i><b>-&gt;op</b>.

                     The first byte of the <i>searchby_res</i> specifies the
                     kind that it wants to search.

                     If the searching kind is an experimental kind (i.e.
                     253 or 254 according to RFC6994).  It also needs to
                     specify the "magic" which is either 2 bytes or 4
                     bytes.  It then also needs to specify the size of
                     the magic by using the 2nd byte which is
                     "kind-length" of a TCP header option and the
                     "kind-length" also includes the first 2 bytes
                     "kind" and "kind-length" itself as a normal TCP
                     header option also does.

                     For example, to search experimental kind 254 with 2
                     byte magic 0xeB9F, the searchby_res should be [
                     254, 4, 0xeB, 0x9F, 0, 0, .... 0 ].

                     To search for the standard window scale option (3),
                     the <i>searchby_res</i> should be [ 3, 0, 0, .... 0 ].
                     Note, kind-length must be 0 for regular option.

                     Searching for No-Op (0) and End-of-Option-List (1)
                     are not supported.

                     <i>len</i> must be at least 2 bytes which is the minimal
                     size of a header option.

                     Supported flags:

                     • <b>BPF_LOAD_HDR_OPT_TCP_SYN </b>to search from the
                       saved_syn packet or the just-received syn packet.

              <b>Return </b>&gt; 0 when found, the header option is copied to
                     <i>searchby_res</i>.  The return value is the total length
                     copied. On failure, a negative error code is
                     returned:

                     <b>-EINVAL </b>if a parameter is invalid.

                     <b>-ENOMSG </b>if the option is not found.

                     <b>-ENOENT </b>if no syn packet is available when
                     <b>BPF_LOAD_HDR_OPT_TCP_SYN </b>is used.

                     <b>-ENOSPC </b>if there is not enough space.  Only <i>len</i>
                     number of bytes are copied.

                     <b>-EFAULT </b>on failure to parse the header options in
                     the packet.

                     <b>-EPERM </b>if the helper cannot be used under the
                     current <i>skops</i><b>-&gt;op</b>.

       <b>long bpf_store_hdr_opt(struct bpf_sock_ops *</b><i>skops</i><b>, const void</b>
       <b>*</b><i>from</i><b>, u32 </b><i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Store header option.  The data will be copied from
                     buffer <i>from</i> with length <i>len</i> to the TCP header.

                     The buffer <i>from</i> should have the whole option that
                     includes the kind, kind-length, and the actual
                     option data.  The <i>len</i> must be at least kind-length
                     long.  The kind-length does not have to be 4 byte
                     aligned.  The kernel will take care of the padding
                     and setting the 4 bytes aligned value to th-&gt;doff.

                     This helper will check for duplicated option by
                     searching the same option in the outgoing skb.

                     This helper can only be called during
                     <b>BPF_SOCK_OPS_WRITE_HDR_OPT_CB</b>.

              <b>Return </b>0 on success, or negative error in case of failure:

                     <b>-EINVAL </b>If param is invalid.

                     <b>-ENOSPC </b>if there is not enough space in the header.
                     Nothing has been written

                     <b>-EEXIST </b>if the option already exists.

                     <b>-EFAULT </b>on failure to parse the existing header
                     options.

                     <b>-EPERM </b>if the helper cannot be used under the
                     current <i>skops</i><b>-&gt;op</b>.

       <b>long bpf_reserve_hdr_opt(struct bpf_sock_ops *</b><i>skops</i><b>, u32 </b><i>len</i><b>, u64</b>
       <i>flags</i><b>)</b>

              <b>Description</b>
                     Reserve <i>len</i> bytes for the bpf header option.  The
                     space will be used by <b>bpf_store_hdr_opt</b>() later in
                     <b>BPF_SOCK_OPS_WRITE_HDR_OPT_CB</b>.

                     If <b>bpf_reserve_hdr_opt</b>() is called multiple times,
                     the total number of bytes will be reserved.

                     This helper can only be called during
                     <b>BPF_SOCK_OPS_HDR_OPT_LEN_CB</b>.

              <b>Return </b>0 on success, or negative error in case of failure:

                     <b>-EINVAL </b>if a parameter is invalid.

                     <b>-ENOSPC </b>if there is not enough space in the header.

                     <b>-EPERM </b>if the helper cannot be used under the
                     current <i>skops</i><b>-&gt;op</b>.

       <b>void *bpf_inode_storage_get(struct bpf_map *</b><i>map</i><b>, void *</b><i>inode</i><b>,</b>
       <b>void *</b><i>value</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get a bpf_local_storage from an <i>inode</i>.

                     Logically, it could be thought of as getting the
                     value from a <i>map</i> with <i>inode</i> as the <b>key</b>.  From this
                     perspective,  the usage is not much different from
                     <b>bpf_map_lookup_elem</b>(<i>map</i>, <b>&amp;</b><i>inode</i>) except this helper
                     enforces the key must be an inode and the map must
                     also be a <b>BPF_MAP_TYPE_INODE_STORAGE</b>.

                     Underneath, the value is stored locally at <i>inode</i>
                     instead of the <i>map</i>.  The <i>map</i> is used as the
                     bpf-local-storage "type". The bpf-local-storage
                     "type" (i.e. the <i>map</i>) is searched against all
                     bpf_local_storage residing at <i>inode</i>.

                     An optional <i>flags</i> (<b>BPF_LOCAL_STORAGE_GET_F_CREATE</b>)
                     can be used such that a new bpf_local_storage will
                     be created if one does not exist.  <i>value</i> can be
                     used together with <b>BPF_LOCAL_STORAGE_GET_F_CREATE</b>
                     to specify the initial value of a
                     bpf_local_storage.  If <i>value</i> is <b>NULL</b>, the new
                     bpf_local_storage will be zero initialized.

              <b>Return </b>A bpf_local_storage pointer is returned on success.

                     <b>NULL </b>if not found or there was an error in adding a
                     new bpf_local_storage.

       <b>int bpf_inode_storage_delete(struct bpf_map *</b><i>map</i><b>, void *</b><i>inode</i><b>)</b>

              <b>Description</b>
                     Delete a bpf_local_storage from an <i>inode</i>.

              <b>Return </b>0 on success.

                     <b>-ENOENT </b>if the bpf_local_storage cannot be found.

       <b>long bpf_d_path(struct path *</b><i>path</i><b>, char *</b><i>buf</i><b>, u32 </b><i>sz</i><b>)</b>

              <b>Description</b>
                     Return full path for given <b>struct path </b>object,
                     which needs to be the kernel BTF <i>path</i> object. The
                     path is returned in the provided buffer <i>buf</i> of size
                     <i>sz</i> and is zero terminated.

              <b>Return </b>On success, the strictly positive length of the
                     string, including the trailing NUL character. On
                     error, a negative value.

       <b>long bpf_copy_from_user(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>user_ptr</i><b>)</b>

              <b>Description</b>
                     Read <i>size</i> bytes from user space address <i>user_ptr</i>
                     and store the data in <i>dst</i>. This is a wrapper of
                     <b>copy_from_user</b>().

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_snprintf_btf(char *</b><i>str</i><b>, u32 </b><i>str_size</i><b>, struct btf_ptr</b>
       <b>*</b><i>ptr</i><b>, u32 </b><i>btf_ptr_size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Use BTF to store a string representation of
                     <i>ptr</i>-&gt;ptr in <i>str</i>, using <i>ptr</i>-&gt;type_id.  This value
                     should specify the type that <i>ptr</i>-&gt;ptr points to.
                     LLVM __builtin_btf_type_id(type, 1) can be used to
                     look up vmlinux BTF type ids. Traversing the data
                     structure using BTF, the type information and
                     values are stored in the first <i>str_size</i> - 1 bytes
                     of <i>str</i>.  Safe copy of the pointer data is carried
                     out to avoid kernel crashes during operation.
                     Smaller types can use string space on the stack;
                     larger programs can use map data to store the
                     string representation.

                     The string can be subsequently shared with
                     userspace via bpf_perf_event_output() or ring
                     buffer interfaces.  bpf_trace_printk() is to be
                     avoided as it places too small a limit on string
                     size to be useful.

                     <i>flags</i> is a combination of

                     <b>BTF_F_COMPACT</b>
                            no formatting around type information

                     <b>BTF_F_NONAME</b>
                            no struct/union member names/types

                     <b>BTF_F_PTR_RAW</b>
                            show raw (unobfuscated) pointer values;
                            equivalent to printk specifier %px.

                     <b>BTF_F_ZERO</b>
                            show zero-valued struct/union members; they
                            are not displayed by default

              <b>Return </b>The number of bytes that were written (or would
                     have been written if output had to be truncated due
                     to string size), or a negative error in cases of
                     failure.

       <b>long bpf_seq_printf_btf(struct seq_file *</b><i>m</i><b>, struct btf_ptr *</b><i>ptr</i><b>,</b>
       <b>u32 </b><i>ptr_size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Use BTF to write to seq_write a string
                     representation of <i>ptr</i>-&gt;ptr, using <i>ptr</i>-&gt;type_id as
                     per bpf_snprintf_btf().  <i>flags</i> are identical to
                     those used for bpf_snprintf_btf.

              <b>Return </b>0 on success or a negative error in case of
                     failure.

       <b>u64 bpf_skb_cgroup_classid(struct sk_buff *</b><i>skb</i><b>)</b>

              <b>Description</b>
                     See <b>bpf_get_cgroup_classid</b>() for the main
                     description.  This helper differs from
                     <b>bpf_get_cgroup_classid</b>() in that the cgroup v1
                     net_cls class is retrieved only from the <i>skb</i>'s
                     associated socket instead of the current process.

              <b>Return </b>The id is returned or 0 in case the id could not be
                     retrieved.

       <b>long bpf_redirect_neigh(u32 </b><i>ifindex</i><b>, struct bpf_redir_neigh</b>
       <b>*</b><i>params</i><b>, int </b><i>plen</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Redirect the packet to another net device of index
                     <i>ifindex</i> and fill in L2 addresses from neighboring
                     subsystem. This helper is somewhat similar to
                     <b>bpf_redirect</b>(), except that it populates L2
                     addresses as well, meaning, internally, the helper
                     relies on the neighbor lookup for the L2 address of
                     the nexthop.

                     The helper will perform a FIB lookup based on the
                     skb's networking header to get the address of the
                     next hop, unless this is supplied by the caller in
                     the <i>params</i> argument. The <i>plen</i> argument indicates
                     the len of <i>params</i> and should be set to 0 if <i>params</i>
                     is NULL.

                     The <i>flags</i> argument is reserved and must be 0. The
                     helper is currently only supported for tc BPF
                     program types, and enabled for IPv4 and IPv6
                     protocols.

              <b>Return </b>The helper returns <b>TC_ACT_REDIRECT </b>on success or
                     <b>TC_ACT_SHOT </b>on error.

       <b>void *bpf_per_cpu_ptr(const void *</b><i>percpu_ptr</i><b>, u32 </b><i>cpu</i><b>)</b>

              <b>Description</b>
                     Take a pointer to a percpu ksym, <i>percpu_ptr</i>, and
                     return a pointer to the percpu kernel variable on
                     <i>cpu</i>. A ksym is an extern variable decorated with
                     '__ksym'. For ksym, there is a global var (either
                     static or global) defined of the same name in the
                     kernel. The ksym is percpu if the global var is
                     percpu.  The returned pointer points to the global
                     percpu var on <i>cpu</i>.

                     bpf_per_cpu_ptr() has the same semantic as
                     per_cpu_ptr() in the kernel, except that
                     bpf_per_cpu_ptr() may return NULL. This happens if
                     <i>cpu</i> is larger than nr_cpu_ids. The caller of
                     bpf_per_cpu_ptr() must check the returned value.

              <b>Return </b>A pointer pointing to the kernel percpu variable on
                     <i>cpu</i>, or NULL, if <i>cpu</i> is invalid.

       <b>void *bpf_this_cpu_ptr(const void *</b><i>percpu_ptr</i><b>)</b>

              <b>Description</b>
                     Take a pointer to a percpu ksym, <i>percpu_ptr</i>, and
                     return a pointer to the percpu kernel variable on
                     this cpu. See the description of 'ksym' in
                     <b>bpf_per_cpu_ptr</b>().

                     bpf_this_cpu_ptr() has the same semantic as
                     this_cpu_ptr() in the kernel. Different from
                     <b>bpf_per_cpu_ptr</b>(), it would never return NULL.

              <b>Return </b>A pointer pointing to the kernel percpu variable on
                     this cpu.

       <b>long bpf_redirect_peer(u32 </b><i>ifindex</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Redirect the packet to another net device of index
                     <i>ifindex</i>.  This helper is somewhat similar to
                     <b>bpf_redirect</b>(), except that the redirection happens
                     to the <i>ifindex</i>' peer device and the netns switch
                     takes place from ingress to ingress without going
                     through the CPU's backlog queue.

                     The <i>flags</i> argument is reserved and must be 0. The
                     helper is currently only supported for tc BPF
                     program types at the ingress hook and for veth and
                     netkit target device types. The peer device must
                     reside in a different network namespace.

              <b>Return </b>The helper returns <b>TC_ACT_REDIRECT </b>on success or
                     <b>TC_ACT_SHOT </b>on error.

       <b>void *bpf_task_storage_get(struct bpf_map *</b><i>map</i><b>, struct</b>
       <b>task_struct *</b><i>task</i><b>, void *</b><i>value</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get a bpf_local_storage from the <i>task</i>.

                     Logically, it could be thought of as getting the
                     value from a <i>map</i> with <i>task</i> as the <b>key</b>.  From this
                     perspective,  the usage is not much different from
                     <b>bpf_map_lookup_elem</b>(<i>map</i>, <b>&amp;</b><i>task</i>) except this helper
                     enforces the key must be a task_struct and the map
                     must also be a <b>BPF_MAP_TYPE_TASK_STORAGE</b>.

                     Underneath, the value is stored locally at <i>task</i>
                     instead of the <i>map</i>.  The <i>map</i> is used as the
                     bpf-local-storage "type". The bpf-local-storage
                     "type" (i.e. the <i>map</i>) is searched against all
                     bpf_local_storage residing at <i>task</i>.

                     An optional <i>flags</i> (<b>BPF_LOCAL_STORAGE_GET_F_CREATE</b>)
                     can be used such that a new bpf_local_storage will
                     be created if one does not exist.  <i>value</i> can be
                     used together with <b>BPF_LOCAL_STORAGE_GET_F_CREATE</b>
                     to specify the initial value of a
                     bpf_local_storage.  If <i>value</i> is <b>NULL</b>, the new
                     bpf_local_storage will be zero initialized.

              <b>Return </b>A bpf_local_storage pointer is returned on success.

                     <b>NULL </b>if not found or there was an error in adding a
                     new bpf_local_storage.

       <b>long bpf_task_storage_delete(struct bpf_map *</b><i>map</i><b>, struct</b>
       <b>task_struct *</b><i>task</i><b>)</b>

              <b>Description</b>
                     Delete a bpf_local_storage from a <i>task</i>.

              <b>Return </b>0 on success.

                     <b>-ENOENT </b>if the bpf_local_storage cannot be found.

       <b>struct task_struct *bpf_get_current_task_btf(void)</b>

              <b>Description</b>
                     Return a BTF pointer to the "current" task.  This
                     pointer can also be used in helpers that accept an
                     <i>ARG_PTR_TO_BTF_ID</i> of type <i>task_struct</i>.

              <b>Return </b>Pointer to the current task.

       <b>long bpf_bprm_opts_set(struct linux_binprm *</b><i>bprm</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Set or clear certain options on <i>bprm</i>:

                     <b>BPF_F_BPRM_SECUREEXEC </b>Set the secureexec bit which
                     sets the <b>AT_SECURE </b>auxv for glibc. The bit is
                     cleared if the flag is not specified.

              <b>Return -EINVAL </b>if invalid <i>flags</i> are passed, zero
                     otherwise.

       <b>u64 bpf_ktime_get_coarse_ns(void)</b>

              <b>Description</b>
                     Return a coarse-grained version of the time elapsed
                     since system boot, in nanoseconds. Does not include
                     time the system was suspended.

                     See: <b>clock_gettime</b>(<b>CLOCK_MONOTONIC_COARSE</b>)

              <b>Return </b>Current <i>ktime</i>.

       <b>long bpf_ima_inode_hash(struct inode *</b><i>inode</i><b>, void *</b><i>dst</i><b>, u32 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Returns the stored IMA hash of the <i>inode</i> (if it's
                     available).  If the hash is larger than <i>size</i>, then
                     only <i>size</i> bytes will be copied to <i>dst</i>

              <b>Return </b>The <b>hash_algo </b>is returned on success, <b>-EOPNOTSUP </b>if
                     IMA is disabled or <b>-EINVAL </b>if invalid arguments are
                     passed.

       <b>struct socket *bpf_sock_from_file(struct file *</b><i>file</i><b>)</b>

              <b>Description</b>
                     If the given file represents a socket, returns the
                     associated socket.

              <b>Return </b>A pointer to a struct socket on success or NULL if
                     the file is not a socket.

       <b>long bpf_check_mtu(void *</b><i>ctx</i><b>, u32 </b><i>ifindex</i><b>, u32 *</b><i>mtu_len</i><b>, s32</b>
       <i>len_diff</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Check packet size against exceeding MTU of net
                     device (based on <i>ifindex</i>).  This helper will likely
                     be used in combination with helpers that
                     adjust/change the packet size.

                     The argument <i>len_diff</i> can be used for querying with
                     a planned size change. This allows to check MTU
                     prior to changing packet ctx. Providing a <i>len_diff</i>
                     adjustment that is larger than the actual packet
                     size (resulting in negative packet size) will in
                     principle not exceed the MTU, which is why it is
                     not considered a failure.  Other BPF helpers are
                     needed for performing the planned size change;
                     therefore the responsibility for catching a
                     negative packet size belongs in those helpers.

                     Specifying <i>ifindex</i> zero means the MTU check is
                     performed against the current net device.  This is
                     practical if this isn't used prior to redirect.

                     On input <i>mtu_len</i> must be a valid pointer, else
                     verifier will reject BPF program.  If the value
                     <i>mtu_len</i> is initialized to zero then the ctx packet
                     size is use.  When value <i>mtu_len</i> is provided as
                     input this specify the L3 length that the MTU check
                     is done against. Remember XDP and TC length operate
                     at L2, but this value is L3 as this correlate to
                     MTU and IP-header tot_len values which are L3
                     (similar behavior as bpf_fib_lookup).

                     The Linux kernel route table can configure MTUs on
                     a more specific per route level, which is not
                     provided by this helper.  For route level MTU
                     checks use the <b>bpf_fib_lookup</b>() helper.

                     <i>ctx</i> is either <b>struct xdp_md </b>for XDP programs or
                     <b>struct sk_buff </b>for tc cls_act programs.

                     The <i>flags</i> argument can be a combination of one or
                     more of the following values:

                     <b>BPF_MTU_CHK_SEGS</b>
                            This flag will only works for <i>ctx</i> <b>struct</b>
                            <b>sk_buff</b>.  If packet context contains extra
                            packet segment buffers (often knows as GSO
                            skb), then MTU check is harder to check at
                            this point, because in transmit path it is
                            possible for the skb packet to get
                            re-segmented (depending on net device
                            features).  This could still be a MTU
                            violation, so this flag enables performing
                            MTU check against segments, with a different
                            violation return code to tell it apart.
                            Check cannot use len_diff.

                     On return <i>mtu_len</i> pointer contains the MTU value of
                     the net device.  Remember the net device configured
                     MTU is the L3 size, which is returned here and XDP
                     and TC length operate at L2.  Helper take this into
                     account for you, but remember when using MTU value
                     in your BPF-code.

              <b>Return</b>

                     • 0 on success, and populate MTU value in <i>mtu_len</i>
                       pointer.

                     • &lt; 0 if any input argument is invalid (<i>mtu_len</i> not
                       updated)

                     MTU violations return positive values, but also
                     populate MTU value in <i>mtu_len</i> pointer, as this can
                     be needed for implementing PMTU handing:

                     • <b>BPF_MTU_CHK_RET_FRAG_NEEDED</b>

                     • <b>BPF_MTU_CHK_RET_SEGS_TOOBIG</b>

       <b>long bpf_for_each_map_elem(struct bpf_map *</b><i>map</i><b>, void</b>
       <b>*</b><i>callback_fn</i><b>, void *</b><i>callback_ctx</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     For each element in <b>map</b>, call <b>callback_fn </b>function
                     with <b>map</b>, <b>callback_ctx </b>and other map-specific
                     parameters.  The <b>callback_fn </b>should be a static
                     function and the <b>callback_ctx </b>should be a pointer
                     to the stack.  The <b>flags </b>is used to control certain
                     aspects of the helper.  Currently, the <b>flags </b>must
                     be 0.

                     The following are a list of supported map types and
                     their respective expected callback signatures:

                     BPF_MAP_TYPE_HASH, BPF_MAP_TYPE_PERCPU_HASH,
                     BPF_MAP_TYPE_LRU_HASH,
                     BPF_MAP_TYPE_LRU_PERCPU_HASH, BPF_MAP_TYPE_ARRAY,
                     BPF_MAP_TYPE_PERCPU_ARRAY

                     long (*callback_fn)(struct bpf_map *map, const void
                     *key, void *value, void *ctx);

                     For per_cpu maps, the map_value is the value on the
                     cpu where the bpf_prog is running.

                     If <b>callback_fn </b>return 0, the helper will continue
                     to the next element. If return value is 1, the
                     helper will skip the rest of elements and return.
                     Other return values are not used now.

              <b>Return </b>The number of traversed map elements for success,
                     <b>-EINVAL </b>for invalid <b>flags</b>.

       <b>long bpf_snprintf(char *</b><i>str</i><b>, u32 </b><i>str_size</i><b>, const char *</b><i>fmt</i><b>, u64</b>
       <b>*</b><i>data</i><b>, u32 </b><i>data_len</i><b>)</b>

              <b>Description</b>
                     Outputs a string into the <b>str </b>buffer of size
                     <b>str_size </b>based on a format string stored in a
                     read-only map pointed by <b>fmt</b>.

                     Each format specifier in <b>fmt </b>corresponds to one u64
                     element in the <b>data </b>array. For strings and pointers
                     where pointees are accessed, only the pointer
                     values are stored in the <i>data</i> array. The <i>data_len</i>
                     is the size of <i>data</i> in bytes - must be a multiple
                     of 8.

                     Formats <b>%s </b>and <b>%p{i,I}{4,6} </b>require to read kernel
                     memory. Reading kernel memory may fail due to
                     either invalid address or valid address but
                     requiring a major memory fault. If reading kernel
                     memory fails, the string for <b>%s </b>will be an empty
                     string, and the ip address for <b>%p{i,I}{4,6} </b>will be
                     0.  Not returning error to bpf program is
                     consistent with what <b>bpf_trace_printk</b>() does for
                     now.

              <b>Return </b>The strictly positive length of the formatted
                     string, including the trailing zero character. If
                     the return value is greater than <b>str_size</b>, <b>str</b>
                     contains a truncated string, guaranteed to be
                     zero-terminated except when <b>str_size </b>is 0.

                     Or <b>-EBUSY </b>if the per-CPU memory copy buffer is
                     busy.

       <b>long bpf_sys_bpf(u32 </b><i>cmd</i><b>, void *</b><i>attr</i><b>, u32 </b><i>attr_size</i><b>)</b>

              <b>Description</b>
                     Execute bpf syscall with given arguments.

              <b>Return </b>A syscall result.

       <b>long bpf_btf_find_by_name_kind(char *</b><i>name</i><b>, int </b><i>name_sz</i><b>, u32 </b><i>kind</i><b>,</b>
       <b>int </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Find BTF type with given name and kind in vmlinux
                     BTF or in module's BTFs.

              <b>Return </b>Returns btf_id and btf_obj_fd in lower and upper 32
                     bits.

       <b>long bpf_sys_close(u32 </b><i>fd</i><b>)</b>

              <b>Description</b>
                     Execute close syscall for given FD.

              <b>Return </b>A syscall result.

       <b>long bpf_timer_init(struct bpf_timer *</b><i>timer</i><b>, struct bpf_map *</b><i>map</i><b>,</b>
       <b>u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Initialize the timer.  First 4 bits of <i>flags</i>
                     specify clockid.  Only CLOCK_MONOTONIC,
                     CLOCK_REALTIME, CLOCK_BOOTTIME are allowed.  All
                     other bits of <i>flags</i> are reserved.  The verifier
                     will reject the program if <i>timer</i> is not from the
                     same <i>map</i>.

              <b>Return </b>0 on success.  <b>-EBUSY </b>if <i>timer</i> is already
                     initialized.  <b>-EINVAL </b>if invalid <i>flags</i> are passed.
                     <b>-EPERM </b>if <i>timer</i> is in a map that doesn't have any
                     user references.  The user space should either hold
                     a file descriptor to a map with timers or pin such
                     map in bpffs. When map is unpinned or file
                     descriptor is closed all timers in the map will be
                     cancelled and freed.

       <b>long bpf_timer_set_callback(struct bpf_timer *</b><i>timer</i><b>, void</b>
       <b>*</b><i>callback_fn</i><b>)</b>

              <b>Description</b>
                     Configure the timer to call <i>callback_fn</i> static
                     function.

              <b>Return </b>0 on success.  <b>-EINVAL </b>if <i>timer</i> was not initialized
                     with bpf_timer_init() earlier.  <b>-EPERM </b>if <i>timer</i> is
                     in a map that doesn't have any user references.
                     The user space should either hold a file descriptor
                     to a map with timers or pin such map in bpffs. When
                     map is unpinned or file descriptor is closed all
                     timers in the map will be cancelled and freed.

       <b>long bpf_timer_start(struct bpf_timer *</b><i>timer</i><b>, u64 </b><i>nsecs</i><b>, u64</b>
       <i>flags</i><b>)</b>

              <b>Description</b>
                     Set timer expiration N nanoseconds from the current
                     time. The configured callback will be invoked in
                     soft irq context on some cpu and will not repeat
                     unless another bpf_timer_start() is made.  In such
                     case the next invocation can migrate to a different
                     cpu.  Since struct bpf_timer is a field inside map
                     element the map owns the timer. The
                     bpf_timer_set_callback() will increment refcnt of
                     BPF program to make sure that callback_fn code
                     stays valid.  When user space reference to a map
                     reaches zero all timers in a map are cancelled and
                     corresponding program's refcnts are decremented.
                     This is done to make sure that Ctrl-C of a user
                     process doesn't leave any timers running. If map is
                     pinned in bpffs the callback_fn can re-arm itself
                     indefinitely.  bpf_map_update/delete_elem() helpers
                     and user space sys_bpf commands cancel and free the
                     timer in the given map element.  The map can
                     contain timers that invoke callback_fn-s from
                     different programs. The same callback_fn can serve
                     different timers from different maps if key/value
                     layout matches across maps.  Every
                     bpf_timer_set_callback() can have different
                     callback_fn.

                     <i>flags</i> can be one of:

                     <b>BPF_F_TIMER_ABS</b>
                            Start the timer in absolute expire value
                            instead of the default relative one.

                     <b>BPF_F_TIMER_CPU_PIN</b>
                            Timer will be pinned to the CPU of the
                            caller.

              <b>Return </b>0 on success.  <b>-EINVAL </b>if <i>timer</i> was not initialized
                     with bpf_timer_init() earlier or invalid <i>flags</i> are
                     passed.

       <b>long bpf_timer_cancel(struct bpf_timer *</b><i>timer</i><b>)</b>

              <b>Description</b>
                     Cancel the timer and wait for callback_fn to finish
                     if it was running.

              <b>Return </b>0 if the timer was not active.  1 if the timer was
                     active.  <b>-EINVAL </b>if <i>timer</i> was not initialized with
                     bpf_timer_init() earlier.  <b>-EDEADLK </b>if callback_fn
                     tried to call bpf_timer_cancel() on its own timer
                     which would have led to a deadlock otherwise.

       <b>u64 bpf_get_func_ip(void *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     Get address of the traced function (for tracing and
                     kprobe programs).

                     When called for kprobe program attached as uprobe
                     it returns probe address for both entry and return
                     uprobe.

              <b>Return </b>Address of the traced function for kprobe.  0 for
                     kprobes placed within the function (not at the
                     entry).  Address of the probe for uprobe and return
                     uprobe.

       <b>u64 bpf_get_attach_cookie(void *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     Get bpf_cookie value provided (optionally) during
                     the program attachment. It might be different for
                     each individual attachment, even if BPF program
                     itself is the same.  Expects BPF program context
                     <i>ctx</i> as a first argument.

                     <b>Supported for the following program types:</b>

                            • kprobe/uprobe;

                            • tracepoint;

                            • perf_event.

              <b>Return </b>Value specified by user at BPF link
                     creation/attachment time or 0, if it was not
                     specified.

       <b>long bpf_task_pt_regs(struct task_struct *</b><i>task</i><b>)</b>

              <b>Description</b>
                     Get the struct pt_regs associated with <b>task</b>.

              <b>Return </b>A pointer to struct pt_regs.

       <b>long bpf_get_branch_snapshot(void *</b><i>entries</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get branch trace from hardware engines like Intel
                     LBR. The hardware engine is stopped shortly after
                     the helper is called. Therefore, the user need to
                     filter branch entries based on the actual use case.
                     To capture branch trace before the trigger point of
                     the BPF program, the helper should be called at the
                     beginning of the BPF program.

                     The data is stored as struct perf_branch_entry into
                     output buffer <i>entries</i>. <i>size</i> is the size of <i>entries</i>
                     in bytes.  <i>flags</i> is reserved for now and must be
                     zero.

              <b>Return </b>On success, number of bytes written to <i>buf</i>. On
                     error, a negative value.

                     <b>-EINVAL </b>if <i>flags</i> is not zero.

                     <b>-ENOENT </b>if architecture does not support branch
                     records.

       <b>long bpf_trace_vprintk(const char *</b><i>fmt</i><b>, u32 </b><i>fmt_size</i><b>, const void</b>
       <b>*</b><i>data</i><b>, u32 </b><i>data_len</i><b>)</b>

              <b>Description</b>
                     Behaves like <b>bpf_trace_printk</b>() helper, but takes
                     an array of u64 to format and can handle more
                     format args as a result.

                     Arguments are to be used as in <b>bpf_seq_printf</b>()
                     helper.

              <b>Return </b>The number of bytes written to the buffer, or a
                     negative error in case of failure.

       <b>struct unix_sock *bpf_skc_to_unix_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a <i>unix_sock</i>
                     pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>long bpf_kallsyms_lookup_name(const char *</b><i>name</i><b>, int </b><i>name_sz</i><b>, int</b>
       <i>flags</i><b>, u64 *</b><i>res</i><b>)</b>

              <b>Description</b>
                     Get the address of a kernel symbol, returned in
                     <i>res</i>. <i>res</i> is set to 0 if the symbol is not found.

              <b>Return </b>On success, zero. On error, a negative value.

                     <b>-EINVAL </b>if <i>flags</i> is not zero.

                     <b>-EINVAL </b>if string <i>name</i> is not the same size as
                     <i>name_sz</i>.

                     <b>-ENOENT </b>if symbol is not found.

                     <b>-EPERM </b>if caller does not have permission to obtain
                     kernel address.

       <b>long bpf_find_vma(struct task_struct *</b><i>task</i><b>, u64 </b><i>addr</i><b>, void</b>
       <b>*</b><i>callback_fn</i><b>, void *</b><i>callback_ctx</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Find vma of <i>task</i> that contains <i>addr</i>, call
                     <i>callback_fn</i> function with <i>task</i>, <i>vma</i>, and
                     <i>callback_ctx</i>.  The <i>callback_fn</i> should be a static
                     function and the <i>callback_ctx</i> should be a pointer
                     to the stack.  The <i>flags</i> is used to control certain
                     aspects of the helper.  Currently, the <i>flags</i> must
                     be 0.

                     The expected callback signature is

                     long (*callback_fn)(struct task_struct *task,
                     struct vm_area_struct *vma, void *callback_ctx);

              <b>Return </b>0 on success.  <b>-ENOENT </b>if <i>task-&gt;mm</i> is NULL, or no
                     vma contains <i>addr</i>.  <b>-EBUSY </b>if failed to try lock
                     mmap_lock.  <b>-EINVAL </b>for invalid <b>flags</b>.

       <b>long bpf_loop(u32 </b><i>nr_loops</i><b>, void *</b><i>callback_fn</i><b>, void</b>
       <b>*</b><i>callback_ctx</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     For <b>nr_loops</b>, call <b>callback_fn </b>function with
                     <b>callback_ctx </b>as the context parameter.  The
                     <b>callback_fn </b>should be a static function and the
                     <b>callback_ctx </b>should be a pointer to the stack.  The
                     <b>flags </b>is used to control certain aspects of the
                     helper.  Currently, the <b>flags </b>must be 0. Currently,
                     nr_loops is limited to 1 &lt;&lt; 23 (~8 million) loops.

                     long (*callback_fn)(u32 index, void *ctx);

                     where <b>index </b>is the current index in the loop. The
                     index is zero-indexed.

                     If <b>callback_fn </b>returns 0, the helper will continue
                     to the next loop. If return value is 1, the helper
                     will skip the rest of the loops and return. Other
                     return values are not used now, and will be
                     rejected by the verifier.

              <b>Return </b>The number of loops performed, <b>-EINVAL </b>for invalid
                     <b>flags</b>, <b>-E2BIG </b>if <b>nr_loops </b>exceeds the maximum
                     number of loops.

       <b>long bpf_strncmp(const char *</b><i>s1</i><b>, u32 </b><i>s1_sz</i><b>, const char *</b><i>s2</i><b>)</b>

              <b>Description</b>
                     Do strncmp() between <b>s1 </b>and <b>s2</b>. <b>s1 </b>doesn't need to
                     be null-terminated and <b>s1_sz </b>is the maximum storage
                     size of <b>s1</b>. <b>s2 </b>must be a read-only string.

              <b>Return </b>An integer less than, equal to, or greater than
                     zero if the first <b>s1_sz </b>bytes of <b>s1 </b>is found to be
                     less than, to match, or be greater than <b>s2</b>.

       <b>long bpf_get_func_arg(void *</b><i>ctx</i><b>, u32 </b><i>n</i><b>, u64 *</b><i>value</i><b>)</b>

              <b>Description</b>
                     Get <b>n</b>-th argument register (zero based) of the
                     traced function (for tracing programs) returned in
                     <b>value</b>.

              <b>Return </b>0 on success.  <b>-EINVAL </b>if n &gt;= argument register
                     count of traced function.

       <b>long bpf_get_func_ret(void *</b><i>ctx</i><b>, u64 *</b><i>value</i><b>)</b>

              <b>Description</b>
                     Get return value of the traced function (for
                     tracing programs) in <b>value</b>.

              <b>Return </b>0 on success.  <b>-EOPNOTSUPP </b>for tracing programs
                     other than BPF_TRACE_FEXIT or BPF_MODIFY_RETURN.

       <b>long bpf_get_func_arg_cnt(void *</b><i>ctx</i><b>)</b>

              <b>Description</b>
                     Get number of registers of the traced function (for
                     tracing programs) where function arguments are
                     stored in these registers.

              <b>Return </b>The number of argument registers of the traced
                     function.

       <b>int bpf_get_retval(void)</b>

              <b>Description</b>
                     Get the BPF program's return value that will be
                     returned to the upper layers.

                     This helper is currently supported by cgroup
                     programs and only by the hooks where BPF program's
                     return value is returned to the userspace via
                     errno.

              <b>Return </b>The BPF program's return value.

       <b>int bpf_set_retval(int </b><i>retval</i><b>)</b>

              <b>Description</b>
                     Set the BPF program's return value that will be
                     returned to the upper layers.

                     This helper is currently supported by cgroup
                     programs and only by the hooks where BPF program's
                     return value is returned to the userspace via
                     errno.

                     Note that there is the following corner case where
                     the program exports an error via bpf_set_retval but
                     signals success via 'return 1':
                        bpf_set_retval(-EPERM); return 1;

                     In this case, the BPF program's return value will
                     use helper's -EPERM. This still holds true for
                     cgroup/bind{4,6} which supports extra 'return 3'
                     success case.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>u64 bpf_xdp_get_buff_len(struct xdp_buff *</b><i>xdp_md</i><b>)</b>

              <b>Description</b>
                     Get the total size of a given xdp buff (linear and
                     paged area)

              <b>Return </b>The total size of a given xdp buffer.

       <b>long bpf_xdp_load_bytes(struct xdp_buff *</b><i>xdp_md</i><b>, u32 </b><i>offset</i><b>, void</b>
       <b>*</b><i>buf</i><b>, u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     This helper is provided as an easy way to load data
                     from a xdp buffer. It can be used to load <i>len</i> bytes
                     from <i>offset</i> from the frame associated to <i>xdp_md</i>,
                     into the buffer pointed by <i>buf</i>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_xdp_store_bytes(struct xdp_buff *</b><i>xdp_md</i><b>, u32 </b><i>offset</i><b>,</b>
       <b>void *</b><i>buf</i><b>, u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     Store <i>len</i> bytes from buffer <i>buf</i> into the frame
                     associated to <i>xdp_md</i>, at <i>offset</i>.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>long bpf_copy_from_user_task(void *</b><i>dst</i><b>, u32 </b><i>size</i><b>, const void</b>
       <b>*</b><i>user_ptr</i><b>, struct task_struct *</b><i>tsk</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Read <i>size</i> bytes from user space address <i>user_ptr</i> in
                     <i>tsk</i>'s address space, and stores the data in <i>dst</i>.
                     <i>flags</i> is not used yet and is provided for future
                     extensibility. This helper can only be used by
                     sleepable programs.

              <b>Return </b>0 on success, or a negative error in case of
                     failure. On error <i>dst</i> buffer is zeroed out.

       <b>long bpf_skb_set_tstamp(struct sk_buff *</b><i>skb</i><b>, u64 </b><i>tstamp</i><b>, u32</b>
       <i>tstamp_type</i><b>)</b>

              <b>Description</b>
                     Change the __sk_buff-&gt;tstamp_type to <i>tstamp_type</i>
                     and set <i>tstamp</i> to the __sk_buff-&gt;tstamp together.

                     If there is no need to change the
                     __sk_buff-&gt;tstamp_type, the tstamp value can be
                     directly written to __sk_buff-&gt;tstamp instead.

                     BPF_SKB_TSTAMP_DELIVERY_MONO is the only tstamp
                     that will be kept during bpf_redirect_*().  A non
                     zero <i>tstamp</i> must be used with the
                     BPF_SKB_TSTAMP_DELIVERY_MONO <i>tstamp_type</i>.

                     A BPF_SKB_TSTAMP_UNSPEC <i>tstamp_type</i> can only be
                     used with a zero <i>tstamp</i>.

                     Only IPv4 and IPv6 skb-&gt;protocol are supported.

                     This function is most useful when it needs to set a
                     mono delivery time to __sk_buff-&gt;tstamp and then
                     bpf_redirect_*() to the egress of an iface.  For
                     example, changing the (rcv) timestamp in
                     __sk_buff-&gt;tstamp at ingress to a mono delivery
                     time and then bpf_redirect_*() to <i>sch_fq@phy-dev</i>.

              <b>Return </b>0 on success.  <b>-EINVAL </b>for invalid input
                     <b>-EOPNOTSUPP </b>for unsupported protocol

       <b>long bpf_ima_file_hash(struct file *</b><i>file</i><b>, void *</b><i>dst</i><b>, u32 </b><i>size</i><b>)</b>

              <b>Description</b>
                     Returns a calculated IMA hash of the <i>file</i>.  If the
                     hash is larger than <i>size</i>, then only <i>size</i> bytes will
                     be copied to <i>dst</i>

              <b>Return </b>The <b>hash_algo </b>is returned on success, <b>-EOPNOTSUP </b>if
                     the hash calculation failed or <b>-EINVAL </b>if invalid
                     arguments are passed.

       <b>void *bpf_kptr_xchg(void *</b><i>map_value</i><b>, void *</b><i>ptr</i><b>)</b>

              <b>Description</b>
                     Exchange kptr at pointer <i>map_value</i> with <i>ptr</i>, and
                     return the old value. <i>ptr</i> can be NULL, otherwise it
                     must be a referenced pointer which will be released
                     when this helper is called.

              <b>Return </b>The old value of kptr (which can be NULL). The
                     returned pointer if not NULL, is a reference which
                     must be released using its corresponding release
                     function, or moved into a BPF map before program
                     exit.

       <b>void *bpf_map_lookup_percpu_elem(struct bpf_map *</b><i>map</i><b>, const void</b>
       <b>*</b><i>key</i><b>, u32 </b><i>cpu</i><b>)</b>

              <b>Description</b>
                     Perform a lookup in <i>percpu map</i> for an entry
                     associated to <i>key</i> on <i>cpu</i>.

              <b>Return </b>Map value associated to <i>key</i> on <i>cpu</i>, or <b>NULL </b>if no
                     entry was found or <i>cpu</i> is invalid.

       <b>struct mptcp_sock *bpf_skc_to_mptcp_sock(void *</b><i>sk</i><b>)</b>

              <b>Description</b>
                     Dynamically cast a <i>sk</i> pointer to a <i>mptcp_sock</i>
                     pointer.

              <b>Return </b><i>sk</i> if casting is valid, or <b>NULL </b>otherwise.

       <b>long bpf_dynptr_from_mem(void *</b><i>data</i><b>, u32 </b><i>size</i><b>, u64 </b><i>flags</i><b>, struct</b>
       <b>bpf_dynptr *</b><i>ptr</i><b>)</b>

              <b>Description</b>
                     Get a dynptr to local memory <i>data</i>.

                     <i>data</i> must be a ptr to a map value.  The maximum
                     <i>size</i> supported is DYNPTR_MAX_SIZE.  <i>flags</i> is
                     currently unused.

              <b>Return </b>0 on success, -E2BIG if the size exceeds
                     DYNPTR_MAX_SIZE, -EINVAL if flags is not 0.

       <b>long bpf_ringbuf_reserve_dynptr(void *</b><i>ringbuf</i><b>, u32 </b><i>size</i><b>, u64</b>
       <i>flags</i><b>, struct bpf_dynptr *</b><i>ptr</i><b>)</b>

              <b>Description</b>
                     Reserve <i>size</i> bytes of payload in a ring buffer
                     <i>ringbuf</i> through the dynptr interface. <i>flags</i> must be
                     0.

                     Please note that a corresponding
                     bpf_ringbuf_submit_dynptr or
                     bpf_ringbuf_discard_dynptr must be called on <i>ptr</i>,
                     even if the reservation fails. This is enforced by
                     the verifier.

              <b>Return </b>0 on success, or a negative error in case of
                     failure.

       <b>void bpf_ringbuf_submit_dynptr(struct bpf_dynptr *</b><i>ptr</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Submit reserved ring buffer sample, pointed to by
                     <i>data</i>, through the dynptr interface. This is a no-op
                     if the dynptr is invalid/null.

                     For more information on <i>flags</i>, please see
                     'bpf_ringbuf_submit'.

              <b>Return </b>Nothing. Always succeeds.

       <b>void bpf_ringbuf_discard_dynptr(struct bpf_dynptr *</b><i>ptr</i><b>, u64</b>
       <i>flags</i><b>)</b>

              <b>Description</b>
                     Discard reserved ring buffer sample through the
                     dynptr interface. This is a no-op if the dynptr is
                     invalid/null.

                     For more information on <i>flags</i>, please see
                     'bpf_ringbuf_discard'.

              <b>Return </b>Nothing. Always succeeds.

       <b>long bpf_dynptr_read(void *</b><i>dst</i><b>, u32 </b><i>len</i><b>, const struct bpf_dynptr</b>
       <b>*</b><i>src</i><b>, u32 </b><i>offset</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Read <i>len</i> bytes from <i>src</i> into <i>dst</i>, starting from
                     <i>offset</i> into <i>src</i>.  <i>flags</i> is currently unused.

              <b>Return </b>0 on success, -E2BIG if <i>offset</i> + <i>len</i> exceeds the
                     length of <i>src</i>'s data, -EINVAL if <i>src</i> is an invalid
                     dynptr or if <i>flags</i> is not 0.

       <b>long bpf_dynptr_write(const struct bpf_dynptr *</b><i>dst</i><b>, u32 </b><i>offset</i><b>,</b>
       <b>void *</b><i>src</i><b>, u32 </b><i>len</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Write <i>len</i> bytes from <i>src</i> into <i>dst</i>, starting from
                     <i>offset</i> into <i>dst</i>.

                     <i>flags</i> must be 0 except for skb-type dynptrs.

                     <b>For skb-type dynptrs:</b>

                            • All data slices of the dynptr are
                              automatically invalidated after
                              <b>bpf_dynptr_write</b>(). This is because
                              writing may pull the skb and change the
                              underlying packet buffer.

                            • For <i>flags</i>, please see the flags accepted
                              by <b>bpf_skb_store_bytes</b>().

              <b>Return </b>0 on success, -E2BIG if <i>offset</i> + <i>len</i> exceeds the
                     length of <i>dst</i>'s data, -EINVAL if <i>dst</i> is an invalid
                     dynptr or if <i>dst</i> is a read-only dynptr or if <i>flags</i>
                     is not correct. For skb-type dynptrs, other errors
                     correspond to errors returned by
                     <b>bpf_skb_store_bytes</b>().

       <b>void *bpf_dynptr_data(const struct bpf_dynptr *</b><i>ptr</i><b>, u32 </b><i>offset</i><b>,</b>
       <b>u32 </b><i>len</i><b>)</b>

              <b>Description</b>
                     Get a pointer to the underlying dynptr data.

                     <i>len</i> must be a statically known value. The returned
                     data slice is invalidated whenever the dynptr is
                     invalidated.

                     skb and xdp type dynptrs may not use
                     bpf_dynptr_data. They should instead use
                     bpf_dynptr_slice and bpf_dynptr_slice_rdwr.

              <b>Return </b>Pointer to the underlying dynptr data, NULL if the
                     dynptr is read-only, if the dynptr is invalid, or
                     if the offset and length is out of bounds.

       <b>s64 bpf_tcp_raw_gen_syncookie_ipv4(struct iphdr *</b><i>iph</i><b>, struct</b>
       <b>tcphdr *</b><i>th</i><b>, u32 </b><i>th_len</i><b>)</b>

              <b>Description</b>
                     Try to issue a SYN cookie for the packet with
                     corresponding IPv4/TCP headers, <i>iph</i> and <i>th</i>, without
                     depending on a listening socket.

                     <i>iph</i> points to the IPv4 header.

                     <i>th</i> points to the start of the TCP header, while
                     <i>th_len</i> contains the length of the TCP header (at
                     least <b>sizeof</b>(<b>struct tcphdr</b>)).

              <b>Return </b>On success, lower 32 bits hold the generated SYN
                     cookie in followed by 16 bits which hold the MSS
                     value for that cookie, and the top 16 bits are
                     unused.

                     On failure, the returned value is one of the
                     following:

                     <b>-EINVAL </b>if <i>th_len</i> is invalid.

       <b>s64 bpf_tcp_raw_gen_syncookie_ipv6(struct ipv6hdr *</b><i>iph</i><b>, struct</b>
       <b>tcphdr *</b><i>th</i><b>, u32 </b><i>th_len</i><b>)</b>

              <b>Description</b>
                     Try to issue a SYN cookie for the packet with
                     corresponding IPv6/TCP headers, <i>iph</i> and <i>th</i>, without
                     depending on a listening socket.

                     <i>iph</i> points to the IPv6 header.

                     <i>th</i> points to the start of the TCP header, while
                     <i>th_len</i> contains the length of the TCP header (at
                     least <b>sizeof</b>(<b>struct tcphdr</b>)).

              <b>Return </b>On success, lower 32 bits hold the generated SYN
                     cookie in followed by 16 bits which hold the MSS
                     value for that cookie, and the top 16 bits are
                     unused.

                     On failure, the returned value is one of the
                     following:

                     <b>-EINVAL </b>if <i>th_len</i> is invalid.

                     <b>-EPROTONOSUPPORT </b>if CONFIG_IPV6 is not builtin.

       <b>long bpf_tcp_raw_check_syncookie_ipv4(struct iphdr *</b><i>iph</i><b>, struct</b>
       <b>tcphdr *</b><i>th</i><b>)</b>

              <b>Description</b>
                     Check whether <i>iph</i> and <i>th</i> contain a valid SYN cookie
                     ACK without depending on a listening socket.

                     <i>iph</i> points to the IPv4 header.

                     <i>th</i> points to the TCP header.

              <b>Return </b>0 if <i>iph</i> and <i>th</i> are a valid SYN cookie ACK.

                     On failure, the returned value is one of the
                     following:

                     <b>-EACCES </b>if the SYN cookie is not valid.

       <b>long bpf_tcp_raw_check_syncookie_ipv6(struct ipv6hdr *</b><i>iph</i><b>, struct</b>
       <b>tcphdr *</b><i>th</i><b>)</b>

              <b>Description</b>
                     Check whether <i>iph</i> and <i>th</i> contain a valid SYN cookie
                     ACK without depending on a listening socket.

                     <i>iph</i> points to the IPv6 header.

                     <i>th</i> points to the TCP header.

              <b>Return </b>0 if <i>iph</i> and <i>th</i> are a valid SYN cookie ACK.

                     On failure, the returned value is one of the
                     following:

                     <b>-EACCES </b>if the SYN cookie is not valid.

                     <b>-EPROTONOSUPPORT </b>if CONFIG_IPV6 is not builtin.

       <b>u64 bpf_ktime_get_tai_ns(void)</b>

              <b>Description</b>
                     A nonsettable system-wide clock derived from
                     wall-clock time but ignoring leap seconds.  This
                     clock does not experience discontinuities and
                     backwards jumps caused by NTP inserting leap
                     seconds as CLOCK_REALTIME does.

                     See: <b>clock_gettime</b>(<b>CLOCK_TAI</b>)

              <b>Return </b>Current <i>ktime</i>.

       <b>long bpf_user_ringbuf_drain(struct bpf_map *</b><i>map</i><b>, void</b>
       <b>*</b><i>callback_fn</i><b>, void *</b><i>ctx</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Drain samples from the specified user ring buffer,
                     and invoke the provided callback for each such
                     sample:

                     long (*callback_fn)(const struct bpf_dynptr
                     *dynptr, void *ctx);

                     If <b>callback_fn </b>returns 0, the helper will continue
                     to try and drain the next sample, up to a maximum
                     of BPF_MAX_USER_RINGBUF_SAMPLES samples. If the
                     return value is 1, the helper will skip the rest of
                     the samples and return. Other return values are not
                     used now, and will be rejected by the verifier.

              <b>Return </b>The number of drained samples if no error was
                     encountered while draining samples, or 0 if no
                     samples were present in the ring buffer. If a
                     user-space producer was epoll-waiting on this map,
                     and at least one sample was drained, they will
                     receive an event notification notifying them of
                     available space in the ring buffer. If the
                     BPF_RB_NO_WAKEUP flag is passed to this function,
                     no wakeup notification will be sent. If the
                     BPF_RB_FORCE_WAKEUP flag is passed, a wakeup
                     notification will be sent even if no sample was
                     drained.

                     On failure, the returned value is one of the
                     following:

                     <b>-EBUSY </b>if the ring buffer is contended, and another
                     calling context was concurrently draining the ring
                     buffer.

                     <b>-EINVAL </b>if user-space is not properly tracking the
                     ring buffer due to the producer position not being
                     aligned to 8 bytes, a sample not being aligned to 8
                     bytes, or the producer position not matching the
                     advertised length of a sample.

                     <b>-E2BIG </b>if user-space has tried to publish a sample
                     which is larger than the size of the ring buffer,
                     or which cannot fit within a struct bpf_dynptr.

       <b>void *bpf_cgrp_storage_get(struct bpf_map *</b><i>map</i><b>, struct cgroup</b>
       <b>*</b><i>cgroup</i><b>, void *</b><i>value</i><b>, u64 </b><i>flags</i><b>)</b>

              <b>Description</b>
                     Get a bpf_local_storage from the <i>cgroup</i>.

                     Logically, it could be thought of as getting the
                     value from a <i>map</i> with <i>cgroup</i> as the <b>key</b>.  From this
                     perspective,  the usage is not much different from
                     <b>bpf_map_lookup_elem</b>(<i>map</i>, <b>&amp;</b><i>cgroup</i>) except this
                     helper enforces the key must be a cgroup struct and
                     the map must also be a <b>BPF_MAP_TYPE_CGRP_STORAGE</b>.

                     In reality, the local-storage value is embedded
                     directly inside of the <i>cgroup</i> object itself, rather
                     than being located in the <b>BPF_MAP_TYPE_CGRP_STORAGE</b>
                     map. When the local-storage value is queried for
                     some <i>map</i> on a <i>cgroup</i> object, the kernel will
                     perform an O(n) iteration over all of the live
                     local-storage values for that <i>cgroup</i> object until
                     the local-storage value for the <i>map</i> is found.

                     An optional <i>flags</i> (<b>BPF_LOCAL_STORAGE_GET_F_CREATE</b>)
                     can be used such that a new bpf_local_storage will
                     be created if one does not exist.  <i>value</i> can be
                     used together with <b>BPF_LOCAL_STORAGE_GET_F_CREATE</b>
                     to specify the initial value of a
                     bpf_local_storage.  If <i>value</i> is <b>NULL</b>, the new
                     bpf_local_storage will be zero initialized.

              <b>Return </b>A bpf_local_storage pointer is returned on success.

                     <b>NULL </b>if not found or there was an error in adding a
                     new bpf_local_storage.

       <b>long bpf_cgrp_storage_delete(struct bpf_map *</b><i>map</i><b>, struct cgroup</b>
       <b>*</b><i>cgroup</i><b>)</b>

              <b>Description</b>
                     Delete a bpf_local_storage from a <i>cgroup</i>.

              <b>Return </b>0 on success.

                     <b>-ENOENT </b>if the bpf_local_storage cannot be found.
</pre> <h2>
EXAMPLES </h2>
<pre>
       Example usage for most of the eBPF helpers listed in this manual
       page are available within the Linux kernel sources, at the
       following locations:

       • <i>samples/bpf/</i>

       • <i>tools/testing/selftests/bpf/</i>
</pre> <h2>
LICENSE </h2>
<pre>
       eBPF programs can have an associated license, passed along with
       the bytecode instructions to the kernel when the programs are
       loaded. The format for that string is identical to the one in use
       for kernel modules (Dual licenses, such as "Dual BSD/GPL", may be
       used). Some helper functions are only accessible to programs that
       are compatible with the GNU General Public License (GNU GPL).

       In order to use such helpers, the eBPF program must be loaded
       with the correct license string passed (via <b>attr</b>) to the <b>bpf</b>()
       system call, and this generally translates into the C source code
       of the program containing a line similar to the following:

          char ____license[] __attribute__((section("license"), used)) = "GPL";
</pre> <h2>
IMPLEMENTATION </h2>
<pre>
       This manual page is an effort to document the existing eBPF
       helper functions.  But as of this writing, the BPF sub-system is
       under heavy development. New eBPF program or map types are added,
       along with new helper functions. Some helpers are occasionally
       made available for additional program types. So in spite of the
       efforts of the community, this page might not be up-to-date. If
       you want to check by yourself what helper functions exist in your
       kernel, or what types of programs they can support, here are some
       files among the kernel tree that you may be interested in:

       • <i>include/uapi/linux/bpf.h</i> is the main BPF header. It contains
         the full list of all helper functions, as well as many other
         BPF definitions including most of the flags, structs or
         constants used by the helpers.

       • <i>net/core/filter.c</i> contains the definition of most
         network-related helper functions, and the list of program types
         from which they can be used.

       • <i>kernel/trace/bpf_trace.c</i> is the equivalent for most tracing
         program-related helpers.

       • <i>kernel/bpf/verifier.c</i> contains the functions used to check that
         valid types of eBPF maps are used with a given helper function.

       • <i>kernel/bpf/</i> directory contains other files in which additional
         helpers are defined (for cgroups, sockmaps, etc.).

       • The bpftool utility can be used to probe the availability of
         helper functions on the system (as well as supported program
         and map types, and a number of other parameters). To do so, run
         <b>bpftool feature probe </b>(see <b>bpftool-feature</b>(8) for details). Add
         the <b>unprivileged </b>keyword to list features available to
         unprivileged users.

       Compatibility between helper functions and program types can
       generally be found in the files where helper functions are
       defined. Look for the <b>struct bpf_func_proto </b>objects and for
       functions returning them: these functions contain a list of
       helpers that a given program type can call. Note that the
       <b>default: </b>label of the <b>switch ... case </b>used to filter helpers can
       call other functions, themselves allowing access to additional
       helpers. The requirement for GPL license is also in those <b>struct</b>
       <b>bpf_func_proto</b>.

       Compatibility between helper functions and map types can be found
       in the <b>check_map_func_compatibility</b>() function in file
       <i>kernel/bpf/verifier.c</i>.

       Helper functions that invalidate the checks on <b>data </b>and <b>data_end</b>
       pointers for network processing are listed in function
       <b>bpf_helper_changes_pkt_data</b>() in file <i>net/core/filter.c</i>.
</pre> <h2>
SEE ALSO </h2>
<pre>
       <a href="../man2/bpf.2.html">bpf(2)</a>, <b>bpftool</b>(8), <a href="cgroups.7.html">cgroups(7)</a>, <a href="../man8/ip.8.html">ip(8)</a>, <a href="../man2/perf_event_open.2.html">perf_event_open(2)</a>,
       <a href="../man2/sendmsg.2.html">sendmsg(2)</a>, <a href="socket.7.html">socket(7)</a>, <a href="../man8/tc-bpf.8.html">tc-bpf(8)</a>
</pre> <h2>
COLOPHON </h2>
<pre>
       This page is part of the <i>man-pages</i> (Linux kernel and C library
       user-space interface documentation) project.  Information about
       the project can be found at 
       ⟨<a href="https://www.kernel.org/doc/man-pages/">https://www.kernel.org/doc/man-pages/</a>⟩.  If you have a bug report
       for this manual page, see
       ⟨<a href="https://git.kernel.org/pub/scm/docs/man-pages/man-pages.git/tree/CONTRIBUTING">https://git.kernel.org/pub/scm/docs/man-pages/man-pages.git/tree/CONTRIBUTING</a>⟩.
       This page was obtained from the tarball man-pages-6.9.1.tar.gz
       fetched from
       ⟨<a href="https://mirrors.edge.kernel.org/pub/linux/docs/man-pages/">https://mirrors.edge.kernel.org/pub/linux/docs/man-pages/</a>⟩ on
       2024-06-26.  If you discover any rendering problems in this HTML
       version of the page, or you believe there is a better or more up-
       to-date source for the page, or you have corrections or
       improvements to the information in this COLOPHON (which is <i>not</i>
       part of the original manual page), send a mail to
       man-pages@man7.org

<span class="footline">Linux v6.9                     2024-01-23                 <i>BPF-HELPERS</i>(7)</span>
</pre>  <p>Pages that refer to this page: <a href="../man2/bpf.2.html">bpf(2)</a>, <a href="capabilities.7.html">capabilities(7)</a> </p> <hr>         <div class="_attribution">
  <p class="_attribution-p">
    ...<br>
    <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html" class="_attribution-link">https://man7.org/linux/man-pages/man7/bpf-helpers.7.html</a>
  </p>
</div>
