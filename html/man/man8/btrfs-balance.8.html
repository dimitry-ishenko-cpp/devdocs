<h1>btrfs-balance(8) — Linux manual page</h1>   <pre>
<span class="headline"><i>BTRFS-BALANCE</i>(8)              Btrfs Manual              <i>BTRFS-BALANCE</i>(8)</span>
</pre> <h2>
NAME </h2>
<pre>
       btrfs-balance - balance block groups on a btrfs filesystem
</pre> <h2>
SYNOPSIS </h2>
<pre>
       <b>btrfs balance </b><i>&lt;subcommand&gt; &lt;args&gt;</i>
</pre> <h2>
DESCRIPTION </h2>
<pre>
       The primary purpose of the balance feature is to spread block
       groups across all devices so they match constraints defined by
       the respective profiles. See <a href="mkfs.btrfs.8.html">mkfs.btrfs(8)</a> section <i>PROFILES</i> for
       more details. The scope of the balancing process can be further
       tuned by use of filters that can select the block groups to
       process. Balance works only on a mounted filesystem. Extent
       sharing is preserved and reflinks are not broken. Files are not
       defragmented nor recompressed, file extents are preserved but the
       physical location on devices will change.

       The balance operation is cancellable by the user. The on-disk
       state of the filesystem is always consistent so an unexpected
       interruption (eg. system crash, reboot) does not corrupt the
       filesystem. The progress of the balance operation is temporarily
       stored as an internal state and will be resumed upon mount,
       unless the mount option <i>skip_balance</i> is specified.

           <b>Warning</b>

           running balance without filters will take a lot of time as it
           basically move data/metadata from the whol filesystem and
           needs to update all block pointers.

       The filters can be used to perform following actions:

       •   convert block group profiles (filter <i>convert</i>)

       •   make block group usage more compact (filter <i>usage</i>)

       •   perform actions only on a given device (filters <i>devid</i>,
           <i>drange</i>)

       The filters can be applied to a combination of block group types
       (data, metadata, system). Note that changing only the <i>system</i> type
       needs the force option. Otherwise <i>system</i> gets automatically
       converted whenever <i>metadata</i> profile is converted.

       When metadata redundancy is reduced (eg. from RAID1 to single)
       the force option is also required and it is noted in system log.

           <b>Note</b>

           the balance operation needs enough work space, ie. space that
           is completely unused in the filesystem, otherwise this may
           lead to ENOSPC reports. See the section <i>ENOSPC</i> for more
           details.
</pre> <h2>
COMPATIBILITY </h2>
<pre>
           <b>Note</b>

           The balance subcommand also exists under the <b>btrfs filesystem</b>
           namespace. This still works for backward compatibility but is
           deprecated and should not be used any more.

           <b>Note</b>

           A short syntax <b>btrfs balance </b><i>&lt;path&gt;</i> works due to backward
           compatibility but is deprecated and should not be used any
           more. Use <b>btrfs balance start </b>command instead.
</pre> <h2>
PERFORMANCE IMPLICATIONS </h2>
<pre>
       Balancing operations are very IO intensive and can also be quite
       CPU intensive, impacting other ongoing filesystem operations.
       Typically large amounts of data are copied from one location to
       another, with corresponding metadata updates.

       Depending upon the block group layout, it can also be seek heavy.
       Performance on rotational devices is noticeably worse compared to
       SSDs or fast arrays.
</pre> <h2>
SUBCOMMAND </h2>
<pre>
       <b>cancel </b><i>&lt;path&gt;</i>
           cancels a running or paused balance, the command will block
           and wait until the current blockgroup being processed
           completes

           Since kernel 5.7 the response time of the cancellation is
           significantly improved, on older kernels it might take a long
           time until currently processed chunk is completely finished.

       <b>pause </b><i>&lt;path&gt;</i>
           pause running balance operation, this will store the state of
           the balance progress and used filters to the filesystem

       <b>resume </b><i>&lt;path&gt;</i>
           resume interrupted balance, the balance status must be stored
           on the filesystem from previous run, eg. after it was paused
           or forcibly interrupted and mounted again with <i>skip_balance</i>

       <b>start </b>[options] <i>&lt;path&gt;</i>
           start the balance operation according to the specified
           filters, without any filters the data and metadata from the
           whole filesystem are moved. The process runs in the
           foreground.

               <b>Note</b>
               the balance command without filters will basically move
               everything in the filesystem to a new physical location
               on devices (ie. it does not affect the logical properties
               of file extents like offsets within files and extent
               sharing). The run time is potentially very long,
               depending on the filesystem size. To prevent starting a
               full balance by accident, the user is warned and has a
               few seconds to cancel the operation before it starts. The
               warning and delay can be skipped with <i>--full-balance</i>
               option.
           Please note that the filters must be written together with
           the <i>-d</i>, <i>-m</i> and <i>-s</i> options, because they’re optional and bare
           <i>-d</i> and <i>-m</i> also work and mean no filters.

               <b>Note</b>
               when the target profile for conversion filter is <i>raid5</i> or
               <i>raid6</i>, there’s a safety timeout of 10 seconds to warn
               users about the status of the feature
           <b>Options</b>

           -d[<i>&lt;filters&gt;</i>]
               act on data block groups, see <b>FILTERS </b>section for details
               about <i>filters</i>

           -m[<i>&lt;filters&gt;</i>]
               act on metadata chunks, see <b>FILTERS </b>section for details
               about <i>filters</i>

           -s[<i>&lt;filters&gt;</i>]
               act on system chunks (requires <i>-f</i>), see <b>FILTERS </b>section
               for details about <i>filters</i>.

           -f
               force a reduction of metadata integrity, eg. when going
               from <i>raid1</i> to <i>single</i>, or skip safety timeout when the
               target conversion profile is <i>raid5</i> or <i>raid6</i>

           --background|--bg
               run the balance operation asynchronously in the
               background, uses <a href="../man2/fork.2.html">fork(2)</a> to start the process that calls
               the kernel ioctl

           --enqueue
               wait if there’s another exclusive operation running,
               otherwise continue

           -v
               (deprecated) alias for global <i>-v</i> option

       <b>status </b>[-v] <i>&lt;path&gt;</i>
           Show status of running or paused balance.

           <b>Options</b>

           -v
               (deprecated) alias for global <i>-v</i> option
</pre> <h2>
FILTERS </h2>
<pre>
       From kernel 3.3 onwards, btrfs balance can limit its action to a
       subset of the whole filesystem, and can be used to change the
       replication configuration (e.g. moving data from single to
       RAID1). This functionality is accessed through the <i>-d</i>, <i>-m</i> or <i>-s</i>
       options to btrfs balance start, which filter on data, metadata
       and system blocks respectively.

       A filter has the following structure: <i>type</i>[=<i>params</i>][,<i>type</i>=...]

       The available types are:

       <b>profiles=</b><i>&lt;profiles&gt;</i>
           Balances only block groups with the given profiles.
           Parameters are a list of profile names separated by "<i>|</i>"
           (pipe).

       <b>usage=</b><i>&lt;percent&gt;</i>, <b>usage=</b><i>&lt;range&gt;</i>
           Balances only block groups with usage under the given
           percentage. The value of 0 is allowed and will clean up
           completely unused block groups, this should not require any
           new work space allocated. You may want to use <i>usage=0</i> in case
           balance is returning ENOSPC and your filesystem is not too
           full.

           The argument may be a single value or a range. The single
           value <i>N</i> means <i>at most N percent used</i>, equivalent to <i>..N</i> range
           syntax. Kernels prior to 4.4 accept only the single value
           format. The minimum range boundary is inclusive, maximum is
           exclusive.

       <b>devid=</b><i>&lt;id&gt;</i>
           Balances only block groups which have at least one chunk on
           the given device. To list devices with ids use <b>btrfs</b>
           <b>filesystem show</b>.

       <b>drange=</b><i>&lt;range&gt;</i>
           Balance only block groups which overlap with the given byte
           range on any device. Use in conjunction with <i>devid</i> to filter
           on a specific device. The parameter is a range specified as
           <i>start..end</i>.

       <b>vrange=</b><i>&lt;range&gt;</i>
           Balance only block groups which overlap with the given byte
           range in the filesystem’s internal virtual address space.
           This is the address space that most reports from btrfs in the
           kernel log use. The parameter is a range specified as
           <i>start..end</i>.

       <b>convert=</b><i>&lt;profile&gt;</i>
           Convert each selected block group to the given profile name
           identified by parameters.

               <b>Note</b>
               starting with kernel 4.5, the <i>data</i> chunks can be
               converted to/from the <i>DUP</i> profile on a single device.

               <b>Note</b>
               starting with kernel 4.6, all profiles can be converted
               to/from <i>DUP</i> on multi-device filesystems.

       <b>limit=</b><i>&lt;number&gt;</i>, <b>limit=</b><i>&lt;range&gt;</i>
           Process only given number of chunks, after all filters are
           applied. This can be used to specifically target a chunk in
           connection with other filters (<i>drange</i>, <i>vrange</i>) or just simply
           limit the amount of work done by a single balance run.

           The argument may be a single value or a range. The single
           value <i>N</i> means <i>at most N chunks</i>, equivalent to <i>..N</i> range
           syntax. Kernels prior to 4.4 accept only the single value
           format. The range minimum and maximum are inclusive.

       <b>stripes=</b><i>&lt;range&gt;</i>
           Balance only block groups which have the given number of
           stripes. The parameter is a range specified as <i>start..end</i>.
           Makes sense for block group profiles that utilize striping,
           ie. RAID0/10/5/6. The range minimum and maximum are
           inclusive.

       <b>soft</b>
           Takes no parameters. Only has meaning when converting between
           profiles. When doing convert from one profile to another and
           soft mode is on, chunks that already have the target profile
           are left untouched. This is useful e.g. when half of the
           filesystem was converted earlier but got cancelled.

           The soft mode switch is (like every other filter) per-type.
           For example, this means that we can convert metadata chunks
           the "hard" way while converting data chunks selectively with
           soft switch.

       Profile names, used in <i>profiles</i> and <i>convert</i> are one of: <i>raid0</i>,
       <i>raid1</i>, <i>raid1c3</i>, <i>raid1c4</i>, <i>raid10</i>, <i>raid5</i>, <i>raid6</i>, <i>dup</i>, <i>single</i>. The
       mixed data/metadata profiles can be converted in the same way,
       but it’s conversion between mixed and non-mixed is not
       implemented. For the constraints of the profiles please refer to
       <a href="mkfs.btrfs.8.html">mkfs.btrfs(8)</a>, section <i>PROFILES</i>.
</pre> <h2>
ENOSPC </h2>
<pre>
       The way balance operates, it usually needs to temporarily create
       a new block group and move the old data there, before the old
       block group can be removed. For that it needs the work space,
       otherwise it fails for ENOSPC reasons. This is not the same
       ENOSPC as if the free space is exhausted. This refers to the
       space on the level of block groups, which are bigger parts of the
       filesystem that contain many file extents.

       The free work space can be calculated from the output of the
       <b>btrfs filesystem show </b>command:

              Label: 'BTRFS'  uuid: 8a9d72cd-ead3-469d-b371-9c7203276265
                      Total devices 2 FS bytes used 77.03GiB
                      devid    1 size 53.90GiB used 51.90GiB path /dev/sdc2
                      devid    2 size 53.90GiB used 51.90GiB path /dev/sde1

       <i>size</i> - <i>used</i> = <i>free work space 53.90GiB</i> - <i>51.90GiB</i> = <i>2.00GiB</i>

       An example of a filter that does not require workspace is
       <i>usage=0</i>. This will scan through all unused block groups of a
       given type and will reclaim the space. After that it might be
       possible to run other filters.

       <b>CONVERSIONS ON MULTIPLE DEVICES</b>

       Conversion to profiles based on striping (RAID0, RAID5/6) require
       the work space on each device. An interrupted balance may leave
       partially filled block groups that consume the work space.
</pre> <h2>
EXAMPLES </h2>
<pre>
       A more comprehensive example when going from one to multiple
       devices, and back, can be found in section <i>TYPICAL USECASES</i> of
       <a href="btrfs-device.8.html">btrfs-device(8)</a>.

   <b>MAKING BLOCK GROUP LAYOUT MORE COMPACT</b>
       The layout of block groups is not normally visible; most tools
       report only summarized numbers of free or used space, but there
       are still some hints provided.

       Let’s use the following real life example and start with the
       output:

           $ btrfs filesystem df /path
           Data, single: total=75.81GiB, used=64.44GiB
           System, RAID1: total=32.00MiB, used=20.00KiB
           Metadata, RAID1: total=15.87GiB, used=8.84GiB
           GlobalReserve, single: total=512.00MiB, used=0.00B

       Roughly calculating for data, <i>75G - 64G = 11G</i>, the used/total
       ratio is about <i>85%</i>. How can we can interpret that:

       •   chunks are filled by 85% on average, ie. the <i>usage</i> filter
           with anything smaller than 85 will likely not affect anything

       •   in a more realistic scenario, the space is distributed
           unevenly, we can assume there are completely used chunks and
           the remaining are partially filled

       Compacting the layout could be used on both. In the former case
       it would spread data of a given chunk to the others and removing
       it. Here we can estimate that roughly 850 MiB of data have to be
       moved (85% of a 1 GiB chunk).

       In the latter case, targeting the partially used chunks will have
       to move less data and thus will be faster. A typical filter
       command would look like:

           # btrfs balance start -dusage=50 /path
           Done, had to relocate 2 out of 97 chunks

           $ btrfs filesystem df /path
           Data, single: total=74.03GiB, used=64.43GiB
           System, RAID1: total=32.00MiB, used=20.00KiB
           Metadata, RAID1: total=15.87GiB, used=8.84GiB
           GlobalReserve, single: total=512.00MiB, used=0.00B

       As you can see, the <i>total</i> amount of data is decreased by just 1
       GiB, which is an expected result. Let’s see what will happen when
       we increase the estimated usage filter.

           # btrfs balance start -dusage=85 /path
           Done, had to relocate 13 out of 95 chunks

           $ btrfs filesystem df /path
           Data, single: total=68.03GiB, used=64.43GiB
           System, RAID1: total=32.00MiB, used=20.00KiB
           Metadata, RAID1: total=15.87GiB, used=8.85GiB
           GlobalReserve, single: total=512.00MiB, used=0.00B

       Now the used/total ratio is about 94% and we moved about <i>74G -</i>
       <i>68G = 6G</i> of data to the remaining blockgroups, ie. the 6GiB are
       now free of filesystem structures, and can be reused for new data
       or metadata block groups.

       We can do a similar exercise with the metadata block groups, but
       this should not typically be necessary, unless the used/total
       ratio is really off. Here the ratio is roughly 50% but the
       difference as an absolute number is "a few gigabytes", which can
       be considered normal for a workload with snapshots or reflinks
       updated frequently.

           # btrfs balance start -musage=50 /path
           Done, had to relocate 4 out of 89 chunks

           $ btrfs filesystem df /path
           Data, single: total=68.03GiB, used=64.43GiB
           System, RAID1: total=32.00MiB, used=20.00KiB
           Metadata, RAID1: total=14.87GiB, used=8.85GiB
           GlobalReserve, single: total=512.00MiB, used=0.00B

       Just 1 GiB decrease, which possibly means there are block groups
       with good utilization. Making the metadata layout more compact
       would in turn require updating more metadata structures, ie. lots
       of IO. As running out of metadata space is a more severe problem,
       it’s not necessary to keep the utilization ratio too high. For
       the purpose of this example, let’s see the effects of further
       compaction:

           # btrfs balance start -musage=70 /path
           Done, had to relocate 13 out of 88 chunks

           $ btrfs filesystem df .
           Data, single: total=68.03GiB, used=64.43GiB
           System, RAID1: total=32.00MiB, used=20.00KiB
           Metadata, RAID1: total=11.97GiB, used=8.83GiB
           GlobalReserve, single: total=512.00MiB, used=0.00B

   <b>GETTING RID OF COMPLETELY UNUSED BLOCK GROUPS</b>
       Normally the balance operation needs a work space, to temporarily
       move the data before the old block groups gets removed. If
       there’s no work space, it ends with <i>no space left</i>.

       There’s a special case when the block groups are completely
       unused, possibly left after removing lots of files or deleting
       snapshots. Removing empty block groups is automatic since 3.18.
       The same can be achieved manually with a notable exception that
       this operation does not require the work space. Thus it can be
       used to reclaim unused block groups to make it available.

           # btrfs balance start -dusage=0 /path

       This should lead to decrease in the <i>total</i> numbers in the <b>btrfs</b>
       <b>filesystem df </b>output.
</pre> <h2>
EXIT STATUS </h2>
<pre>
       Unless indicated otherwise below, all <b>btrfs balance </b>subcommands
       return a zero exit status if they succeed, and non zero in case
       of failure.

       The <b>pause</b>, <b>cancel</b>, and <b>resume </b>subcommands exit with a status of <b>2</b>
       if they fail because a balance operation was not running.

       The <b>status </b>subcommand exits with a status of <b>0 </b>if a balance
       operation is not running, <b>1 </b>if the command-line usage is
       incorrect or a balance operation is still running, and <b>2 </b>on other
       errors.
</pre> <h2>
AVAILABILITY </h2>
<pre>
       <b>btrfs </b>is part of btrfs-progs. Please refer to the btrfs wiki
       <b>http://btrfs.wiki.kernel.org </b>for further details.
</pre> <h2>
SEE ALSO </h2>
<pre>
       <a href="mkfs.btrfs.8.html">mkfs.btrfs(8)</a>, <a href="btrfs-device.8.html">btrfs-device(8)</a>
</pre> <h2>
COLOPHON </h2>
<pre>
       This page is part of the <i>btrfs-progs</i> (btrfs filesystem tools)
       project.  Information about the project can be found at 
       ⟨<a href="https://btrfs.wiki.kernel.org/index.php/Btrfs_source_repositories">https://btrfs.wiki.kernel.org/index.php/Btrfs_source_repositories</a>⟩.
       If you have a bug report for this manual page, see
       ⟨<a href="https://btrfs.wiki.kernel.org/index.php/Problem_FAQ#How_do_I_report_bugs_and_issues.3F">https://btrfs.wiki.kernel.org/index.php/Problem_FAQ#How_do_I_report_bugs_and_issues.3F</a>⟩.
       This page was obtained from the project's upstream Git repository
       ⟨git://git.kernel.org/pub/scm/linux/kernel/git/kdave/btrfs-progs.git⟩
       on 2024-06-14.  (At that time, the date of the most recent commit
       that was found in the repository was 2024-05-02.)  If you
       discover any rendering problems in this HTML version of the page,
       or you believe there is a better or more up-to-date source for
       the page, or you have corrections or improvements to the
       information in this COLOPHON (which is <i>not</i> part of the original
       manual page), send a mail to man-pages@man7.org

<span class="footline">Btrfs v5.16.1                  02/06/2022               <i>BTRFS-BALANCE</i>(8)</span>
</pre>  <p>Pages that refer to this page: <a href="btrfs.8.html">btrfs(8)</a>, <a href="btrfs-convert.8.html">btrfs-convert(8)</a>, <a href="btrfs-device.8.html">btrfs-device(8)</a>, <a href="btrfstune.8.html">btrfstune(8)</a>, <a href="mkfs.btrfs.8.html">mkfs.btrfs(8)</a> </p> <hr>         <div class="_attribution">
  <p class="_attribution-p">
    ...<br>
    <a href="https://man7.org/linux/man-pages/man8/btrfs-balance.8.html" class="_attribution-link">https://man7.org/linux/man-pages/man8/btrfs-balance.8.html</a>
  </p>
</div>
