<h1>tc-fq_pie(8) — Linux manual page</h1>   <pre>
<span class="headline"><i>FQ-PIE</i>(8)                         Linux                        <i>FQ-PIE</i>(8)</span>
</pre> <h2>
NAME </h2>
<pre>
       FQ-PIE - Flow Queue Proportional Integral controller Enhanced
</pre> <h2>
SYNOPSIS </h2>
<pre>
       <b>tc qdisc ... fq_pie </b>[ <b>limit </b>PACKETS ] [ <b>flows </b>NUMBER ]
                           [ <b>target </b>TIME ] [ <b>tupdate </b>TIME ]
                           [ <b>alpha </b>NUMBER ] [ <b>beta </b>NUMBER ]
                           [ <b>quantum </b>BYTES ] [ <b>memory_limit </b>BYTES ]
                           [ <b>ecn_prob </b>PERENTAGE ] [ [<b>no</b>]<b>ecn </b>]
                           [ [<b>no</b>]<b>bytemode </b>] [ [<b>no_</b>]<b>dq_rate_estimator </b>]
</pre> <h2>
DESCRIPTION </h2>
<pre>
       FQ-PIE (Flow Queuing with Proportional Integral controller
       Enhanced) is a queuing discipline that combines Flow Queuing with
       the PIE AQM scheme. FQ-PIE uses a Jenkins hash function to
       classify incoming packets into different flows and is used to
       provide a fair share of the bandwidth to all the flows using the
       qdisc. Each such flow is managed by the PIE algorithm.
</pre> <h2>
ALGORITHM </h2>
<pre>
       The FQ-PIE algorithm consists of two logical parts: the scheduler
       which selects which queue to dequeue a packet from, and the PIE
       AQM which works on each of the queues. The major work of FQ-PIE
       is mostly in the scheduling part. The interaction between the
       scheduler and the PIE algorithm is straight forward.

       During the enqueue stage, a hashing-based scheme is used, where
       flows are hashed into a number of buckets with each bucket having
       its own queue. The number of buckets is configurable, and
       presently defaults to 1024 in the implementation.  The flow
       hashing is performed on the 5-tuple of source and destination IP
       addresses, port numbers and IP protocol number. Once the packet
       has been successfully classified into a queue, it is handed over
       to the PIE algorithm for enqueuing. It is then added to the tail
       of the selected queue, and the queue's byte count is updated by
       the packet size. If the queue is not currently active (i.e., if
       it is not in either the list of new or the list of old queues) ,
       it is added to the end of the list of new queues, and its number
       of credits is initiated to the configured quantum. Otherwise, the
       queue is left in its current queue list.

       During the dequeue stage, the scheduler first looks at the list
       of new queues; for the queue at the head of that list, if that
       queue has a negative number of credits (i.e., it has already
       dequeued at least a quantum of bytes), it is given an additional
       quantum of credits, the queue is put onto the end of the list of
       old queues, and the routine selects the next queue and starts
       again. Otherwise, that queue is selected for dequeue again. If
       the list of new queues is empty, the scheduler proceeds down the
       list of old queues in the same fashion (checking the credits, and
       either selecting the queue for dequeuing, or adding credits and
       putting the queue back at the end of the list). After having
       selected a queue from which to dequeue a packet, the PIE
       algorithm is invoked on that queue.

       Finally, if the PIE algorithm does not return a packet, then the
       queue must be empty and the scheduler does one of two things:

       If the queue selected for dequeue came from the list of new
       queues, it is moved to the end of the list of old queues. If
       instead it came from the list of old queues, that queue is
       removed from the list, to be added back (as a new queue) the next
       time a packet arrives that hashes to that queue. Then (since no
       packet was available for dequeue), the whole dequeue process is
       restarted from the beginning.

       If, instead, the scheduler did get a packet back from the PIE
       algorithm, it subtracts the size of the packet from the byte
       credits for the selected queue and returns the packet as the
       result of the dequeue operation.
</pre> <h2>
PARAMETERS </h2>
<pre>
   <b>limit</b>
       It is the limit on the queue size in packets. Incoming packets
       are dropped when the limit is reached. The default value is 10240
       packets.

   <b>flows</b>
       It is the number of flows into which the incoming packets are
       classified. Due to the stochastic nature of hashing, multiple
       flows may end up being hashed into the same slot. Newer flows
       have priority over older ones. This parameter can be set only at
       load time since memory has to be allocated for the hash table.
       The default value is 1024.

   <b>target</b>
       It is the queue delay which the PIE algorithm tries to maintain.
       The default target delay is 15ms.

   <b>tupdate</b>
       It is the time interval at which the system drop probability is
       calculated.  The default is 15ms.

   <b>alpha</b>
   <b>beta</b>
       alpha and beta are parameters chosen to control the drop
       probability. These should be in the range between 0 and 32.

   <b>quantum</b>
       quantum signifies the number of bytes that may be dequeued from a
       queue before switching to the next queue in the deficit round
       robin scheme.

   <b>memory_limit</b>
       It is the maximum total memory allowed for packets of all flows.
       The default is 32Mb.

   <b>ecn_prob</b>
       It is the drop probability threshold below which packets will be
       ECN marked instead of getting dropped. The default is 10%.
       Setting this parameter requires <b>ecn </b>to be enabled.

   [<b>no</b>]<b>ecn</b>
       It has the same semantics as <b>pie </b>and can be used to mark packets
       instead of dropping them. If <b>ecn </b>has been enabled, <b>noecn </b>can be
       used to turn it off and vice-a-versa.

   [<b>no</b>]<b>bytemode</b>
       It is used to scale drop probability proportional to packet size
       <b>bytemode </b>to turn on bytemode, <b>nobytemode </b>to turn off bytemode. By
       default, <b>bytemode </b>is turned off.

   [<b>no_</b>]<b>dq_rate_estimator</b>
       <b>dq_rate_estimator </b>can be used to calculate queue delay using
       Little's Law, <b>no_dq_rate_estimator </b>can be used to calculate queue
       delay using timestamp. By default, <b>dq_rate_estimator </b>is turned
       off.
</pre> <h2>
EXAMPLES </h2>
<pre>
       # tc qdisc add dev eth0 root fq_pie
       # tc -s qdisc show dev eth0
       qdisc fq_pie 8001: root refcnt 2 limit 10240p flows 1024 target
       15.0ms tupdate 16.0ms alpha 2 beta 20 quantum 1514b memory_limit
       32Mb ecn_prob 10
        Sent 159173586 bytes 105261 pkt (dropped 24, overlimits 0
       requeues 0)
        backlog 75700b 50p requeues 0
         pkts_in 105311 overlimit 0 overmemory 0 dropped 24 ecn_mark 0
         new_flow_count 7332 new_flows_len 0 old_flows_len 4 memory_used
       108800

       # tc qdisc add dev eth0 root fq_pie dq_rate_estimator
       # tc -s qdisc show dev eth0
       qdisc fq_pie 8001: root refcnt 2 limit 10240p flows 1024 target
       15.0ms tupdate 16.0ms alpha 2 beta 20 quantum 1514b memory_limit
       32Mb ecn_prob 10 dq_rate_estimator
        Sent 8263620 bytes 5550 pkt (dropped 4, overlimits 0 requeues 0)
        backlog 805448b 532p requeues 0
         pkts_in 6082 overlimit 0 overmemory 0 dropped 4 ecn_mark 0
         new_flow_count 94 new_flows_len 0 old_flows_len 8 memory_used
       1157632
</pre> <h2>
SEE ALSO </h2>
<pre>
       <a href="tc.8.html">tc(8)</a>, <a href="tc-pie.8.html">tc-pie(8)</a>, <a href="tc-fq_codel.8.html">tc-fq_codel(8)</a>
</pre> <h2>
SOURCES </h2>
<pre>
       RFC 8033: <a href="https://tools.ietf.org/html/rfc8033">https://tools.ietf.org/html/rfc8033</a>
</pre> <h2>
AUTHORS </h2>
<pre>
       FQ-PIE was implemented by Mohit P. Tahiliani. Please report
       corrections to the Linux Networking mailing list
       &lt;netdev@vger.kernel.org&gt;.
</pre> <h2>
COLOPHON </h2>
<pre>
       This page is part of the <i>iproute2</i> (utilities for controlling
       TCP/IP networking and traffic) project.  Information about the
       project can be found at 
       ⟨<a href="http://www.linuxfoundation.org/collaborate/workgroups/networking/iproute2">http://www.linuxfoundation.org/collaborate/workgroups/networking/iproute2</a>⟩.
       If you have a bug report for this manual page, send it to
       netdev@vger.kernel.org, shemminger@osdl.org.  This page was
       obtained from the project's upstream Git repository
       ⟨<a href="https://git.kernel.org/pub/scm/network/iproute2/iproute2.git">https://git.kernel.org/pub/scm/network/iproute2/iproute2.git</a>⟩ on
       2024-06-14.  (At that time, the date of the most recent commit
       that was found in the repository was 2024-06-11.)  If you
       discover any rendering problems in this HTML version of the page,
       or you believe there is a better or more up-to-date source for
       the page, or you have corrections or improvements to the
       information in this COLOPHON (which is <i>not</i> part of the original
       manual page), send a mail to man-pages@man7.org

<span class="footline">iproute2                     23 January 2020                   <i>FQ-PIE</i>(8)</span>
</pre>  <p>Pages that refer to this page: <a href="tc.8.html">tc(8)</a> </p> <hr>         <div class="_attribution">
  <p class="_attribution-p">
    ...<br>
    <a href="https://man7.org/linux/man-pages/man8/FQ-PIE.8.html" class="_attribution-link">https://man7.org/linux/man-pages/man8/FQ-PIE.8.html</a>
  </p>
</div>
