<h1>valgrind(1) — Linux manual page</h1>   <pre>
<span class="headline"><i>VALGRIND</i>(1)                     valgrind                     <i>VALGRIND</i>(1)</span>
</pre> <h2>
NAME </h2>
<pre>
       valgrind - a suite of tools for debugging and profiling programs
</pre> <h2>
SYNOPSIS </h2>
<pre>

       <b>valgrind </b>[<i>valgrind-options</i>] [<i>your-program</i>] [<i>your-program-options</i>]
</pre> <h2>
DESCRIPTION </h2>
<pre>
       <b>Valgrind </b>is a flexible program for debugging and profiling Linux
       executables. It consists of a core, which provides a synthetic
       CPU in software, and a series of debugging and profiling tools.
       The architecture is modular, so that new tools can be created
       easily and without disturbing the existing structure.

       Some of the options described below work with all Valgrind tools,
       and some only work with a few or one. The section MEMCHECK
       OPTIONS and those below it describe tool-specific options.

       This manual page covers only basic usage and options. For more
       comprehensive information, please see the HTML documentation on
       your system: $INSTALL/share/doc/valgrind/html/index.html, or
       online: <a href="http://www.valgrind.org/docs/manual/index.html">http://www.valgrind.org/docs/manual/index.html</a>.
</pre> <h2>
TOOL SELECTION OPTIONS </h2>
<pre>
       The single most important option.

       <b>--tool=&lt;toolname&gt; [default: memcheck]</b>
           Run the Valgrind tool called <i>toolname</i>, e.g. memcheck,
           cachegrind, callgrind, helgrind, drd, massif, dhat, lackey,
           none, exp-bbv, etc.
</pre> <h2>
BASIC OPTIONS </h2>
<pre>
       These options work with all tools.

       <b>-h --help</b>
           Show help for all options, both for the core and for the
           selected tool. If the option is repeated it is equivalent to
           giving <b>--help-debug</b>.

       <b>--help-debug</b>
           Same as <b>--help</b>, but also lists debugging options which
           usually are only of use to Valgrind's developers.

       <b>--version</b>
           Show the version number of the Valgrind core. Tools can have
           their own version numbers. There is a scheme in place to
           ensure that tools only execute when the core version is one
           they are known to work with. This was done to minimise the
           chances of strange problems arising from tool-vs-core version
           incompatibilities.

       <b>-q</b>, <b>--quiet</b>
           Run silently, and only print error messages. Useful if you
           are running regression tests or have some other automated
           test machinery.

       <b>-v</b>, <b>--verbose</b>
           Be more verbose. Gives extra information on various aspects
           of your program, such as: the shared objects loaded, the
           suppressions used, the progress of the instrumentation and
           execution engines, and warnings about unusual behaviour.
           Repeating the option increases the verbosity level.

       <b>--trace-children=&lt;yes|no&gt; [default: no]</b>
           When enabled, Valgrind will trace into sub-processes
           initiated via the <i>exec</i> system call. This is necessary for
           multi-process programs.

           Note that Valgrind does trace into the child of a <i>fork</i> (it
           would be difficult not to, since <i>fork</i> makes an identical copy
           of a process), so this option is arguably badly named.
           However, most children of <i>fork</i> calls immediately call <i>exec</i>
           anyway.

       <b>--trace-children-skip=patt1,patt2,...</b>
           This option only has an effect when <b>--trace-children=yes </b>is
           specified. It allows for some children to be skipped. The
           option takes a comma separated list of patterns for the names
           of child executables that Valgrind should not trace into.
           Patterns may include the metacharacters ?  and *, which have
           the usual meaning.

           This can be useful for pruning uninteresting branches from a
           tree of processes being run on Valgrind. But you should be
           careful when using it. When Valgrind skips tracing into an
           executable, it doesn't just skip tracing that executable, it
           also skips tracing any of that executable's child processes.
           In other words, the flag doesn't merely cause tracing to stop
           at the specified executables -- it skips tracing of entire
           process subtrees rooted at any of the specified executables.

       <b>--trace-children-skip-by-arg=patt1,patt2,...</b>
           This is the same as <b>--trace-children-skip</b>, with one
           difference: the decision as to whether to trace into a child
           process is made by examining the arguments to the child
           process, rather than the name of its executable.

       <b>--child-silent-after-fork=&lt;yes|no&gt; [default: no]</b>
           When enabled, Valgrind will not show any debugging or logging
           output for the child process resulting from a <i>fork</i> call. This
           can make the output less confusing (although more misleading)
           when dealing with processes that create children. It is
           particularly useful in conjunction with <i>--trace-children=</i>.
           Use of this option is also strongly recommended if you are
           requesting XML output (<i>--xml=yes</i>), since otherwise the XML
           from child and parent may become mixed up, which usually
           makes it useless.

       <b>--vgdb=&lt;no|yes|full&gt; [default: yes]</b>
           Valgrind will provide "gdbserver" functionality when
           <b>--vgdb=yes </b>or <b>--vgdb=full </b>is specified. This allows an
           external GNU GDB debugger to control and debug your program
           when it runs on Valgrind.  <b>--vgdb=full </b>incurs significant
           performance overheads, but provides more precise breakpoints
           and watchpoints. See Debugging your program using Valgrind's
           gdbserver and GDB for a detailed description.

           If the embedded gdbserver is enabled but no gdb is currently
           being used, the vgdb command line utility can send "monitor
           commands" to Valgrind from a shell. The Valgrind core
           provides a set of Valgrind monitor commands. A tool can
           optionally provide tool specific monitor commands, which are
           documented in the tool specific chapter.

       <b>--vgdb-error=&lt;number&gt; [default: 999999999]</b>
           Use this option when the Valgrind gdbserver is enabled with
           <b>--vgdb=yes </b>or <b>--vgdb=full</b>. Tools that report errors will wait
           for "number" errors to be reported before freezing the
           program and waiting for you to connect with GDB. It follows
           that a value of zero will cause the gdbserver to be started
           before your program is executed. This is typically used to
           insert GDB breakpoints before execution, and also works with
           tools that do not report errors, such as Massif.

       <b>--vgdb-stop-at=&lt;set&gt; [default: none]</b>
           Use this option when the Valgrind gdbserver is enabled with
           <b>--vgdb=yes </b>or <b>--vgdb=full</b>. The Valgrind gdbserver will be
           invoked for each error after <b>--vgdb-error </b>have been reported.
           You can additionally ask the Valgrind gdbserver to be invoked
           for other events, specified in one of the following ways:

           •   a comma separated list of one or more of <b>startup exit</b>
               <b>abexit valgrindabexit</b>.

               The values <b>startup exit valgrindabexit </b>respectively
               indicate to invoke gdbserver before your program is
               executed, after the last instruction of your program, on
               Valgrind abnormal exit (e.g. internal error, out of
               memory, ...).

               The option <b>abexit </b>is similar to <b>exit </b>but tells to invoke
               gdbserver only when your application exits abnormally
               (i.e. with an exit code different of 0).

               Note: <b>startup </b>and <b>--vgdb-error=0 </b>will both cause Valgrind
               gdbserver to be invoked before your program is executed.
               The <b>--vgdb-error=0 </b>will in addition cause your program to
               stop on all subsequent errors.

           •   <b>all </b>to specify the complete set. It is equivalent to
               <b>--vgdb-stop-at=startup,exit,abexit,valgrindabexit</b>.

           •   <b>none </b>for the empty set.

       <b>--track-fds=&lt;yes|no|all&gt; [default: no]</b>
           When enabled, Valgrind will print out a list of open file
           descriptors on exit or on request, via the gdbserver monitor
           command <i>v.info open_fds</i>. Along with each file descriptor is
           printed a stack backtrace of where the file was opened and
           any details relating to the file descriptor such as the file
           name or socket details. Use <b>all </b>to include reporting on
           stdin, stdout and stderr.

       <b>--time-stamp=&lt;yes|no&gt; [default: no]</b>
           When enabled, each message is preceded with an indication of
           the elapsed wallclock time since startup, expressed as days,
           hours, minutes, seconds and milliseconds.

       <b>--log-fd=&lt;number&gt; [default: 2, stderr]</b>
           Specifies that Valgrind should send all of its messages to
           the specified file descriptor. The default, 2, is the
           standard error channel (stderr). Note that this may interfere
           with the client's own use of stderr, as Valgrind's output
           will be interleaved with any output that the client sends to
           stderr.

       <b>--log-file=&lt;filename&gt;</b>
           Specifies that Valgrind should send all of its messages to
           the specified file. If the file name is empty, it causes an
           abort. There are three special format specifiers that can be
           used in the file name.

           <b>%p </b>is replaced with the current process ID. This is very
           useful for program that invoke multiple processes. WARNING:
           If you use <b>--trace-children=yes </b>and your program invokes
           multiple processes OR your program forks without calling exec
           afterwards, and you don't use this specifier (or the <b>%q</b>
           specifier below), the Valgrind output from all those
           processes will go into one file, possibly jumbled up, and
           possibly incomplete. Note: If the program forks and calls
           exec afterwards, Valgrind output of the child from the period
           between fork and exec will be lost. Fortunately this gap is
           really tiny for most programs; and modern programs use
           posix_spawn anyway.

           <b>%n </b>is replaced with a file sequence number unique for this
           process. This is useful for processes that produces several
           files from the same filename template.

           <b>%q{FOO} </b>is replaced with the contents of the environment
           variable <i>FOO</i>. If the <b>{FOO} </b>part is malformed, it causes an
           abort. This specifier is rarely needed, but very useful in
           certain circumstances (eg. when running MPI programs). The
           idea is that you specify a variable which will be set
           differently for each process in the job, for example
           BPROC_RANK or whatever is applicable in your MPI setup. If
           the named environment variable is not set, it causes an
           abort. Note that in some shells, the <b>{ </b>and <b>} </b>characters may
           need to be escaped with a backslash.

           <b>%% </b>is replaced with <b>%</b>.

           If an <b>% </b>is followed by any other character, it causes an
           abort.

           If the file name specifies a relative file name, it is put in
           the program's initial working directory: this is the current
           directory when the program started its execution after the
           fork or after the exec. If it specifies an absolute file name
           (ie. starts with '/') then it is put there.

       <b>--log-socket=&lt;ip-address:port-number&gt;</b>
           Specifies that Valgrind should send all of its messages to
           the specified port at the specified IP address. The port may
           be omitted, in which case port 1500 is used. If a connection
           cannot be made to the specified socket, Valgrind falls back
           to writing output to the standard error (stderr). This option
           is intended to be used in conjunction with the
           valgrind-listener program. For further details, see the
           commentary in the manual.

       <b>--enable-debuginfod=&lt;no|yes&gt; [default: yes]</b>
           When enabled Valgrind will attempt to download missing
           debuginfo from debuginfod servers if space-separated server
           URLs are present in the $DEBUGINFOD_URLS environment
           variable. This option is supported on Linux only.
</pre> <h2>
ERROR-RELATED OPTIONS </h2>
<pre>
       These options are used by all tools that can report errors, e.g.
       Memcheck, but not Cachegrind.

       <b>--xml=&lt;yes|no&gt; [default: no]</b>
           When enabled, the important parts of the output (e.g. tool
           error messages) will be in XML format rather than plain text.
           Furthermore, the XML output will be sent to a different
           output channel than the plain text output. Therefore, you
           also must use one of <b>--xml-fd</b>, <b>--xml-file </b>or <b>--xml-socket </b>to
           specify where the XML is to be sent.

           Less important messages will still be printed in plain text,
           but because the XML output and plain text output are sent to
           different output channels (the destination of the plain text
           output is still controlled by <b>--log-fd</b>, <b>--log-file </b>and
           <b>--log-socket</b>) this should not cause problems.

           This option is aimed at making life easier for tools that
           consume Valgrind's output as input, such as GUI front ends.
           Currently this option works with Memcheck, Helgrind and DRD.
           The output format is specified in the file
           docs/internals/xml-output-protocol4.txt in the source tree
           for Valgrind 3.5.0 or later.

           The recommended options for a GUI to pass, when requesting
           XML output, are: <b>--xml=yes </b>to enable XML output, <b>--xml-file</b>
           to send the XML output to a (presumably GUI-selected) file,
           <b>--log-file </b>to send the plain text output to a second
           GUI-selected file, <b>--child-silent-after-fork=yes</b>, and <b>-q </b>to
           restrict the plain text output to critical error messages
           created by Valgrind itself. For example, failure to read a
           specified suppressions file counts as a critical error
           message. In this way, for a successful run the text output
           file will be empty. But if it isn't empty, then it will
           contain important information which the GUI user should be
           made aware of.

       <b>--xml-fd=&lt;number&gt; [default: -1, disabled]</b>
           Specifies that Valgrind should send its XML output to the
           specified file descriptor. It must be used in conjunction
           with <b>--xml=yes</b>.

       <b>--xml-file=&lt;filename&gt;</b>
           Specifies that Valgrind should send its XML output to the
           specified file. It must be used in conjunction with
           <b>--xml=yes</b>. Any <b>%p </b>or <b>%q </b>sequences appearing in the filename
           are expanded in exactly the same way as they are for
           <b>--log-file</b>. See the description of --log-file for details.

       <b>--xml-socket=&lt;ip-address:port-number&gt;</b>
           Specifies that Valgrind should send its XML output the
           specified port at the specified IP address. It must be used
           in conjunction with <b>--xml=yes</b>. The form of the argument is
           the same as that used by <b>--log-socket</b>. See the description of
           <b>--log-socket </b>for further details.

       <b>--xml-user-comment=&lt;string&gt;</b>
           Embeds an extra user comment string at the start of the XML
           output. Only works when <b>--xml=yes </b>is specified; ignored
           otherwise.

       <b>--demangle=&lt;yes|no&gt; [default: yes]</b>
           Enable/disable automatic demangling (decoding) of C++ names.
           Enabled by default. When enabled, Valgrind will attempt to
           translate encoded C++ names back to something approaching the
           original. The demangler handles symbols mangled by g++
           versions 2.X, 3.X and 4.X.

           An important fact about demangling is that function names
           mentioned in suppressions files should be in their mangled
           form. Valgrind does not demangle function names when
           searching for applicable suppressions, because to do
           otherwise would make suppression file contents dependent on
           the state of Valgrind's demangling machinery, and also slow
           down suppression matching.

       <b>--num-callers=&lt;number&gt; [default: 12]</b>
           Specifies the maximum number of entries shown in stack traces
           that identify program locations. Note that errors are
           commoned up using only the top four function locations (the
           place in the current function, and that of its three
           immediate callers). So this doesn't affect the total number
           of errors reported.

           The maximum value for this is 500. Note that higher settings
           will make Valgrind run a bit more slowly and take a bit more
           memory, but can be useful when working with programs with
           deeply-nested call chains.

       <b>--unw-stack-scan-thresh=&lt;number&gt; [default: 0] </b>,
       <b>--unw-stack-scan-frames=&lt;number&gt; [default: 5]</b>
           Stack-scanning support is available only on ARM targets.

           These flags enable and control stack unwinding by stack
           scanning. When the normal stack unwinding mechanisms -- usage
           of Dwarf CFI records, and frame-pointer following -- fail,
           stack scanning may be able to recover a stack trace.

           Note that stack scanning is an imprecise, heuristic mechanism
           that may give very misleading results, or none at all. It
           should be used only in emergencies, when normal unwinding
           fails, and it is important to nevertheless have stack traces.

           Stack scanning is a simple technique: the unwinder reads
           words from the stack, and tries to guess which of them might
           be return addresses, by checking to see if they point just
           after ARM or Thumb call instructions. If so, the word is
           added to the backtrace.

           The main danger occurs when a function call returns, leaving
           its return address exposed, and a new function is called, but
           the new function does not overwrite the old address. The
           result of this is that the backtrace may contain entries for
           functions which have already returned, and so be very
           confusing.

           A second limitation of this implementation is that it will
           scan only the page (4KB, normally) containing the starting
           stack pointer. If the stack frames are large, this may result
           in only a few (or not even any) being present in the trace.
           Also, if you are unlucky and have an initial stack pointer
           near the end of its containing page, the scan may miss all
           interesting frames.

           By default stack scanning is disabled. The normal use case is
           to ask for it when a stack trace would otherwise be very
           short. So, to enable it, use --unw-stack-scan-thresh=number.
           This requests Valgrind to try using stack scanning to
           "extend" stack traces which contain fewer than number frames.

           If stack scanning does take place, it will only generate at
           most the number of frames specified by
           --unw-stack-scan-frames. Typically, stack scanning generates
           so many garbage entries that this value is set to a low value
           (5) by default. In no case will a stack trace larger than the
           value specified by --num-callers be created.

       <b>--error-limit=&lt;yes|no&gt; [default: yes]</b>
           When enabled, Valgrind stops reporting errors after
           10,000,000 in total, or 1,000 different ones, have been seen.
           This is to stop the error tracking machinery from becoming a
           huge performance overhead in programs with many errors.

       <b>--error-exitcode=&lt;number&gt; [default: 0]</b>
           Specifies an alternative exit code to return if Valgrind
           reported any errors in the run. When set to the default value
           (zero), the return value from Valgrind will always be the
           return value of the process being simulated. When set to a
           nonzero value, that value is returned instead, if Valgrind
           detects any errors. This is useful for using Valgrind as part
           of an automated test suite, since it makes it easy to detect
           test cases for which Valgrind has reported errors, just by
           inspecting return codes. When set to a nonzero value and
           Valgrind detects no error, the return value of Valgrind will
           be the return value of the program being simulated.

       <b>--exit-on-first-error=&lt;yes|no&gt; [default: no]</b>
           If this option is enabled, Valgrind exits on the first error.
           A nonzero exit value must be defined using --error-exitcode
           option. Useful if you are running regression tests or have
           some other automated test machinery.

       <b>--error-markers=&lt;begin&gt;,&lt;end&gt; [default: none]</b>
           When errors are output as plain text (i.e. XML not used),
           <b>--error-markers </b>instructs to output a line containing the
           <b>begin </b>(<b>end</b>) string before (after) each error.

           Such marker lines facilitate searching for errors and/or
           extracting errors in an output file that contain valgrind
           errors mixed with the program output.

           Note that empty markers are accepted. So, only using a begin
           (or an end) marker is possible.

       <b>--show-error-list=no|yes|all [default: no]</b>
           If this option is yes, for tools that report errors, valgrind
           will show the list of detected errors and the list of used
           suppressions at exit. The value all indicates to also show
           the list of suppressed errors.

           Note that at verbosity 2 and above, valgrind automatically
           shows the list of detected errors and the list of used
           suppressions at exit, unless <b>--show-error-list=no </b>is
           selected.

       <b>-s</b>
           Specifying <b>-s </b>is equivalent to <b>--show-error-list=yes</b>.

       <b>--sigill-diagnostics=&lt;yes|no&gt; [default: yes]</b>
           Enable/disable printing of illegal instruction diagnostics.
           Enabled by default, but defaults to disabled when <b>--quiet </b>is
           given. The default can always be explicitly overridden by
           giving this option.

           When enabled, a warning message will be printed, along with
           some diagnostics, whenever an instruction is encountered that
           Valgrind cannot decode or translate, before the program is
           given a SIGILL signal. Often an illegal instruction indicates
           a bug in the program or missing support for the particular
           instruction in Valgrind. But some programs do deliberately
           try to execute an instruction that might be missing and trap
           the SIGILL signal to detect processor features. Using this
           flag makes it possible to avoid the diagnostic output that
           you would otherwise get in such cases.

       <b>--keep-debuginfo=&lt;yes|no&gt; [default: no]</b>
           When enabled, keep ("archive") symbols and all other
           debuginfo for unloaded code. This allows saved stack traces
           to include file/line info for code that has been dlclose'd
           (or similar). Be careful with this, since it can lead to
           unbounded memory use for programs which repeatedly load and
           unload shared objects.

           Some tools and some functionalities have only limited support
           for archived debug info. Memcheck fully supports it.
           Generally, tools that report errors can use archived debug
           info to show the error stack traces. The known limitations
           are: Helgrind's past access stack trace of a race condition
           is does not use archived debug info. Massif (and more
           generally the xtree Massif output format) does not make use
           of archived debug info. Only Memcheck has been (somewhat)
           tested with <b>--keep-debuginfo=yes</b>, so other tools may have
           unknown limitations.

       <b>--show-below-main=&lt;yes|no&gt; [default: no]</b>
           By default, stack traces for errors do not show any functions
           that appear beneath <b>main </b>because most of the time it's
           uninteresting C library stuff and/or gobbledygook.
           Alternatively, if <b>main </b>is not present in the stack trace,
           stack traces will not show any functions below <b>main</b>-like
           functions such as glibc's <b>__libc_start_main</b>. Furthermore, if
           <b>main</b>-like functions are present in the trace, they are
           normalised as <b>(below main)</b>, in order to make the output more
           deterministic.

           If this option is enabled, all stack trace entries will be
           shown and <b>main</b>-like functions will not be normalised.

       <b>--fullpath-after=&lt;string&gt; [default: don't show source paths]</b>
           By default Valgrind only shows the filenames in stack traces,
           but not full paths to source files. When using Valgrind in
           large projects where the sources reside in multiple different
           directories, this can be inconvenient.  <b>--fullpath-after</b>
           provides a flexible solution to this problem. When this
           option is present, the path to each source file is shown,
           with the following all-important caveat: if <b>string </b>is found
           in the path, then the path up to and including <b>string </b>is
           omitted, else the path is shown unmodified. Note that <b>string</b>
           is not required to be a prefix of the path.

           For example, consider a file named
           /home/janedoe/blah/src/foo/bar/xyzzy.c. Specifying
           <b>--fullpath-after=/home/janedoe/blah/src/ </b>will cause Valgrind
           to show the name as foo/bar/xyzzy.c.

           Because the string is not required to be a prefix,
           <b>--fullpath-after=src/ </b>will produce the same output. This is
           useful when the path contains arbitrary machine-generated
           characters. For example, the path
           /my/build/dir/C32A1B47/blah/src/foo/xyzzy can be pruned to
           foo/xyzzy using <b>--fullpath-after=/blah/src/</b>.

           If you simply want to see the full path, just specify an
           empty string: <b>--fullpath-after=</b>. This isn't a special case,
           merely a logical consequence of the above rules.

           Finally, you can use <b>--fullpath-after </b>multiple times. Any
           appearance of it causes Valgrind to switch to producing full
           paths and applying the above filtering rule. Each produced
           path is compared against all the <b>--fullpath-after</b>-specified
           strings, in the order specified. The first string to match
           causes the path to be truncated as described above. If none
           match, the full path is shown. This facilitates chopping off
           prefixes when the sources are drawn from a number of
           unrelated directories.

       <b>--extra-debuginfo-path=&lt;path&gt; [default: undefined and unused]</b>
           By default Valgrind searches in several well-known paths for
           debug objects, such as /usr/lib/debug/.

           However, there may be scenarios where you may wish to put
           debug objects at an arbitrary location, such as external
           storage when running Valgrind on a mobile device with limited
           local storage. Another example might be a situation where you
           do not have permission to install debug object packages on
           the system where you are running Valgrind.

           In these scenarios, you may provide an absolute path as an
           extra, final place for Valgrind to search for debug objects
           by specifying <b>--extra-debuginfo-path=/path/to/debug/objects</b>.
           The given path will be prepended to the absolute path name of
           the searched-for object. For example, if Valgrind is looking
           for the debuginfo for /w/x/y/zz.so and
           <b>--extra-debuginfo-path=/a/b/c </b>is specified, it will look for
           a debug object at /a/b/c/w/x/y/zz.so.

           This flag should only be specified once. If it is specified
           multiple times, only the last instance is honoured.

       <b>--debuginfo-server=ipaddr:port [default: undefined and unused]</b>
           This is a new, experimental, feature introduced in version
           3.9.0.

           In some scenarios it may be convenient to read debuginfo from
           objects stored on a different machine. With this flag,
           Valgrind will query a debuginfo server running on ipaddr and
           listening on port port, if it cannot find the debuginfo
           object in the local filesystem.

           The debuginfo server must accept TCP connections on port
           port. The debuginfo server is contained in the source file
           auxprogs/valgrind-di-server.c. It will only serve from the
           directory it is started in.  port defaults to 1500 in both
           client and server if not specified.

           If Valgrind looks for the debuginfo for /w/x/y/zz.so by using
           the debuginfo server, it will strip the pathname components
           and merely request zz.so on the server. That in turn will
           look only in its current working directory for a matching
           debuginfo object.

           The debuginfo data is transmitted in small fragments (8 KB)
           as requested by Valgrind. Each block is compressed using LZO
           to reduce transmission time. The implementation has been
           tuned for best performance over a single-stage 802.11g (WiFi)
           network link.

           Note that checks for matching primary vs debug objects, using
           GNU debuglink CRC scheme, are performed even when using the
           debuginfo server. To disable such checking, you need to also
           specify --allow-mismatched-debuginfo=yes.

           By default the Valgrind build system will build
           valgrind-di-server for the target platform, which is almost
           certainly not what you want. So far we have been unable to
           find out how to get automake/autoconf to build it for the
           build platform. If you want to use it, you will have to
           recompile it by hand using the command shown at the top of
           auxprogs/valgrind-di-server.c.

           Valgrind can also download debuginfo via debuginfod. See the
           DEBUGINFOD section for more information.

       <b>--allow-mismatched-debuginfo=no|yes [no]</b>
           When reading debuginfo from separate debuginfo objects,
           Valgrind will by default check that the main and debuginfo
           objects match, using the GNU debuglink mechanism. This
           guarantees that it does not read debuginfo from out of date
           debuginfo objects, and also ensures that Valgrind can't crash
           as a result of mismatches.

           This check can be overridden using
           --allow-mismatched-debuginfo=yes. This may be useful when the
           debuginfo and main objects have not been split in the proper
           way. Be careful when using this, though: it disables all
           consistency checking, and Valgrind has been observed to crash
           when the main and debuginfo objects don't match.

       <b>--suppressions=&lt;filename&gt; [default:</b>
       <b>$PREFIX/lib/valgrind/default.supp]</b>
           Specifies an extra file from which to read descriptions of
           errors to suppress. You may use up to 100 extra suppression
           files.

       <b>--gen-suppressions=&lt;yes|no|all&gt; [default: no]</b>
           When set to <i>yes</i>, Valgrind will pause after every error shown
           and print the line:

                   ---- Print suppression ? --- [Return/N/n/Y/y/C/c] ----

           Pressing <i>Ret</i>, or <i>N Ret</i> or <i>n Ret</i>, causes Valgrind continue
           execution without printing a suppression for this error.

           Pressing <i>Y Ret</i> or <i>y Ret</i> causes Valgrind to write a
           suppression for this error. You can then cut and paste it
           into a suppression file if you don't want to hear about the
           error in the future.

           When set to <i>all</i>, Valgrind will print a suppression for every
           reported error, without querying the user.

           This option is particularly useful with C++ programs, as it
           prints out the suppressions with mangled names, as required.

           Note that the suppressions printed are as specific as
           possible. You may want to common up similar ones, by adding
           wildcards to function names, and by using frame-level
           wildcards. The wildcarding facilities are powerful yet
           flexible, and with a bit of careful editing, you may be able
           to suppress a whole family of related errors with only a few
           suppressions.

           Sometimes two different errors are suppressed by the same
           suppression, in which case Valgrind will output the
           suppression more than once, but you only need to have one
           copy in your suppression file (but having more than one won't
           cause problems). Also, the suppression name is given as
           &lt;insert a suppression name here&gt;; the name doesn't really
           matter, it's only used with the <b>-v </b>option which prints out
           all used suppression records.

       <b>--input-fd=&lt;number&gt; [default: 0, stdin]</b>
           When using <b>--gen-suppressions=yes</b>, Valgrind will stop so as
           to read keyboard input from you when each error occurs. By
           default it reads from the standard input (stdin), which is
           problematic for programs which close stdin. This option
           allows you to specify an alternative file descriptor from
           which to read input.

       <b>--dsymutil=no|yes [yes]</b>
           This option is only relevant when running Valgrind on macOS.

           macOS uses a deferred debug information (debuginfo) linking
           scheme. When object files containing debuginfo are linked
           into a .dylib or an executable, the debuginfo is not copied
           into the final file. Instead, the debuginfo must be linked
           manually by running dsymutil, a system-provided utility, on
           the executable or .dylib. The resulting combined debuginfo is
           placed in a directory alongside the executable or .dylib, but
           with the extension .dSYM.

           With <b>--dsymutil=no</b>, Valgrind will detect cases where the
           .dSYM directory is either missing, or is present but does not
           appear to match the associated executable or .dylib, most
           likely because it is out of date. In these cases, Valgrind
           will print a warning message but take no further action.

           With <b>--dsymutil=yes</b>, Valgrind will, in such cases,
           automatically run dsymutil as necessary to bring the
           debuginfo up to date. For all practical purposes, if you
           always use <b>--dsymutil=yes</b>, then there is never any need to
           run dsymutil manually or as part of your applications's build
           system, since Valgrind will run it as necessary.

           Valgrind will not attempt to run dsymutil on any executable
           or library in /usr/, /bin/, /sbin/, /opt/, /sw/, /System/,
           /Library/ or /Applications/ since dsymutil will always fail
           in such situations. It fails both because the debuginfo for
           such pre-installed system components is not available
           anywhere, and also because it would require write privileges
           in those directories.

           Be careful when using <b>--dsymutil=yes</b>, since it will cause
           pre-existing .dSYM directories to be silently deleted and
           re-created. Also note that dsymutil is quite slow, sometimes
           excessively so.

       <b>--max-stackframe=&lt;number&gt; [default: 2000000]</b>
           The maximum size of a stack frame. If the stack pointer moves
           by more than this amount then Valgrind will assume that the
           program is switching to a different stack.

           You may need to use this option if your program has large
           stack-allocated arrays. Valgrind keeps track of your
           program's stack pointer. If it changes by more than the
           threshold amount, Valgrind assumes your program is switching
           to a different stack, and Memcheck behaves differently than
           it would for a stack pointer change smaller than the
           threshold. Usually this heuristic works well. However, if
           your program allocates large structures on the stack, this
           heuristic will be fooled, and Memcheck will subsequently
           report large numbers of invalid stack accesses. This option
           allows you to change the threshold to a different value.

           You should only consider use of this option if Valgrind's
           debug output directs you to do so. In that case it will tell
           you the new threshold you should specify.

           In general, allocating large structures on the stack is a bad
           idea, because you can easily run out of stack space,
           especially on systems with limited memory or which expect to
           support large numbers of threads each with a small stack, and
           also because the error checking performed by Memcheck is more
           effective for heap-allocated data than for stack-allocated
           data. If you have to use this option, you may wish to
           consider rewriting your code to allocate on the heap rather
           than on the stack.

       <b>--main-stacksize=&lt;number&gt; [default: use current 'ulimit' value]</b>
           Specifies the size of the main thread's stack.

           To simplify its memory management, Valgrind reserves all
           required space for the main thread's stack at startup. That
           means it needs to know the required stack size at startup.

           By default, Valgrind uses the current "ulimit" value for the
           stack size, or 16 MB, whichever is lower. In many cases this
           gives a stack size in the range 8 to 16 MB, which almost
           never overflows for most applications.

           If you need a larger total stack size, use <b>--main-stacksize</b>
           to specify it. Only set it as high as you need, since
           reserving far more space than you need (that is, hundreds of
           megabytes more than you need) constrains Valgrind's memory
           allocators and may reduce the total amount of memory that
           Valgrind can use. This is only really of significance on
           32-bit machines.

           On Linux, you may request a stack of size up to 2GB. Valgrind
           will stop with a diagnostic message if the stack cannot be
           allocated.

           <b>--main-stacksize </b>only affects the stack size for the
           program's initial thread. It has no bearing on the size of
           thread stacks, as Valgrind does not allocate those.

           You may need to use both <b>--main-stacksize </b>and
           <b>--max-stackframe </b>together. It is important to understand that
           <b>--main-stacksize </b>sets the maximum total stack size, whilst
           <b>--max-stackframe </b>specifies the largest size of any one stack
           frame. You will have to work out the <b>--main-stacksize </b>value
           for yourself (usually, if your applications segfaults). But
           Valgrind will tell you the needed <b>--max-stackframe </b>size, if
           necessary.

           As discussed further in the description of <b>--max-stackframe</b>,
           a requirement for a large stack is a sign of potential
           portability problems. You are best advised to place all large
           data in heap-allocated memory.

       <b>--max-threads=&lt;number&gt; [default: 500]</b>
           By default, Valgrind can handle to up to 500 threads.
           Occasionally, that number is too small. Use this option to
           provide a different limit. E.g.  --max-threads=3000.

       <b>--realloc-zero-bytes-frees=yes|no [default: yes for glibc no</b>
       <b>otherwise]</b>
           The behaviour of realloc() is implementation defined (in C17,
           in C23 it is likely to become undefined). Valgrind tries to
           work in the same way as the underlying system and C runtime
           library that it was configured and built on. However, if you
           use a different C runtime library then this default may be
           wrong. If the value is <b>yes </b>then <i>realloc</i> will deallocate the
           memory and return NULL. If the value is <b>no </b>then <i>realloc</i> will
           not deallocate the memory and the size will be handled as
           though it were one byte.

           As an example, if you use Valgrind installed via a package on
           a Linux distro using GNU libc but link your test executable
           with musl libc or the JEMalloc library then consider using
           --realloc-zero-bytes-frees=no.

           Address Sanitizer has a similar and even wordier option
           allocator_frees_and_returns_null_on_realloc_zero.
</pre> <h2>
MALLOC()-RELATED OPTIONS </h2>
<pre>
       For tools that use their own version of malloc (e.g. Memcheck,
       Massif, Helgrind, DRD), the following options apply.

       <b>--alignment=&lt;number&gt; [default: 8 or 16, depending on the</b>
       <b>platform]</b>
           By default Valgrind's <b>malloc</b>, <b>realloc</b>, etc, return a block
           whose starting address is 8-byte aligned or 16-byte aligned
           (the value depends on the platform and matches the platform
           default). This option allows you to specify a different
           alignment. The supplied value must be greater than or equal
           to the default, less than or equal to 4096, and must be a
           power of two.

       <b>--redzone-size=&lt;number&gt; [default: depends on the tool]</b>
           Valgrind's <b>malloc, realloc, </b>etc, add padding blocks before
           and after each heap block allocated by the program being run.
           Such padding blocks are called redzones. The default value
           for the redzone size depends on the tool. For example,
           Memcheck adds and protects a minimum of 16 bytes before and
           after each block allocated by the client. This allows it to
           detect block underruns or overruns of up to 16 bytes.

           Increasing the redzone size makes it possible to detect
           overruns of larger distances, but increases the amount of
           memory used by Valgrind. Decreasing the redzone size will
           reduce the memory needed by Valgrind but also reduces the
           chances of detecting over/underruns, so is not recommended.

       <b>--xtree-memory=none|allocs|full [none]</b>
           Tools replacing Valgrind's <b>malloc, realloc, </b>etc, can
           optionally produce an execution tree detailing which piece of
           code is responsible for heap memory usage. See Execution
           Trees for a detailed explanation about execution trees.

           When set to <i>none</i>, no memory execution tree is produced.

           When set to <i>allocs</i>, the memory execution tree gives the
           current number of allocated bytes and the current number of
           allocated blocks.

           When set to <i>full</i>, the memory execution tree gives 6 different
           measurements : the current number of allocated bytes and
           blocks (same values as for <i>allocs</i>), the total number of
           allocated bytes and blocks, the total number of freed bytes
           and blocks.

           Note that the overhead in cpu and memory to produce an xtree
           depends on the tool. The overhead in cpu is small for the
           value <i>allocs</i>, as the information needed to produce this
           report is maintained in any case by the tool. For massif and
           helgrind, specifying <i>full</i> implies to capture a stack trace
           for each free operation, while normally these tools only
           capture an allocation stack trace. For Memcheck, the cpu
           overhead for the value <i>full</i> is small, as this can only be
           used in combination with <b>--keep-stacktraces=alloc-and-free </b>or
           <b>--keep-stacktraces=alloc-then-free</b>, which already records a
           stack trace for each free operation. The memory overhead
           varies between 5 and 10 words per unique stacktrace in the
           xtree, plus the memory needed to record the stack trace for
           the free operations, if needed specifically for the xtree.

       <b>--xtree-memory-file=&lt;filename&gt; [default: xtmemory.kcg.%p]</b>
           Specifies that Valgrind should produce the xtree memory
           report in the specified file. Any <b>%p </b>or <b>%q </b>sequences
           appearing in the filename are expanded in exactly the same
           way as they are for <b>--log-file</b>. See the description of --log-
           file for details.

           If the filename contains the extension <b>.ms</b>, then the produced
           file format will be a massif output file format. If the
           filename contains the extension <b>.kcg </b>or no extension is
           provided or recognised, then the produced file format will be
           a callgrind output format.

           See Execution Trees for a detailed explanation about
           execution trees formats.
</pre> <h2>
UNCOMMON OPTIONS </h2>
<pre>
       These options apply to all tools, as they affect certain obscure
       workings of the Valgrind core. Most people won't need to use
       them.

       <b>--smc-check=&lt;none|stack|all|all-non-file&gt; [default: all-non-file</b>
       <b>for x86/amd64/s390x, stack for other archs]</b>
           This option controls Valgrind's detection of self-modifying
           code. If no checking is done, when a program executes some
           code, then overwrites it with new code, and executes the new
           code, Valgrind will continue to execute the translations it
           made for the old code. This will likely lead to incorrect
           behaviour and/or crashes.

           For "modern" architectures -- anything that's not x86, amd64
           or s390x -- the default is <i>stack</i>. This is because a correct
           program must take explicit action to reestablish D-I cache
           coherence following code modification. Valgrind observes and
           honours such actions, with the result that self-modifying
           code is transparently handled with zero extra cost.

           For x86, amd64 and s390x, the program is not required to
           notify the hardware of required D-I coherence syncing. Hence
           the default is <i>all-non-file</i>, which covers the normal case of
           generating code into an anonymous (non-file-backed) mmap'd
           area.

           The meanings of the four available settings are as follows.
           No detection (<i>none</i>), detect self-modifying code on the stack
           (which is used by GCC to implement nested functions) (<i>stack</i>),
           detect self-modifying code everywhere (<i>all</i>), and detect
           self-modifying code everywhere except in file-backed mappings
           (<i>all-non-file</i>).

           Running with <i>all</i> will slow Valgrind down noticeably. Running
           with <i>none</i> will rarely speed things up, since very little code
           gets dynamically generated in most programs. The
           <b>VALGRIND_DISCARD_TRANSLATIONS </b>client request is an
           alternative to <b>--smc-check=all </b>and <b>--smc-check=all-non-file</b>
           that requires more programmer effort but allows Valgrind to
           run your program faster, by telling it precisely when
           translations need to be re-made.

           <b>--smc-check=all-non-file </b>provides a cheaper but more limited
           version of <b>--smc-check=all</b>. It adds checks to any
           translations that do not originate from file-backed memory
           mappings. Typical applications that generate code, for
           example JITs in web browsers, generate code into anonymous
           mmaped areas, whereas the "fixed" code of the browser always
           lives in file-backed mappings.  <b>--smc-check=all-non-file</b>
           takes advantage of this observation, limiting the overhead of
           checking to code which is likely to be JIT generated.

       <b>--read-inline-info=&lt;yes|no&gt; [default: see below]</b>
           When enabled, Valgrind will read information about inlined
           function calls from DWARF3 debug info. This slows Valgrind
           startup and makes it use more memory (typically for each
           inlined piece of code, 6 words and space for the function
           name), but it results in more descriptive stacktraces.
           Currently, this functionality is enabled by default only for
           Linux, FreeBSD, Android and Solaris targets and only for the
           tools Memcheck, Massif, Helgrind and DRD. Here is an example
           of some stacktraces with <b>--read-inline-info=no</b>:

               ==15380== Conditional jump or move depends on uninitialised value(s)
               ==15380==    at 0x80484EA: main (inlinfo.c:6)
               ==15380==
               ==15380== Conditional jump or move depends on uninitialised value(s)
               ==15380==    at 0x8048550: fun_noninline (inlinfo.c:6)
               ==15380==    by 0x804850E: main (inlinfo.c:34)
               ==15380==
               ==15380== Conditional jump or move depends on uninitialised value(s)
               ==15380==    at 0x8048520: main (inlinfo.c:6)

           And here are the same errors with <b>--read-inline-info=yes</b>:

               ==15377== Conditional jump or move depends on uninitialised value(s)
               ==15377==    at 0x80484EA: fun_d (inlinfo.c:6)
               ==15377==    by 0x80484EA: fun_c (inlinfo.c:14)
               ==15377==    by 0x80484EA: fun_b (inlinfo.c:20)
               ==15377==    by 0x80484EA: fun_a (inlinfo.c:26)
               ==15377==    by 0x80484EA: main (inlinfo.c:33)
               ==15377==
               ==15377== Conditional jump or move depends on uninitialised value(s)
               ==15377==    at 0x8048550: fun_d (inlinfo.c:6)
               ==15377==    by 0x8048550: fun_noninline (inlinfo.c:41)
               ==15377==    by 0x804850E: main (inlinfo.c:34)
               ==15377==
               ==15377== Conditional jump or move depends on uninitialised value(s)
               ==15377==    at 0x8048520: fun_d (inlinfo.c:6)
               ==15377==    by 0x8048520: main (inlinfo.c:35)

       <b>--read-var-info=&lt;yes|no&gt; [default: no]</b>
           When enabled, Valgrind will read information about variable
           types and locations from DWARF3 debug info. This slows
           Valgrind startup significantly and makes it use significantly
           more memory, but for the tools that can take advantage of it
           (Memcheck, Helgrind, DRD) it can result in more precise error
           messages. For example, here are some standard errors issued
           by Memcheck:

               ==15363== Uninitialised byte(s) found during client check request
               ==15363==    at 0x80484A9: croak (varinfo1.c:28)
               ==15363==    by 0x8048544: main (varinfo1.c:55)
               ==15363==  Address 0x80497f7 is 7 bytes inside data symbol "global_i2"
               ==15363==
               ==15363== Uninitialised byte(s) found during client check request
               ==15363==    at 0x80484A9: croak (varinfo1.c:28)
               ==15363==    by 0x8048550: main (varinfo1.c:56)
               ==15363==  Address 0xbea0d0cc is on thread 1's stack
               ==15363==  in frame #1, created by main (varinfo1.c:45)

           And here are the same errors with <b>--read-var-info=yes</b>:

               ==15370== Uninitialised byte(s) found during client check request
               ==15370==    at 0x80484A9: croak (varinfo1.c:28)
               ==15370==    by 0x8048544: main (varinfo1.c:55)
               ==15370==  Location 0x80497f7 is 0 bytes inside global_i2[7],
               ==15370==  a global variable declared at varinfo1.c:41
               ==15370==
               ==15370== Uninitialised byte(s) found during client check request
               ==15370==    at 0x80484A9: croak (varinfo1.c:28)
               ==15370==    by 0x8048550: main (varinfo1.c:56)
               ==15370==  Location 0xbeb4a0cc is 0 bytes inside local var "local"
               ==15370==  declared at varinfo1.c:46, in frame #1 of thread 1

       <b>--vgdb-poll=&lt;number&gt; [default: 5000]</b>
           As part of its main loop, the Valgrind scheduler will poll to
           check if some activity (such as an external command or some
           input from a gdb) has to be handled by gdbserver. This
           activity poll will be done after having run the given number
           of basic blocks (or slightly more than the given number of
           basic blocks). This poll is quite cheap so the default value
           is set relatively low. You might further decrease this value
           if vgdb cannot use ptrace system call to interrupt Valgrind
           if all threads are (most of the time) blocked in a system
           call.

       <b>--vgdb-shadow-registers=no|yes [default: no]</b>
           When activated, gdbserver will expose the Valgrind shadow
           registers to GDB. With this, the value of the Valgrind shadow
           registers can be examined or changed using GDB. Exposing
           shadow registers only works with GDB version 7.1 or later.

       <b>--vgdb-prefix=&lt;prefix&gt; [default: /tmp/vgdb-pipe]</b>
           To communicate with gdb/vgdb, the Valgrind gdbserver creates
           3 files (2 named FIFOs and a mmap shared memory file). The
           prefix option controls the directory and prefix for the
           creation of these files.

       <b>--run-libc-freeres=&lt;yes|no&gt; [default: yes]</b>
           This option is only relevant when running Valgrind on Linux
           with GNU libc.

           The GNU C library (<b>libc.so</b>), which is used by all programs,
           may allocate memory for its own uses. Usually it doesn't
           bother to free that memory when the program ends—there would
           be no point, since the Linux kernel reclaims all process
           resources when a process exits anyway, so it would just slow
           things down.

           The glibc authors realised that this behaviour causes leak
           checkers, such as Valgrind, to falsely report leaks in glibc,
           when a leak check is done at exit. In order to avoid this,
           they provided a routine called <b>__libc_freeres </b>specifically to
           make glibc release all memory it has allocated. Memcheck
           therefore tries to run <b>__libc_freeres </b>at exit.

           Unfortunately, in some very old versions of glibc,
           <b>__libc_freeres </b>is sufficiently buggy to cause segmentation
           faults. This was particularly noticeable on Red Hat 7.1. So
           this option is provided in order to inhibit the run of
           <b>__libc_freeres</b>. If your program seems to run fine on
           Valgrind, but segfaults at exit, you may find that
           <b>--run-libc-freeres=no </b>fixes that, although at the cost of
           possibly falsely reporting space leaks in libc.so.

       <b>--run-cxx-freeres=&lt;yes|no&gt; [default: yes]</b>
           This option is only relevant when running Valgrind on Linux,
           FreeBSD or Solaris C++ programs using libstdc++.

           The GNU Standard C++ library (<b>libstdc++.so</b>), which is used by
           all C++ programs compiled with g++, may allocate memory for
           its own uses. Usually it doesn't bother to free that memory
           when the program ends—there would be no point, since the
           kernel reclaims all process resources when a process exits
           anyway, so it would just slow things down.

           The gcc authors realised that this behaviour causes leak
           checkers, such as Valgrind, to falsely report leaks in
           libstdc++, when a leak check is done at exit. In order to
           avoid this, they provided a routine called
           <b>__gnu_cxx::__freeres </b>specifically to make libstdc++ release
           all memory it has allocated. Memcheck therefore tries to run
           <b>__gnu_cxx::__freeres </b>at exit.

           For the sake of flexibility and unforeseen problems with
           <b>__gnu_cxx::__freeres</b>, option <b>--run-cxx-freeres=no </b>exists,
           although at the cost of possibly falsely reporting space
           leaks in libstdc++.so.

       <b>--sim-hints=hint1,hint2,...</b>
           Pass miscellaneous hints to Valgrind which slightly modify
           the simulated behaviour in nonstandard or dangerous ways,
           possibly to help the simulation of strange features. By
           default no hints are enabled. Use with caution! Currently
           known hints are:

           •   <b>lax-ioctls: </b>Be very lax about ioctl handling; the only
               assumption is that the size is correct. Doesn't require
               the full buffer to be initialised when writing. Without
               this, using some device drivers with a large number of
               strange ioctl commands becomes very tiresome.

           •   <b>fuse-compatible: </b>Enable special handling for certain
               system calls that may block in a FUSE file-system. This
               may be necessary when running Valgrind on a
               multi-threaded program that uses one thread to manage a
               FUSE file-system and another thread to access that
               file-system.

           •   <b>enable-outer: </b>Enable some special magic needed when the
               program being run is itself Valgrind.

           •   <b>no-inner-prefix: </b>Disable printing a prefix <b>&gt; </b>in front of
               each stdout or stderr output line in an inner Valgrind
               being run by an outer Valgrind. This is useful when
               running Valgrind regression tests in an outer/inner
               setup. Note that the prefix <b>&gt; </b>will always be printed in
               front of the inner debug logging lines.

           •   <b>no-nptl-pthread-stackcache: </b>This hint is only relevant
               when running Valgrind on Linux; it is ignored on FreeBSD,
               Solaris and macOS.

               The GNU glibc pthread library (<b>libpthread.so</b>), which is
               used by pthread programs, maintains a cache of pthread
               stacks. When a pthread terminates, the memory used for
               the pthread stack and some thread local storage related
               data structure are not always directly released. This
               memory is kept in a cache (up to a certain size), and is
               re-used if a new thread is started.

               This cache causes the helgrind tool to report some false
               positive race condition errors on this cached memory, as
               helgrind does not understand the internal glibc cache
               synchronisation primitives. So, when using helgrind,
               disabling the cache helps to avoid false positive race
               conditions, in particular when using thread local storage
               variables (e.g. variables using the <b>__thread </b>qualifier).

               When using the memcheck tool, disabling the cache ensures
               the memory used by glibc to handle __thread variables is
               directly released when a thread terminates.

               Note: Valgrind disables the cache using some internal
               knowledge of the glibc stack cache implementation and by
               examining the debug information of the pthread library.
               This technique is thus somewhat fragile and might not
               work for all glibc versions. This has been successfully
               tested with various glibc versions (e.g. 2.11, 2.16,
               2.18) on various platforms.

           •   <b>lax-doors: </b>(Solaris only) Be very lax about door syscall
               handling over unrecognised door file descriptors. Does
               not require that full buffer is initialised when writing.
               Without this, programs using libdoor(3LIB) functionality
               with completely proprietary semantics may report large
               number of false positives.

           •   <b>fallback-llsc: </b>(MIPS and ARM64 only): Enables an
               alternative implementation of Load-Linked (LL) and
               Store-Conditional (SC) instructions. The standard
               implementation gives more correct behaviour, but can
               cause indefinite looping on certain processor
               implementations that are intolerant of extra memory
               references between LL and SC. So far this is known only
               to happen on Cavium 3 cores. You should not need to use
               this flag, since the relevant cores are detected at
               startup and the alternative implementation is
               automatically enabled if necessary. There is no
               equivalent anti-flag: you cannot force-disable the
               alternative implementation, if it is automatically
               enabled. The underlying problem exists because the
               "standard" implementation of LL and SC is done by copying
               through LL and SC instructions into the instrumented
               code. However, tools may insert extra instrumentation
               memory references in between the LL and SC instructions.
               These memory references are not present in the original
               uninstrumented code, and their presence in the
               instrumented code can cause the SC instructions to
               persistently fail, leading to indefinite looping in LL-SC
               blocks. The alternative implementation gives correct
               behaviour of LL and SC instructions between threads in a
               process, up to and including the ABA scenario. It also
               gives correct behaviour between a Valgrinded thread and a
               non-Valgrinded thread running in a different process,
               that communicate via shared memory, but only up to and
               including correct CAS behaviour -- in this case the ABA
               scenario may not be correctly handled.

       <b>--scheduling-quantum=&lt;number&gt; [default: 100000]</b>
           The <b>--scheduling-quantum </b>option controls the maximum number
           of basic blocks executed by a thread before releasing the
           lock used by Valgrind to serialise thread execution. Smaller
           values give finer interleaving but increases the scheduling
           overhead. Finer interleaving can be useful to reproduce race
           conditions with helgrind or DRD. For more details about the
           Valgrind thread serialisation scheme and its impact on
           performance and thread scheduling, see Scheduling and Multi-
           Thread Performance.

       <b>--fair-sched=&lt;no|yes|try&gt; [default: no]</b>
           The <b>--fair-sched </b>option controls the locking mechanism used
           by Valgrind to serialise thread execution. The locking
           mechanism controls the way the threads are scheduled, and
           different settings give different trade-offs between fairness
           and performance. For more details about the Valgrind thread
           serialisation scheme and its impact on performance and thread
           scheduling, see Scheduling and Multi-Thread Performance.

           •   The value <b>--fair-sched=yes </b>activates a fair scheduler. In
               short, if multiple threads are ready to run, the threads
               will be scheduled in a round robin fashion. This
               mechanism is not available on all platforms or Linux
               versions. If not available, using <b>--fair-sched=yes </b>will
               cause Valgrind to terminate with an error.

               You may find this setting improves overall responsiveness
               if you are running an interactive multithreaded program,
               for example a web browser, on Valgrind.

           •   The value <b>--fair-sched=try </b>activates fair scheduling if
               available on the platform. Otherwise, it will
               automatically fall back to <b>--fair-sched=no</b>.

           •   The value <b>--fair-sched=no </b>activates a scheduler which
               does not guarantee fairness between threads ready to run,
               but which in general gives the highest performance.

       <b>--kernel-variant=variant1,variant2,...</b>
           Handle system calls and ioctls arising from minor variants of
           the default kernel for this platform. This is useful for
           running on hacked kernels or with kernel modules which
           support nonstandard ioctls, for example. Use with caution. If
           you don't understand what this option does then you almost
           certainly don't need it. Currently known variants are:

           •   <b>bproc</b>: support the <b>sys_broc </b>system call on x86. This is
               for running on BProc, which is a minor variant of
               standard Linux which is sometimes used for building
               clusters.

           •   <b>android-no-hw-tls</b>: some versions of the Android emulator
               for ARM do not provide a hardware TLS (thread-local
               state) register, and Valgrind crashes at startup. Use
               this variant to select software support for TLS.

           •   <b>android-gpu-sgx5xx</b>: use this to support handling of
               proprietary ioctls for the PowerVR SGX 5XX series of GPUs
               on Android devices. Failure to select this does not cause
               stability problems, but may cause Memcheck to report
               false errors after the program performs GPU-specific
               ioctls.

           •   <b>android-gpu-adreno3xx</b>: similarly, use this to support
               handling of proprietary ioctls for the Qualcomm Adreno
               3XX series of GPUs on Android devices.

       <b>--merge-recursive-frames=&lt;number&gt; [default: 0]</b>
           Some recursive algorithms, for example balanced binary tree
           implementations, create many different stack traces, each
           containing cycles of calls. A cycle is defined as two
           identical program counter values separated by zero or more
           other program counter values. Valgrind may then use a lot of
           memory to store all these stack traces. This is a poor use of
           memory considering that such stack traces contain repeated
           uninteresting recursive calls instead of more interesting
           information such as the function that has initiated the
           recursive call.

           The option <b>--merge-recursive-frames=&lt;number&gt; </b>instructs
           Valgrind to detect and merge recursive call cycles having a
           size of up to <b>&lt;number&gt; </b>frames. When such a cycle is detected,
           Valgrind records the cycle in the stack trace as a unique
           program counter.

           The value 0 (the default) causes no recursive call merging. A
           value of 1 will cause stack traces of simple recursive
           algorithms (for example, a factorial implementation) to be
           collapsed. A value of 2 will usually be needed to collapse
           stack traces produced by recursive algorithms such as binary
           trees, quick sort, etc. Higher values might be needed for
           more complex recursive algorithms.

           Note: recursive calls are detected by analysis of program
           counter values. They are not detected by looking at function
           names.

       <b>--num-transtab-sectors=&lt;number&gt; [default: 6 for Android</b>
       <b>platforms, 16 for all others]</b>
           Valgrind translates and instruments your program's machine
           code in small fragments (basic blocks). The translations are
           stored in a translation cache that is divided into a number
           of sections (sectors). If the cache is full, the sector
           containing the oldest translations is emptied and reused. If
           these old translations are needed again, Valgrind must
           re-translate and re-instrument the corresponding machine
           code, which is expensive. If the "executed instructions"
           working set of a program is big, increasing the number of
           sectors may improve performance by reducing the number of
           re-translations needed. Sectors are allocated on demand. Once
           allocated, a sector can never be freed, and occupies
           considerable space, depending on the tool and the value of
           <b>--avg-transtab-entry-size </b>(about 40 MB per sector for
           Memcheck). Use the option <b>--stats=yes </b>to obtain precise
           information about the memory used by a sector and the
           allocation and recycling of sectors.

       <b>--avg-transtab-entry-size=&lt;number&gt; [default: 0, meaning use tool</b>
       <b>provided default]</b>
           Average size of translated basic block. This average size is
           used to dimension the size of a sector. Each tool provides a
           default value to be used. If this default value is too small,
           the translation sectors will become full too quickly. If this
           default value is too big, a significant part of the
           translation sector memory will be unused. Note that the
           average size of a basic block translation depends on the
           tool, and might depend on tool options. For example, the
           memcheck option <b>--track-origins=yes </b>increases the size of the
           basic block translations. Use <b>--avg-transtab-entry-size </b>to
           tune the size of the sectors, either to gain memory or to
           avoid too many retranslations.

       <b>--aspace-minaddr=&lt;address&gt; [default: depends on the platform]</b>
           To avoid potential conflicts with some system libraries,
           Valgrind does not use the address space below
           <b>--aspace-minaddr </b>value, keeping it reserved in case a library
           specifically requests memory in this region. So, some
           "pessimistic" value is guessed by Valgrind depending on the
           platform. On linux, by default, Valgrind avoids using the
           first 64MB even if typically there is no conflict in this
           complete zone. You can use the option <b>--aspace-minaddr </b>to
           have your memory hungry application benefitting from more of
           this lower memory. On the other hand, if you encounter a
           conflict, increasing aspace-minaddr value might solve it.
           Conflicts will typically manifest themselves with mmap
           failures in the low range of the address space. The provided
           address must be page aligned and must be equal or bigger to
           0x1000 (4KB). To find the default value on your platform, do
           something such as valgrind -d -d date 2&gt;&amp;1 | grep -i minaddr.
           Values lower than 0x10000 (64KB) are known to create problems
           on some distributions.

       <b>--valgrind-stacksize=&lt;number&gt; [default: 1MB]</b>
           For each thread, Valgrind needs its own 'private' stack. The
           default size for these stacks is largely dimensioned, and so
           should be sufficient in most cases. In case the size is too
           small, Valgrind will segfault. Before segfaulting, a warning
           might be produced by Valgrind when approaching the limit.

           Use the option <b>--valgrind-stacksize </b>if such an (unlikely)
           warning is produced, or Valgrind dies due to a segmentation
           violation. Such segmentation violations have been seen when
           demangling huge C++ symbols.

           If your application uses many threads and needs a lot of
           memory, you can gain some memory by reducing the size of
           these Valgrind stacks using the option <b>--valgrind-stacksize</b>.

       <b>--show-emwarns=&lt;yes|no&gt; [default: no]</b>
           When enabled, Valgrind will emit warnings about its CPU
           emulation in certain cases. These are usually not
           interesting.

       <b>--require-text-symbol=:sonamepatt:fnnamepatt</b>
           When a shared object whose soname matches <i>sonamepatt</i> is
           loaded into the process, examine all the text symbols it
           exports. If none of those match <i>fnnamepatt</i>, print an error
           message and abandon the run. This makes it possible to ensure
           that the run does not continue unless a given shared object
           contains a particular function name.

           Both <i>sonamepatt</i> and <i>fnnamepatt</i> can be written using the usual
           <i>?</i>  and <i>*</i> wildcards. For example: <i>":*libc.so*:foo?bar"</i>. You
           may use characters other than a colon to separate the two
           patterns. It is only important that the first character and
           the separator character are the same. For example, the above
           example could also be written <i>"Q*libc.so*Qfoo?bar"</i>. Multiple
            <i>--require-text-symbol</i> flags are allowed, in which case
           shared objects that are loaded into the process will be
           checked against all of them.

           The purpose of this is to support reliable usage of marked-up
           libraries. For example, suppose we have a version of GCC's
           <i>libgomp.so</i> which has been marked up with annotations to
           support Helgrind. It is only too easy and confusing to load
           the wrong, un-annotated <i>libgomp.so</i> into the application. So
           the idea is: add a text symbol in the marked-up library, for
           example <i>annotated_for_helgrind_3_6</i>, and then give the flag
           <i>--require-text-symbol=:*libgomp*so*:annotated_for_helgrind_3_6</i>
           so that when <i>libgomp.so</i> is loaded, Valgrind scans its symbol
           table, and if the symbol isn't present the run is aborted,
           rather than continuing silently with the un-marked-up
           library. Note that you should put the entire flag in quotes
           to stop shells expanding up the <i>*</i> and <i>?</i>  wildcards.

       <b>--soname-synonyms=syn1=pattern1,syn2=pattern2,...</b>
           When a shared library is loaded, Valgrind checks for
           functions in the library that must be replaced or wrapped.
           For example, Memcheck replaces some string and memory
           functions (strchr, strlen, strcpy, memchr, memcpy, memmove,
           etc.) with its own versions. Such replacements are normally
           done only in shared libraries whose soname matches a
           predefined soname pattern (e.g.  <i>libc.so*</i> on linux). By
           default, no replacement is done for a statically linked
           binary or for alternative libraries, except for the
           allocation functions (malloc, free, calloc, memalign,
           realloc, operator new, operator delete, etc.) Such allocation
           functions are intercepted by default in any shared library or
           in the executable if they are exported as global symbols.
           This means that if a replacement allocation library such as
           tcmalloc is found, its functions are also intercepted by
           default. In some cases, the replacements allow
           <b>--soname-synonyms </b>to specify one additional synonym pattern,
           giving flexibility in the replacement. Or to prevent
           interception of all public allocation symbols.

           Currently, this flexibility is only allowed for the malloc
           related functions, using the synonym <i>somalloc</i>. This synonym
           is usable for all tools doing standard replacement of malloc
           related functions (e.g. memcheck, helgrind, drd, massif,
           dhat).

           •   Alternate malloc library: to replace the malloc related
               functions in a specific alternate library with soname
               <i>mymalloclib.so</i> (and not in any others), give the option
               <b>--soname-synonyms=somalloc=mymalloclib.so</b>. A pattern can
               be used to match multiple libraries sonames. For example,
               <b>--soname-synonyms=somalloc=*tcmalloc* </b>will match the
               soname of all variants of the tcmalloc library (native,
               debug, profiled, ... tcmalloc variants).

               Note: the soname of a elf shared library can be retrieved
               using the readelf utility.

           •   Replacements in a statically linked library are done by
               using the <i>NONE</i> pattern. For example, if you link with
               <i>libtcmalloc.a</i>, and only want to intercept the malloc
               related functions in the executable (and standard
               libraries) themselves, but not any other shared
               libraries, you can give the option
               <b>--soname-synonyms=somalloc=NONE</b>. Note that a NONE pattern
               will match the main executable and any shared library
               having no soname.

           •   To only intercept allocation symbols in the default
               system libraries, but not in any other shared library or
               the executable defining public malloc or operator new
               related functions use a non-existing library name like
               <b>--soname-synonyms=somalloc=nouserintercepts </b>(where
               <i>nouserintercepts</i> can be any non-existing library name).

           •   Shared library of the dynamic (runtime) linker is
               excluded from searching for global public symbols, such
               as those for the malloc related functions (identified by
               <i>somalloc</i> synonym).

       <b>--progress-interval=&lt;number&gt; [default: 0, meaning 'disabled']</b>
           This is an enhancement to Valgrind's debugging output. It is
           unlikely to be of interest to end users.

           When <i>number</i> is set to a non-zero value, Valgrind will print a
           one-line progress summary every <i>number</i> seconds. Valid
           settings for <i>number</i> are between 0 and 3600 inclusive. Here's
           some example output with <i>number</i> set to 10:

               PROGRESS: U 110s, W 113s, 97.3% CPU, EvC 414.79M, TIn 616.7k, TOut 0.5k, #thr 67
               PROGRESS: U 120s, W 124s, 96.8% CPU, EvC 505.27M, TIn 636.6k, TOut 3.0k, #thr 64
               PROGRESS: U 130s, W 134s, 97.0% CPU, EvC 574.90M, TIn 657.5k, TOut 3.0k, #thr 63

           Each line shows:

           •   <i>U</i>: total user time

           •   <i>W</i>: total wallclock time

           •   <i>CPU</i>: overall average cpu use

           •   <i>EvC</i>: number of event checks. An event check is a
               backwards branch in the simulated program, so this is a
               measure of forward progress of the program

           •   <i>TIn</i>: number of code blocks instrumented by the JIT

           •   <i>TOut</i>: number of instrumented code blocks that have been
               thrown away

           •   <i>#thr</i>: number of threads in the program

           From the progress of these, it is possible to observe:

           •   when the program is compute bound (<i>TIn</i> rises slowly, <i>EvC</i>
               rises rapidly)

           •   when the program is in a spinloop (<i>TIn</i>/<i>TOut</i> fixed, <i>EvC</i>
               rises rapidly)

           •   when the program is JIT-bound (<i>TIn</i> rises rapidly)

           •   when the program is rapidly discarding code (<i>TOut</i> rises
               rapidly)

           •   when the program is about to achieve some expected state
               (<i>EvC</i> arrives at some value you expect)

           •   when the program is idling (<i>U</i> rises more slowly than <i>W</i>)
</pre> <h2>
DEBUGGING VALGRIND OPTIONS </h2>
<pre>
       There are also some options for debugging Valgrind itself. You
       shouldn't need to use them in the normal run of things. If you
       wish to see the list, use the <b>--help-debug </b>option.
</pre> <h2>
MEMCHECK OPTIONS </h2>
<pre>
       <b>--leak-check=&lt;no|summary|yes|full&gt; [default: summary]</b>
           When enabled, search for memory leaks when the client program
           finishes. If set to <i>summary</i>, it says how many leaks occurred.
           If set to <i>full</i> or <i>yes</i>, each individual leak will be shown in
           detail and/or counted as an error, as specified by the
           options <b>--show-leak-kinds </b>and <b>--errors-for-leak-kinds</b>.

           If <i>--xml=yes</i> is given, memcheck will automatically use the
           value <i>--leak-check=full</i>. You can use <b>--show-leak-kinds=none</b>
           to reduce the size of the xml output if you are not
           interested in the leak results.

       <b>--leak-resolution=&lt;low|med|high&gt; [default: high]</b>
           When doing leak checking, determines how willing Memcheck is
           to consider different backtraces to be the same for the
           purposes of merging multiple leaks into a single leak report.
           When set to <i>low</i>, only the first two entries need match. When
           <i>med</i>, four entries have to match. When <i>high</i>, all entries need
           to match.

           For hardcore leak debugging, you probably want to use
           <b>--leak-resolution=high </b>together with <b>--num-callers=40 </b>or some
           such large number.

           Note that the <b>--leak-resolution </b>setting does not affect
           Memcheck's ability to find leaks. It only changes how the
           results are presented.

       <b>--show-leak-kinds=&lt;set&gt; [default: definite,possible]</b>
           Specifies the leak kinds to show in a <i>full</i> leak search, in
           one of the following ways:

           •   a comma separated list of one or more of <b>definite</b>
               <b>indirect possible reachable</b>.

           •   <b>all </b>to specify the complete set (all leak kinds). It is
               equivalent to
               <b>--show-leak-kinds=definite,indirect,possible,reachable</b>.

           •   <b>none </b>for the empty set.

       <b>--errors-for-leak-kinds=&lt;set&gt; [default: definite,possible]</b>
           Specifies the leak kinds to count as errors in a <i>full</i> leak
           search. The <b>&lt;set&gt; </b>is specified similarly to <b>--show-leak-kinds</b>

       <b>--leak-check-heuristics=&lt;set&gt; [default: all]</b>
           Specifies the set of leak check heuristics to be used during
           leak searches. The heuristics control which interior pointers
           to a block cause it to be considered as reachable. The
           heuristic set is specified in one of the following ways:

           •   a comma separated list of one or more of <b>stdstring</b>
               <b>length64 newarray multipleinheritance</b>.

           •   <b>all </b>to activate the complete set of heuristics. It is
               equivalent to
               <b>--leak-check-heuristics=stdstring,length64,newarray,multipleinheritance</b>.

           •   <b>none </b>for the empty set.

           Note that these heuristics are dependent on the layout of the
           objects produced by the C++ compiler. They have been tested
           with some gcc versions (e.g. 4.4 and 4.7). They might not
           work properly with other C++ compilers.

       <b>--show-reachable=&lt;yes|no&gt; </b>, <b>--show-possibly-lost=&lt;yes|no&gt;</b>
           These options provide an alternative way to specify the leak
           kinds to show:

           •   <b>--show-reachable=no --show-possibly-lost=yes </b>is
               equivalent to <b>--show-leak-kinds=definite,possible</b>.

           •   <b>--show-reachable=no --show-possibly-lost=no </b>is equivalent
               to <b>--show-leak-kinds=definite</b>.

           •   <b>--show-reachable=yes </b>is equivalent to
               <b>--show-leak-kinds=all</b>.

           Note that <b>--show-possibly-lost=no </b>has no effect if
           <b>--show-reachable=yes </b>is specified.

       <b>--xtree-leak=&lt;no|yes&gt; [no]</b>
           If set to yes, the results for the leak search done at exit
           will be output in a 'Callgrind Format' execution tree file.
           Note that this automatically sets the options
           <b>--leak-check=full </b>and <b>--show-leak-kinds=all</b>, to allow xtree
           visualisation tools such as kcachegrind to select what kind
           to leak to visualize. The produced file will contain the
           following events:

           •   <b>RB </b>: Reachable Bytes

           •   <b>PB </b>: Possibly lost Bytes

           •   <b>IB </b>: Indirectly lost Bytes

           •   <b>DB </b>: Definitely lost Bytes (direct plus indirect)

           •   <b>DIB </b>: Definitely Indirectly lost Bytes (subset of DB)

           •   <b>RBk </b>: reachable Blocks

           •   <b>PBk </b>: Possibly lost Blocks

           •   <b>IBk </b>: Indirectly lost Blocks

           •   <b>DBk </b>: Definitely lost Blocks

           The increase or decrease for all events above will also be
           output in the file to provide the delta (increase or
           decrease) between 2 successive leak searches. For example,
           <b>iRB </b>is the increase of the <b>RB </b>event, <b>dPBk </b>is the decrease of
           <b>PBk </b>event. The values for the increase and decrease events
           will be zero for the first leak search done.

           See Execution Trees for a detailed explanation about
           execution trees.

       <b>--xtree-leak-file=&lt;filename&gt; [default: xtleak.kcg.%p]</b>
           Specifies that Valgrind should produce the xtree leak report
           in the specified file. Any <b>%p</b>, <b>%q </b>or <b>%n </b>sequences appearing
           in the filename are expanded in exactly the same way as they
           are for <b>--log-file</b>. See the description of --log-file for
           details.

           See Execution Trees for a detailed explanation about
           execution trees formats.

       <b>--undef-value-errors=&lt;yes|no&gt; [default: yes]</b>
           Controls whether Memcheck reports uses of undefined value
           errors. Set this to <i>no</i> if you don't want to see undefined
           value errors. It also has the side effect of speeding up
           Memcheck somewhat. AddrCheck (removed in Valgrind 3.1.0)
           functioned like Memcheck with <b>--undef-value-errors=no</b>.

       <b>--track-origins=&lt;yes|no&gt; [default: no]</b>
           Controls whether Memcheck tracks the origin of uninitialised
           values. By default, it does not, which means that although it
           can tell you that an uninitialised value is being used in a
           dangerous way, it cannot tell you where the uninitialised
           value came from. This often makes it difficult to track down
           the root problem.

           When set to <i>yes</i>, Memcheck keeps track of the origins of all
           uninitialised values. Then, when an uninitialised value error
           is reported, Memcheck will try to show the origin of the
           value. An origin can be one of the following four places: a
           heap block, a stack allocation, a client request, or
           miscellaneous other sources (eg, a call to <i>brk</i>).

           For uninitialised values originating from a heap block,
           Memcheck shows where the block was allocated. For
           uninitialised values originating from a stack allocation,
           Memcheck can tell you which function allocated the value, but
           no more than that -- typically it shows you the source
           location of the opening brace of the function. So you should
           carefully check that all of the function's local variables
           are initialised properly.

           Performance overhead: origin tracking is expensive. It halves
           Memcheck's speed and increases memory use by a minimum of
           100MB, and possibly more. Nevertheless it can drastically
           reduce the effort required to identify the root cause of
           uninitialised value errors, and so is often a programmer
           productivity win, despite running more slowly.

           Accuracy: Memcheck tracks origins quite accurately. To avoid
           very large space and time overheads, some approximations are
           made. It is possible, although unlikely, that Memcheck will
           report an incorrect origin, or not be able to identify any
           origin.

           Note that the combination <b>--track-origins=yes </b>and
           <b>--undef-value-errors=no </b>is nonsensical. Memcheck checks for
           and rejects this combination at startup.

       <b>--partial-loads-ok=&lt;yes|no&gt; [default: yes]</b>
           Controls how Memcheck handles 32-, 64-, 128- and 256-bit
           naturally aligned loads from addresses for which some bytes
           are addressable and others are not. When <i>yes</i>, such loads do
           not produce an address error. Instead, loaded bytes
           originating from illegal addresses are marked as
           uninitialised, and those corresponding to legal addresses are
           handled in the normal way.

           When <i>no</i>, loads from partially invalid addresses are treated
           the same as loads from completely invalid addresses: an
           illegal-address error is issued, and the resulting bytes are
           marked as initialised.

           Note that code that behaves in this way is in violation of
           the ISO C/C++ standards, and should be considered broken. If
           at all possible, such code should be fixed.

       <b>--expensive-definedness-checks=&lt;no|auto|yes&gt; [default: auto]</b>
           Controls whether Memcheck should employ more precise but also
           more expensive (time consuming) instrumentation when checking
           the definedness of certain values. In particular, this
           affects the instrumentation of integer adds, subtracts and
           equality comparisons.

           Selecting <b>--expensive-definedness-checks=yes </b>causes Memcheck
           to use the most accurate analysis possible. This minimises
           false error rates but can cause up to 30% performance
           degradation.

           Selecting <b>--expensive-definedness-checks=no </b>causes Memcheck
           to use the cheapest instrumentation possible. This maximises
           performance but will normally give an unusably high false
           error rate.

           The default setting, <b>--expensive-definedness-checks=auto</b>, is
           strongly recommended. This causes Memcheck to use the minimum
           of expensive instrumentation needed to achieve the same false
           error rate as <b>--expensive-definedness-checks=yes</b>. It also
           enables an instrumentation-time analysis pass which aims to
           further reduce the costs of accurate instrumentation.
           Overall, the performance loss is generally around 5% relative
           to <b>--expensive-definedness-checks=no</b>, although this is
           strongly workload dependent. Note that the exact
           instrumentation settings in this mode are architecture
           dependent.

       <b>--keep-stacktraces=alloc|free|alloc-and-free|alloc-then-free|none</b>
       <b>[default: alloc-and-free]</b>
           Controls which stack trace(s) to keep for malloc'd and/or
           free'd blocks.

           With <i>alloc-then-free</i>, a stack trace is recorded at allocation
           time, and is associated with the block. When the block is
           freed, a second stack trace is recorded, and this replaces
           the allocation stack trace. As a result, any "use after free"
           errors relating to this block can only show a stack trace for
           where the block was freed.

           With <i>alloc-and-free</i>, both allocation and the deallocation
           stack traces for the block are stored. Hence a "use after
           free" error will show both, which may make the error easier
           to diagnose. Compared to <i>alloc-then-free</i>, this setting
           slightly increases Valgrind's memory use as the block
           contains two references instead of one.

           With <i>alloc</i>, only the allocation stack trace is recorded (and
           reported). With <i>free</i>, only the deallocation stack trace is
           recorded (and reported). These values somewhat decrease
           Valgrind's memory and cpu usage. They can be useful depending
           on the error types you are searching for and the level of
           detail you need to analyse them. For example, if you are only
           interested in memory leak errors, it is sufficient to record
           the allocation stack traces.

           With <i>none</i>, no stack traces are recorded for malloc and free
           operations. If your program allocates a lot of blocks and/or
           allocates/frees from many different stack traces, this can
           significantly decrease cpu and/or memory required. Of course,
           few details will be reported for errors related to heap
           blocks.

           Note that once a stack trace is recorded, Valgrind keeps the
           stack trace in memory even if it is not referenced by any
           block. Some programs (for example, recursive algorithms) can
           generate a huge number of stack traces. If Valgrind uses too
           much memory in such circumstances, you can reduce the memory
           required with the options <i>--keep-stacktraces</i> and/or by using
           a smaller value for the option <i>--num-callers</i>.

           If you want to use --xtree-memory=full memory profiling (see
           Execution Trees), then you cannot specify
           <i>--keep-stacktraces=free</i> or <i>--keep-stacktraces=none</i>.

       <b>--freelist-vol=&lt;number&gt; [default: 20000000]</b>
           When the client program releases memory using <b>free </b>(in C) or
           delete (C++), that memory is not immediately made available
           for re-allocation. Instead, it is marked inaccessible and
           placed in a queue of freed blocks. The purpose is to defer as
           long as possible the point at which freed-up memory comes
           back into circulation. This increases the chance that
           Memcheck will be able to detect invalid accesses to blocks
           for some significant period of time after they have been
           freed.

           This option specifies the maximum total size, in bytes, of
           the blocks in the queue. The default value is twenty million
           bytes. Increasing this increases the total amount of memory
           used by Memcheck but may detect invalid uses of freed blocks
           which would otherwise go undetected.

       <b>--freelist-big-blocks=&lt;number&gt; [default: 1000000]</b>
           When making blocks from the queue of freed blocks available
           for re-allocation, Memcheck will in priority re-circulate the
           blocks with a size greater or equal to <b>--freelist-big-blocks</b>.
           This ensures that freeing big blocks (in particular freeing
           blocks bigger than <b>--freelist-vol</b>) does not immediately lead
           to a re-circulation of all (or a lot of) the small blocks in
           the free list. In other words, this option increases the
           likelihood to discover dangling pointers for the "small"
           blocks, even when big blocks are freed.

           Setting a value of 0 means that all the blocks are
           re-circulated in a FIFO order.

       <b>--workaround-gcc296-bugs=&lt;yes|no&gt; [default: no]</b>
           When enabled, assume that reads and writes some small
           distance below the stack pointer are due to bugs in GCC 2.96,
           and does not report them. The "small distance" is 256 bytes
           by default. Note that GCC 2.96 is the default compiler on
           some ancient Linux distributions (RedHat 7.X) and so you may
           need to use this option. Do not use it if you do not have to,
           as it can cause real errors to be overlooked. A better
           alternative is to use a more recent GCC in which this bug is
           fixed.

           You may also need to use this option when working with GCC
           3.X or 4.X on 32-bit PowerPC Linux. This is because GCC
           generates code which occasionally accesses below the stack
           pointer, particularly for floating-point to/from integer
           conversions. This is in violation of the 32-bit PowerPC ELF
           specification, which makes no provision for locations below
           the stack pointer to be accessible.

           This option is deprecated as of version 3.12 and may be
           removed from future versions. You should instead use
           <b>--ignore-range-below-sp </b>to specify the exact range of offsets
           below the stack pointer that should be ignored. A suitable
           equivalent is <b>--ignore-range-below-sp=1024-1</b>.

       <b>--ignore-range-below-sp=&lt;number&gt;-&lt;number&gt;</b>
           This is a more general replacement for the deprecated
           <b>--workaround-gcc296-bugs </b>option. When specified, it causes
           Memcheck not to report errors for accesses at the specified
           offsets below the stack pointer. The two offsets must be
           positive decimal numbers and -- somewhat counterintuitively
           -- the first one must be larger, in order to imply a
           non-wraparound address range to ignore. For example, to
           ignore 4 byte accesses at 8192 bytes below the stack pointer,
           use <b>--ignore-range-below-sp=8192-8189</b>. Only one range may be
           specified.

       <b>--show-mismatched-frees=&lt;yes|no&gt; [default: yes]</b>
           When enabled, Memcheck checks that heap blocks are
           deallocated using a function that matches the allocating
           function. That is, it expects <i>free</i> to be used to deallocate
           blocks allocated by <i>malloc</i>, <i>delete</i> for blocks allocated by
           <i>new</i>, and <i>delete[]</i> for blocks allocated by <i>new[]</i>. If a
           mismatch is detected, an error is reported. This is in
           general important because in some environments, freeing with
           a non-matching function can cause crashes.

           There is however a scenario where such mismatches cannot be
           avoided. That is when the user provides implementations of
           <i>new</i>/<i>new[]</i> that call <i>malloc</i> and of <i>delete</i>/<i>delete[]</i> that call
           <i>free</i>, and these functions are asymmetrically inlined. For
           example, imagine that <i>delete[]</i> is inlined but <i>new[]</i> is not.
           The result is that Memcheck "sees" all <i>delete[]</i> calls as
           direct calls to <i>free</i>, even when the program source contains
           no mismatched calls.

           This causes a lot of confusing and irrelevant error reports.
           <i>--show-mismatched-frees=no</i> disables these checks. It is not
           generally advisable to disable them, though, because you may
           miss real errors as a result.

       <b>--show-realloc-size-zero=&lt;yes|no&gt; [default: yes]</b>
           When enabled, Memcheck checks for uses of <i>realloc</i> with a size
           of zero. This usage of <i>realloc</i> is unsafe since it is not
           portable. On some systems it will behave like <i>free</i>. On other
           systems it will either do nothing or else behave like a call
           to <i>free</i> followed by a call to <i>malloc</i> with a size of zero.

       <b>--ignore-ranges=0xPP-0xQQ[,0xRR-0xSS]</b>
           Any ranges listed in this option (and multiple ranges can be
           specified, separated by commas) will be ignored by Memcheck's
           addressability checking.

       <b>--malloc-fill=&lt;hexnumber&gt;</b>
           Fills blocks allocated by malloc, new, etc, but not by
           calloc, with the specified byte. This can be useful when
           trying to shake out obscure memory corruption problems. The
           allocated area is still regarded by Memcheck as undefined --
           this option only affects its contents. Note that
           <b>--malloc-fill </b>does not affect a block of memory when it is
           used as argument to client requests VALGRIND_MEMPOOL_ALLOC or
           VALGRIND_MALLOCLIKE_BLOCK.

       <b>--free-fill=&lt;hexnumber&gt;</b>
           Fills blocks freed by free, delete, etc, with the specified
           byte value. This can be useful when trying to shake out
           obscure memory corruption problems. The freed area is still
           regarded by Memcheck as not valid for access -- this option
           only affects its contents. Note that <b>--free-fill </b>does not
           affect a block of memory when it is used as argument to
           client requests VALGRIND_MEMPOOL_FREE or
           VALGRIND_FREELIKE_BLOCK.
</pre> <h2>
CACHEGRIND OPTIONS </h2>
<pre>
       <b>--cachegrind-out-file=&lt;file&gt;</b>
           Write the Cachegrind output file to file rather than to the
           default output file, cachegrind.out.&lt;pid&gt;. The <b>%p </b>and <b>%q</b>
           format specifiers can be used to embed the process ID and/or
           the contents of an environment variable in the name, as is
           the case for the core option <b>--log-file</b>.

       <b>--cache-sim=no|yes [no]</b>
           Enables or disables collection of cache access and miss
           counts.

       <b>--branch-sim=no|yes [no]</b>
           Enables or disables collection of branch instruction and
           misprediction counts.

       <b>--instr-at-start=no|yes [yes]</b>
           Enables or disables instrumentation at the start of
           execution. Use this in combination with
           CACHEGRIND_START_INSTRUMENTATION and
           CACHEGRIND_STOP_INSTRUMENTATION to measure only part of a
           client program's execution.

       <b>--I1=&lt;size&gt;,&lt;associativity&gt;,&lt;line size&gt;</b>
           Specify the size, associativity and line size of the level 1
           instruction cache. Only useful with <b>--cache-sim=yes</b>.

       <b>--D1=&lt;size&gt;,&lt;associativity&gt;,&lt;line size&gt;</b>
           Specify the size, associativity and line size of the level 1
           data cache. Only useful with <b>--cache-sim=yes</b>.

       <b>--LL=&lt;size&gt;,&lt;associativity&gt;,&lt;line size&gt;</b>
           Specify the size, associativity and line size of the
           last-level cache. Only useful with <b>--cache-sim=yes</b>.
</pre> <h2>
CALLGRIND OPTIONS </h2>
<pre>
       <b>--callgrind-out-file=&lt;file&gt;</b>
           Write the profile data to file rather than to the default
           output file, callgrind.out.&lt;pid&gt;. The <b>%p </b>and <b>%q </b>format
           specifiers can be used to embed the process ID and/or the
           contents of an environment variable in the name, as is the
           case for the core option <b>--log-file</b>. When multiple dumps are
           made, the file name is modified further; see below.

       <b>--dump-line=&lt;no|yes&gt; [default: yes]</b>
           This specifies that event counting should be performed at
           source line granularity. This allows source annotation for
           sources which are compiled with debug information (<b>-g</b>).

       <b>--dump-instr=&lt;no|yes&gt; [default: no]</b>
           This specifies that event counting should be performed at
           per-instruction granularity. This allows for assembly code
           annotation. Currently the results can only be displayed by
           KCachegrind.

       <b>--compress-strings=&lt;no|yes&gt; [default: yes]</b>
           This option influences the output format of the profile data.
           It specifies whether strings (file and function names) should
           be identified by numbers. This shrinks the file, but makes it
           more difficult for humans to read (which is not recommended
           in any case).

       <b>--compress-pos=&lt;no|yes&gt; [default: yes]</b>
           This option influences the output format of the profile data.
           It specifies whether numerical positions are always specified
           as absolute values or are allowed to be relative to previous
           numbers. This shrinks the file size.

       <b>--combine-dumps=&lt;no|yes&gt; [default: no]</b>
           When enabled, when multiple profile data parts are to be
           generated these parts are appended to the same output file.
           Not recommended.

       <b>--dump-every-bb=&lt;count&gt; [default: 0, never]</b>
           Dump profile data every <b>count </b>basic blocks. Whether a dump is
           needed is only checked when Valgrind's internal scheduler is
           run. Therefore, the minimum setting useful is about 100000.
           The count is a 64-bit value to make long dump periods
           possible.

       <b>--dump-before=&lt;function&gt;</b>
           Dump when entering <b>function</b>.

       <b>--zero-before=&lt;function&gt;</b>
           Zero all costs when entering <b>function</b>.

       <b>--dump-after=&lt;function&gt;</b>
           Dump when leaving <b>function</b>.

       <b>--instr-atstart=&lt;yes|no&gt; [default: yes]</b>
           Specify if you want Callgrind to start simulation and
           profiling from the beginning of the program. When set to no,
           Callgrind will not be able to collect any information,
           including calls, but it will have at most a slowdown of
           around 4, which is the minimum Valgrind overhead.
           Instrumentation can be interactively enabled via
           callgrind_control -i on.

           Note that the resulting call graph will most probably not
           contain <b>main</b>, but will contain all the functions executed
           after instrumentation was enabled. Instrumentation can also
           be programmatically enabled/disabled. See the Callgrind
           include file callgrind.h for the macro you have to use in
           your source code.

           For cache simulation, results will be less accurate when
           switching on instrumentation later in the program run, as the
           simulator starts with an empty cache at that moment. Switch
           on event collection later to cope with this error.

       <b>--collect-atstart=&lt;yes|no&gt; [default: yes]</b>
           Specify whether event collection is enabled at beginning of
           the profile run.

           To only look at parts of your program, you have two
           possibilities:

            1. Zero event counters before entering the program part you
               want to profile, and dump the event counters to a file
               after leaving that program part.

            2. Switch on/off collection state as needed to only see
               event counters happening while inside of the program part
               you want to profile.

           The second option can be used if the program part you want to
           profile is called many times. Option 1, i.e. creating a lot
           of dumps is not practical here.

           Collection state can be toggled at entry and exit of a given
           function with the option <b>--toggle-collect</b>. If you use this
           option, collection state should be disabled at the beginning.
           Note that the specification of <b>--toggle-collect </b>implicitly
           sets <b>--collect-state=no</b>.

           Collection state can be toggled also by inserting the client
           request CALLGRIND_TOGGLE_COLLECT ; at the needed code
           positions.

       <b>--toggle-collect=&lt;function&gt;</b>
           Toggle collection on entry/exit of <b>function</b>.

       <b>--collect-jumps=&lt;no|yes&gt; [default: no]</b>
           This specifies whether information for (conditional) jumps
           should be collected. As above, callgrind_annotate currently
           is not able to show you the data. You have to use KCachegrind
           to get jump arrows in the annotated code.

       <b>--collect-systime=&lt;no|yes|msec|usec|nsec&gt; [default: no]</b>
           This specifies whether information for system call times
           should be collected.

           The value no indicates to record no system call information.

           The other values indicate to record the number of system
           calls done (sysCount event) and the elapsed time (sysTime
           event) spent in system calls. The --collect-systime value
           gives the unit used for sysTime : milli seconds, micro
           seconds or nano seconds. With the value nsec, callgrind also
           records the cpu time spent during system calls (sysCpuTime).

           The value yes is a synonym of msec. The value nsec is not
           supported on Darwin.

       <b>--collect-bus=&lt;no|yes&gt; [default: no]</b>
           This specifies whether the number of global bus events
           executed should be collected. The event type "Ge" is used for
           these events.

       <b>--cache-sim=&lt;yes|no&gt; [default: no]</b>
           Specify if you want to do full cache simulation. By default,
           only instruction read accesses will be counted ("Ir"). With
           cache simulation, further event counters are enabled: Cache
           misses on instruction reads ("I1mr"/"ILmr"), data read
           accesses ("Dr") and related cache misses ("D1mr"/"DLmr"),
           data write accesses ("Dw") and related cache misses
           ("D1mw"/"DLmw"). For more information, see Cachegrind: a
           cache and branch-prediction profiler.

       <b>--branch-sim=&lt;yes|no&gt; [default: no]</b>
           Specify if you want to do branch prediction simulation.
           Further event counters are enabled: Number of executed
           conditional branches and related predictor misses
           ("Bc"/"Bcm"), executed indirect jumps and related misses of
           the jump address predictor ("Bi"/"Bim").
</pre> <h2>
HELGRIND OPTIONS </h2>
<pre>
       <b>--free-is-write=no|yes [default: no]</b>
           When enabled (not the default), Helgrind treats freeing of
           heap memory as if the memory was written immediately before
           the free. This exposes races where memory is referenced by
           one thread, and freed by another, but there is no observable
           synchronisation event to ensure that the reference happens
           before the free.

           This functionality is new in Valgrind 3.7.0, and is regarded
           as experimental. It is not enabled by default because its
           interaction with custom memory allocators is not well
           understood at present. User feedback is welcomed.

       <b>--track-lockorders=no|yes [default: yes]</b>
           When enabled (the default), Helgrind performs lock order
           consistency checking. For some buggy programs, the large
           number of lock order errors reported can become annoying,
           particularly if you're only interested in race errors. You
           may therefore find it helpful to disable lock order checking.

       <b>--history-level=none|approx|full [default: full]</b>
           <b>--history-level=full </b>(the default) causes Helgrind collects
           enough information about "old" accesses that it can produce
           two stack traces in a race report -- both the stack trace for
           the current access, and the trace for the older, conflicting
           access. To limit memory usage, "old" accesses stack traces
           are limited to a maximum of <i>--history-backtrace-size</i> entries
           (default 8) or to <b>--num-callers </b>value if this value is
           smaller.

           Collecting such information is expensive in both speed and
           memory, particularly for programs that do many inter-thread
           synchronisation events (locks, unlocks, etc). Without such
           information, it is more difficult to track down the root
           causes of races. Nonetheless, you may not need it in
           situations where you just want to check for the presence or
           absence of races, for example, when doing regression testing
           of a previously race-free program.

           <b>--history-level=none </b>is the opposite extreme. It causes
           Helgrind not to collect any information about previous
           accesses. This can be dramatically faster than
           <b>--history-level=full</b>.

           <b>--history-level=approx </b>provides a compromise between these
           two extremes. It causes Helgrind to show a full trace for the
           later access, and approximate information regarding the
           earlier access. This approximate information consists of two
           stacks, and the earlier access is guaranteed to have occurred
           somewhere between program points denoted by the two stacks.
           This is not as useful as showing the exact stack for the
           previous access (as <b>--history-level=full </b>does), but it is
           better than nothing, and it is almost as fast as
           <b>--history-level=none</b>.

       <b>--history-backtrace-size=&lt;number&gt; [default: 8]</b>
           When <i>--history-level=full</i> is selected,
           <i>--history-backtrace-size=number</i> indicates how many entries to
           record in "old" accesses stack traces.

       <b>--delta-stacktrace=no|yes [default: yes on linux amd64/x86]</b>
           This flag only has any effect at <b>--history-level=full</b>.

           <b>--delta-stacktrace </b>configures the way Helgrind captures the
           stacktraces for the option <b>--history-level=full</b>. Such a
           stacktrace is typically needed each time a new piece of
           memory is read or written in a basic block of instructions.

           <b>--delta-stacktrace=no </b>causes Helgrind to compute a full
           history stacktrace from the unwind info each time a
           stacktrace is needed.

           <b>--delta-stacktrace=yes </b>indicates to Helgrind to derive a new
           stacktrace from the previous stacktrace, as long as there was
           no call instruction, no return instruction, or any other
           instruction changing the call stack since the previous
           stacktrace was captured. If no such instruction was executed,
           the new stacktrace can be derived from the previous
           stacktrace by just changing the top frame to the current
           program counter. This option can speed up Helgrind by 25%
           when using <b>--history-level=full</b>.

           The following aspects have to be considered when using
           <b>--delta-stacktrace=yes </b>:

           •   In some cases (for example in a function prologue), the
               valgrind unwinder might not properly unwind the stack,
               due to some limitations and/or due to wrong unwind info.
               When using --delta-stacktrace=yes, the wrong stack trace
               captured in the function prologue will be kept till the
               next call or return.

           •   On the other hand, --delta-stacktrace=yes sometimes helps
               to obtain a correct stacktrace, for example when the
               unwind info allows a correct stacktrace to be done in the
               beginning of the sequence, but not later on in the
               instruction sequence.

           •   Determining which instructions are changing the callstack
               is partially based on platform dependent heuristics,
               which have to be tuned/validated specifically for the
               platform. Also, unwinding in a function prologue must be
               good enough to allow using --delta-stacktrace=yes.
               Currently, the option --delta-stacktrace=yes has been
               reasonably validated only on linux x86 32 bits and linux
               amd64 64 bits. For more details about how to validate
               --delta-stacktrace=yes, see debug option
               --hg-sanity-flags and the function check_cached_rcec_ok
               in libhb_core.c.

       <b>--conflict-cache-size=N [default: 1000000]</b>
           This flag only has any effect at <b>--history-level=full</b>.

           Information about "old" conflicting accesses is stored in a
           cache of limited size, with LRU-style management. This is
           necessary because it isn't practical to store a stack trace
           for every single memory access made by the program.
           Historical information on not recently accessed locations is
           periodically discarded, to free up space in the cache.

           This option controls the size of the cache, in terms of the
           number of different memory addresses for which conflicting
           access information is stored. If you find that Helgrind is
           showing race errors with only one stack instead of the
           expected two stacks, try increasing this value.

           The minimum value is 10,000 and the maximum is 30,000,000
           (thirty times the default value). Increasing the value by 1
           increases Helgrind's memory requirement by very roughly 100
           bytes, so the maximum value will easily eat up three extra
           gigabytes or so of memory.

       <b>--check-stack-refs=no|yes [default: yes]</b>
           By default Helgrind checks all data memory accesses made by
           your program. This flag enables you to skip checking for
           accesses to thread stacks (local variables). This can improve
           performance, but comes at the cost of missing races on
           stack-allocated data.

       <b>--ignore-thread-creation=&lt;yes|no&gt; [default: no]</b>
           Controls whether all activities during thread creation should
           be ignored. By default enabled only on Solaris. Solaris
           provides higher throughput, parallelism and scalability than
           other operating systems, at the cost of more fine-grained
           locking activity. This means for example that when a thread
           is created under glibc, just one big lock is used for all
           thread setup. Solaris libc uses several fine-grained locks
           and the creator thread resumes its activities as soon as
           possible, leaving for example stack and TLS setup sequence to
           the created thread. This situation confuses Helgrind as it
           assumes there is some false ordering in place between creator
           and created thread; and therefore many types of race
           conditions in the application would not be reported. To
           prevent such false ordering, this command line option is set
           to yes by default on Solaris. All activity (loads, stores,
           client requests) is therefore ignored during:

           •   pthread_create() call in the creator thread

           •   thread creation phase (stack and TLS setup) in the
               created thread

           Also new memory allocated during thread creation is
           untracked, that is race reporting is suppressed there. DRD
           does the same thing implicitly. This is necessary because
           Solaris libc caches many objects and reuses them for
           different threads and that confuses Helgrind.
</pre> <h2>
DRD OPTIONS </h2>
<pre>
       <b>--check-stack-var=&lt;yes|no&gt; [default: no]</b>
           Controls whether DRD detects data races on stack variables.
           Verifying stack variables is disabled by default because most
           programs do not share stack variables over threads.

       <b>--exclusive-threshold=&lt;n&gt; [default: off]</b>
           Print an error message if any mutex or writer lock has been
           held longer than the time specified in milliseconds. This
           option enables the detection of lock contention.

       <b>--join-list-vol=&lt;n&gt; [default: 10]</b>
           Data races that occur between a statement at the end of one
           thread and another thread can be missed if memory access
           information is discarded immediately after a thread has been
           joined. This option allows one to specify for how many joined
           threads memory access information should be retained.

        <b>--first-race-only=&lt;yes|no&gt; [default: no]</b>
           Whether to report only the first data race that has been
           detected on a memory location or all data races that have
           been detected on a memory location.

        <b>--free-is-write=&lt;yes|no&gt; [default: no]</b>
           Whether to report races between accessing memory and freeing
           memory. Enabling this option may cause DRD to run slightly
           slower. Notes:

           •   Don't enable this option when using custom memory
               allocators that use the VG_USERREQ__MALLOCLIKE_BLOCK and
               VG_USERREQ__FREELIKE_BLOCK because that would result in
               false positives.

           •   Don't enable this option when using reference-counted
               objects because that will result in false positives, even
               when that code has been annotated properly with
               ANNOTATE_HAPPENS_BEFORE and ANNOTATE_HAPPENS_AFTER. See
               e.g. the output of the following command for an example:
               valgrind --tool=drd --free-is-write=yes
               drd/tests/annotate_smart_pointer.

        <b>--report-signal-unlocked=&lt;yes|no&gt; [default: yes]</b>
           Whether to report calls to <b>pthread_cond_signal </b>and
           <b>pthread_cond_broadcast </b>where the mutex associated with the
           signal through <b>pthread_cond_wait </b>or <b>pthread_cond_timed_wait</b>is
           not locked at the time the signal is sent. Sending a signal
           without holding a lock on the associated mutex is a common
           programming error which can cause subtle race conditions and
           unpredictable behavior. There exist some uncommon
           synchronization patterns however where it is safe to send a
           signal without holding a lock on the associated mutex.

       <b>--segment-merging=&lt;yes|no&gt; [default: yes]</b>
           Controls segment merging. Segment merging is an algorithm to
           limit memory usage of the data race detection algorithm.
           Disabling segment merging may improve the accuracy of the
           so-called 'other segments' displayed in race reports but can
           also trigger an out of memory error.

       <b>--segment-merging-interval=&lt;n&gt; [default: 10]</b>
           Perform segment merging only after the specified number of
           new segments have been created. This is an advanced
           configuration option that allows one to choose whether to
           minimize DRD's memory usage by choosing a low value or to let
           DRD run faster by choosing a slightly higher value. The
           optimal value for this parameter depends on the program being
           analyzed. The default value works well for most programs.

       <b>--shared-threshold=&lt;n&gt; [default: off]</b>
           Print an error message if a reader lock has been held longer
           than the specified time (in milliseconds). This option
           enables the detection of lock contention.

       <b>--show-confl-seg=&lt;yes|no&gt; [default: yes]</b>
           Show conflicting segments in race reports. Since this
           information can help to find the cause of a data race, this
           option is enabled by default. Disabling this option makes the
           output of DRD more compact.

       <b>--show-stack-usage=&lt;yes|no&gt; [default: no]</b>
           Print stack usage at thread exit time. When a program creates
           a large number of threads it becomes important to limit the
           amount of virtual memory allocated for thread stacks. This
           option makes it possible to observe how much stack memory has
           been used by each thread of the client program. Note: the DRD
           tool itself allocates some temporary data on the client
           thread stack. The space necessary for this temporary data
           must be allocated by the client program when it allocates
           stack memory, but is not included in stack usage reported by
           DRD.

       <b>--ignore-thread-creation=&lt;yes|no&gt; [default: no]</b>
           Controls whether all activities during thread creation should
           be ignored. By default enabled only on Solaris. Solaris
           provides higher throughput, parallelism and scalability than
           other operating systems, at the cost of more fine-grained
           locking activity. This means for example that when a thread
           is created under glibc, just one big lock is used for all
           thread setup. Solaris libc uses several fine-grained locks
           and the creator thread resumes its activities as soon as
           possible, leaving for example stack and TLS setup sequence to
           the created thread. This situation confuses DRD as it assumes
           there is some false ordering in place between creator and
           created thread; and therefore many types of race conditions
           in the application would not be reported. To prevent such
           false ordering, this command line option is set to yes by
           default on Solaris. All activity (loads, stores, client
           requests) is therefore ignored during:

           •   pthread_create() call in the creator thread

           •   thread creation phase (stack and TLS setup) in the
               created thread

       <b>--trace-addr=&lt;address&gt; [default: none]</b>
           Trace all load and store activity for the specified address.
           This option may be specified more than once.

       <b>--ptrace-addr=&lt;address&gt; [default: none]</b>
           Trace all load and store activity for the specified address
           and keep doing that even after the memory at that address has
           been freed and reallocated.

       <b>--trace-alloc=&lt;yes|no&gt; [default: no]</b>
           Trace all memory allocations and deallocations. May produce a
           huge amount of output.

       <b>--trace-barrier=&lt;yes|no&gt; [default: no]</b>
           Trace all barrier activity.

       <b>--trace-cond=&lt;yes|no&gt; [default: no]</b>
           Trace all condition variable activity.

       <b>--trace-fork-join=&lt;yes|no&gt; [default: no]</b>
           Trace all thread creation and all thread termination events.

       <b>--trace-hb=&lt;yes|no&gt; [default: no]</b>
           Trace execution of the ANNOTATE_HAPPENS_BEFORE(),
           ANNOTATE_HAPPENS_AFTER() and ANNOTATE_HAPPENS_DONE() client
           requests.

       <b>--trace-mutex=&lt;yes|no&gt; [default: no]</b>
           Trace all mutex activity.

       <b>--trace-rwlock=&lt;yes|no&gt; [default: no]</b>
           Trace all reader-writer lock activity.

       <b>--trace-semaphore=&lt;yes|no&gt; [default: no]</b>
           Trace all semaphore activity.
</pre> <h2>
MASSIF OPTIONS </h2>
<pre>
       <b>--heap=&lt;yes|no&gt; [default: yes]</b>
           Specifies whether heap profiling should be done.

       <b>--heap-admin=&lt;size&gt; [default: 8]</b>
           If heap profiling is enabled, gives the number of
           administrative bytes per block to use. This should be an
           estimate of the average, since it may vary. For example, the
           allocator used by glibc on Linux requires somewhere between 4
           to 15 bytes per block, depending on various factors. That
           allocator also requires admin space for freed blocks, but
           Massif cannot account for this.

       <b>--stacks=&lt;yes|no&gt; [default: no]</b>
           Specifies whether stack profiling should be done. This option
           slows Massif down greatly, and so is off by default. Note
           that Massif assumes that the main stack has size zero at
           start-up. This is not true, but doing otherwise accurately is
           difficult. Furthermore, starting at zero better indicates the
           size of the part of the main stack that a user program
           actually has control over.

       <b>--pages-as-heap=&lt;yes|no&gt; [default: no]</b>
           Tells Massif to profile memory at the page level rather than
           at the malloc'd block level. See above for details.

       <b>--depth=&lt;number&gt; [default: 30]</b>
           Maximum depth of the allocation trees recorded for detailed
           snapshots. Increasing it will make Massif run somewhat more
           slowly, use more memory, and produce bigger output files.

       <b>--alloc-fn=&lt;name&gt;</b>
           Functions specified with this option will be treated as
           though they were a heap allocation function such as <b>malloc</b>.
           This is useful for functions that are wrappers to <b>malloc </b>or
           <b>new</b>, which can fill up the allocation trees with
           uninteresting information. This option can be specified
           multiple times on the command line, to name multiple
           functions.

           Note that the named function will only be treated this way if
           it is the top entry in a stack trace, or just below another
           function treated this way. For example, if you have a
           function <b>malloc1 </b>that wraps <b>malloc</b>, and <b>malloc2 </b>that wraps
           <b>malloc1</b>, just specifying <b>--alloc-fn=malloc2 </b>will have no
           effect. You need to specify <b>--alloc-fn=malloc1 </b>as well. This
           is a little inconvenient, but the reason is that checking for
           allocation functions is slow, and it saves a lot of time if
           Massif can stop looking through the stack trace entries as
           soon as it finds one that doesn't match rather than having to
           continue through all the entries.

           Note that C++ names are demangled. Note also that overloaded
           C++ names must be written in full. Single quotes may be
           necessary to prevent the shell from breaking them up. For
           example:

               --alloc-fn='operator new(unsigned, std::nothrow_t const&amp;)'

           Arguments of type size_t need to be replaced with unsigned
           long on 64bit platforms and unsigned on 32bit platforms.

           <b>--alloc-fn </b>will work with inline functions. Inline function
           names are not mangled, which means that you only need to
           provide the function name and not the argument list.

           <b>--alloc-fn </b>does not support wildcards.

       <b>--ignore-fn=&lt;name&gt;</b>
           Any direct heap allocation (i.e. a call to <b>malloc</b>, <b>new</b>, etc,
           or a call to a function named by an <b>--alloc-fn </b>option) that
           occurs in a function specified by this option will be
           ignored. This is mostly useful for testing purposes. This
           option can be specified multiple times on the command line,
           to name multiple functions.

           Any <b>realloc </b>of an ignored block will also be ignored, even if
           the <b>realloc </b>call does not occur in an ignored function. This
           avoids the possibility of negative heap sizes if ignored
           blocks are shrunk with <b>realloc</b>.

           The rules for writing C++ function names are the same as for
           <b>--alloc-fn </b>above.

       <b>--threshold=&lt;m.n&gt; [default: 1.0]</b>
           The significance threshold for heap allocations, as a
           percentage of total memory size. Allocation tree entries that
           account for less than this will be aggregated. Note that this
           should be specified in tandem with ms_print's option of the
           same name.

       <b>--peak-inaccuracy=&lt;m.n&gt; [default: 1.0]</b>
           Massif does not necessarily record the actual global memory
           allocation peak; by default it records a peak only when the
           global memory allocation size exceeds the previous peak by at
           least 1.0%. This is because there can be many local
           allocation peaks along the way, and doing a detailed snapshot
           for every one would be expensive and wasteful, as all but one
           of them will be later discarded. This inaccuracy can be
           changed (even to 0.0%) via this option, but Massif will run
           drastically slower as the number approaches zero.

       <b>--time-unit=&lt;i|ms|B&gt; [default: i]</b>
           The time unit used for the profiling. There are three
           possibilities: instructions executed (i), which is good for
           most cases; real (wallclock) time (ms, i.e. milliseconds),
           which is sometimes useful; and bytes allocated/deallocated on
           the heap and/or stack (B), which is useful for very short-run
           programs, and for testing purposes, because it is the most
           reproducible across different machines.

       <b>--detailed-freq=&lt;n&gt; [default: 10]</b>
           Frequency of detailed snapshots. With <b>--detailed-freq=1</b>,
           every snapshot is detailed.

       <b>--max-snapshots=&lt;n&gt; [default: 100]</b>
           The maximum number of snapshots recorded. If set to N, for
           all programs except very short-running ones, the final number
           of snapshots will be between N/2 and N.

       <b>--massif-out-file=&lt;file&gt; [default: massif.out.%p]</b>
           Write the profile data to file rather than to the default
           output file, massif.out.&lt;pid&gt;. The <b>%p </b>and <b>%q </b>format
           specifiers can be used to embed the process ID and/or the
           contents of an environment variable in the name, as is the
           case for the core option <b>--log-file</b>.
</pre> <h2>
BBV OPTIONS </h2>
<pre>
       <b>--bb-out-file=&lt;name&gt; [default: bb.out.%p]</b>
           This option selects the name of the basic block vector file.
           The <b>%p </b>and <b>%q </b>format specifiers can be used to embed the
           process ID and/or the contents of an environment variable in
           the name, as is the case for the core option <b>--log-file</b>.

       <b>--pc-out-file=&lt;name&gt; [default: pc.out.%p]</b>
           This option selects the name of the PC file. This file holds
           program counter addresses and function name info for the
           various basic blocks. This can be used in conjunction with
           the basic block vector file to fast-forward via function
           names instead of just instruction counts. The <b>%p </b>and <b>%q</b>
           format specifiers can be used to embed the process ID and/or
           the contents of an environment variable in the name, as is
           the case for the core option <b>--log-file</b>.

       <b>--interval-size=&lt;number&gt; [default: 100000000]</b>
           This option selects the size of the interval to use. The
           default is 100 million instructions, which is a commonly used
           value. Other sizes can be used; smaller intervals can help
           programs with finer-grained phases. However smaller interval
           size can lead to accuracy issues due to warm-up effects (When
           fast-forwarding the various architectural features will be
           un-initialized, and it will take some number of instructions
           before they "warm up" to the state a full simulation would be
           at without the fast-forwarding. Large interval sizes tend to
           mitigate this.)

       <b>--instr-count-only [default: no]</b>
           This option tells the tool to only display instruction count
           totals, and to not generate the actual basic block vector
           file. This is useful for debugging, and for gathering
           instruction count info without generating the large basic
           block vector files.
</pre> <h2>
LACKEY OPTIONS </h2>
<pre>
       <b>--basic-counts=&lt;no|yes&gt; [default: yes]</b>
           When enabled, Lackey prints the following statistics and
           information about the execution of the client program:

            1. The number of calls to the function specified by the
               <b>--fnname </b>option (the default is main). If the program has
               had its symbols stripped, the count will always be zero.

            2. The number of conditional branches encountered and the
               number and proportion of those taken.

            3. The number of superblocks entered and completed by the
               program. Note that due to optimisations done by the JIT,
               this is not at all an accurate value.

            4. The number of guest (x86, amd64, ppc, etc.) instructions
               and IR statements executed. IR is Valgrind's RISC-like
               intermediate representation via which all instrumentation
               is done.

            5. Ratios between some of these counts.

            6. The exit code of the client program.

       <b>--detailed-counts=&lt;no|yes&gt; [default: no]</b>
           When enabled, Lackey prints a table containing counts of
           loads, stores and ALU operations, differentiated by their IR
           types. The IR types are identified by their IR name ("I1",
           "I8", ... "I128", "F32", "F64", and "V128").

       <b>--trace-mem=&lt;no|yes&gt; [default: no]</b>
           When enabled, Lackey prints the size and address of almost
           every memory access made by the program. See the comments at
           the top of the file lackey/lk_main.c for details about the
           output format, how it works, and inaccuracies in the address
           trace. Note that this option produces immense amounts of
           output.

       <b>--trace-superblocks=&lt;no|yes&gt; [default: no]</b>
           When enabled, Lackey prints out the address of every
           superblock (a single entry, multiple exit, linear chunk of
           code) executed by the program. This is primarily of interest
           to Valgrind developers. See the comments at the top of the
           file lackey/lk_main.c for details about the output format.
           Note that this option produces large amounts of output.

       <b>--fnname=&lt;name&gt; [default: main]</b>
           Changes the function for which calls are counted when
           <b>--basic-counts=yes </b>is specified.
</pre> <h2>
DEBUGINFOD </h2>
<pre>
       Valgrind supports the downloading of debuginfo files via
       debuginfod, an HTTP server for distributing ELF/DWARF debugging
       information. When a debuginfo file cannot be found locally,
       Valgrind is able to query debuginfod servers for the file using
       the file's build-id.

       In order to use this feature debuginfod-find must be installed
       and the $DEBUGINFOD_URLS environment variable must contain
       space-separated URLs of debuginfod servers. Valgrind does not
       support debuginfod-find verbose output that is normally enabled
       with $DEBUGINFOD_PROGRESS and $DEBUGINFOD_VERBOSE. These
       environment variables will be ignored. This feature is supported
       on Linux only.

       For more information regarding debuginfod, see <b>Elfutils</b>
       <b>Debuginfod</b>[1] .
</pre> <h2>
SEE ALSO </h2>
<pre>
       <a href="cg_annotate.1.html">cg_annotate(1)</a>, <a href="callgrind_annotate.1.html">callgrind_annotate(1)</a>, <a href="callgrind_control.1.html">callgrind_control(1)</a>,
       <a href="ms_print.1.html">ms_print(1)</a>, $INSTALL/share/doc/valgrind/html/index.html or
       <a href="http://www.valgrind.org/docs/manual/index.html">http://www.valgrind.org/docs/manual/index.html</a>, <b>Debugging your</b>
       <b>program using Valgrind's gdbserver and GDB</b>[2] <b>vgdb</b>[3], <b>Valgrind</b>
       <b>monitor commands</b>[4], <b>The Commentary</b>[5], <b>Scheduling and</b>
       <b>Multi-Thread Performance</b>[6], <b>Cachegrind: a cache and</b>
       <b>branch-prediction profiler</b>[7].  <b>Execution Trees</b>[8]
</pre> <h2>
AUTHOR </h2>
<pre>
       See the AUTHORS file in the valgrind distribution for a
       comprehensive list of authors.

       This manpage was written by Andres Roldan &lt;aroldan@debian.org&gt;
       and the Valgrind developers.
</pre> <h2>
NOTES </h2>
<pre>
        1. Elfutils Debuginfod
           <a href="https://sourceware.org/elfutils/Debuginfod.html">https://sourceware.org/elfutils/Debuginfod.html</a>

        2. Debugging your program using Valgrind's gdbserver and GDB
           <a href="http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.gdbserver">http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.gdbserver</a>

        3. vgdb
           <a href="http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.vgdb">http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.vgdb</a>

        4. Valgrind monitor commands
           <a href="http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.valgrind-monitor-commands">http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.valgrind-monitor-commands</a>

        5. The Commentary
           <a href="http://www.valgrind.org/docs/manual/manual-core.html#manual-core.comment">http://www.valgrind.org/docs/manual/manual-core.html#manual-core.comment</a>

        6. Scheduling and Multi-Thread Performance
           <a href="http://www.valgrind.org/docs/manual/manual-core.html#manual-core.pthreads_perf_sched">http://www.valgrind.org/docs/manual/manual-core.html#manual-core.pthreads_perf_sched</a>

        7. Cachegrind: a cache and branch-prediction profiler
           <a href="http://www.valgrind.org/docs/manual/cg-manual.html">http://www.valgrind.org/docs/manual/cg-manual.html</a>

        8. Execution Trees
           <a href="http://www.valgrind.org/docs/manual/manual-core.html#manual-core.xtree">http://www.valgrind.org/docs/manual/manual-core.html#manual-core.xtree</a>
</pre> <h2>
COLOPHON </h2>
<pre>
       This page is part of the <i>valgrind</i> (a system for debugging and
       profiling Linux programs) project.  Information about the project
       can be found at ⟨<a href="http://www.valgrind.org/">http://www.valgrind.org/</a>⟩.  If you have a bug
       report for this manual page, see
       ⟨<a href="http://www.valgrind.org/support/bug_reports.html">http://www.valgrind.org/support/bug_reports.html</a>⟩.  This page
       was obtained from the project's upstream Git repository
       ⟨<a href="http://sourceware.org/git/valgrind.git">http://sourceware.org/git/valgrind.git</a>⟩ on 2024-06-14.  (At that
       time, the date of the most recent commit that was found in the
       repository was 2024-06-10.)  If you discover any rendering
       problems in this HTML version of the page, or you believe there
       is a better or more up-to-date source for the page, or you have
       corrections or improvements to the information in this COLOPHON
       (which is <i>not</i> part of the original manual page), send a mail to
       man-pages@man7.org

<span class="footline">Release 3.24.0.GIT             06/14/2024                    <i>VALGRIND</i>(1)</span>
</pre>  <p>Pages that refer to this page: <a href="callgrind_annotate.1.html">callgrind_annotate(1)</a>, <a href="callgrind_control.1.html">callgrind_control(1)</a>, <a href="cg_annotate.1.html">cg_annotate(1)</a>, <a href="cg_diff.1.html">cg_diff(1)</a>, <a href="cg_merge.1.html">cg_merge(1)</a>, <a href="dbpmda.1.html">dbpmda(1)</a>, <a href="ms_print.1.html">ms_print(1)</a>, <a href="valgrind-di-server.1.html">valgrind-di-server(1)</a>, <a href="valgrind-listener.1.html">valgrind-listener(1)</a>, <a href="vgdb.1.html">vgdb(1)</a>, <a href="../man3/malloc.3.html">malloc(3)</a>, <a href="../man8/ovs-ctl.8.html">ovs-ctl(8)</a> </p> <hr>         <div class="_attribution">
  <p class="_attribution-p">
    ...<br>
    <a href="https://man7.org/linux/man-pages/man1/valgrind.1.html" class="_attribution-link">https://man7.org/linux/man-pages/man1/valgrind.1.html</a>
  </p>
</div>
