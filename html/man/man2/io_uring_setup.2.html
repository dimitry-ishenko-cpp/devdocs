<h1>io_uring_setup(2) — Linux manual page</h1>   <pre>
<span class="headline"><i>io_uring_setup</i>(2)       Linux Programmer's Manual      <i>io_uring_setup</i>(2)</span>
</pre> <h2>
NAME </h2>
<pre>
       io_uring_setup - setup a context for performing asynchronous I/O
</pre> <h2>
SYNOPSIS </h2>
<pre>
       <b>#include &lt;liburing.h&gt;</b>

       <b>int io_uring_setup(u32 </b><i>entries</i><b>, struct io_uring_params *</b><i>p</i><b>);</b>
</pre> <h2>
DESCRIPTION </h2>
<pre>
       The <a href="io_uring_setup.2.html">io_uring_setup(2)</a> system call sets up a submission queue (SQ)
       and completion queue (CQ) with at least <i>entries</i> entries, and
       returns a file descriptor which can be used to perform subsequent
       operations on the io_uring instance.  The submission and
       completion queues are shared between userspace and the kernel,
       which eliminates the need to copy data when initiating and
       completing I/O.

       <i>params</i> is used by the application to pass options to the kernel,
       and by the kernel to convey information about the ring buffers.

           struct io_uring_params {
               __u32 sq_entries;
               __u32 cq_entries;
               __u32 flags;
               __u32 sq_thread_cpu;
               __u32 sq_thread_idle;
               __u32 features;
               __u32 wq_fd;
               __u32 resv[3];
               struct io_sqring_offsets sq_off;
               struct io_cqring_offsets cq_off;
           };

       The <i>flags</i>, <i>sq_thread_cpu</i>, and <i>sq_thread_idle</i> fields are used to
       configure the io_uring instance.  <i>flags</i> is a bit mask of 0 or
       more of the following values ORed together:

       <b>IORING_SETUP_IOPOLL</b>
              Perform busy-waiting for an I/O completion, as opposed to
              getting notifications via an asynchronous IRQ (Interrupt
              Request).  The file system (if any) and block device must
              support polling in order for this to work.  Busy-waiting
              provides lower latency, but may consume more CPU resources
              than interrupt driven I/O.  Currently, this feature is
              usable only on a file descriptor opened using the <b>O_DIRECT</b>
              flag.  When a read or write is submitted to a polled
              context, the application must poll for completions on the
              CQ ring by calling <a href="io_uring_enter.2.html">io_uring_enter(2)</a>.  It is illegal to
              mix and match polled and non-polled I/O on an io_uring
              instance.

              This is only applicable for storage devices for now, and
              the storage device must be configured for polling. How to
              do that depends on the device type in question. For NVMe
              devices, the nvme driver must be loaded with the
              <i>poll_queues</i> parameter set to the desired number of polling
              queues. The polling queues will be shared appropriately
              between the CPUs in the system, if the number is less than
              the number of online CPU threads.

       <b>IORING_SETUP_SQPOLL</b>
              When this flag is specified, a kernel thread is created to
              perform submission queue polling.  An io_uring instance
              configured in this way enables an application to issue I/O
              without ever context switching into the kernel.  By using
              the submission queue to fill in new submission queue
              entries and watching for completions on the completion
              queue, the application can submit and reap I/Os without
              doing a single system call.

              If the kernel thread is idle for more than <i>sq_thread_idle</i>
              milliseconds, it will set the <b>IORING_SQ_NEED_WAKEUP </b>bit in
              the <i>flags</i> field of the <i>struct io_sq_ring</i>.  When this
              happens, the application must call <a href="io_uring_enter.2.html">io_uring_enter(2)</a> to
              wake the kernel thread.  If I/O is kept busy, the kernel
              thread will never sleep.  An application making use of
              this feature will need to guard the <a href="io_uring_enter.2.html">io_uring_enter(2)</a> call
              with the following code sequence:

                  /*
                   * Ensure that the wakeup flag is read after the tail pointer
                   * has been written. It's important to use memory load acquire
                   * semantics for the flags read, as otherwise the application
                   * and the kernel might not agree on the consistency of the
                   * wakeup flag.
                   */
                  unsigned flags = atomic_load_relaxed(sq_ring-&gt;flags);
                  if (flags &amp; IORING_SQ_NEED_WAKEUP)
                      io_uring_enter(fd, 0, 0, IORING_ENTER_SQ_WAKEUP);

              where <i>sq_ring</i> is a submission queue ring setup using the
              <i>struct io_sqring_offsets</i> described below.

       Note that, when using a ring setup with
              <b>IORING_SETUP_SQPOLL, </b>you never directly call the
              <a href="io_uring_enter.2.html">io_uring_enter(2)</a> system call. That is usually taken care
              of by liburing's <a href="../man3/io_uring_submit.3.html">io_uring_submit(3)</a> function. It
              automatically determines if you are using polling mode or
              not and deals with when your program needs to call
              <a href="io_uring_enter.2.html">io_uring_enter(2)</a> without you having to bother about it.

       Before version 5.11 of the Linux kernel, to successfully use this
       feature, the
              application must register a set of files to be used for IO
              through <a href="io_uring_register.2.html">io_uring_register(2)</a> using the
              <b>IORING_REGISTER_FILES </b>opcode. Failure to do so will result
              in submitted IO being errored with <b>EBADF.  </b>The presence of
              this feature can be detected by the
              <b>IORING_FEAT_SQPOLL_NONFIXED </b>feature flag.  In version 5.11
              and later, it is no longer necessary to register files to
              use this feature. 5.11 also allows using this as non-root,
              if the user has the <b>CAP_SYS_NICE </b>capability. In 5.13 this
              requirement was also relaxed, and no special privileges
              are needed for SQPOLL in newer kernels. Certain stable
              kernels older than 5.13 may also support unprivileged
              SQPOLL.

       <b>IORING_SETUP_SQ_AFF</b>
              If this flag is specified, then the poll thread will be
              bound to the cpu set in the <i>sq_thread_cpu</i> field of the
              <i>struct io_uring_params</i>.  This flag is only meaningful when
              <b>IORING_SETUP_SQPOLL </b>is specified. When cgroup setting
              <i>cpuset.cpus</i> changes (typically in container environment),
              the bounded cpu set may be changed as well.

       <b>IORING_SETUP_CQSIZE</b>
              Create the completion queue with <i>struct</i>
              <i>io_uring_params.cq_entries</i> entries.  The value must be
              greater than <i>entries</i>, and may be rounded up to the next
              power-of-two.

       <b>IORING_SETUP_CLAMP</b>
              If this flag is specified, and if <i>entries</i> exceeds
              <b>IORING_MAX_ENTRIES</b>, then <i>entries</i> will be clamped at
              <b>IORING_MAX_ENTRIES</b>.  If the flag <b>IORING_SETUP_CQSIZE </b>is
              set, and if the value of <i>struct io_uring_params.cq_entries</i>
              exceeds <b>IORING_MAX_CQ_ENTRIES</b>, then it will be clamped at
              <b>IORING_MAX_CQ_ENTRIES</b>.

       <b>IORING_SETUP_ATTACH_WQ</b>
              This flag should be set in conjunction with <i>struct</i>
              <i>io_uring_params.wq_fd</i> being set to an existing io_uring
              ring file descriptor. When set, the io_uring instance
              being created will share the asynchronous worker thread
              backend of the specified io_uring ring, rather than create
              a new separate thread pool.

       <b>IORING_SETUP_R_DISABLED</b>
              If this flag is specified, the io_uring ring starts in a
              disabled state.  In this state, restrictions can be
              registered, but submissions are not allowed.  See
              <a href="io_uring_register.2.html">io_uring_register(2)</a> for details on how to enable the
              ring. Available since 5.10.

       <b>IORING_SETUP_SUBMIT_ALL</b>
              Normally io_uring stops submitting a batch of requests, if
              one of these requests results in an error. This can cause
              submission of less than what is expected, if a request
              ends in error while being submitted. If the ring is
              created with this flag, <a href="io_uring_enter.2.html">io_uring_enter(2)</a> will continue
              submitting requests even if it encounters an error
              submitting a request. CQEs are still posted for errored
              request regardless of whether or not this flag is set at
              ring creation time, the only difference is if the submit
              sequence is halted or continued when an error is observed.
              Available since 5.18.

       <b>IORING_SETUP_COOP_TASKRUN</b>
              By default, io_uring will interrupt a task running in
              userspace when a completion event comes in. This is to
              ensure that completions run in a timely manner. For a lot
              of use cases, this is overkill and can cause reduced
              performance from both the inter-processor interrupt used
              to do this, the kernel/user transition, the needless
              interruption of the tasks userspace activities, and
              reduced batching if completions come in at a rapid rate.
              Most applications don't need the forceful interruption, as
              the events are processed at any kernel/user transition.
              The exception are setups where the application uses
              multiple threads operating on the same ring, where the
              application waiting on completions isn't the one that
              submitted them. For most other use cases, setting this
              flag will improve performance. Available since 5.19.

       <b>IORING_SETUP_TASKRUN_FLAG</b>
              Used in conjunction with <b>IORING_SETUP_COOP_TASKRUN, </b>this
              provides a flag, <b>IORING_SQ_TASKRUN, </b>which is set in the SQ
              ring <i>flags</i> whenever completions are pending that should be
              processed. liburing will check for this flag even when
              doing <a href="../man3/io_uring_peek_cqe.3.html">io_uring_peek_cqe(3)</a> and enter the kernel to process
              them, and applications can do the same. This makes
              <b>IORING_SETUP_TASKRUN_FLAG </b>safe to use even when
              applications rely on a peek style operation on the CQ ring
              to see if anything might be pending to reap. Available
              since 5.19.

       <b>IORING_SETUP_SQE128</b>
              If set, io_uring will use 128-byte SQEs rather than the
              normal 64-byte sized variant. This is a requirement for
              using certain request types, as of 5.19 only the
              <b>IORING_OP_URING_CMD </b>passthrough command for NVMe
              passthrough needs this. Available since 5.19.

       <b>IORING_SETUP_CQE32</b>
              If set, io_uring will use 32-byte CQEs rather than the
              normal 16-byte sized variant. This is a requirement for
              using certain request types, as of 5.19 only the
              <b>IORING_OP_URING_CMD </b>passthrough command for NVMe
              passthrough needs this. Available since 5.19.

       <b>IORING_SETUP_SINGLE_ISSUER</b>
              A hint to the kernel that only a single task (or thread)
              will submit requests, which is used for internal
              optimisations. The submission task is either the task that
              created the ring, or if <b>IORING_SETUP_R_DISABLED </b>is
              specified then it is the task that enables the ring
              through <a href="io_uring_register.2.html">io_uring_register(2)</a>.  The kernel enforces this
              rule, failing requests with <b>-EEXIST </b>if the restriction is
              violated.  Note that when <b>IORING_SETUP_SQPOLL </b>is set it is
              considered that the polling task is doing all submissions
              on behalf of the userspace and so it always complies with
              the rule disregarding how many userspace tasks do
              <a href="io_uring_enter.2.html">io_uring_enter(2)</a>.  Available since 6.0.

       <b>IORING_SETUP_DEFER_TASKRUN</b>
              By default, io_uring will process all outstanding work at
              the end of any system call or thread interrupt. This can
              delay the application from making other progress.  Setting
              this flag will hint to io_uring that it should defer work
              until an <a href="io_uring_enter.2.html">io_uring_enter(2)</a> call with the
              <b>IORING_ENTER_GETEVENTS </b>flag set. This allows the
              application to request work to run just before it wants to
              process completions.  This flag requires the
              <b>IORING_SETUP_SINGLE_ISSUER </b>flag to be set, and also
              enforces that the call to <a href="io_uring_enter.2.html">io_uring_enter(2)</a> is called from
              the same thread that submitted requests.  Note that if
              this flag is set then it is the application's
              responsibility to periodically trigger work (for example
              via any of the CQE waiting functions) or else completions
              may not be delivered.  Available since 6.1.

       <b>IORING_SETUP_NO_MMAP</b>
              By default, io_uring allocates kernel memory that callers
              must subsequently <a href="mmap.2.html">mmap(2)</a>.  If this flag is set, io_uring
              instead uses caller-allocated buffers; <i>p-&gt;cq_off.user_addr</i>
              must point to the memory for the sq/cq rings, and
              <i>p-&gt;sq_off.user_addr</i> must point to the memory for the sqes.
              Each allocation must be contiguous memory.  Typically,
              callers should allocate this memory by using <a href="mmap.2.html">mmap(2)</a> to
              allocate a huge page.  If this flag is set, a subsequent
              attempt to <a href="mmap.2.html">mmap(2)</a> the io_uring file descriptor will fail.
              Available since 6.5.

       <b>IORING_SETUP_REGISTERED_FD_ONLY</b>
              If this flag is set, io_uring will register the ring file
              descriptor, and return the registered descriptor index,
              without ever allocating an unregistered file descriptor.
              The caller will need to use
              <b>IORING_REGISTER_USE_REGISTERED_RING </b>when calling
              <a href="io_uring_register.2.html">io_uring_register(2)</a>.  This flag only makes sense when
              used alongside with <b>IORING_SETUP_NO_MMAP, </b>which also needs
              to be set.  Available since 6.5.

       <b>IORING_SETUP_NO_SQARRAY</b>
              If this flag is set, entries in the submission queue will
              be submitted in order, wrapping around to the first entry
              after reaching the end of the queue. In other words, there
              will be no more indirection via the array of submission
              entries, and the queue will be indexed directly by the
              submission queue tail and the range of indexed represented
              by it modulo queue size. Subsequently, the user should not
              map the array of submission queue entries, and the
              corresponding offset in <i>struct io_sqring_offsets</i> will be
              set to zero. Available since 6.6.

       If no flags are specified, the io_uring instance is setup for
       interrupt driven I/O.  I/O may be submitted using
       <a href="io_uring_enter.2.html">io_uring_enter(2)</a> and can be reaped by polling the completion
       queue.

       The <i>resv</i> array must be initialized to zero.

       <i>features</i> is filled in by the kernel, which specifies various
       features supported by current kernel version.

       <b>IORING_FEAT_SINGLE_MMAP</b>
              If this flag is set, the two SQ and CQ rings can be mapped
              with a single <a href="mmap.2.html">mmap(2)</a> call. The SQEs must still be
              allocated separately. This brings the necessary <a href="mmap.2.html">mmap(2)</a>
              calls down from three to two. Available since kernel 5.4.

       <b>IORING_FEAT_NODROP</b>
              If this flag is set, io_uring supports almost never
              dropping completion events.  A dropped event can only
              occur if the kernel runs out of memory, in which case you
              have worse problems than a lost event. Your application
              and others will likely get OOM killed anyway. If a
              completion event occurs and the CQ ring is full, the
              kernel stores the event internally until such a time that
              the CQ ring has room for more entries. In earlier kernels,
              if this overflow condition is entered, attempting to
              submit more IO would fail with the <b>-EBUSY </b>error value, if
              it can't flush the overflown events to the CQ ring. If
              this happens, the application must reap events from the CQ
              ring and attempt the submit again. If the kernel has no
              free memory to store the event internally it will be
              visible by an increase in the overflow value on the
              cqring.  Available since kernel 5.5. Additionally
              <a href="io_uring_enter.2.html">io_uring_enter(2)</a> will return <b>-EBADR </b>the next time it
              would otherwise sleep waiting for completions (since
              kernel 5.19).

       <b>IORING_FEAT_SUBMIT_STABLE</b>
              If this flag is set, applications can be certain that any
              data for async offload has been consumed when the kernel
              has consumed the SQE. Available since kernel 5.5.

       <b>IORING_FEAT_RW_CUR_POS</b>
              If this flag is set, applications can specify <i>offset</i> == <b>-1</b>
              with <b>IORING_OP_{READV,WRITEV} </b>,
              <b>IORING_OP_{READ,WRITE}_FIXED </b>, and <b>IORING_OP_{READ,WRITE}</b>
              to mean current file position, which behaves like
              <a href="preadv2.2.html">preadv2(2)</a> and <a href="pwritev2.2.html">pwritev2(2)</a> with <i>offset</i> == <b>-1.  </b>It'll use
              (and update) the current file position. This obviously
              comes with the caveat that if the application has multiple
              reads or writes in flight, then the end result will not be
              as expected. This is similar to threads sharing a file
              descriptor and doing IO using the current file position.
              Available since kernel 5.6.

       <b>IORING_FEAT_CUR_PERSONALITY</b>
              If this flag is set, then io_uring guarantees that both
              sync and async execution of a request assumes the
              credentials of the task that called <i>io_uring_enter(2)</i> to
              queue the requests. If this flag isn't set, then requests
              are issued with the credentials of the task that
              originally registered the io_uring. If only one task is
              using a ring, then this flag doesn't matter as the
              credentials will always be the same. Note that this is the
              default behavior, tasks can still register different
              personalities through <i>io_uring_register(2)</i> with
              <b>IORING_REGISTER_PERSONALITY </b>and specify the personality to
              use in the sqe. Available since kernel 5.6.

       <b>IORING_FEAT_FAST_POLL</b>
              If this flag is set, then io_uring supports using an
              internal poll mechanism to drive data/space readiness.
              This means that requests that cannot read or write data to
              a file no longer need to be punted to an async thread for
              handling, instead they will begin operation when the file
              is ready. This is similar to doing poll + read/write in
              userspace, but eliminates the need to do so. If this flag
              is set, requests waiting on space/data consume a lot less
              resources doing so as they are not blocking a thread.
              Available since kernel 5.7.

       <b>IORING_FEAT_POLL_32BITS</b>
              If this flag is set, the <b>IORING_OP_POLL_ADD </b>command
              accepts the full 32-bit range of epoll based flags. Most
              notably <b>EPOLLEXCLUSIVE </b>which allows exclusive (waking
              single waiters) behavior. Available since kernel 5.9.

       <b>IORING_FEAT_SQPOLL_NONFIXED</b>
              If this flag is set, the <b>IORING_SETUP_SQPOLL </b>feature no
              longer requires the use of fixed files. Any normal file
              descriptor can be used for IO commands without needing
              registration. Available since kernel 5.11.

       <b>IORING_FEAT_ENTER_EXT_ARG</b>
              If this flag is set, then the <a href="io_uring_enter.2.html">io_uring_enter(2)</a> system
              call supports passing in an extended argument instead of
              just the <i>sigset_t</i> of earlier kernels. This.  extended
              argument is of type <i>struct io_uring_getevents_arg</i> and
              allows the caller to pass in both a <i>sigset_t</i> and a timeout
              argument for waiting on events. The struct layout is as
              follows:

               struct io_uring_getevents_arg {
                  __u64 sigmask;
                  __u32 sigmask_sz;
                  __u32 pad;
                  __u64 ts;
              };

              and a pointer to this struct must be passed in if
              <b>IORING_ENTER_EXT_ARG </b>is set in the flags for the enter
              system call. Available since kernel 5.11.

       <b>IORING_FEAT_NATIVE_WORKERS</b>
              If this flag is set, io_uring is using native workers for
              its async helpers.  Previous kernels used kernel threads
              that assumed the identity of the original io_uring owning
              task, but later kernels will actively create what looks
              more like regular process threads instead. Available since
              kernel 5.12.

       <b>IORING_FEAT_RSRC_TAGS</b>
              If this flag is set, then io_uring supports a variety of
              features related to fixed files and buffers. In
              particular, it indicates that registered buffers can be
              updated in-place, whereas before the full set would have
              to be unregistered first. Available since kernel 5.13.

       <b>IORING_FEAT_CQE_SKIP</b>
              If this flag is set, then io_uring supports setting
              <b>IOSQE_CQE_SKIP_SUCCESS </b>in the submitted SQE, indicating
              that no CQE should be generated for this SQE if it
              executes normally. If an error happens processing the SQE,
              a CQE with the appropriate error value will still be
              generated. Available since kernel 5.17.

       <b>IORING_FEAT_LINKED_FILE</b>
              If this flag is set, then io_uring supports sane
              assignment of files for SQEs that have dependencies. For
              example, if a chain of SQEs are submitted with
              <b>IOSQE_IO_LINK, </b>then kernels without this flag will prepare
              the file for each link upfront.  If a previous link opens
              a file with a known index, eg if direct descriptors are
              used with open or accept, then file assignment needs to
              happen post execution of that SQE. If this flag is set,
              then the kernel will defer file assignment until execution
              of a given request is started. Available since kernel
              5.17.

       <b>IORING_FEAT_REG_REG_RING</b>
              If this flag is set, then io_uring supports calling
              <a href="io_uring_register.2.html">io_uring_register(2)</a> using a registered ring fd, via
              <b>IORING_REGISTER_USE_REGISTERED_RING</b>.  Available since
              kernel 6.3.

       The rest of the fields in the <i>struct io_uring_params</i> are filled
       in by the kernel, and provide the information necessary to memory
       map the submission queue, completion queue, and the array of
       submission queue entries.  <i>sq_entries</i> specifies the number of
       submission queue entries allocated.  <i>sq_off</i> describes the offsets
       of various ring buffer fields:

           struct io_sqring_offsets {
               __u32 head;
               __u32 tail;
               __u32 ring_mask;
               __u32 ring_entries;
               __u32 flags;
               __u32 dropped;
               __u32 array;
               __u32 resv1;
               __u64 user_addr;
           };

       Taken together, <i>sq_entries</i> and <i>sq_off</i> provide all of the
       information necessary for accessing the submission queue ring
       buffer and the submission queue entry array.  The submission
       queue can be mapped with a call like:

           ptr = mmap(0, sq_off.array + sq_entries * sizeof(__u32),
                      PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE,
                      ring_fd, IORING_OFF_SQ_RING);

       where <i>sq_off</i> is the <i>io_sqring_offsets</i> structure, and <i>ring_fd</i> is
       the file descriptor returned from <a href="io_uring_setup.2.html">io_uring_setup(2)</a>.  The
       addition of <i>sq_off.array</i> to the length of the region accounts for
       the fact that the ring is located at the end of the data
       structure.  As an example, the ring buffer head pointer can be
       accessed by adding <i>sq_off.head</i> to the address returned from
       <a href="mmap.2.html">mmap(2)</a>:

           head = ptr + sq_off.head;

       The <i>flags</i> field is used by the kernel to communicate state
       information to the application.  Currently, it is used to inform
       the application when a call to <a href="io_uring_enter.2.html">io_uring_enter(2)</a> is necessary.
       See the documentation for the <b>IORING_SETUP_SQPOLL </b>flag above.
       The <i>dropped</i> member is incremented for each invalid submission
       queue entry encountered in the ring buffer.

       The head and tail track the ring buffer state.  The tail is
       incremented by the application when submitting new I/O, and the
       head is incremented by the kernel when the I/O has been
       successfully submitted.  Determining the index of the head or
       tail into the ring is accomplished by applying a mask:

           index = tail &amp; ring_mask;

       The array of submission queue entries is mapped with:

           sqentries = mmap(0, sq_entries * sizeof(struct io_uring_sqe),
                            PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE,
                            ring_fd, IORING_OFF_SQES);

       The completion queue is described by <i>cq_entries</i> and <i>cq_off</i> shown
       here:

           struct io_cqring_offsets {
               __u32 head;
               __u32 tail;
               __u32 ring_mask;
               __u32 ring_entries;
               __u32 overflow;
               __u32 cqes;
               __u32 flags;
               __u32 resv1;
               __u64 user_addr;
           };

       The completion queue is simpler, since the entries are not
       separated from the queue itself, and can be mapped with:

           ptr = mmap(0, cq_off.cqes + cq_entries * sizeof(struct io_uring_cqe),
                      PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, ring_fd,
                      IORING_OFF_CQ_RING);

       Closing the file descriptor returned by <a href="io_uring_setup.2.html">io_uring_setup(2)</a> will
       free all resources associated with the io_uring context. Note
       that this may happen asynchronously within the kernel, so it is
       not guaranteed that resources are freed immediately.
</pre> <h2>
RETURN VALUE </h2>
<pre>
       <a href="io_uring_setup.2.html">io_uring_setup(2)</a> returns a new file descriptor on success.  The
       application may then provide the file descriptor in a subsequent
       <a href="mmap.2.html">mmap(2)</a> call to map the submission and completion queues, or to
       the <a href="io_uring_register.2.html">io_uring_register(2)</a> or <a href="io_uring_enter.2.html">io_uring_enter(2)</a> system calls.

       On error, a negative error code is returned. The caller should
       not rely on <i><a href="../man3/errno.3.html">errno</a></i> variable.
</pre> <h2>
ERRORS </h2>
<pre>
       <b>EFAULT </b>params is outside your accessible address space.

       <b>EINVAL </b>The resv array contains non-zero data, p.flags contains an
              unsupported flag, <i>entries</i> is out of bounds,
              <b>IORING_SETUP_SQ_AFF </b>was specified, but <b>IORING_SETUP_SQPOLL</b>
              was not, or <b>IORING_SETUP_CQSIZE </b>was specified, but
              <i>io_uring_params.cq_entries</i> was invalid.
              <b>IORING_SETUP_REGISTERED_FD_ONLY </b>was specified, but
              <b>IORING_SETUP_NO_MMAP </b>was not.

       <b>EMFILE </b>The per-process limit on the number of open file
              descriptors has been reached (see the description of
              <b>RLIMIT_NOFILE </b>in <a href="getrlimit.2.html">getrlimit(2)</a>).

       <b>ENFILE </b>The system-wide limit on the total number of open files
              has been reached.

       <b>ENOMEM </b>Insufficient kernel resources are available.

       <b>EPERM  IORING_SETUP_SQPOLL </b>was specified, but the effective user
              ID of the caller did not have sufficient privileges.

       <b>EPERM  </b><i>/proc/sys/kernel/io_uring_disabled</i> has the value 2, or it
              has the value 1 and the calling process does not hold the
              <b>CAP_SYS_ADMIN </b>capability or is not a member of
              <i>/proc/sys/kernel/io_uring_group.</i>
</pre> <h2>
SEE ALSO </h2>
<pre>
       <a href="io_uring_register.2.html">io_uring_register(2)</a>, <a href="io_uring_enter.2.html">io_uring_enter(2)</a>
</pre> <h2>
COLOPHON </h2>
<pre>
       This page is part of the <i>liburing</i> (A library for io_uring)
       project.  Information about the project can be found at 
       ⟨<a href="https://github.com/axboe/liburing">https://github.com/axboe/liburing</a>⟩.  If you have a bug report for
       this manual page, send it to io-uring@vger.kernel.org.  This page
       was obtained from the project's upstream Git repository
       ⟨<a href="https://github.com/axboe/liburing">https://github.com/axboe/liburing</a>⟩ on 2024-06-14.  (At that
       time, the date of the most recent commit that was found in the
       repository was 2024-06-03.)  If you discover any rendering
       problems in this HTML version of the page, or you believe there
       is a better or more up-to-date source for the page, or you have
       corrections or improvements to the information in this COLOPHON
       (which is <i>not</i> part of the original manual page), send a mail to
       man-pages@man7.org

<span class="footline">Linux                          2019-01-29              <i>io_uring_setup</i>(2)</span>
</pre>  <p>Pages that refer to this page: <a href="io_uring_enter2.2.html">io_uring_enter2(2)</a>, <a href="io_uring_enter.2.html">io_uring_enter(2)</a>, <a href="io_uring_register.2.html">io_uring_register(2)</a>, <a href="io_uring_setup.2.html">io_uring_setup(2)</a>, <a href="syscalls.2.html">syscalls(2)</a>, <a href="../man3/io_uring_queue_exit.3.html">io_uring_queue_exit(3)</a>, <a href="../man3/io_uring_queue_init.3.html">io_uring_queue_init(3)</a>, <a href="../man3/io_uring_queue_init_mem.3.html">io_uring_queue_init_mem(3)</a>, <a href="../man3/io_uring_queue_init_params.3.html">io_uring_queue_init_params(3)</a>, <a href="../man7/io_uring.7.html">io_uring(7)</a> </p> <hr>         <div class="_attribution">
  <p class="_attribution-p">
    ...<br>
    <a href="https://man7.org/linux/man-pages/man2/io_uring_setup.2.html" class="_attribution-link">https://man7.org/linux/man-pages/man2/io_uring_setup.2.html</a>
  </p>
</div>
