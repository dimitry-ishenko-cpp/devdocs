<h1 id="varnish-counters-7">varnish-counters</h1> <section id="varnish-counter-field-definitions"> <h2>Varnish counter field definitions</h2> <dl class="field-list simple"> <dt class="field-odd">Manual section<span class="colon">:</span>
</dt> <dd class="field-odd">
<p>7</p> </dd> </dl> <section id="lck-lock-counters"> <h3>LCK – Lock Counters</h3>  <p>Counters which track the activity in the different classes of mutex-locks.</p> <p>The counts may be slightly wrong if there are more than one lock instantiated in each class (ie: .creat &gt; 1)</p>  <p><code>creat</code> – <code>counter</code> - debug</p>  <p>Created locks</p>  <p><code>destroy</code> – <code>counter</code> - debug</p>  <p>Destroyed locks</p>  <p><code>locks</code> – <code>counter</code> - debug</p>  <p>Lock Operations</p>  <p><code>dbg_busy</code> – <code>counter</code> - debug</p>  <p>Contended lock operations</p> <p>If the <code>lck</code> debug bit is set: Lock operations which returned EBUSY on the first locking attempt.</p> <p>If the <code>lck</code> debug bit is unset, this counter will never be incremented even if lock operations are contended.</p>  <p><code>dbg_try_fail</code> – <code>counter</code> - debug</p>  <p>Contended trylock operations</p> <p>If the <code>lck</code> debug bit is set: Trylock operations which returned EBUSY.</p> <p>If the <code>lck</code> debug bit is unset, this counter will never be incremented even if lock operations are contended.</p>  </section> <section id="main-main-counters"> <h3>MAIN – Main counters</h3> <p><code>summs</code> – <code>counter</code> - debug</p>  <p>stat summ operations</p> <p>Number of times per-thread statistics were summed into the global counters.</p>  <p><code>uptime</code> – <code>counter</code> - info</p>  <p>Child process uptime</p> <p>How long the child process has been running.</p>  <p><code>sess_conn</code> – <code>counter</code> - info</p>  <p>Sessions accepted</p> <p>Count of sessions successfully accepted</p>  <p><code>sess_fail</code> – <code>counter</code> - info</p>  <p>Session accept failures</p> <p>Count of failures to accept TCP connection.</p> <p>This counter is the sum of the sess_fail_* counters, which give more detailed information.</p>  <p><code>sess_fail_econnaborted</code> – <code>counter</code> - info</p>  <p>Session accept failures: connection aborted</p> <p>Detailed reason for sess_fail: Connection aborted by the client, usually harmless.</p>  <p><code>sess_fail_eintr</code> – <code>counter</code> - info</p>  <p>Session accept failures: interrupted system call</p> <p>Detailed reason for sess_fail: The accept() call was interrupted, usually harmless</p>  <p><code>sess_fail_emfile</code> – <code>counter</code> - info</p>  <p>Session accept failures: too many open files</p> <p>Detailed reason for sess_fail: No file descriptor was available. Consider raising RLIMIT_NOFILE (see ulimit -n).</p>  <p><code>sess_fail_ebadf</code> – <code>counter</code> - info</p>  <p>Session accept failures: bad file descriptor</p> <p>Detailed reason for sess_fail: The listen socket file descriptor was invalid. Should never happen.</p>  <p><code>sess_fail_enomem</code> – <code>counter</code> - info</p>  <p>Session accept failures: not enough memory</p> <p>Detailed reason for sess_fail: Most likely insufficient socket buffer memory. Should never happen</p>  <p><code>sess_fail_other</code> – <code>counter</code> - info</p>  <p>Session accept failures: other</p> <p>Detailed reason for sess_fail: neither of the above, see SessError log (varnishlog -g raw -i SessError).</p>  <p><code>client_req_400</code> – <code>counter</code> - info</p>  <p>Client requests received, subject to 400 errors</p> <p>400 means we couldn’t make sense of the request, it was malformed in some drastic way.</p>  <p><code>client_req_417</code> – <code>counter</code> - info</p>  <p>Client requests received, subject to 417 errors</p> <p>417 means that something went wrong with an Expect: header.</p>  <p><code>client_req</code> – <code>counter</code> - info</p>  <p>Good client requests received</p> <p>The count of parseable client requests seen.</p>  <p><code>esi_req</code> – <code>counter</code> - info</p>  <p>ESI subrequests</p> <p>Number of ESI subrequests made.</p>  <p><code>cache_hit</code> – <code>counter</code> - info</p>  <p>Cache hits</p> <p>Count of cache hits. A cache hit indicates that an object has been delivered to a client without fetching it from a backend server.</p>  <p><code>cache_hit_grace</code> – <code>counter</code> - info</p>  <p>Cache grace hits</p> <p>Count of cache hits with grace. A cache hit with grace is a cache hit where the object is expired. Note that such hits are also included in the cache_hit counter.</p>  <p><code>cache_hitpass</code> – <code>counter</code> - info</p>  <p>Cache hits for pass.</p> <p>Count of hits for pass. A cache hit for pass indicates that Varnish is going to pass the request to the backend and this decision has been cached in it self. This counts how many times the cached decision is being used.</p>  <p><code>cache_hitmiss</code> – <code>counter</code> - info</p>  <p>Cache hits for miss.</p> <p>Count of hits for miss. A cache hit for miss indicates that Varnish is going to proceed as for a cache miss without request coalescing, and this decision has been cached. This counts how many times the cached decision is being used.</p>  <p><code>cache_miss</code> – <code>counter</code> - info</p>  <p>Cache misses</p> <p>Count of misses. A cache miss indicates the object was fetched from the backend before delivering it to the client.</p>  <p><code>beresp_uncacheable</code> – <code>counter</code> - info</p>   <p>Uncacheable backend responses</p>  <p>Count of backend responses considered uncacheable.</p>  <p><code>beresp_shortlived</code> – <code>counter</code> - info</p>   <p>Shortlived objects</p>  <p>Count of objects created with ttl+grace+keep shorter than the ‘shortlived’ runtime parameter.</p>  <p><code>backend_conn</code> – <code>counter</code> - info</p>  <p>Backend conn. success</p> <p>How many backend connections have successfully been established.</p>  <p><code>backend_unhealthy</code> – <code>counter</code> - info</p>  <p>Backend conn. not attempted</p>  <p><code>backend_busy</code> – <code>counter</code> - info</p>  <p>Backend conn. too many</p>  <p><code>backend_fail</code> – <code>counter</code> - info</p>  <p>Backend conn. failures</p>  <p><code>backend_reuse</code> – <code>counter</code> - info</p>  <p>Backend conn. reuses</p> <p>Count of backend connection reuses. This counter is increased whenever we reuse a recycled connection.</p>  <p><code>backend_recycle</code> – <code>counter</code> - info</p>  <p>Backend conn. recycles</p> <p>Count of backend connection recycles. This counter is increased whenever we have a keep-alive connection that is put back into the pool of connections. It has not yet been used, but it might be, unless the backend closes it.</p>  <p><code>backend_retry</code> – <code>counter</code> - info</p>  <p>Backend conn. retry</p>  <p><code>fetch_head</code> – <code>counter</code> - info</p>  <p>Fetch no body (HEAD)</p> <p>beresp with no body because the request is HEAD.</p>  <p><code>fetch_length</code> – <code>counter</code> - info</p>  <p>Fetch with Length</p> <p>beresp.body with Content-Length.</p>  <p><code>fetch_chunked</code> – <code>counter</code> - info</p>  <p>Fetch chunked</p> <p>beresp.body with Chunked.</p>  <p><code>fetch_eof</code> – <code>counter</code> - info</p>  <p>Fetch EOF</p> <p>beresp.body with EOF.</p>  <p><code>fetch_bad</code> – <code>counter</code> - info</p>  <p>Fetch bad T-E</p> <p>beresp.body length/fetch could not be determined.</p>  <p><code>fetch_none</code> – <code>counter</code> - info</p>  <p>Fetch no body</p> <p>beresp.body empty</p>  <p><code>fetch_1xx</code> – <code>counter</code> - info</p>  <p>Fetch no body (1xx)</p> <p>beresp with no body because of 1XX response.</p>  <p><code>fetch_204</code> – <code>counter</code> - info</p>  <p>Fetch no body (204)</p> <p>beresp with no body because of 204 response.</p>  <p><code>fetch_304</code> – <code>counter</code> - info</p>  <p>Fetch no body (304)</p> <p>beresp with no body because of 304 response.</p>  <p><code>fetch_failed</code> – <code>counter</code> - info</p>  <p>Fetch failed (all causes)</p> <p>beresp fetch failed.</p>  <p><code>bgfetch_no_thread</code> – <code>counter</code> - info</p>  <p>Background fetch failed (no thread)</p> <p>A bgfetch triggered by a grace hit failed, no thread available.</p>  <p><code>pools</code> – <code>gauge</code> - info</p>  <p>Number of thread pools</p> <p>Number of thread pools. See also parameter thread_pools. NB: Presently pools cannot be removed once created.</p>  <p><code>threads</code> – <code>gauge</code> - info</p>  <p>Total number of threads</p> <p>Number of threads in all pools. See also parameters thread_pools, thread_pool_min and thread_pool_max.</p>  <p><code>threads_limited</code> – <code>counter</code> - info</p>  <p>Threads hit max</p> <p>Number of times more threads were needed, but limit was reached in a thread pool. See also parameter thread_pool_max.</p>  <p><code>threads_created</code> – <code>counter</code> - info</p>  <p>Threads created</p> <p>Total number of threads created in all pools.</p>  <p><code>threads_destroyed</code> – <code>counter</code> - info</p>  <p>Threads destroyed</p> <p>Total number of threads destroyed in all pools.</p>  <p><code>threads_failed</code> – <code>counter</code> - info</p>  <p>Thread creation failed</p> <p>Number of times creating a thread failed. See VSL::Debug for diagnostics. See also parameter thread_fail_delay.</p>  <p><code>thread_queue_len</code> – <code>gauge</code> - info</p>  <p>Length of session queue</p> <p>Length of session queue waiting for threads. NB: Only updates once per second. See also parameter thread_queue_limit.</p>  <p><code>busy_sleep</code> – <code>counter</code> - info</p>  <p>Number of requests sent to sleep on busy objhdr</p> <p>Number of requests sent to sleep without a worker thread because they found a busy object.</p>  <p><code>busy_wakeup</code> – <code>counter</code> - info</p>  <p>Number of requests woken after sleep on busy objhdr</p> <p>Number of requests taken off the busy object sleep list and rescheduled.</p>  <p><code>busy_killed</code> – <code>counter</code> - info</p>  <p>Number of requests killed after sleep on busy objhdr</p> <p>Number of requests killed from the busy object sleep list due to lack of resources.</p>  <p><code>sess_queued</code> – <code>counter</code> - info</p>  <p>Sessions queued for thread</p> <p>Number of times session was queued waiting for a thread. See also parameter thread_queue_limit.</p>  <p><code>sess_dropped</code> – <code>counter</code> - info</p>  <p>Sessions dropped for thread</p> <p>Number of times an HTTP/1 session was dropped because the queue was too long already. See also parameter thread_queue_limit.</p>  <p><code>req_dropped</code> – <code>counter</code> - info</p>  <p>Requests dropped</p> <p>Number of times an HTTP/2 stream was refused because the queue was too long already. See also parameter thread_queue_limit.</p>  <p><code>n_object</code> – <code>gauge</code> - info</p>  <p>object structs made</p> <p>Approximate number of HTTP objects (headers + body, if present) in the cache.</p>  <p><code>n_vampireobject</code> – <code>gauge</code> - diag</p>  <p>unresurrected objects</p> <p>Number of unresurrected objects</p>  <p><code>n_objectcore</code> – <code>gauge</code> - info</p>  <p>objectcore structs made</p> <p>Approximate number of object metadata elements in the cache. Each object needs an objectcore, extra objectcores are for hit-for-miss, hit-for-pass and busy objects.</p>  <p><code>n_objecthead</code> – <code>gauge</code> - info</p>  <p>objecthead structs made</p> <p>Approximate number of different hash entries in the cache.</p>  <p><code>n_backend</code> – <code>gauge</code> - info</p>  <p>Number of backends</p> <p>Number of backends known to us.</p>  <p><code>n_expired</code> – <code>counter</code> - info</p>  <p>Number of expired objects</p> <p>Number of objects that expired from cache because of old age.</p>  <p><code>n_lru_nuked</code> – <code>counter</code> - info</p>  <p>Number of LRU nuked objects</p> <p>How many objects have been forcefully evicted from storage to make room for a new object.</p>  <p><code>n_lru_moved</code> – <code>counter</code> - diag</p>  <p>Number of LRU moved objects</p> <p>Number of move operations done on the LRU list.</p>  <p><code>n_lru_limited</code> – <code>counter</code> - info</p>  <p>Reached nuke_limit</p> <p>Number of times more storage space were needed, but limit was reached in a nuke_limit. See also parameter nuke_limit.</p>  <p><code>losthdr</code> – <code>counter</code> - info</p>  <p>HTTP header overflows</p>  <p><code>s_sess</code> – <code>counter</code> - info</p>  <p>Total sessions seen</p>  <p><code>n_pipe</code> – <code>gauge</code> - info</p>  <p>Number of ongoing pipe sessions</p>  <p><code>pipe_limited</code> – <code>counter</code> - info</p>  <p>Pipes hit pipe_sess_max</p> <p>Number of times more pipes were needed, but the limit was reached. See also parameter pipe_sess_max.</p>  <p><code>s_pipe</code> – <code>counter</code> - info</p>  <p>Total pipe sessions seen</p>  <p><code>s_pass</code> – <code>counter</code> - info</p>  <p>Total pass-ed requests seen</p>  <p><code>s_fetch</code> – <code>counter</code> - info</p>  <p>Total backend fetches initiated</p> <p>Total backend fetches initiated, including background fetches.</p>  <p><code>s_bgfetch</code> – <code>counter</code> - info</p>  <p>Total backend background fetches initiated</p>  <p><code>s_synth</code> – <code>counter</code> - info</p>  <p>Total synthetic responses made</p>  <p><code>s_req_hdrbytes</code> – <code>counter</code> - info</p>  <p>Request header bytes</p> <p>Total request header bytes received</p>  <p><code>s_req_bodybytes</code> – <code>counter</code> - info</p>  <p>Request body bytes</p> <p>Total request body bytes received</p>  <p><code>s_resp_hdrbytes</code> – <code>counter</code> - info</p>  <p>Response header bytes</p> <p>Total response header bytes transmitted</p>  <p><code>s_resp_bodybytes</code> – <code>counter</code> - info</p>  <p>Response body bytes</p> <p>Total response body bytes transmitted</p>  <p><code>s_pipe_hdrbytes</code> – <code>counter</code> - info</p>  <p>Pipe request header bytes</p> <p>Total request bytes received for piped sessions</p>  <p><code>s_pipe_in</code> – <code>counter</code> - info</p>  <p>Piped bytes from client</p> <p>Total number of bytes forwarded from clients in pipe sessions</p>  <p><code>s_pipe_out</code> – <code>counter</code> - info</p>  <p>Piped bytes to client</p> <p>Total number of bytes forwarded to clients in pipe sessions</p>  <p><code>sess_closed</code> – <code>counter</code> - info</p>  <p>Session Closed</p>  <p><code>sess_closed_err</code> – <code>counter</code> - info</p>  <p>Session Closed with error</p> <p>Total number of sessions closed with errors. See sc_* diag counters for detailed breakdown</p>  <p><code>sess_readahead</code> – <code>counter</code> - info</p>  <p>Session Read Ahead</p>  <p><code>sess_herd</code> – <code>counter</code> - diag</p>  <p>Session herd</p> <p>Number of times the timeout_linger triggered</p>  <p><code>sc_rem_close</code> – <code>counter</code> - diag</p>  <p>Session OK REM_CLOSE</p> <p>Number of session closes with REM_CLOSE (Client Closed)</p>  <p><code>sc_req_close</code> – <code>counter</code> - diag</p>  <p>Session OK REQ_CLOSE</p> <p>Number of session closes with REQ_CLOSE (Client requested close)</p>  <p><code>sc_req_http10</code> – <code>counter</code> - diag</p>  <p>Session Err REQ_HTTP10</p> <p>Number of session closes with Error REQ_HTTP10 (Proto &lt; HTTP/1.1)</p>  <p><code>sc_rx_bad</code> – <code>counter</code> - diag</p>  <p>Session Err RX_BAD</p> <p>Number of session closes with Error RX_BAD (Received bad req/resp)</p>  <p><code>sc_rx_body</code> – <code>counter</code> - diag</p>  <p>Session Err RX_BODY</p> <p>Number of session closes with Error RX_BODY (Failure receiving req.body)</p>  <p><code>sc_rx_junk</code> – <code>counter</code> - diag</p>  <p>Session Err RX_JUNK</p> <p>Number of session closes with Error RX_JUNK (Received junk data)</p>  <p><code>sc_rx_overflow</code> – <code>counter</code> - diag</p>  <p>Session Err RX_OVERFLOW</p> <p>Number of session closes with Error RX_OVERFLOW (Received buffer overflow)</p>  <p><code>sc_rx_timeout</code> – <code>counter</code> - diag</p>  <p>Session Err RX_TIMEOUT</p> <p>Number of session closes with Error RX_TIMEOUT (Receive timeout)</p>  <p><code>sc_rx_close_idle</code> – <code>counter</code> - diag</p>  <p>Session Err RX_CLOSE_IDLE</p> <p>Number of session closes with Error RX_CLOSE_IDLE: timeout_idle has been exceeded while waiting for a client request.</p>  <p><code>sc_tx_pipe</code> – <code>counter</code> - diag</p>  <p>Session OK TX_PIPE</p> <p>Number of session closes with TX_PIPE (Piped transaction)</p>  <p><code>sc_tx_error</code> – <code>counter</code> - diag</p>  <p>Session Err TX_ERROR</p> <p>Number of session closes with Error TX_ERROR (Error transaction)</p>  <p><code>sc_tx_eof</code> – <code>counter</code> - diag</p>  <p>Session OK TX_EOF</p> <p>Number of session closes with TX_EOF (EOF transmission)</p>  <p><code>sc_resp_close</code> – <code>counter</code> - diag</p>  <p>Session OK RESP_CLOSE</p> <p>Number of session closes with RESP_CLOSE (Backend/VCL requested close)</p>  <p><code>sc_overload</code> – <code>counter</code> - diag</p>  <p>Session Err OVERLOAD</p> <p>Number of session closes with Error OVERLOAD (Out of some resource)</p>  <p><code>sc_pipe_overflow</code> – <code>counter</code> - diag</p>  <p>Session Err PIPE_OVERFLOW</p> <p>Number of session closes with Error PIPE_OVERFLOW (Session pipe overflow)</p>  <p><code>sc_range_short</code> – <code>counter</code> - diag</p>  <p>Session Err RANGE_SHORT</p> <p>Number of session closes with Error RANGE_SHORT (Insufficient data for range)</p>  <p><code>sc_req_http20</code> – <code>counter</code> - diag</p>  <p>Session Err REQ_HTTP20</p> <p>Number of session closes with Error REQ_HTTP20 (HTTP2 not accepted)</p>  <p><code>sc_vcl_failure</code> – <code>counter</code> - diag</p>  <p>Session Err VCL_FAILURE</p> <p>Number of session closes with Error VCL_FAILURE (VCL failure)</p>  <p><code>client_resp_500</code> – <code>counter</code> - diag</p>  <p>Delivery failed due to insufficient workspace.</p> <p>Number of times we failed a response due to running out of workspace memory during delivery.</p>  <p><code>ws_backend_overflow</code> – <code>counter</code> - diag</p>  <p>workspace_backend overflows</p> <p>Number of times we ran out of space in workspace_backend.</p>  <p><code>ws_client_overflow</code> – <code>counter</code> - diag</p>  <p>workspace_client overflows</p> <p>Number of times we ran out of space in workspace_client.</p>  <p><code>ws_thread_overflow</code> – <code>counter</code> - diag</p>  <p>workspace_thread overflows</p> <p>Number of times we ran out of space in workspace_thread.</p>  <p><code>ws_session_overflow</code> – <code>counter</code> - diag</p>  <p>workspace_session overflows</p> <p>Number of times we ran out of space in workspace_session.</p>  <p><code>shm_records</code> – <code>counter</code> - diag</p>  <p>SHM records</p> <p>Number of log records written to the shared memory log.</p>  <p><code>shm_writes</code> – <code>counter</code> - diag</p>  <p>SHM writes</p> <p>Number of individual writes to the shared memory log. A single write may batch multiple records for bufferred tasks.</p>  <p><code>shm_flushes</code> – <code>counter</code> - diag</p>  <p>SHM flushes due to overflow</p> <p>Number of writes performed before the end of a bufferred task because adding a record to a batch would exceed vsl_buffer.</p>  <p><code>shm_cont</code> – <code>counter</code> - diag</p>  <p>SHM lock contention</p> <p>Number of times a write had to wait for the lock.</p>  <p><code>shm_cycles</code> – <code>counter</code> - diag</p>  <p>SHM cycles through VSL space</p> <p>Number of times a write of log records would reach past the end of the shared memory log, cycling back to the beginning.</p>  <p><code>shm_bytes</code> – <code>counter</code> - diag</p>  <p>SHM bytes</p> <p>Number of bytes written to the shared memory log.</p>  <p><code>backend_req</code> – <code>counter</code> - info</p>  <p>Backend requests made</p>  <p><code>n_vcl</code> – <code>gauge</code> - info</p>  <p>Number of loaded VCLs in total</p>  <p><code>n_vcl_avail</code> – <code>gauge</code> - diag</p>  <p>Number of VCLs available</p>  <p><code>n_vcl_discard</code> – <code>gauge</code> - diag</p>  <p>Number of discarded VCLs</p>  <p><code>vcl_fail</code> – <code>counter</code> - info</p>  <p>VCL failures</p> <p>Count of failures which prevented VCL from completing.</p>  <p><code>bans</code> – <code>gauge</code> - info</p>  <p>Count of bans</p> <p>Number of all bans in system, including bans superseded by newer bans and bans already checked by the ban-lurker.</p>  <p><code>bans_completed</code> – <code>gauge</code> - diag</p>  <p>Number of bans marked ‘completed’</p> <p>Number of bans which are no longer active, either because they got checked by the ban-lurker or superseded by newer identical bans.</p>  <p><code>bans_obj</code> – <code>gauge</code> - diag</p>  <p>Number of bans using obj.*</p> <p>Number of bans which use obj.* variables. These bans can possibly be washed by the ban-lurker.</p>  <p><code>bans_req</code> – <code>gauge</code> - diag</p>  <p>Number of bans using req.*</p> <p>Number of bans which use req.* variables. These bans can not be washed by the ban-lurker.</p>  <p><code>bans_added</code> – <code>counter</code> - diag</p>  <p>Bans added</p> <p>Counter of bans added to ban list.</p>  <p><code>bans_deleted</code> – <code>counter</code> - diag</p>  <p>Bans deleted</p> <p>Counter of bans deleted from ban list.</p>  <p><code>bans_tested</code> – <code>counter</code> - diag</p>  <p>Bans tested against objects (lookup)</p> <p>Count of how many bans and objects have been tested against each other during hash lookup.</p>  <p><code>bans_obj_killed</code> – <code>counter</code> - diag</p>  <p>Objects killed by bans (lookup)</p> <p>Number of objects killed by bans during object lookup.</p>  <p><code>bans_lurker_tested</code> – <code>counter</code> - diag</p>  <p>Bans tested against objects (lurker)</p> <p>Count of how many bans and objects have been tested against each other by the ban-lurker.</p>  <p><code>bans_tests_tested</code> – <code>counter</code> - diag</p>  <p>Ban tests tested against objects (lookup)</p> <p>Count of how many tests and objects have been tested against each other during lookup. ‘ban req.url == foo &amp;&amp; req.http.host == bar’ counts as one in ‘bans_tested’ and as two in ‘bans_tests_tested’</p>  <p><code>bans_lurker_tests_tested</code> – <code>counter</code> - diag</p>  <p>Ban tests tested against objects (lurker)</p> <p>Count of how many tests and objects have been tested against each other by the ban-lurker. ‘ban req.url == foo &amp;&amp; req.http.host == bar’ counts as one in ‘bans_tested’ and as two in ‘bans_tests_tested’</p>  <p><code>bans_lurker_obj_killed</code> – <code>counter</code> - diag</p>  <p>Objects killed by bans (lurker)</p> <p>Number of objects killed by the ban-lurker.</p>  <p><code>bans_lurker_obj_killed_cutoff</code> – <code>counter</code> - diag</p>  <p>Objects killed by bans for cutoff (lurker)</p> <p>Number of objects killed by the ban-lurker to keep the number of bans below ban_cutoff.</p>  <p><code>bans_dups</code> – <code>counter</code> - diag</p>  <p>Bans superseded by other bans</p> <p>Count of bans replaced by later identical bans.</p>  <p><code>bans_lurker_contention</code> – <code>counter</code> - diag</p>  <p>Lurker gave way for lookup</p> <p>Number of times the ban-lurker had to wait for lookups.</p>  <p><code>bans_persisted_bytes</code> – <code>gauge</code> - diag</p>  <p>Bytes used by the persisted ban lists</p> <p>Number of bytes used by the persisted ban lists.</p>  <p><code>bans_persisted_fragmentation</code> – <code>gauge</code> - diag</p>  <p>Extra bytes in persisted ban lists due to fragmentation</p> <p>Number of extra bytes accumulated through dropped and completed bans in the persistent ban lists.</p>  <p><code>n_purges</code> – <code>counter</code> - info</p>  <p>Number of purge operations executed</p>  <p><code>n_obj_purged</code> – <code>counter</code> - info</p>  <p>Number of purged objects</p>  <p><code>exp_mailed</code> – <code>counter</code> - diag</p>  <p>Number of objects mailed to expiry thread</p> <p>Number of objects mailed to expiry thread for handling.</p>  <p><code>exp_received</code> – <code>counter</code> - diag</p>  <p>Number of objects received by expiry thread</p> <p>Number of objects received by expiry thread for handling.</p>  <p><code>hcb_nolock</code> – <code>counter</code> - debug</p>  <p>HCB Lookups without lock</p>  <p><code>hcb_lock</code> – <code>counter</code> - debug</p>  <p>HCB Lookups with lock</p>  <p><code>hcb_insert</code> – <code>counter</code> - debug</p>  <p>HCB Inserts</p>  <p><code>esi_errors</code> – <code>counter</code> - diag</p>  <p>ESI parse errors (unlock)</p>  <p><code>esi_warnings</code> – <code>counter</code> - diag</p>  <p>ESI parse warnings (unlock)</p>  <p><code>vmods</code> – <code>gauge</code> - info</p>  <p>Loaded VMODs</p>  <p><code>n_gzip</code> – <code>counter</code> - info</p>  <p>Gzip operations</p>  <p><code>n_gunzip</code> – <code>counter</code> - info</p>  <p>Gunzip operations</p>  <p><code>n_test_gunzip</code> – <code>counter</code> - info</p>  <p>Test gunzip operations</p> <p>Those operations occur when Varnish receives a compressed object from a backend. They are done to verify the gzip stream while it’s inserted in storage.</p>  <p><code>http1_iovs_flush</code> – <code>counter</code> - info</p>  <p>Premature iovec flushes</p> <p>Number of additional writes performed on HTTP1 connections because the number of IO vectors was too small to submit all possible IO in one go. This number is configured through the <code>http1_iovs</code> parameter for client connections and implicitly defined by the amount of free workspace for backend connections.</p>  </section> <section id="mempool-memory-pool-counters"> <h3>MEMPOOL – Memory Pool Counters</h3> <p><code>live</code> – <code>gauge</code> - debug</p>  <p>In use</p>  <p><code>pool</code> – <code>gauge</code> - debug</p>  <p>In Pool</p>  <p><code>sz_wanted</code> – <code>gauge</code> - debug</p>  <p>Size requested</p>  <p><code>sz_actual</code> – <code>gauge</code> - debug</p>  <p>Size allocated</p>  <p><code>allocs</code> – <code>counter</code> - debug</p>  <p>Allocations</p>  <p><code>frees</code> – <code>counter</code> - debug</p>  <p>Frees</p>  <p><code>recycle</code> – <code>counter</code> - debug</p>  <p>Recycled from pool</p>  <p><code>timeout</code> – <code>counter</code> - debug</p>  <p>Timed out from pool</p>  <p><code>toosmall</code> – <code>counter</code> - debug</p>  <p>Too small to recycle</p>  <p><code>surplus</code> – <code>counter</code> - debug</p>  <p>Too many for pool</p>  <p><code>randry</code> – <code>counter</code> - debug</p>  <p>Pool ran dry</p>  </section> <section id="mgt-management-process-counters"> <h3>MGT – Management Process Counters</h3> <p><code>uptime</code> – <code>counter</code> - info</p>  <p>Management process uptime</p> <p>Uptime in seconds of the management process</p>  <p><code>child_start</code> – <code>counter</code> - diag</p>  <p>Child process started</p> <p>Number of times the child process has been started</p>  <p><code>child_exit</code> – <code>counter</code> - diag</p>  <p>Child process normal exit</p> <p>Number of times the child process has been cleanly stopped</p>  <p><code>child_stop</code> – <code>counter</code> - diag</p>  <p>Child process unexpected exit</p> <p>Number of times the child process has exited with an unexpected return code</p>  <p><code>child_died</code> – <code>counter</code> - diag</p>  <p>Child process died (signal)</p> <p>Number of times the child process has died due to signals</p>  <p><code>child_dump</code> – <code>counter</code> - diag</p>  <p>Child process core dumped</p> <p>Number of times the child process has produced core dumps</p>  <p><code>child_panic</code> – <code>counter</code> - diag</p>  <p>Child process panic</p> <p>Number of times the management process has caught a child panic</p>  </section> <section id="sma-malloc-stevedore-counters"> <h3>SMA – Malloc Stevedore Counters</h3> <p><code>c_req</code> – <code>counter</code> - info</p>  <p>Allocator requests</p> <p>Number of times the storage has been asked to provide a storage segment.</p>  <p><code>c_fail</code> – <code>counter</code> - info</p>  <p>Allocator failures</p> <p>Number of times the storage has failed to provide a storage segment.</p>  <p><code>c_bytes</code> – <code>counter</code> - info</p>  <p>Bytes allocated</p> <p>Number of total bytes allocated by this storage.</p>  <p><code>c_freed</code> – <code>counter</code> - info</p>  <p>Bytes freed</p> <p>Number of total bytes returned to this storage.</p>  <p><code>g_alloc</code> – <code>gauge</code> - info</p>  <p>Allocations outstanding</p> <p>Number of storage allocations outstanding.</p>  <p><code>g_bytes</code> – <code>gauge</code> - info</p>  <p>Bytes outstanding</p> <p>Number of bytes allocated from the storage.</p>  <p><code>g_space</code> – <code>gauge</code> - info</p>  <p>Bytes available</p> <p>Number of bytes left in the storage.</p>  </section> <section id="smf-file-stevedore-counters"> <h3>SMF – File Stevedore Counters</h3> <p><code>c_req</code> – <code>counter</code> - info</p>  <p>Allocator requests</p> <p>Number of times the storage has been asked to provide a storage segment.</p>  <p><code>c_fail</code> – <code>counter</code> - info</p>  <p>Allocator failures</p> <p>Number of times the storage has failed to provide a storage segment.</p>  <p><code>c_bytes</code> – <code>counter</code> - info</p>  <p>Bytes allocated</p> <p>Number of total bytes allocated by this storage.</p>  <p><code>c_freed</code> – <code>counter</code> - info</p>  <p>Bytes freed</p> <p>Number of total bytes returned to this storage.</p>  <p><code>g_alloc</code> – <code>gauge</code> - info</p>  <p>Allocations outstanding</p> <p>Number of storage allocations outstanding.</p>  <p><code>g_bytes</code> – <code>gauge</code> - info</p>  <p>Bytes outstanding</p> <p>Number of bytes allocated from the storage.</p>  <p><code>g_space</code> – <code>gauge</code> - info</p>  <p>Bytes available</p> <p>Number of bytes left in the storage.</p>  <p><code>g_smf</code> – <code>gauge</code> - info</p>  <p>N struct smf</p>  <p><code>g_smf_frag</code> – <code>gauge</code> - info</p>  <p>N small free smf</p>  <p><code>g_smf_large</code> – <code>gauge</code> - info</p>  <p>N large free smf</p>  </section> <section id="smu-umem-stevedore-counters"> <h3>SMU – Umem Stevedore Counters</h3> <p><code>c_req</code> – <code>counter</code> - info</p>  <p>Allocator requests</p> <p>Number of times the storage has been asked to provide a storage segment.</p>  <p><code>c_fail</code> – <code>counter</code> - info</p>  <p>Allocator failures</p> <p>Number of times the storage has failed to provide a storage segment.</p>  <p><code>c_bytes</code> – <code>counter</code> - info</p>  <p>Bytes allocated</p> <p>Number of total bytes allocated by this storage.</p>  <p><code>c_freed</code> – <code>counter</code> - info</p>  <p>Bytes freed</p> <p>Number of total bytes returned to this storage.</p>  <p><code>g_alloc</code> – <code>gauge</code> - info</p>  <p>Allocations outstanding</p> <p>Number of storage allocations outstanding.</p>  <p><code>g_bytes</code> – <code>gauge</code> - info</p>  <p>Bytes outstanding</p> <p>Number of bytes allocated from the storage.</p>  <p><code>g_space</code> – <code>gauge</code> - info</p>  <p>Bytes available</p> <p>Number of bytes left in the storage.</p>  </section> <section id="vbe-backend-counters"> <h3>VBE – Backend Counters</h3> <p><code>happy</code> – <code>bitmap</code> - info</p>  <p>Happy health probes</p> <p>Represents the last probe results as a bitmap. Happy probes are bits set to 1, and the unhappy ones are set to 0. The highest bits represent the oldest probes.</p>  <p><code>bereq_hdrbytes</code> – <code>counter</code> - info</p>  <p>Request header bytes</p> <p>Total backend request header bytes sent</p>  <p><code>bereq_bodybytes</code> – <code>counter</code> - info</p>  <p>Request body bytes</p> <p>Total backend request body bytes sent</p>  <p><code>beresp_hdrbytes</code> – <code>counter</code> - info</p>  <p>Response header bytes</p> <p>Total backend response header bytes received</p>  <p><code>beresp_bodybytes</code> – <code>counter</code> - info</p>  <p>Response body bytes</p> <p>Total backend response body bytes received</p>  <p><code>pipe_hdrbytes</code> – <code>counter</code> - info</p>  <p>Pipe request header bytes</p> <p>Total request bytes sent for piped sessions</p>  <p><code>pipe_out</code> – <code>counter</code> - info</p>  <p>Piped bytes to backend</p> <p>Total number of bytes forwarded to backend in pipe sessions</p>  <p><code>pipe_in</code> – <code>counter</code> - info</p>  <p>Piped bytes from backend</p> <p>Total number of bytes forwarded from backend in pipe sessions</p>  <p><code>conn</code> – <code>gauge</code> - info</p>  <p>Concurrent connections used</p> <p>The number of currently used connections to the backend. This number is always less or equal to the number of connections to the backend (as, for example shown as ESTABLISHED for TCP connections in netstat) due to connection pooling.</p>  <p><code>req</code> – <code>counter</code> - info</p>  <p>Backend requests sent</p>  <p><code>unhealthy</code> – <code>counter</code> - info</p>  <p>Fetches not attempted due to backend being unhealthy</p>  <p><code>busy</code> – <code>counter</code> - info</p>  <p>Fetches not attempted due to backend being busy</p> <p>Number of times the max_connections limit was reached</p>  <p><code>fail</code> – <code>counter</code> - info</p>  <p>Connections failed</p> <p>Counter of failed opens. Detailed reasons are given in the fail_* counters (DIAG level) and in the log under the FetchError tag.</p> <p>This counter is the sum of all detailed fail_* counters.</p> <p>All fail_* counters may be slightly inaccurate for efficiency.</p>  <p><code>fail_eacces</code> – <code>counter</code> - diag</p>  <p>Connections failed with EACCES or EPERM</p>  <p><code>fail_eaddrnotavail</code> – <code>counter</code> - diag</p>  <p>Connections failed with EADDRNOTAVAIL</p>  <p><code>fail_econnrefused</code> – <code>counter</code> - diag</p>  <p>Connections failed with ECONNREFUSED</p>  <p><code>fail_enetunreach</code> – <code>counter</code> - diag</p>  <p>Connections failed with ENETUNREACH</p>  <p><code>fail_etimedout</code> – <code>counter</code> - diag</p>  <p>Connections failed ETIMEDOUT</p>  <p><code>fail_other</code> – <code>counter</code> - diag</p>  <p>Connections failed for other reason</p>  <p><code>helddown</code> – <code>counter</code> - diag</p>  <p>Connection opens not attempted</p> <p>Connections not attempted during the backend_local_error_holddown or backend_remote_error_holddown interval after a fundamental connection issue.</p>  </section> <section id="authors"> <h3>AUTHORS</h3> <p>This man page was written by Lasse Karstensen, using content from vsc2rst written by Tollef Fog Heen.</p> </section> </section><div class="_attribution">
  <p class="_attribution-p">
    Copyright &copy; 2006 Verdens Gang AS<br>Copyright &copy; 2006&ndash;2020 Varnish Software AS<br>Licensed under the BSD-2-Clause License.<br>
    <a href="https://varnish-cache.org/docs/7.4/reference/varnish-counters.html" class="_attribution-link">https://varnish-cache.org/docs/7.4/reference/varnish-counters.html</a>
  </p>
</div>
