<h1>wsrep_provider_options</h1> <div> <div class="node creole"> <div class="answer formatted">  <h2 class="anchored_heading" id="wsrep_provider_options">wsrep_provider_options</h2> <p>The following options can be set as part of the Galera <a href="../galera-cluster-system-variables/index.html#wsrep_provider_options">wsrep_provider_options</a> variable. Dynamic options can be changed while the server is running.</p> <p>Options need to be provided as a semicolon (;) separated list on a single line. Options that are not explicitly set are set to their default value.</p> <p>Note that before Galera 3, the <code>repl</code> tag was named <code>replicator</code>.</p> <h4 class="anchored_heading" id="base_dir"><code>base_dir</code></h4> <ul start="1"><li>
<strong>Description:</strong> Specifies the data directory </li></ul> <hr> <h4 class="anchored_heading" id="base_host"><code>base_host</code></h4> <ul start="1">
<li>
<strong>Description:</strong> For internal use. Should not be manually set. </li>
<li>
<strong>Default:</strong> <code>127.0.0.1</code> (detected network address) </li>
</ul> <hr> <h4 class="anchored_heading" id="base_port"><code>base_port</code></h4> <ul start="1">
<li>
<strong>Description:</strong> For internal use. Should not be manually set. </li>
<li>
<strong>Default:</strong> <code>4567</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="certlog_conflicts"><code>cert.log_conflicts</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Certification failure log details. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>no</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="certoptimistic_pa"><code>cert.optimistic_pa</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Controls parallel application of actions on the replica. If set, the full range of parallelization as determined by the certification algorithm is permitted. If not set, the parallel applying window will not exceed that seen on the primary, and applying will start no sooner than after all actions it has seen on the master are committed. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>yes</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="debug"><code>debug</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Enable debugging. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>no</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsauto_evict"><code>evs.auto_evict</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Number of entries the node permits for a given delayed node before triggering the Auto Eviction protocol. An entry is added to a delayed list for each delayed response from a node. If set to <code>0</code>, the default, the Auto Eviction protocol is disabled for this node. See <a href="https://galeracluster.com/library/documentation/auto-eviction.html">Auto Eviction</a> for more. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evscausal_keepalive_period"><code>evs.causal_keepalive_period</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Used by the developers only, and not manually serviceable. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> The <a href="#evskeepalive_period">evs.keepalive_period</a>. </li>
</ul> <hr> <h4 class="anchored_heading" id="evsdebug_log_mask"><code>evs.debug_log_mask</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Controls EVS debug logging. Only effective when <a href="../galera-cluster-system-variables/index.html#wsrep_debug">wsrep_debug</a> is on. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>0x1</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsdelay_margin"><code>evs.delay_margin</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Time that response times can be delayed before this node adds an entry to the delayed list. See <a href="#evsauto_evict">evs.auto_evict</a>. Must be set to a higher value than the round-trip delay time between nodes. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT1S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsdelayed_keep_period"><code>evs.delayed_keep_period</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Time that this node requires a previously delayed node to remain responsive before being removed from the delayed list. See <a href="#evsauto_evict">evs.auto_evict</a>. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT30S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsevict"><code>evs.evict</code></h4> <ul start="1">
<li>
<strong>Description:</strong> When set to the gcomm UUID of a node, that node is evicted from the cluster. When set to an empty string, the eviction list is cleared on the node where it is set. See <a href="#evsauto_evict">evs.auto_evict</a>. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> Empty string </li>
</ul> <hr> <h4 class="anchored_heading" id="evsinactive_check_period"><code>evs.inactive_check_period</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Frequency of checks for peer inactivity (looking for nodes with delayed responses), after which nodes may be added to the delayed list, and later evicted. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code> PT0.5S </code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsinactive_timeout"><code>evs.inactive_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Time limit that a node can be inactive before being pronounced as dead. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT15S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsinfo_log_mask"><code>evs.info_log_mask </code></h4> <ul start="1">
<li>
<strong>Description:</strong> Controls extra EVS info logging. Bits: <ul start="1">
<li>0x1 – extra view change information </li>
<li>0x2 – extra state change information </li>
<li>0x4 – statistics </li>
<li>0x8 – profiling (only available in builds with profiling enabled) </li>
</ul> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsinstall_timeout"><code>evs.install_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Timeout on waits for install message acknowledgments. Replaces evs.consensus_timeout. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>PT7.5S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsjoin_retrans_period"><code>evs.join_retrans_period</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Time period for how often retransmission of EVS join messages when forming cluster membership should occur. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>PT1S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evskeepalive_period"><code>evs.keepalive_period</code></h4> <ul start="1">
<li>
<strong>Description:</strong> How often keepalive signals should be transmitted when there's no other traffic. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>PT1S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsmax_install_timeouts"><code>evs.max_install_timeouts</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Number of membership install rounds to attempt before timing out. The total rounds will be this value plus two. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>3</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evssend_window"><code>evs.send_window</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Maximum number of packets that can be replicated at a time, Must be more than <a href="#evsuser_send_window">evs.user_send_window</a>, which applies to data packets only (double is recommended). In WAN environments can be set much higher than the default, for example <code>512</code>. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>4</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsstats_report_period"><code>evs.stats_report_period</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Reporting period for EVS statistics. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT1M</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evssuspect_timeout"><code>evs.suspect_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> A node will be suspected to be dead after this period of inactivity. If all nodes agree, the node is dropped from the cluster before <a href="#evsinactive_timeout">evs.inactive_timeout</a> is reached. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT5S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsuse_aggregate"><code>evs.use_aggregate</code></h4> <ul start="1">
<li>
<strong>Description:</strong> If set to <code>true</code> (the default), small packets will be aggregated into one where possible. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>true</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsuser_send_window"><code>evs.user_send_window</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Maximum number of data packets that can be replicated at a time. Must be smaller than <a href="#evssend_window">evs.send_window</a> (half is recommended). In WAN environments can be set much higher than the default, for example <code>512</code>. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>2</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsversion"><code>evs.version</code></h4> <ul start="1">
<li>
<strong>Description:</strong> EVS protocol version. Defaults to <code>0</code> for backward compatibility. Certain EVS features (e.g. auto eviction) require more recent versions. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="evsview_forget_timeout"><code>evs.view_forget_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Time after which past views will be dropped from the view history. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>P1D</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcachedir"><code>gcache.dir</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Directory where GCache files are placed. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> The working directory </li>
</ul> <hr> <h4 class="anchored_heading" id="gcachekeep_pages_size"><code>gcache.keep_pages_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Total size of the page storage pages for caching. One page is always present if only page storage is enabled. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcachemem_size"><code>gcache.mem_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Maximum size of size of the malloc() store for setups that have spare RAM. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcachename"><code>gcache.name</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Gcache ring buffer storage file name. By default placed in the working directory, changing to another location or partition can reduce disk IO. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>./galera.cache</code> --- </li>
</ul> <h4 class="anchored_heading" id="gcachepage_size"><code>gcache.page_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Size of the page storage page files. These are prefixed by <code>gcache.page</code>. Can be set to as large as the disk can handle. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>128M</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcacherecover"><code>gcache.recover</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Whether or not gcache recovery takes place when the node starts up. If it is possible to recover gcache, the node can then provide IST to other joining nodes, which assists when the whole cluster is restarted. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>no</code> </li>
<li>
<strong>Introduced:</strong> <a href="https://mariadb.com/kb/en/mariadb-10120-release-notes/">MariaDB 10.1.20</a>, <a href="https://mariadb.com/kb/en/mariadb-galera-cluster-10029-release-notes/">MariaDB Galera 10.0.29</a>, <a href="https://mariadb.com/kb/en/mariadb-galera-cluster-5554-release-notes/">MariaDB Galera 5.5.54</a> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcachesize"><code>gcache.size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Gcache ring buffer storage size (the space the node uses for caching write sets), preallocated on startup. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>128M</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcommthread_prio"><code>gcomm.thread_prio</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Gcomm thread policy and priority (in the format <code>policy:priority</code>. Priority is an integer, while policy can be one of: <ul>
<li>
<code>fifo</code>: First-in, first-out scheduling. Always preempt other, batch or idle threads and can only be preempted by other <code>fifo</code> threads of a higher priority or blocked by an I/O request. </li>
<li>
<code>rr</code>: Round-robin scheduling. Always preempt other, batch or idle threads. Runs for a fixed period of time after which the thread is stopped and moved to the end of the list, being replaced by another round-robin thread with the same priority. Otherwise runs until preempted by other <code>rr</code> threads of a higher priority or blocked by an I/O request. </li>
<li>
<code>other</code>: Default scheduling on Linux. Threads run until preempted by a thread of a higher priority or a superior scheduling designation, or blocked by an I/O request. </li>
</ul> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> Empty string </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsfc_debug"><code>gcs.fc_debug</code></h4> <ul start="1">
<li>
<strong>Description:</strong> If set to a value greater than zero (the default), debug statistics about SST flow control will be posted each time after the specified number of writesets. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsfc_factor"><code>gcs.fc_factor</code></h4> <ul start="1">
<li>
<strong>Description:</strong>Fraction below <a href="#gcsfc_limit">gcs.fc_limit</a> which if the recv queue drops below, replication resumes. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>1.0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsfc_limit"><code>gcs.fc_limit</code></h4> <ul start="1">
<li>
<strong>Description:</strong> If the recv queue exceeds this many writesets, replication is paused. Can increase greatly in master-slave setups. Replication will resume again according to the <a href="#gcsfc_factor">gcs.fc_factor</a> setting. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>16</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsfc_master_slave"><code>gcs.fc_master_slave</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Whether to assume that the cluster only contains one master. Deprecated since Galera 4.10 (<a href="https://mariadb.com/kb/en/mariadb-1081-release-notes/">MariaDB 10.8.1</a>, <a href="https://mariadb.com/kb/en/mariadb-1072-release-notes/">MariaDB 10.7.2</a>, <a href="https://mariadb.com/kb/en/mariadb-1066-release-notes/">MariaDB 10.6.6</a>, <a href="https://mariadb.com/kb/en/mariadb-10514-release-notes/">MariaDB 10.5.14</a>, <a href="https://mariadb.com/kb/en/mariadb-10422-release-notes/">MariaDB 10.4.22</a>) - see <a href="#gcsfc_single_primary">gcs.fc_single_primary</a> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>no</code> </li>
</ul> <h4 class="anchored_heading" id="gcsfc_single_primary"><code>gcs.fc_single_primary</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Defines whether there is more than one source of replication. As the number of nodes in the cluster grows, the larger the calculated gcs.fc_limit gets. At the same time, the number of writes from the nodes increases. When this parameter value is set to NO (multi-primary), the gcs.fc_limit parameter is dynamically modified to give more margin for each node to be a bit further behind applying writes. The gcs.fc_limit parameter is modified by the square root of the cluster size, that is, in a four-node cluster it is two times higher than the base value. This is done to compensate for the increasing replication rate noise. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>no</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsmax_packet_size"><code>gcs.max_packet_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Maximum packet size, after which writesets become fragmented. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>64500</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsmax_throttle"><code>gcs.max_throttle</code></h4> <ul start="1">
<li>
<strong>Description:</strong> How much we can throttle replication rate during state transfer (to avoid running out of memory). Set it to 0.0 if stopping replication is acceptable for the sake of completing state transfer. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0.25</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsrecv_q_hard_limit"><code>gcs.recv_q_hard_limit</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Maximum size of the recv queue. If exceeded, the server aborts. Half of available RAM plus swap is a recommended size. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> LLONG_MAX </li>
</ul> <hr> <h4 class="anchored_heading" id="gcsrecv_q_soft_limit"><code>gcs.recv_q_soft_limit</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Fraction of <a href="#gcsrecv_q_hard_limit">gcs.recv_q_hard_limit</a> after which replication rate is throttled. The rate of throttling increases linearly from zero (the regular, varying rate of replication) at and below <code>csrecv_q_soft_limit</code> to one (full throttling) at <a href="#gcsrecv_q_hard_limit">gcs.recv_q_hard_limit</a> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0.25</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gcssync_donor"><code>gcs.sync_donor</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Whether or not the rest of the cluster should stay in sync with the donor. If set to <code>YES</code> (<code>NO</code> is default), if the donor is blocked by state transfer, the whole cluster is also blocked. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>no</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcastlisten_addr"><code>gmcast.listen_addr</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Address Galera listens for connections from other nodes. Can be used to override the default port to listen, which is obtained from the connection address. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>tcp://0.0.0.0:4567</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcastmcast_addr"><code>gmcast.mcast_addr</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Not set by default, but if set, UDP multicast will be used for replication. Must be identical on all nodes.For example, <code>gmcast.mcast_addr=239.192.0.11</code> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> None </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcastmcast_ttl"><code>gmcast.mcast_ttl</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Multicast packet TTL (time to live) value. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>1</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcastpeer_timeout"><code>gmcast.peer_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Connection timeout for initiating message relaying. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT3S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcastsegment"><code>gmcast.segment</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Defines the segment to which the node belongs. By default, all nodes are placed in the same segment (<code>0</code>). Usually, you would place all nodes in the same datacenter in the same segment. Galera protocol traffic is only redirected to one node in each segment, and then relayed to other nodes in that same segment, which saves cross-datacenter network traffic at the expense of some extra latency. State transfers are also, preferably but not exclusively, taken from the same segment. If there are no nodes available in the same segment, state transfer will be taken from a node in another segment. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
<li>
<strong>Range:</strong> <code>0</code> to <code>255</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcasttime_wait"><code>gmcast.time_wait</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Waiting time before allowing a peer that was declared outside of the stable view to reconnect. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT5S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="gmcastversion"><code>gmcast.version</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Deprecated option. Gmcast version. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="istrecv_addr"><code>ist.recv_addr</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Address for listening for Incremental State Transfer. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> &lt;address&gt;:&lt;port+1&gt; from <a href="../galera-cluster-system-variables/index.html#wsrep_node_address">wsrep_node_address</a> </li>
</ul> <hr> <h4 class="anchored_heading" id="istrecv_bind"><code>ist.recv_bind</code></h4> <ul start="1">
<li>
<strong>Description:</strong> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> Empty string </li>
<li>
<strong>Introduced:</strong> <a href="https://mariadb.com/kb/en/mariadb-10117-release-notes/">MariaDB 10.1.17</a>, <a href="https://mariadb.com/kb/en/mariadb-galera-cluster-10027-release-notes/">MariaDB Galera 10.0.27</a>, <a href="https://mariadb.com/kb/en/mariadb-galera-cluster-5551-release-notes/">MariaDB Galera 5.5.51</a> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcannounce_timeout"><code>pc.announce_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Period of time for which cluster joining announcements are sent every 1/2 second. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT3S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcchecksum"><code>pc.checksum</code></h4> <ul start="1">
<li>
<strong>Description:</strong> For debug purposes, by default <code>false</code> (<code>true</code> in earlier releases), indicates whether to checksum replicated messages on PC level. Safe to turn off. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>false</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcignore_quorum"><code>pc.ignore_quorum</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Whether to ignore quorum calculations, for example when a master splits from several slaves, it will remain in operation if set to <code>true</code> (<code>false is default</code>). Use with care however, as in master-slave setups, slaves will not automatically reconnect to the master if set. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>false</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcignore_sb"><code>pc.ignore_sb</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Whether to permit updates to be processed even in the case of split brain (when a node is disconnected from its remaining peers). Safe in master-slave setups, but could lead to data inconsistency in a multi-master setup. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>false</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pclinger"><code>pc.linger</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Time that the PC protocol waits for EVS termination. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT20S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcnpvo"><code>pc.npvo</code></h4> <ul start="1">
<li>
<strong>Description:</strong> If set to <code>true</code> (<code>false</code> is default), when there are primary component conficts, the most recent component will override the older. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>false</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcrecovery"><code>pc.recovery</code></h4> <ul start="1">
<li>
<strong>Description:</strong> If set to <code>true</code> (the default), the Primary Component state is stored on disk and in the case of a full cluster crash (e.g power outages), automatic recovery is then possible. Subsequent graceful full cluster restarts will require explicit bootstrapping for a new Primary Component. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>true</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcversion"><code>pc.version</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Deprecated option. PC protocol version. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcwait_prim"><code>pc.wait_prim</code></h4> <ul start="1">
<li>
<strong>Description:</strong> When set to <code>true</code>, the default, the node will wait for a primary component for the period of time specified by <a href="#pc.wait_prim_timeout">pc.wait_prim_timeout</a>. Used to bring up non-primary components and make them primary using <a href="#pcbootstrap.">pc.bootstrap</a>. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>true</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcwait_prim_timeout"><code>pc.wait_prim_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Ttime to wait for a primary component. See <a href="#pcwait_prim">pc.wait_prim</a>. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>PT30S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="pcweight"><code>pc.weight</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Node weight, used for quorum calculation. See the Codership article <a href="https://galeracluster.com/library/documentation/weighted-quorum.html#weighted-quorum">Weighted Quorum</a>. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>1</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="protonetbackend"><code>protonet.backend </code></h4> <ul start="1">
<li>
<strong>Description:</strong> Deprecated option. Transport backend to use. Only ASIO is supported currently. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>asio</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="protonetversion"><code>protonet.version</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Deprecated option. Protonet version. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>0</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="replcausal_read_timeout"><code>repl.causal_read_timeout</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Timeout period for causal reads. </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>PT30S</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="replcommit_order"><code>repl.commit_order</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Whether or not out-of-order committing is permitted, and under what conditions. By default it is not permitted, but setting this can improve parallel performance. <ul start="1">
<li>
<code>0</code> BYPASS: No commit order monitoring is done (useful for measuring the performance penalty). </li>
<li>
<code>1</code> OOOC: Out-of-order committing is permitted for all transactions. </li>
<li>
<code>2</code> LOCAL_OOOC: Out-of-order committing is permitted for local transactions only. </li>
<li>
<code>3</code> NO_OOOC: Out-of-order committing is not permitted at all. </li>
</ul> </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>3</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="replkey_format"><code>repl.key_format</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Format for key replication. Can be one of: <ul start="1">
<li>
<code>FLAT8</code> - shorter key with a higher probability of false positives when matching </li>
<li>
<code>FLAT16</code> - longer key with a lower probability of false positives when matching </li>
<li>
<code>FLAT8A</code> - shorter key with a higher probability of false positives when matching, includes annotations for debug purposes </li>
<li>
<code>FLAT16A</code> - longer key with a lower probability of false positives when matching, includes annotations for debug purposes </li>
</ul> </li>
<li>
<strong>Dynamic:</strong> Yes </li>
<li>
<strong>Default:</strong> <code>FLAT8</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="replmax_ws_size"><code>repl.max_ws_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> </li>
<li>
<strong>Dynamic:</strong> </li>
<li>
<strong>Default:</strong> <code>2147483647</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="replproto_max"><code>repl.proto_max</code></h4> <ul start="1">
<li>
<strong>Description:</strong> </li>
<li>
<strong>Dynamic:</strong> </li>
<li>
<strong>Default:</strong> <code>9</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="socketchecksum"><code>socket.checksum</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Method used for generating checksum. Note: If Galera 25.2.x and 25.3.x are both being used in the cluster, MariaDB with Galera 25.3.x must be started with <code>wsrep_provider_options='socket.checksum=1'</code> in order to make it backward compatible with Galera v2. Galera wsrep providers other than 25.3.x or 25.2.x are not supported. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>2</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="socketdynamic"><code>socket.dynamic</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Allow both encrypted and unencrypted connections between nodes. Typically this should be set to <code>false</code> (the default), when set to <code>true</code> encrypted connections will still be preferred, but will fall back to unencrypted connections when encryption is not possible, e.g. not enabled on all nodes yet. Needs to be <code>true</code> on all nodes when wanting to enable or disable encryption via a rolling restart. As this can't be changed at runtime a rolling restart to enable or disable encryption may need three restarts per node in total: one to enable <code>socket.dynamic</code> on each node, one to change the actual encryption settings on each node, and a final round to change <code>socket.dynamic</code> back to <code>false</code>. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>false</code> </li>
<li>
<strong>Introduced:</strong> <a href="https://mariadb.com/kb/en/mariadb-10419-release-notes/">MariaDB 10.4.19</a>, <a href="https://mariadb.com/kb/en/mariadb-10510-release-notes/">MariaDB 10.5.10</a>, <a href="https://mariadb.com/kb/en/mariadb-1060-release-notes/">MariaDB 10.6.0</a> </li>
</ul> <hr> <h4 class="anchored_heading" id="socketrecv_buf_size"><code>socket.recv_buf_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Size in bytes of the receive buffer used on the network sockets between nodes, passed on to the kernel via the SO_RCVBUF socket option. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <ul start="1">
<li>&gt;= <a href="https://mariadb.com/kb/en/mariadb-10323-release-notes/">MariaDB 10.3.23</a>, <a href="https://mariadb.com/kb/en/mariadb-10232-release-notes/">MariaDB 10.2.32</a>, <a href="https://mariadb.com/kb/en/mariadb-10145-release-notes/">MariaDB 10.1.45</a>: Auto </li>
<li>&lt; <a href="https://mariadb.com/kb/en/mariadb-10322-release-notes/">MariaDB 10.3.22</a>: <a href="https://mariadb.com/kb/en/mariadb-10231-release-notes/">MariaDB 10.2.31</a>, <a href="https://mariadb.com/kb/en/mariadb-10144-release-notes/">MariaDB 10.1.44</a>: <code>212992</code> </li>
</ul> </li>
</ul> <hr> <h4 class="anchored_heading" id="socketsend_buf_size"><code>socket.send_buf_size</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Size in bytes of the send buffer used on the network sockets between nodes, passed on to the kernel via the SO_SNDBUF socket option. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong>: Auto </li>
<li>
<strong>Introduced:</strong> <a href="https://mariadb.com/kb/en/mariadb-10323-release-notes/">MariaDB 10.3.23</a>, <a href="https://mariadb.com/kb/en/mariadb-10232-release-notes/">MariaDB 10.2.32</a>, <a href="https://mariadb.com/kb/en/mariadb-10145-release-notes/">MariaDB 10.1.45</a> </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl"><code>socket.ssl</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Explicitly enables TLS usage by the wsrep Provider. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> <code>NO</code> </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl_ca"><code>socket.ssl_ca</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Path to Certificate Authority (CA) file. Implicitly enables the <code><a href="#socket.ssl">socket.ssl</a></code> option. </li>
<li>
<strong>Dynamic:</strong> No </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl_cert"><code>socket.ssl_cert</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Path to TLS certificate. Implicitly enables the <code><a href="#socket.ssl">socket.ssl</a></code> option. </li>
<li>
<strong>Dynamic:</strong> No </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl_cipher"><code>socket.ssl_cipher</code></h4> <ul start="1">
<li>
<strong>Description:</strong> TLS cipher to use. Implicitly enables the <code><a href="#socket.ssl">socket.ssl</a></code> option. Since <a href="https://mariadb.com/kb/en/mariadb-10218-release-notes/">MariaDB 10.2.18</a> defaults to the value of the <code><a href="../ssltls-system-variables/index.html#ssl_cipher">ssl_cipher</a></code> system variable. </li>
<li>
<strong>Dynamic:</strong> No </li>
<li>
<strong>Default:</strong> system default, before <a href="https://mariadb.com/kb/en/mariadb-10218-release-notes/">MariaDB 10.2.18</a> defaults to <code>AES128-SHA</code>. </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl_compression"><code>socket.ssl_compression</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Compression to use on TLS connections. Implicitly enables the <code><a href="#socket.ssl">socket.ssl</a></code> option. </li>
<li>
<strong>Dynamic:</strong> No </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl_key"><code>socket.ssl_key</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Path to TLS key file. Implicitly enables the <code><a href="#socket.ssl">socket.ssl</a></code> option. </li>
<li>
<strong>Dynamic:</strong> No </li>
</ul> <hr> <h4 class="anchored_heading" id="socketssl_password_file"><code>socket.ssl_password_file</code></h4> <ul start="1">
<li>
<strong>Description:</strong> Path to password file to use in TLS connections. Implicitly enables the <code><a href="#socket.ssl">socket.ssl</a></code> option. </li>
<li>
<strong>Dynamic:</strong> No </li>
</ul> <hr> <h2 class="anchored_heading" id="see-also">See Also</h2> <ul start="1"><li><a href="https://galeracluster.com/library/documentation/galera-parameters.html">Galera parameters documentation from Codership</a></li></ul> </div>     </div> <div id="content_disclaimer" class="graybox"> Content reproduced on this site is the property of its respective owners, and this content is not reviewed in advance by MariaDB. The views, information and opinions expressed by this content do not necessarily represent those of MariaDB or any other party. </div> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2023 MariaDB<br>Licensed under the Creative Commons Attribution 3.0 Unported License and the GNU Free Documentation License.<br>
    <a href="https://mariadb.com/kb/en/wsrep_provider_options/" class="_attribution-link">https://mariadb.com/kb/en/wsrep_provider_options/</a>
  </p>
</div>
