<h1>S3 Storage Engine Internals</h1> <div> <div class="node creole"> <div class="answer formatted"> <div class="mariadb_from_10_5 mariadb from_10_5 product">
<strong class="product_title">MariaDB starting with <a href="../what-is-mariadb-105/index.html">10.5</a></strong><p>The <a href="../s3-storage-engine/index.html">S3 storage engine</a> has been available since <a href="https://mariadb.com/kb/en/mariadb-1054-release-notes/">MariaDB 10.5.4</a>.</p> </div> <p> The <a href="../s3-storage-engine/index.html">S3 storage engine</a> is based on the <a href="../aria-storage-engine/index.html">Aria</a> code. Internally the S3 storage inherits from the Aria code, with hooks that change reads, so that instead of reading data from the local disk it reads things from S3.</p> <p>The S3 engine uses it's own page cache, modified to be able to handle reading blocks from S3 (of size <code>s3_block_size</code>). Internally the S3 page cache uses pages of <a href="../aria-system-variables/index.html#aria_block_size">aria-block-size</a> for splitting the blocks read from S3.</p> <h2 class="anchored_heading" id="alter-table">ALTER TABLE</h2> <p><a href="../alter-table/index.html">ALTER TABLE</a> will first create a local table in the normal Aria on disk format and then move both index and data to S3 in buckets of S3_BLOCK_SIZE. The .frm file is also copied to S3 for discovery to support discovery for other MariaDB servers. One can also use ALTER TABLE to change the structure of an S3 table.</p> <h2 class="anchored_heading" id="partitioning-tables">Partitioning Tables</h2> <p>Starting from <a href="https://mariadb.com/kb/en/mariadb-1053-release-notes/">MariaDB 10.5.3</a>, S3 tables can also be used with <a href="../partitioning-tables/index.html">Partitioning tables</a>. All <a href="../alter-table/index.html">ALTER PARTITION</a> operations are supported except:</p> <ul start="1">
<li>REBUILD PARTITION </li>
<li>TRUNCATE PARTITION </li>
<li>REORGANIZE PARTITION </li>
</ul> <h2 class="anchored_heading" id="big-reads">Big Reads</h2> <p>One of the properties of many S3 implementations is that they favor large reads. It's said that 4M gives the best performance, which is why the default value for <code>S3_BLOCK_SIZE</code> is 4M.</p> <h2 class="anchored_heading" id="compression">Compression</h2> <p>If compression (<code>COMPRESSION_ALGORITHM=zlib</code>) is used, then all index blocks and data blocks are compressed. The <code>.frm</code> file and Aria definition header (first page/pages in the index file) are not compressed as these are used by discovery/open.</p> <p>If compression is used, then the local block size is <code>S3_BLOCK_SIZE</code>, but the block stored in S3 will be the size of the compressed block.</p> <p>Typical compression we have seen is in the range of 80% saved space.</p> <h2 class="anchored_heading" id="structure-stored-on-s3">Structure Stored on S3</h2> <p>The table will be copied in S3 into the following locations:</p> <pre class="fixed" data-language="sql">frm file (for discovery):
s3_bucket/database/table/frm

First index block (contains description of the Aria file):
s3_bucket/database/table/aria

Rest of the index file:
s3_bucket/database/table/index/block_number

Data file:
s3_bucket/database/table/data/block_number
</pre>
<p>block_number is a 6-digit decimal number, prefixed with 0 (Can be larger than 6 numbers, the prefix is just for nice output)</p> <h2 class="anchored_heading" id="using-the-awsctl-python-tool-to-examine-data">Using the awsctl Python Tool to Examine Data</h2> <h3 class="anchored_heading" id="installing-awsctl-on-linux">Installing awsctl on Linux</h3> <pre class="fixed" data-language="sql"># install python-pip (on an OpenSuse distribution)
# use the appropriate command for your distribution
zypper install python-pip
pip install --upgrade pip

# the following installs awscli tools in ~/.local/bin
pip install --upgrade --user awscli
export PATH=~/.local/bin:$PATH

# configure your aws credentials
aws configure
</pre>
<h3 class="anchored_heading" id="using-the-awsctl-tool">Using the awsctl Tool</h3> <p>One can use the <code>aws</code> python tool to see how things are stored on S3:</p> <pre class="fixed" data-language="sql">shell&gt; aws s3 ls --recursive s3://mariadb-bucket/
2019-05-10 17:46:48       8192 foo/test1/aria
2019-05-10 17:46:49    3227648 foo/test1/data/000001
2019-05-10 17:46:48        942 foo/test1/frm
2019-05-10 17:46:48    1015808 foo/test1/index/000001
</pre>
<p>To delete an obsolete table <code>foo.test1</code> one can do:</p> <pre class="fixed" data-language="sql">shell&gt; ~/.local/bin/aws s3 rm --recursive s3://mariadb-bucket/foo/test1
delete: s3://mariadb-bucket/foo/test1/aria
delete: s3://mariadb-bucket/foo/test1/data/000001
delete: s3://mariadb-bucket/foo/test1/frm
delete: s3://mariadb-bucket/foo/test1/index/000001
</pre>
<h2 class="anchored_heading" id="see-also">See Also</h2> <ul start="1"><li><a href="../using-the-s3-storage-engine/index.html">Using the S3 storage engine</a></li></ul> </div>     </div> <div id="content_disclaimer" class="graybox"> Content reproduced on this site is the property of its respective owners, and this content is not reviewed in advance by MariaDB. The views, information and opinions expressed by this content do not necessarily represent those of MariaDB or any other party. </div> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2023 MariaDB<br>Licensed under the Creative Commons Attribution 3.0 Unported License and the GNU Free Documentation License.<br>
    <a href="https://mariadb.com/kb/en/s3-storage-engine-internals/" class="_attribution-link">https://mariadb.com/kb/en/s3-storage-engine-internals/</a>
  </p>
</div>
