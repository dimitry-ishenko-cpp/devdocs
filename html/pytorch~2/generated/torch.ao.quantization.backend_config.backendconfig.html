<h1 id="backendconfig">BackendConfig</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig">
<code>class torch.ao.quantization.backend_config.BackendConfig(name='')</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/backend_config/backend_config.html#BackendConfig"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Config that defines the set of patterns that can be quantized on a given backend, and how reference quantized models can be produced from these patterns.</p> <p>A pattern in this context refers to a module, a functional, an operator, or a directed acyclic graph of the above. Each pattern supported on the target backend can be individually configured through <a class="reference internal" href="torch.ao.quantization.backend_config.backendpatternconfig.html#torch.ao.quantization.backend_config.BackendPatternConfig" title="torch.ao.quantization.backend_config.BackendPatternConfig"><code>BackendPatternConfig</code></a> in terms of:</p> <ol class="arabic simple"> <li>The supported input/output activation, weight, and bias data types</li> <li>How observers and quant/dequant ops are inserted in order to construct the reference pattern, and</li> <li>(Optionally) Fusion, QAT, and reference module mappings.</li> </ol> <p>The format of the patterns is described in: <a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/ao/quantization/backend_config/README.md">https://github.com/pytorch/pytorch/blob/master/torch/ao/quantization/backend_config/README.md</a></p> <p>Example usage:</p> <pre data-language="python">import torch
from torch.ao.quantization.backend_config import (
    BackendConfig,
    BackendPatternConfig,
    DTypeConfig,
    ObservationType,
)

weighted_int8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.quint8,
    weight_dtype=torch.qint8,
    bias_dtype=torch.float)

def fuse_conv2d_relu(is_qat, conv, relu):
    return torch.ao.nn.intrinsic.ConvReLU2d(conv, relu)

# For quantizing Linear
linear_config = BackendPatternConfig(torch.nn.Linear)             .set_observation_type(ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT)             .add_dtype_config(weighted_int8_dtype_config)             .set_root_module(torch.nn.Linear)             .set_qat_module(torch.ao.nn.qat.Linear)             .set_reference_quantized_module(torch.ao.nn.quantized.reference.Linear)

# For fusing Conv2d + ReLU into ConvReLU2d
conv_relu_config = BackendPatternConfig((torch.nn.Conv2d, torch.nn.ReLU))             .set_observation_type(ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT)             .add_dtype_config(weighted_int8_dtype_config)             .set_fused_module(torch.ao.nn.intrinsic.ConvReLU2d)             .set_fuser_method(fuse_conv2d_relu)

# For quantizing ConvReLU2d
fused_conv_relu_config = BackendPatternConfig(torch.ao.nn.intrinsic.ConvReLU2d)             .set_observation_type(ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT)             .add_dtype_config(weighted_int8_dtype_config)             .set_root_module(torch.nn.Conv2d)             .set_qat_module(torch.ao.nn.intrinsic.qat.ConvReLU2d)             .set_reference_quantized_module(torch.ao.nn.quantized.reference.Conv2d)

backend_config = BackendConfig("my_backend")             .set_backend_pattern_config(linear_config)             .set_backend_pattern_config(conv_relu_config)             .set_backend_pattern_config(fused_conv_relu_config)
</pre>  <dl class="py property"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig.configs">
<code>property configs: List[BackendPatternConfig]</code> </dt> <dd>
<p>Return a copy of the list of configs set in this <code>BackendConfig</code>.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig.from_dict">
<code>classmethod from_dict(backend_config_dict)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/backend_config/backend_config.html#BackendConfig.from_dict"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Create a <code>BackendConfig</code> from a dictionary with the following items:</p>  <p>“name”: the name of the target backend</p> <p>“configs”: a list of dictionaries that each represents a <code>BackendPatternConfig</code></p>  <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.ao.quantization.backend_config.BackendConfig" title="torch.ao.quantization.backend_config.backend_config.BackendConfig">BackendConfig</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_config">
<code>set_backend_pattern_config(config)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/backend_config/backend_config.html#BackendConfig.set_backend_pattern_config"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the config for an pattern that can be run on the target backend. This overrides any existing config for the given pattern.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.ao.quantization.backend_config.BackendConfig" title="torch.ao.quantization.backend_config.backend_config.BackendConfig">BackendConfig</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_configs">
<code>set_backend_pattern_configs(configs)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/backend_config/backend_config.html#BackendConfig.set_backend_pattern_configs"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the configs for patterns that can be run on the target backend. This overrides any existing config for a given pattern if it was previously registered already.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.ao.quantization.backend_config.BackendConfig" title="torch.ao.quantization.backend_config.backend_config.BackendConfig">BackendConfig</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig.set_name">
<code>set_name(name)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/backend_config/backend_config.html#BackendConfig.set_name"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the name of the target backend.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.ao.quantization.backend_config.BackendConfig" title="torch.ao.quantization.backend_config.backend_config.BackendConfig">BackendConfig</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.quantization.backend_config.BackendConfig.to_dict">
<code>to_dict()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/backend_config/backend_config.html#BackendConfig.to_dict"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Convert this <code>BackendConfig</code> to a dictionary with the items described in <a class="reference internal" href="#torch.ao.quantization.backend_config.BackendConfig.from_dict" title="torch.ao.quantization.backend_config.BackendConfig.from_dict"><code>from_dict()</code></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)">Dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)">Any</a>]</p> </dd> </dl> </dd>
</dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.ao.quantization.backend_config.BackendConfig.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.ao.quantization.backend_config.BackendConfig.html</a>
  </p>
</div>
