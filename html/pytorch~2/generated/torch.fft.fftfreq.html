<h1 id="torch-fft-fftfreq">torch.fft.fftfreq</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.fft.fftfreq">
<code>torch.fft.fftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</code> </dt> <dd>
<p>Computes the discrete Fourier Transform sample frequencies for a signal of size <code>n</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>By convention, <a class="reference internal" href="torch.fft.fft.html#torch.fft.fft" title="torch.fft.fft"><code>fft()</code></a> returns positive frequency terms first, followed by the negative frequencies in reverse order, so that <code>f[-i]</code> for all <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>i</mi><mo>≤</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">0 &lt; i \leq n/2</annotation></semantics></math></span></span></span> in Python gives the negative frequency terms. For an FFT of length <code>n</code> and with inputs spaced in length unit <code>d</code>, the frequencies are:</p> <pre data-language="python">f = [0, 1, ..., (n - 1) // 2, -(n // 2), ..., -1] / (d * n)
</pre> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For even lengths, the Nyquist frequency at <code>f[n/2]</code> can be thought of as either negative or positive. <a class="reference internal" href="#torch.fft.fftfreq" title="torch.fft.fftfreq"><code>fftfreq()</code></a> follows NumPy’s convention of taking it to be negative.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – the FFT length</li> <li>
<strong>d</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – The sampling length scale. The spacing between individual samples of the FFT input. The default assumes unit spacing, dividing that result by the actual spacing gives the result in physical frequency units.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>out</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</li> <li>
<strong>dtype</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, optional) – the desired data type of returned tensor. Default: if <code>None</code>, uses a global default (see <a class="reference internal" href="torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code>torch.set_default_tensor_type()</code></a>).</li> <li>
<strong>layout</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.layout" title="torch.layout"><code>torch.layout</code></a>, optional) – the desired layout of returned Tensor. Default: <code>torch.strided</code>.</li> <li>
<strong>device</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.device" title="torch.device"><code>torch.device</code></a>, optional) – the desired device of returned tensor. Default: if <code>None</code>, uses the current device for the default tensor type (see <a class="reference internal" href="torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code>torch.set_default_tensor_type()</code></a>). <code>device</code> will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.</li> <li>
<strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – If autograd should record operations on the returned tensor. Default: <code>False</code>.</li> </ul> </dd> </dl> <h4 class="rubric">Example</h4> <pre data-language="python">&gt;&gt;&gt; torch.fft.fftfreq(5)
tensor([ 0.0000,  0.2000,  0.4000, -0.4000, -0.2000])
</pre> <p>For even input, we can see the Nyquist frequency at <code>f[2]</code> is given as negative:</p> <pre data-language="python">&gt;&gt;&gt; torch.fft.fftfreq(4)
tensor([ 0.0000,  0.2500, -0.5000, -0.2500])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.fft.fftfreq.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.fft.fftfreq.html</a>
  </p>
</div>
