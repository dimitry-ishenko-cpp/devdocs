<h1 id="torch-autograd-function-functionctx-mark-dirty">torch.autograd.function.FunctionCtx.mark_dirty</h1> <dl class="py method"> <dt class="sig sig-object py" id="torch.autograd.function.FunctionCtx.mark_dirty">
<code>FunctionCtx.mark_dirty(*args)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/autograd/function.html#FunctionCtx.mark_dirty"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Marks given tensors as modified in an in-place operation.</p> <p><strong>This should be called at most once, only from inside the</strong> <code>forward()</code> <strong>method, and all arguments should be inputs.</strong></p> <p>Every tensor that’s been modified in-place in a call to <code>forward()</code> should be given to this function, to ensure correctness of our checks. It doesn’t matter whether the function is called before or after modification.</p> <dl> <dt>Examples::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; class Inplace(Function):
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, x):
&gt;&gt;&gt;         x_npy = x.numpy() # x_npy shares storage with x
&gt;&gt;&gt;         x_npy += 1
&gt;&gt;&gt;         ctx.mark_dirty(x)
&gt;&gt;&gt;         return x
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     @once_differentiable
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         return grad_output
&gt;&gt;&gt;
&gt;&gt;&gt; a = torch.tensor(1., requires_grad=True, dtype=torch.double).clone()
&gt;&gt;&gt; b = a * a
&gt;&gt;&gt; Inplace.apply(a)  # This would lead to wrong gradients!
&gt;&gt;&gt;                   # but the engine would not know unless we mark_dirty
&gt;&gt;&gt; b.backward() # RuntimeError: one of the variables needed for gradient
&gt;&gt;&gt;              # computation has been modified by an inplace operation
</pre> </dd> </dl>  </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.autograd.function.FunctionCtx.mark_dirty.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.autograd.function.FunctionCtx.mark_dirty.html</a>
  </p>
</div>
