<h1 id="movingaverageminmaxobserver">MovingAverageMinMaxObserver</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.quantization.observer.MovingAverageMinMaxObserver">
<code>class torch.ao.quantization.observer.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, **kwargs)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/quantization/observer.html#MovingAverageMinMaxObserver"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Observer module for computing the quantization parameters based on the moving average of the min and max values.</p> <p>This observer computes the quantization parameters based on the moving averages of minimums and maximums of the incoming tensors. The module records the average minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>averaging_constant</strong> – Averaging constant for min/max.</li> <li>
<strong>dtype</strong> – dtype argument to the <code>quantize</code> node needed to implement the reference model spec.</li> <li>
<strong>qscheme</strong> – Quantization scheme to be used</li> <li>
<strong>reduce_range</strong> – Reduces the range of the quantized data type by 1 bit</li> <li>
<strong>quant_min</strong> – Minimum quantization value. If unspecified, it will follow the 8-bit setup.</li> <li>
<strong>quant_max</strong> – Maximum quantization value. If unspecified, it will follow the 8-bit setup.</li> <li>
<strong>eps</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – Epsilon value for float32, Defaults to <code>torch.finfo(torch.float32).eps</code>.</li> </ul> </dd> </dl> <p>The moving average min/max is computed as follows</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>x</mi><mtext>min</mtext></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>x</mi><mtext>min</mtext></msub><mo>=</mo><mtext>None</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>c</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mtext>min</mtext></msub><mo>+</mo><mi>c</mi><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>x</mi><mtext>max</mtext></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>x</mi><mtext>max</mtext></msub><mo>=</mo><mtext>None</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>c</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mtext>max</mtext></msub><mo>+</mo><mi>c</mi><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{ll} x_\text{min} = \begin{cases} \min(X) &amp; \text{if~}x_\text{min} = \text{None} \\ (1 - c) x_\text{min} + c \min(X) &amp; \text{otherwise} \end{cases}\\ x_\text{max} = \begin{cases} \max(X) &amp; \text{if~}x_\text{max} = \text{None} \\ (1 - c) x_\text{max} + c \max(X) &amp; \text{otherwise} \end{cases}\\ \end{array}</annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mtext>min/max</mtext></msub></mrow><annotation encoding="application/x-tex">x_\text{min/max}</annotation></semantics></math></span></span></span> is the running average min/max, <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span></span></span> is is the incoming tensor, and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span></span></span> is the <code>averaging_constant</code>.</p> <p>The scale and zero point are then computed as in <a class="reference internal" href="torch.ao.quantization.observer.minmaxobserver.html#torch.ao.quantization.observer.MinMaxObserver" title="torch.ao.quantization.observer.MinMaxObserver"><code>MinMaxObserver</code></a>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Only works with <code>torch.per_tensor_affine</code> quantization scheme.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>If the running minimum equals to the running maximum, the scale and zero_point are set to 1.0 and 0.</p> </div> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver.html</a>
  </p>
</div>
