<h1 id="torch-cov">torch.cov</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.cov">
<code>torch.cov(input, *, correction=1, fweights=None, aweights=None) → Tensor</code> </dt> <dd>
<p>Estimates the covariance matrix of the variables given by the <code>input</code> matrix, where rows are the variables and columns are the observations.</p> <p>A covariance matrix is a square matrix giving the covariance of each pair of variables. The diagonal contains the variance of each variable (covariance of a variable with itself). By definition, if <code>input</code> represents a single variable (Scalar or 1D) then its variance is returned.</p> <p>The sample covariance of the variables <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span></span> and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span></span> is given by:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>cov</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo stretchy="false">)</mo></mrow><mrow><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>N</mi><mo>−</mo><mi>δ</mi><mi>N</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{cov}(x,y) = \frac{\sum^{N}_{i = 1}(x_{i} - \bar{x})(y_{i} - \bar{y})}{\max(0,~N~-~\delta N)} </annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar{x}</annotation></semantics></math></span></span></span> and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar{y}</annotation></semantics></math></span></span></span> are the simple means of the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span></span> and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span></span> respectively, and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">\delta N</annotation></semantics></math></span></span></span> is the <code>correction</code>.</p> <p>If <code>fweights</code> and/or <code>aweights</code> are provided, the weighted covariance is calculated, which is given by:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>cov</mtext><mi>w</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>μ</mi><mi>x</mi><mo>∗</mo></msubsup><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>μ</mi><mi>y</mi><mo>∗</mo></msubsup><mo stretchy="false">)</mo></mrow><mrow><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><mo>−</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><msub><mi>a</mi><mi>i</mi></msub></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mi>i</mi></msub></mrow></mfrac><mi>δ</mi><mi>N</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{cov}_w(x,y) = \frac{\sum^{N}_{i = 1}w_i(x_{i} - \mu_x^*)(y_{i} - \mu_y^*)} {\max(0,~\sum^{N}_{i = 1}w_i~-~\frac{\sum^{N}_{i = 1}w_ia_i}{\sum^{N}_{i = 1}w_i}~\delta N)} </annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span></span></span> denotes <code>fweights</code> or <code>aweights</code> (<code>f</code> and <code>a</code> for brevity) based on whichever is provided, or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>=</mo><mi>f</mi><mo>×</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">w = f \times a</annotation></semantics></math></span></span></span> if both are provided, and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>μ</mi><mi>x</mi><mo>∗</mo></msubsup><mo>=</mo><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>w</mi><mi>i</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\mu_x^* = \frac{\sum^{N}_{i = 1}w_ix_{i} }{\sum^{N}_{i = 1}w_i}</annotation></semantics></math></span></span></span> is the weighted mean of the variable. If not provided, <code>f</code> and/or <code>a</code> can be seen as a <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant="double-struck">1</mn></mrow><annotation encoding="application/x-tex">\mathbb{1}</annotation></semantics></math></span></span></span> vector of appropriate size.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – A 2D matrix containing multiple variables and observations, or a Scalar or 1D vector representing a single variable.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>correction</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – difference between the sample size and sample degrees of freedom. Defaults to Bessel’s correction, <code>correction = 1</code> which returns the unbiased estimate, even if both <code>fweights</code> and <code>aweights</code> are specified. <code>correction = 0</code> will return the simple average. Defaults to <code>1</code>.</li> <li>
<strong>fweights</strong> (<a class="reference internal" href="torch.tensor.html#torch.tensor" title="torch.tensor">tensor</a><em>, </em><em>optional</em>) – A Scalar or 1D tensor of observation vector frequencies representing the number of times each observation should be repeated. Its numel must equal the number of columns of <code>input</code>. Must have integral dtype. Ignored if <code>None</code>. Defaults to <code>None</code>.</li> <li>
<strong>aweights</strong> (<a class="reference internal" href="torch.tensor.html#torch.tensor" title="torch.tensor">tensor</a><em>, </em><em>optional</em>) – A Scalar or 1D array of observation vector weights. These relative weights are typically large for observations considered “important” and smaller for observations considered less “important”. Its numel must equal the number of columns of <code>input</code>. Must have floating point dtype. Ignored if <code>None</code>. Defaults to <code>None</code>.</li> </ul> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>(Tensor) The covariance matrix of the variables.</p> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.corrcoef.html#torch.corrcoef" title="torch.corrcoef"><code>torch.corrcoef()</code></a> normalized covariance matrix.</p> </div> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[0, 2], [1, 1], [2, 0]]).T
&gt;&gt;&gt; x
tensor([[0, 1, 2],
        [2, 1, 0]])
&gt;&gt;&gt; torch.cov(x)
tensor([[ 1., -1.],
        [-1.,  1.]])
&gt;&gt;&gt; torch.cov(x, correction=0)
tensor([[ 0.6667, -0.6667],
        [-0.6667,  0.6667]])
&gt;&gt;&gt; fw = torch.randint(1, 10, (3,))
&gt;&gt;&gt; fw
tensor([1, 6, 9])
&gt;&gt;&gt; aw = torch.rand(3)
&gt;&gt;&gt; aw
tensor([0.4282, 0.0255, 0.4144])
&gt;&gt;&gt; torch.cov(x, fweights=fw, aweights=aw)
tensor([[ 0.4169, -0.4169],
        [-0.4169,  0.4169]])
</pre> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.cov.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.cov.html</a>
  </p>
</div>
