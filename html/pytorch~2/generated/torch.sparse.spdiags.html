<h1 id="torch-sparse-spdiags">torch.sparse.spdiags</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.sparse.spdiags">
<code>torch.sparse.spdiags(diagonals, offsets, shape, layout=None) → Tensor</code> </dt> <dd>
<p>Creates a sparse 2D tensor by placing the values from rows of <code>diagonals</code> along specified diagonals of the output</p> <p>The <code>offsets</code> tensor controls which diagonals are set.</p> <ul class="simple"> <li>If <code>offsets[i]</code> = 0, it is the main diagonal</li> <li>If <code>offsets[i]</code> &lt; 0, it is below the main diagonal</li> <li>If <code>offsets[i]</code> &gt; 0, it is above the main diagonal</li> </ul> <p>The number of rows in <code>diagonals</code> must match the length of <code>offsets</code>, and an offset may not be repeated.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>diagonals</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – Matrix storing diagonals row-wise</li> <li>
<strong>offsets</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – The diagonals to be set, stored as a vector</li> <li>
<strong>shape</strong> (<em>2-tuple</em><em> of </em><em>ints</em>) – The desired shape of the result</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>layout</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.layout" title="torch.layout"><code>torch.layout</code></a>, optional) – The desired layout of the returned tensor. <code>torch.sparse_coo</code>, <code>torch.sparse_csc</code> and <code>torch.sparse_csr</code> are supported. Default: <code>torch.sparse_coo</code></p> </dd> </dl> <p>Examples:</p> <p>Set the main and first two lower diagonals of a matrix:</p> <pre data-language="python">&gt;&gt;&gt; diags = torch.arange(9).reshape(3, 3)
&gt;&gt;&gt; diags
tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
&gt;&gt;&gt; s = torch.sparse.spdiags(diags, torch.tensor([0, -1, -2]), (3, 3))
&gt;&gt;&gt; s
tensor(indices=tensor([[0, 1, 2, 1, 2, 2],
                       [0, 1, 2, 0, 1, 0]]),
       values=tensor([0, 1, 2, 3, 4, 6]),
       size=(3, 3), nnz=6, layout=torch.sparse_coo)
&gt;&gt;&gt; s.to_dense()
tensor([[0, 0, 0],
        [3, 1, 0],
        [6, 4, 2]])
</pre> <p>Change the output layout:</p> <pre data-language="python">&gt;&gt;&gt; diags = torch.arange(9).reshape(3, 3)
&gt;&gt;&gt; diags
tensor([[0, 1, 2],[3, 4, 5], [6, 7, 8])
&gt;&gt;&gt; s = torch.sparse.spdiags(diags, torch.tensor([0, -1, -2]), (3, 3), layout=torch.sparse_csr)
&gt;&gt;&gt; s
tensor(crow_indices=tensor([0, 1, 3, 6]),
       col_indices=tensor([0, 0, 1, 0, 1, 2]),
       values=tensor([0, 3, 1, 6, 4, 2]), size=(3, 3), nnz=6,
       layout=torch.sparse_csr)
&gt;&gt;&gt; s.to_dense()
tensor([[0, 0, 0],
        [3, 1, 0],
        [6, 4, 2]])
</pre> <p>Set partial diagonals of a large output:</p> <pre data-language="python">&gt;&gt;&gt; diags = torch.tensor([[1, 2], [3, 4]])
&gt;&gt;&gt; offsets = torch.tensor([0, -1])
&gt;&gt;&gt; torch.sparse.spdiags(diags, offsets, (5, 5)).to_dense()
tensor([[1, 0, 0, 0, 0],
        [3, 2, 0, 0, 0],
        [0, 4, 0, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0]])
</pre> <div class="admonition note"> <p class="admonition-title">Note</p> <p>When setting the values along a given diagonal the index into the diagonal and the index into the row of <code>diagonals</code> is taken as the column index in the output. This has the effect that when setting a diagonal with a positive offset <code>k</code> the first value along that diagonal will be the value in position <code>k</code> of the row of <code>diagonals</code></p> </div> <p>Specifying a positive offset:</p> <pre data-language="python">&gt;&gt;&gt; diags = torch.tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]])
&gt;&gt;&gt; torch.sparse.spdiags(diags, torch.tensor([0, 1, 2]), (5, 5)).to_dense()
tensor([[1, 2, 3, 0, 0],
        [0, 2, 3, 0, 0],
        [0, 0, 3, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.sparse.spdiags.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.sparse.spdiags.html</a>
  </p>
</div>
