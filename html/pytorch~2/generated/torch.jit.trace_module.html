<h1 id="torch-jit-trace-module">torch.jit.trace_module</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.jit.trace_module">
<code>torch.jit.trace_module(mod, inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-05, strict=True, _force_outplace=False, _module_class=None, _compilation_unit=&lt;torch.jit.CompilationUnit object&gt;, example_inputs_is_kwarg=False, _store_inputs=True)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/jit/_trace.html#trace_module"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Trace a module and return an executable <a class="reference internal" href="torch.jit.scriptmodule.html#torch.jit.ScriptModule" title="torch.jit.ScriptModule"><code>ScriptModule</code></a> that will be optimized using just-in-time compilation. When a module is passed to <a class="reference internal" href="torch.jit.trace.html#torch.jit.trace" title="torch.jit.trace"><code>torch.jit.trace</code></a>, only the <code>forward</code> method is run and traced. With <code>trace_module</code>, you can specify a dictionary of method names to example inputs to trace (see the <code>inputs</code>) argument below.</p> <p>See <a class="reference internal" href="torch.jit.trace.html#torch.jit.trace" title="torch.jit.trace"><code>torch.jit.trace</code></a> for more information on tracing.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>mod</strong> (<a class="reference internal" href="torch.nn.module.html#torch.nn.Module" title="torch.nn.Module">torch.nn.Module</a>) – A <code>torch.nn.Module</code> containing methods whose names are specified in <code>inputs</code>. The given methods will be compiled as a part of a single <code>ScriptModule</code>.</li> <li>
<strong>inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)">dict</a>) – A dict containing sample inputs indexed by method names in <code>mod</code>. The inputs will be passed to methods whose names correspond to inputs’ keys while tracing. <code>{ 'forward' : example_forward_input, 'method2': example_method2_input}</code>
</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>check_trace</strong> (<code>bool</code>, optional) – Check if the same inputs run through traced code produce the same outputs. Default: <code>True</code>. You might want to disable this if, for example, your network contains non- deterministic ops or if you are sure that the network is correct despite a checker failure.</li> <li>
<strong>check_inputs</strong> (<a class="reference internal" href="../hub.html#torch.hub.list" title="torch.hub.list">list</a><em> of </em><em>dicts</em><em>, </em><em>optional</em>) – A list of dicts of input arguments that should be used to check the trace against what is expected. Each tuple is equivalent to a set of input arguments that would be specified in <code>inputs</code>. For best results, pass in a set of checking inputs representative of the space of shapes and types of inputs you expect the network to see. If not specified, the original <code>inputs</code> are used for checking</li> <li>
<strong>check_tolerance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – Floating-point comparison tolerance to use in the checker procedure. This can be used to relax the checker strictness in the event that results diverge numerically for a known reason, such as operator fusion.</li> <li>
<strong>example_inputs_is_kwarg</strong> (<code>bool</code>, optional) – This parameter indicate whether the example inputs is a pack pack of keyword arguments. Default: <code>False</code>.</li> </ul> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A <a class="reference internal" href="torch.jit.scriptmodule.html#torch.jit.ScriptModule" title="torch.jit.ScriptModule"><code>ScriptModule</code></a> object with a single <code>forward</code> method containing the traced code. When <code>func</code> is a <code>torch.nn.Module</code>, the returned <a class="reference internal" href="torch.jit.scriptmodule.html#torch.jit.ScriptModule" title="torch.jit.ScriptModule"><code>ScriptModule</code></a> will have the same set of sub-modules and parameters as <code>func</code>.</p> </dd> </dl> <p>Example (tracing a module with multiple methods):</p> <pre data-language="python">import torch
import torch.nn as nn

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv2d(1, 1, 3)

    def forward(self, x):
        return self.conv(x)

    def weighted_kernel_sum(self, weight):
        return weight * self.conv.weight


n = Net()
example_weight = torch.rand(1, 1, 3, 3)
example_forward_input = torch.rand(1, 1, 3, 3)

# Trace a specific method and construct `ScriptModule` with
# a single `forward` method
module = torch.jit.trace(n.forward, example_forward_input)

# Trace a module (implicitly traces `forward`) and construct a
# `ScriptModule` with a single `forward` method
module = torch.jit.trace(n, example_forward_input)

# Trace specific methods on a module (specified in `inputs`), constructs
# a `ScriptModule` with `forward` and `weighted_kernel_sum` methods
inputs = {'forward' : example_forward_input, 'weighted_kernel_sum' : example_weight}
module = torch.jit.trace_module(n, inputs)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.jit.trace_module.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.jit.trace_module.html</a>
  </p>
</div>
