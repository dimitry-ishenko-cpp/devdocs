<h1 id="torch-nn-functional-gelu">torch.nn.functional.gelu</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nn.functional.gelu">
<code>torch.nn.functional.gelu(input, approximate='none') → Tensor</code> </dt> <dd>
<p>When the approximate argument is ‘none’, it applies element-wise the function <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>GELU</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>∗</mo><mi mathvariant="normal">Φ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{GELU}(x) = x * \Phi(x)</annotation></semantics></math></span></span></span></p> <p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Φ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Phi(x)</annotation></semantics></math></span></span></span> is the Cumulative Distribution Function for Gaussian Distribution.</p> <p>When the approximate argument is ‘tanh’, Gelu is estimated with</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>GELU</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.5</mn><mo>∗</mo><mi>x</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mtext>Tanh</mtext><mo stretchy="false">(</mo><msqrt><mrow><mn>2</mn><mi mathvariant="normal">/</mi><mi>π</mi></mrow></msqrt><mo>∗</mo><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mn>0.044715</mn><mo>∗</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{GELU}(x) = 0.5 * x * (1 + \text{Tanh}(\sqrt{2 / \pi} * (x + 0.044715 * x^3))) </annotation></semantics></math></span></span></span>
</div>
<p>See <a class="reference external" href="https://arxiv.org/abs/1606.08415">Gaussian Error Linear Units (GELUs)</a>.</p> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.functional.gelu.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.functional.gelu.html</a>
  </p>
</div>
