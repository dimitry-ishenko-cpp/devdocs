<h1 id="torch-linalg-lu-factor">torch.linalg.lu_factor</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.lu_factor">
<code>torch.linalg.lu_factor(A, *, bool pivot=True, out=None) -&gt; (Tensor, Tensor)</code> </dt> <dd>
<p>Computes a compact representation of the LU factorization with partial pivoting of a matrix.</p> <p>This function computes a compact representation of the decomposition given by <a class="reference internal" href="torch.linalg.lu.html#torch.linalg.lu" title="torch.linalg.lu"><code>torch.linalg.lu()</code></a>. If the matrix is square, this representation may be used in <a class="reference internal" href="torch.linalg.lu_solve.html#torch.linalg.lu_solve" title="torch.linalg.lu_solve"><code>torch.linalg.lu_solve()</code></a> to solve system of linear equations that share the matrix <code>A</code>.</p> <p>The returned decomposition is represented as a named tuple <code>(LU, pivots)</code>. The <code>LU</code> matrix has the same shape as the input matrix <code>A</code>. Its upper and lower triangular parts encode the non-constant elements of <code>L</code> and <code>U</code> of the LU decomposition of <code>A</code>.</p> <p>The returned permutation matrix is represented by a 1-indexed vector. <code>pivots[i] == j</code> represents that in the <code>i</code>-th step of the algorithm, the <code>i</code>-th row was permuted with the <code>j-1</code>-th row.</p> <p>On CUDA, one may use <code>pivot</code><code>= False</code>. In this case, this function returns the LU decomposition without pivoting if it exists.</p> <p>Supports inputs of float, double, cfloat and cdouble dtypes. Also supports batches of matrices, and if the inputs are batches of matrices then the output has the same batch dimensions.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>When inputs are on a CUDA device, this function synchronizes that device with the CPU. For a version of this function that does not synchronize, see <a class="reference internal" href="torch.linalg.lu_factor_ex.html#torch.linalg.lu_factor_ex" title="torch.linalg.lu_factor_ex"><code>torch.linalg.lu_factor_ex()</code></a>.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>The LU decomposition is almost never unique, as often there are different permutation matrices that can yield different LU decompositions. As such, different platforms, like SciPy, or inputs on different devices, may produce different valid decompositions.</p> <p>Gradient computations are only supported if the input matrix is full-rank. If this condition is not met, no error will be thrown, but the gradient may not be finite. This is because the LU decomposition with pivoting is not differentiable at these points.</p> </div> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.linalg.lu_solve.html#torch.linalg.lu_solve" title="torch.linalg.lu_solve"><code>torch.linalg.lu_solve()</code></a> solves a system of linear equations given the output of this function provided the input matrix was square and invertible.</p> <p><a class="reference internal" href="torch.lu_unpack.html#torch.lu_unpack" title="torch.lu_unpack"><code>torch.lu_unpack()</code></a> unpacks the tensors returned by <a class="reference internal" href="#torch.linalg.lu_factor" title="torch.linalg.lu_factor"><code>lu_factor()</code></a> into the three matrices <code>P, L, U</code> that form the decomposition.</p> <p><a class="reference internal" href="torch.linalg.lu.html#torch.linalg.lu" title="torch.linalg.lu"><code>torch.linalg.lu()</code></a> computes the LU decomposition with partial pivoting of a possibly non-square matrix. It is a composition of <a class="reference internal" href="#torch.linalg.lu_factor" title="torch.linalg.lu_factor"><code>lu_factor()</code></a> and <a class="reference internal" href="torch.lu_unpack.html#torch.lu_unpack" title="torch.lu_unpack"><code>torch.lu_unpack()</code></a>.</p> <p><a class="reference internal" href="torch.linalg.solve.html#torch.linalg.solve" title="torch.linalg.solve"><code>torch.linalg.solve()</code></a> solves a system of linear equations. It is a composition of <a class="reference internal" href="#torch.linalg.lu_factor" title="torch.linalg.lu_factor"><code>lu_factor()</code></a> and <a class="reference internal" href="torch.linalg.lu_solve.html#torch.linalg.lu_solve" title="torch.linalg.lu_solve"><code>lu_solve()</code></a>.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>A</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, m, n)</code> where <code>*</code> is zero or more batch dimensions.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>pivot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – Whether to compute the LU decomposition with partial pivoting, or the regular LU decomposition. <code>pivot</code><code>= False</code> not supported on CPU. Default: <code>True</code>.</li> <li>
<strong>out</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a><em>, </em><em>optional</em>) – tuple of two tensors to write the output to. Ignored if <code>None</code>. Default: <code>None</code>.</li> </ul> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A named tuple <code>(LU, pivots)</code>.</p> </dd> <dt class="field-even">Raises</dt> <dd class="field-even">
<p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.12)"><strong>RuntimeError</strong></a> – if the <code>A</code> matrix is not invertible or any matrix in a batched <code>A</code> is not invertible.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(2, 3, 3)
&gt;&gt;&gt; B1 = torch.randn(2, 3, 4)
&gt;&gt;&gt; B2 = torch.randn(2, 3, 7)
&gt;&gt;&gt; A_factor = torch.linalg.lu_factor(A)
&gt;&gt;&gt; X1 = torch.linalg.lu_solve(A_factor, B1)
&gt;&gt;&gt; X2 = torch.linalg.lu_solve(A_factor, B2)
&gt;&gt;&gt; torch.allclose(A @ X1, B1)
True
&gt;&gt;&gt; torch.allclose(A @ X2, B2)
True
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.lu_factor.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.lu_factor.html</a>
  </p>
</div>
