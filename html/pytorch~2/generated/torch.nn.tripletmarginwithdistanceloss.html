<h1 id="tripletmarginwithdistanceloss">TripletMarginWithDistanceLoss</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.nn.TripletMarginWithDistanceLoss">
<code>class torch.nn.TripletMarginWithDistanceLoss(*, distance_function=None, margin=1.0, swap=False, reduction='mean')</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/modules/loss.html#TripletMarginWithDistanceLoss"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Creates a criterion that measures the triplet loss given input tensors <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span></span>, <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span></span>, and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> (representing anchor, positive, and negative examples, respectively), and a nonnegative, real-valued function (“distance function”) used to compute the relationship between the anchor and positive example (“positive distance”) and the anchor and negative example (“negative distance”).</p> <p>The unreduced loss (i.e., with <code>reduction</code> set to <code>'none'</code>) can be described as:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mi>L</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>l</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>l</mi><mi>N</mi></msub><msup><mo stretchy="false">}</mo><mi mathvariant="normal">⊤</mi></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi>l</mi><mi>i</mi></msub><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>n</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\ell(a, p, n) = L = \{l_1,\dots,l_N\}^\top, \quad l_i = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\} </annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span></span> is the batch size; <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span></span></span> is a nonnegative, real-valued function quantifying the closeness of two tensors, referred to as the <code>distance_function</code>; and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">margin</annotation></semantics></math></span></span></span> is a nonnegative margin representing the minimum difference between the positive and negative distances that is required for the loss to be 0. The input tensors have <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span></span> elements each and can be of any shape that the distance function can handle.</p> <p>If <code>reduction</code> is not <code>'none'</code> (default <code>'mean'</code>), then:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">mean</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if reduction</mtext><mo>=</mo><mtext>‘mean’;</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">sum</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if reduction</mtext><mo>=</mo><mtext>‘sum’.</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\ell(x, y) = \begin{cases} \operatorname{mean}(L), &amp; \text{if reduction} = \text{`mean';}\\ \operatorname{sum}(L), &amp; \text{if reduction} = \text{`sum'.} \end{cases} </annotation></semantics></math></span></span></span>
</div>
<p>See also <a class="reference internal" href="torch.nn.tripletmarginloss.html#torch.nn.TripletMarginLoss" title="torch.nn.TripletMarginLoss"><code>TripletMarginLoss</code></a>, which computes the triplet loss for input tensors using the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">l_p</annotation></semantics></math></span></span></span> distance as the distance function.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>distance_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – A nonnegative, real-valued function that quantifies the closeness of two tensors. If not specified, <code>nn.PairwiseDistance</code> will be used. Default: <code>None</code>
</li> <li>
<strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – A nonnegative margin representing the minimum difference between the positive and negative distances required for the loss to be 0. Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives. Default: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></span>.</li> <li>
<strong>swap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – Whether to use the distance swap described in the paper <code>Learning shallow convolutional feature descriptors with triplet losses</code> by V. Balntas, E. Riba et al. If True, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation. Default: <code>False</code>.</li> <li>
<strong>reduction</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><em>optional</em>) – Specifies the (optional) reduction to apply to the output: <code>'none'</code> | <code>'mean'</code> | <code>'sum'</code>. <code>'none'</code>: no reduction will be applied, <code>'mean'</code>: the sum of the output will be divided by the number of elements in the output, <code>'sum'</code>: the output will be summed. Default: <code>'mean'</code>
</li> </ul> </dd> </dl> <dl class="simple"> <dt>Shape:</dt>
<dd>
<ul class="simple"> <li>Input: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mo>∗</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, *)</annotation></semantics></math></span></span></span> where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span></span> represents any number of additional dimensions as supported by the distance function.</li> <li>Output: A Tensor of shape <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N)</annotation></semantics></math></span></span></span> if <code>reduction</code> is <code>'none'</code>, or a scalar otherwise.</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; # Initialize embeddings
&gt;&gt;&gt; embedding = nn.Embedding(1000, 128)
&gt;&gt;&gt; anchor_ids = torch.randint(0, 1000, (1,))
&gt;&gt;&gt; positive_ids = torch.randint(0, 1000, (1,))
&gt;&gt;&gt; negative_ids = torch.randint(0, 1000, (1,))
&gt;&gt;&gt; anchor = embedding(anchor_ids)
&gt;&gt;&gt; positive = embedding(positive_ids)
&gt;&gt;&gt; negative = embedding(negative_ids)
&gt;&gt;&gt;
&gt;&gt;&gt; # Built-in Distance Function
&gt;&gt;&gt; triplet_loss = \
&gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())
&gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)
&gt;&gt;&gt; output.backward()
&gt;&gt;&gt;
&gt;&gt;&gt; # Custom Distance Function
&gt;&gt;&gt; def l_infinity(x1, x2):
&gt;&gt;&gt;     return torch.max(torch.abs(x1 - x2), dim=1).values
&gt;&gt;&gt;
&gt;&gt;&gt; triplet_loss = (
&gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5))
&gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)
&gt;&gt;&gt; output.backward()
&gt;&gt;&gt;
&gt;&gt;&gt; # Custom Distance Function (Lambda)
&gt;&gt;&gt; triplet_loss = (
&gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(
&gt;&gt;&gt;         distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))
&gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)
&gt;&gt;&gt; output.backward()
</pre> <dl class="simple"> <dt>Reference:</dt>
<dd>
<p>V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses: <a class="reference external" href="http://www.bmva.org/bmvc/2016/papers/paper119/index.html">http://www.bmva.org/bmvc/2016/papers/paper119/index.html</a></p> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.TripletMarginWithDistanceLoss.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.TripletMarginWithDistanceLoss.html</a>
  </p>
</div>
