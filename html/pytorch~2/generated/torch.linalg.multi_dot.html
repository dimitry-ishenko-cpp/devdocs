<h1 id="torch-linalg-multi-dot">torch.linalg.multi_dot</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.multi_dot">
<code>torch.linalg.multi_dot(tensors, *, out=None)</code> </dt> <dd>
<p>Efficiently multiplies two or more matrices by reordering the multiplications so that the fewest arithmetic operations are performed.</p> <p>Supports inputs of float, double, cfloat and cdouble dtypes. This function does not support batched inputs.</p> <p>Every tensor in <code>tensors</code> must be 2D, except for the first and last which may be 1D. If the first tensor is a 1D vector of shape <code>(n,)</code> it is treated as a row vector of shape <code>(1, n)</code>, similarly if the last tensor is a 1D vector of shape <code>(n,)</code> it is treated as a column vector of shape <code>(n, 1)</code>.</p> <p>If the first and last tensors are matrices, the output will be a matrix. However, if either is a 1D vector, then the output will be a 1D vector.</p> <p>Differences with <code>numpy.linalg.multi_dot</code>:</p> <ul class="simple"> <li>Unlike <code>numpy.linalg.multi_dot</code>, the first and last tensors must either be 1D or 2D whereas NumPy allows them to be nD</li> </ul> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function does not broadcast.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This function is implemented by chaining <a class="reference internal" href="torch.mm.html#torch.mm" title="torch.mm"><code>torch.mm()</code></a> calls after computing the optimal matrix multiplication order.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The cost of multiplying two matrices with shapes <code>(a, b)</code> and <code>(b, c)</code> is <code>a * b * c</code>. Given matrices <code>A</code>, <code>B</code>, <code>C</code> with shapes <code>(10, 100)</code>, <code>(100, 5)</code>, <code>(5, 50)</code> respectively, we can calculate the cost of different multiplication orders as follows:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">cost</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>A</mi><mi>B</mi><mo stretchy="false">)</mo><mi>C</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>=</mo><mn>10</mn><mo>×</mo><mn>100</mn><mo>×</mo><mn>5</mn><mo>+</mo><mn>10</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>50</mn><mo>=</mo><mn>7500</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">cost</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">(</mo><mi>B</mi><mi>C</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>=</mo><mn>10</mn><mo>×</mo><mn>100</mn><mo>×</mo><mn>50</mn><mo>+</mo><mn>100</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>50</mn><mo>=</mo><mn>75000</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*} \operatorname{cost}((AB)C) &amp;= 10 \times 100 \times 5 + 10 \times 5 \times 50 = 7500 \\ \operatorname{cost}(A(BC)) &amp;= 10 \times 100 \times 50 + 100 \times 5 \times 50 = 75000 \end{align*}</annotation></semantics></math></span></span></span>
</div>
<p>In this case, multiplying <code>A</code> and <code>B</code> first followed by <code>C</code> is 10 times faster.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>tensors</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a><em>]</em>) – two or more tensors to multiply. The first and last tensors may be 1D or 2D. Every other tensor must be 2D.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – output tensor. Ignored if <code>None</code>. Default: <code>None</code>.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; from torch.linalg import multi_dot

&gt;&gt;&gt; multi_dot([torch.tensor([1, 2]), torch.tensor([2, 3])])
tensor(8)
&gt;&gt;&gt; multi_dot([torch.tensor([[1, 2]]), torch.tensor([2, 3])])
tensor([8])
&gt;&gt;&gt; multi_dot([torch.tensor([[1, 2]]), torch.tensor([[2], [3]])])
tensor([[8]])

&gt;&gt;&gt; A = torch.arange(2 * 3).view(2, 3)
&gt;&gt;&gt; B = torch.arange(3 * 2).view(3, 2)
&gt;&gt;&gt; C = torch.arange(2 * 2).view(2, 2)
&gt;&gt;&gt; multi_dot((A, B, C))
tensor([[ 26,  49],
        [ 80, 148]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.multi_dot.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.multi_dot.html</a>
  </p>
</div>
