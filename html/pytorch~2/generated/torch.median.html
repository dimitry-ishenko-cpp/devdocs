<h1 id="torch-median">torch.median</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.median">
<code>torch.median(input) → Tensor</code> </dt> <dd>
<p>Returns the median of the values in <code>input</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The median is not unique for <code>input</code> tensors with an even number of elements. In this case the lower of the two medians is returned. To compute the mean of both medians, use <a class="reference internal" href="torch.quantile.html#torch.quantile" title="torch.quantile"><code>torch.quantile()</code></a> with <code>q=0.5</code> instead.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function produces deterministic (sub)gradients unlike <code>median(dim=0)</code></p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a
tensor([[ 1.5219, -1.5212,  0.2202]])
&gt;&gt;&gt; torch.median(a)
tensor(0.2202)
</pre> <dl class="py function"> <dt class="sig sig-object py"> <span class="sig-prename descclassname">torch.</span><span class="sig-name descname">median</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">-1</span></em>, <em class="sig-param"><span class="n">keepdim</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">out</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span>
</dt> 
</dl> <p>Returns a namedtuple <code>(values, indices)</code> where <code>values</code> contains the median of each row of <code>input</code> in the dimension <code>dim</code>, and <code>indices</code> contains the index of the median values found in the dimension <code>dim</code>.</p> <p>By default, <code>dim</code> is the last dimension of the <code>input</code> tensor.</p> <p>If <code>keepdim</code> is <code>True</code>, the output tensors are of the same size as <code>input</code> except in the dimension <code>dim</code> where they are of size 1. Otherwise, <code>dim</code> is squeezed (see <a class="reference internal" href="torch.squeeze.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), resulting in the outputs tensor having 1 fewer dimension than <code>input</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The median is not unique for <code>input</code> tensors with an even number of elements in the dimension <code>dim</code>. In this case the lower of the two medians is returned. To compute the mean of both medians in <code>input</code>, use <a class="reference internal" href="torch.quantile.html#torch.quantile" title="torch.quantile"><code>torch.quantile()</code></a> with <code>q=0.5</code> instead.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p><code>indices</code> does not necessarily contain the first occurrence of each median value found, unless it is unique. The exact implementation details are device-specific. Do not expect the same result when run on CPU and GPU in general. For the same reason do not expect the gradients to be deterministic.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – the dimension to reduce.</li> <li>
<strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a>) – whether the output tensor has <code>dim</code> retained or not.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<em>(</em><a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a><em>)</em><em>, </em><em>optional</em>) – The first tensor will be populated with the median values and the second tensor, which must have dtype long, with their indices in the dimension <code>dim</code> of <code>input</code>.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(4, 5)
&gt;&gt;&gt; a
tensor([[ 0.2505, -0.3982, -0.9948,  0.3518, -1.3131],
        [ 0.3180, -0.6993,  1.0436,  0.0438,  0.2270],
        [-0.2751,  0.7303,  0.2192,  0.3321,  0.2488],
        [ 1.0778, -1.9510,  0.7048,  0.4742, -0.7125]])
&gt;&gt;&gt; torch.median(a, 1)
torch.return_types.median(values=tensor([-0.3982,  0.2270,  0.2488,  0.4742]), indices=tensor([1, 4, 4, 3]))
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.median.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.median.html</a>
  </p>
</div>
