<h1 id="event">Event</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.cuda.Event">
<code>class torch.cuda.Event(enable_timing=False, blocking=False, interprocess=False)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Wrapper around a CUDA event.</p> <p>CUDA events are synchronization markers that can be used to monitor the device’s progress, to accurately measure timing, and to synchronize CUDA streams.</p> <p>The underlying CUDA events are lazily initialized when the event is first recorded or exported to another process. After creation, only streams on the same device may record the event. However, streams on any device can wait on the event.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>enable_timing</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – indicates if the event should measure time (default: <code>False</code>)</li> <li>
<strong>blocking</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – if <code>True</code>, <a class="reference internal" href="#torch.cuda.Event.wait" title="torch.cuda.Event.wait"><code>wait()</code></a> will be blocking (default: <code>False</code>)</li> <li>
<strong>interprocess</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a>) – if <code>True</code>, the event can be shared between processes (default: <code>False</code>)</li> </ul> </dd> </dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.elapsed_time">
<code>elapsed_time(end_event)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.elapsed_time"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the time elapsed in milliseconds after the event was recorded and before the end_event was recorded.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.from_ipc_handle">
<code>classmethod from_ipc_handle(device, handle)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.from_ipc_handle"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Reconstruct an event from an IPC handle on the given device.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.ipc_handle">
<code>ipc_handle()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.ipc_handle"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns an IPC handle of this event. If not recorded yet, the event will use the current device.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.query">
<code>query()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.query"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Checks if all work currently captured by event has completed.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A boolean indicating if all work currently captured by event has completed.</p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.record">
<code>record(stream=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.record"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Records the event in a given stream.</p> <p>Uses <code>torch.cuda.current_stream()</code> if no stream is specified. The stream’s device must match the event’s device.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.synchronize">
<code>synchronize()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.synchronize"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Waits for the event to complete.</p> <p>Waits until the completion of all work currently captured in this event. This prevents the CPU thread from proceeding until the event completes.</p>  <div class="admonition note"> <p class="admonition-title">Note</p> <p>This is a wrapper around <code>cudaEventSynchronize()</code>: see <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html">CUDA Event documentation</a> for more info.</p> </div>  </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.Event.wait">
<code>wait(stream=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#Event.wait"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Makes all future work submitted to the given stream wait for this event.</p> <p>Use <code>torch.cuda.current_stream()</code> if no stream is specified.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This is a wrapper around <code>cudaStreamWaitEvent()</code>: see <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html">CUDA Event documentation</a> for more info.</p> </div> </dd>
</dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.cuda.Event.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.cuda.Event.html</a>
  </p>
</div>
