<h1 id="inference-mode">inference_mode</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.inference_mode">
<code>class torch.inference_mode(mode=True)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/autograd/grad_mode.html#inference_mode"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Context-manager that enables or disables inference mode</p> <p>InferenceMode is a new context manager analogous to <a class="reference internal" href="torch.no_grad.html#torch.no_grad" title="torch.no_grad"><code>no_grad</code></a> to be used when you are certain your operations will have no interactions with autograd (e.g., model training). Code run under this mode gets better performance by disabling view tracking and version counter bumps. Note that unlike some other mechanisms that locally enable or disable grad, entering inference_mode also disables to <a class="reference internal" href="../autograd.html#forward-mode-ad"><span class="std std-ref">forward-mode AD</span></a>.</p> <p>This context manager is thread local; it will not affect computation in other threads.</p> <p>Also functions as a decorator.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Inference mode is one of several mechanisms that can enable or disable gradients locally see <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/autograd.html#locally-disable-grad-doc"><span class="std std-ref">Locally disabling gradient computation</span></a> for more information on how they compare.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em> or </em><em>function</em>) â€“ Either a boolean flag whether to enable or disable inference mode or a Python function to decorate with inference mode enabled</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; import torch
&gt;&gt;&gt; x = torch.ones(1, 2, 3, requires_grad=True)
&gt;&gt;&gt; with torch.inference_mode():
...     y = x * x
&gt;&gt;&gt; y.requires_grad
False
&gt;&gt;&gt; y._version
Traceback (most recent call last):
File "&lt;stdin&gt;", line 1, in &lt;module&gt;
RuntimeError: Inference tensors do not track version counter.
&gt;&gt;&gt; @torch.inference_mode()
... def func(x):
...     return x * x
&gt;&gt;&gt; out = func(x)
&gt;&gt;&gt; out.requires_grad
False
&gt;&gt;&gt; @torch.inference_mode
... def doubler(x):
...     return x * 2
&gt;&gt;&gt; out = doubler(x)
&gt;&gt;&gt; out.requires_grad
False
</pre> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.inference_mode.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.inference_mode.html</a>
  </p>
</div>
