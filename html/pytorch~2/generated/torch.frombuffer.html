<h1 id="torch-frombuffer">torch.frombuffer</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.frombuffer">
<code>torch.frombuffer(buffer, *, dtype, count=-1, offset=0, requires_grad=False) → Tensor</code> </dt> <dd>
<p>Creates a 1-dimensional <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor"><code>Tensor</code></a> from an object that implements the Python buffer protocol.</p> <p>Skips the first <code>offset</code> bytes in the buffer, and interprets the rest of the raw bytes as a 1-dimensional tensor of type <a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>dtype</code></a> with <code>count</code> elements.</p> <p>Note that either of the following must be true:</p> <p>1. <code>count</code> is a positive non-zero number, and the total number of bytes in the buffer is less than <code>offset</code> plus <code>count</code> times the size (in bytes) of <a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>dtype</code></a>.</p> <p>2. <code>count</code> is negative, and the length (number of bytes) of the buffer subtracted by the <code>offset</code> is a multiple of the size (in bytes) of <a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>dtype</code></a>.</p> <p>The returned tensor and buffer share the same memory. Modifications to the tensor will be reflected in the buffer and vice versa. The returned tensor is not resizable.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This function increments the reference count for the object that owns the shared memory. Therefore, such memory will not be deallocated before the returned tensor goes out of scope.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function’s behavior is undefined when passed an object implementing the buffer protocol whose data is not on the CPU. Doing so is likely to cause a segmentation fault.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function does not try to infer the <a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>dtype</code></a> (hence, it is not optional). Passing a different <a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>dtype</code></a> than its source may result in unexpected behavior.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>buffer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.12)">object</a>) – a Python object that exposes the buffer interface.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>dtype</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>) – the desired data type of returned tensor.</li> <li>
<strong>count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – the number of desired elements to be read. If negative, all the elements (until the end of the buffer) will be read. Default: -1.</li> <li>
<strong>offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – the number of bytes to skip at the start of the buffer. Default: 0.</li> <li>
<strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – If autograd should record operations on the returned tensor. Default: <code>False</code>.</li> </ul> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; import array
&gt;&gt;&gt; a = array.array('i', [1, 2, 3])
&gt;&gt;&gt; t = torch.frombuffer(a, dtype=torch.int32)
&gt;&gt;&gt; t
tensor([ 1,  2,  3])
&gt;&gt;&gt; t[0] = -1
&gt;&gt;&gt; a
array([-1,  2,  3])

&gt;&gt;&gt; # Interprets the signed char bytes as 32-bit integers.
&gt;&gt;&gt; # Each 4 signed char elements will be interpreted as
&gt;&gt;&gt; # 1 signed 32-bit integer.
&gt;&gt;&gt; import array
&gt;&gt;&gt; a = array.array('b', [-1, 0, 0, 0])
&gt;&gt;&gt; torch.frombuffer(a, dtype=torch.int32)
tensor([255], dtype=torch.int32)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.frombuffer.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.frombuffer.html</a>
  </p>
</div>
