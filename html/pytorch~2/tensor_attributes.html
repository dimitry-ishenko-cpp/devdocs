<h1 id="tensor-attributes-doc">Tensor Attributes</h1> <p id="tensor-attributes">Each <code>torch.Tensor</code> has a <a class="reference internal" href="#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, <a class="reference internal" href="#torch.device" title="torch.device"><code>torch.device</code></a>, and <a class="reference internal" href="#torch.layout" title="torch.layout"><code>torch.layout</code></a>.</p>  <h2 id="dtype-doc">torch.dtype</h2> <dl class="py class" id="torch-dtype"> <dt class="sig sig-object py" id="torch.dtype">
<code>class torch.dtype</code> </dt> 
</dl> <p>A <a class="reference internal" href="#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> is an object that represents the data type of a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>. PyTorch has twelve different data types:</p> <table class="docutils colwidths-auto align-default"> <thead> <tr>
<th class="head"><p>Data type</p></th> <th class="head"><p>dtype</p></th> <th class="head"><p>Legacy Constructors</p></th> </tr> </thead>  <tr>
<td><p>32-bit floating point</p></td> <td><p><code>torch.float32</code> or <code>torch.float</code></p></td> <td><p><code>torch.*.FloatTensor</code></p></td> </tr> <tr>
<td><p>64-bit floating point</p></td> <td><p><code>torch.float64</code> or <code>torch.double</code></p></td> <td><p><code>torch.*.DoubleTensor</code></p></td> </tr> <tr>
<td><p>64-bit complex</p></td> <td><p><code>torch.complex64</code> or <code>torch.cfloat</code></p></td> <td></td> </tr> <tr>
<td><p>128-bit complex</p></td> <td><p><code>torch.complex128</code> or <code>torch.cdouble</code></p></td> <td></td> </tr> <tr>
<td><p>16-bit floating point <a class="footnote-reference brackets" href="#id3" id="id1">1</a></p></td> <td><p><code>torch.float16</code> or <code>torch.half</code></p></td> <td><p><code>torch.*.HalfTensor</code></p></td> </tr> <tr>
<td><p>16-bit floating point <a class="footnote-reference brackets" href="#id4" id="id2">2</a></p></td> <td><p><code>torch.bfloat16</code></p></td> <td><p><code>torch.*.BFloat16Tensor</code></p></td> </tr> <tr>
<td><p>8-bit integer (unsigned)</p></td> <td><p><code>torch.uint8</code></p></td> <td><p><code>torch.*.ByteTensor</code></p></td> </tr> <tr>
<td><p>8-bit integer (signed)</p></td> <td><p><code>torch.int8</code></p></td> <td><p><code>torch.*.CharTensor</code></p></td> </tr> <tr>
<td><p>16-bit integer (signed)</p></td> <td><p><code>torch.int16</code> or <code>torch.short</code></p></td> <td><p><code>torch.*.ShortTensor</code></p></td> </tr> <tr>
<td><p>32-bit integer (signed)</p></td> <td><p><code>torch.int32</code> or <code>torch.int</code></p></td> <td><p><code>torch.*.IntTensor</code></p></td> </tr> <tr>
<td><p>64-bit integer (signed)</p></td> <td><p><code>torch.int64</code> or <code>torch.long</code></p></td> <td><p><code>torch.*.LongTensor</code></p></td> </tr> <tr>
<td><p>Boolean</p></td> <td><p><code>torch.bool</code></p></td> <td><p><code>torch.*.BoolTensor</code></p></td> </tr>  </table> <dl class="footnote brackets"> <dt class="label" id="id3">
<code>1</code> </dt> <dd>
<p>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important.</p> </dd> <dt class="label" id="id4">
<code>2</code> </dt> <dd>
<p>Sometimes referred to as Brain Floating Point: use 1 sign, 8 exponent and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as <code>float32</code></p> </dd> </dl> <p>To find out if a <a class="reference internal" href="#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> is a floating point data type, the property <a class="reference internal" href="generated/torch.is_floating_point.html#torch.is_floating_point" title="torch.is_floating_point"><code>is_floating_point</code></a> can be used, which returns <code>True</code> if the data type is a floating point data type.</p> <p>To find out if a <a class="reference internal" href="#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> is a complex data type, the property <a class="reference internal" href="generated/torch.is_complex.html#torch.is_complex" title="torch.is_complex"><code>is_complex</code></a> can be used, which returns <code>True</code> if the data type is a complex data type.</p> <p id="type-promotion-doc">When the dtypes of inputs to an arithmetic operation (<code>add</code>, <code>sub</code>, <code>div</code>, <code>mul</code>) differ, we promote by finding the minimum dtype that satisfies the following rules:</p> <ul class="simple"> <li>If the type of a scalar operand is of a higher category than tensor operands (where complex &gt; floating &gt; integral &gt; boolean), we promote to a type with sufficient size to hold all scalar operands of that category.</li> <li>If a zero-dimension tensor operand has a higher category than dimensioned operands, we promote to a type with sufficient size and category to hold all zero-dim tensor operands of that category.</li> <li>If there are no higher-category zero-dim operands, we promote to a type with sufficient size and category to hold all dimensioned operands.</li> </ul> <p>A floating point scalar operand has dtype <code>torch.get_default_dtype()</code> and an integral non-boolean scalar operand has dtype <code>torch.int64</code>. Unlike numpy, we do not inspect values when determining the minimum <code>dtypes</code> of an operand. Quantized and complex types are not yet supported.</p> <p>Promotion Examples:</p> <pre data-language="python">&gt;&gt;&gt; float_tensor = torch.ones(1, dtype=torch.float)
&gt;&gt;&gt; double_tensor = torch.ones(1, dtype=torch.double)
&gt;&gt;&gt; complex_float_tensor = torch.ones(1, dtype=torch.complex64)
&gt;&gt;&gt; complex_double_tensor = torch.ones(1, dtype=torch.complex128)
&gt;&gt;&gt; int_tensor = torch.ones(1, dtype=torch.int)
&gt;&gt;&gt; long_tensor = torch.ones(1, dtype=torch.long)
&gt;&gt;&gt; uint_tensor = torch.ones(1, dtype=torch.uint8)
&gt;&gt;&gt; double_tensor = torch.ones(1, dtype=torch.double)
&gt;&gt;&gt; bool_tensor = torch.ones(1, dtype=torch.bool)
# zero-dim tensors
&gt;&gt;&gt; long_zerodim = torch.tensor(1, dtype=torch.long)
&gt;&gt;&gt; int_zerodim = torch.tensor(1, dtype=torch.int)

&gt;&gt;&gt; torch.add(5, 5).dtype
torch.int64
# 5 is an int64, but does not have higher category than int_tensor so is not considered.
&gt;&gt;&gt; (int_tensor + 5).dtype
torch.int32
&gt;&gt;&gt; (int_tensor + long_zerodim).dtype
torch.int32
&gt;&gt;&gt; (long_tensor + int_tensor).dtype
torch.int64
&gt;&gt;&gt; (bool_tensor + long_tensor).dtype
torch.int64
&gt;&gt;&gt; (bool_tensor + uint_tensor).dtype
torch.uint8
&gt;&gt;&gt; (float_tensor + double_tensor).dtype
torch.float64
&gt;&gt;&gt; (complex_float_tensor + complex_double_tensor).dtype
torch.complex128
&gt;&gt;&gt; (bool_tensor + int_tensor).dtype
torch.int32
# Since long is a different kind than float, result dtype only needs to be large enough
# to hold the float.
&gt;&gt;&gt; torch.add(long_tensor, float_tensor).dtype
torch.float32
</pre> <dl class="simple"> <dt>
<code>When the output tensor of an arithmetic operation is specified, we allow casting to its dtype except that:</code> </dt>
<dd>
<ul class="simple"> <li>An integral output tensor cannot accept a floating point tensor.</li> <li>A boolean output tensor cannot accept a non-boolean tensor.</li> <li>A non-complex output tensor cannot accept a complex tensor</li> </ul> </dd> </dl> <p>Casting Examples:</p> <pre data-language="python"># allowed:
&gt;&gt;&gt; float_tensor *= float_tensor
&gt;&gt;&gt; float_tensor *= int_tensor
&gt;&gt;&gt; float_tensor *= uint_tensor
&gt;&gt;&gt; float_tensor *= bool_tensor
&gt;&gt;&gt; float_tensor *= double_tensor
&gt;&gt;&gt; int_tensor *= long_tensor
&gt;&gt;&gt; int_tensor *= uint_tensor
&gt;&gt;&gt; uint_tensor *= int_tensor

# disallowed (RuntimeError: result type can't be cast to the desired output type):
&gt;&gt;&gt; int_tensor *= float_tensor
&gt;&gt;&gt; bool_tensor *= int_tensor
&gt;&gt;&gt; bool_tensor *= uint_tensor
&gt;&gt;&gt; float_tensor *= complex_float_tensor
</pre>   <h2 id="device-doc">torch.device</h2> <dl class="py class" id="torch-device"> <dt class="sig sig-object py" id="torch.device">
<code>class torch.device</code> </dt> 
</dl> <p>A <a class="reference internal" href="#torch.device" title="torch.device"><code>torch.device</code></a> is an object representing the device on which a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> is or will be allocated.</p> <p>The <a class="reference internal" href="#torch.device" title="torch.device"><code>torch.device</code></a> contains a device type (<code>'cpu'</code>, <code>'cuda'</code> or <code>'mps'</code>) and optional device ordinal for the device type. If the device ordinal is not present, this object will always represent the current device for the device type, even after <a class="reference internal" href="generated/torch.cuda.set_device.html#torch.cuda.set_device" title="torch.cuda.set_device"><code>torch.cuda.set_device()</code></a> is called; e.g., a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> constructed with device <code>'cuda'</code> is equivalent to <code>'cuda:X'</code> where X is the result of <a class="reference internal" href="generated/torch.cuda.current_device.html#torch.cuda.current_device" title="torch.cuda.current_device"><code>torch.cuda.current_device()</code></a>.</p> <p>A <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>â€™s device can be accessed via the <a class="reference internal" href="generated/torch.tensor.device.html#torch.Tensor.device" title="torch.Tensor.device"><code>Tensor.device</code></a> property.</p> <p>A <a class="reference internal" href="#torch.device" title="torch.device"><code>torch.device</code></a> can be constructed via a string or via a string and device ordinal</p> <p>Via a string:</p> <pre data-language="python">&gt;&gt;&gt; torch.device('cuda:0')
device(type='cuda', index=0)

&gt;&gt;&gt; torch.device('cpu')
device(type='cpu')

&gt;&gt;&gt; torch.device('mps')
device(type='mps')

&gt;&gt;&gt; torch.device('cuda')  # current cuda device
device(type='cuda')
</pre> <p>Via a string and device ordinal:</p> <pre data-language="python">&gt;&gt;&gt; torch.device('cuda', 0)
device(type='cuda', index=0)

&gt;&gt;&gt; torch.device('mps', 0)
device(type='mps', index=0)

&gt;&gt;&gt; torch.device('cpu', 0)
device(type='cpu', index=0)
</pre> <p>The device object can also be used as a context manager to change the default device tensors are allocated on:</p> <pre data-language="python">&gt;&gt;&gt; with torch.device('cuda:1'):
...     r = torch.randn(2, 3)
&gt;&gt;&gt; r.device
device(type='cuda', index=1)
</pre> <p>This context manager has no effect if a factory function is passed an explicit, non-None device argument. To globally change the default device, see also <a class="reference internal" href="generated/torch.set_default_device.html#torch.set_default_device" title="torch.set_default_device"><code>torch.set_default_device()</code></a>.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function imposes a slight performance cost on every Python call to the torch API (not just factory functions). If this is causing problems for you, please comment on <a class="reference external" href="https://github.com/pytorch/pytorch/issues/92701">https://github.com/pytorch/pytorch/issues/92701</a></p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The <a class="reference internal" href="#torch.device" title="torch.device"><code>torch.device</code></a> argument in functions can generally be substituted with a string. This allows for fast prototyping of code.</p> <pre data-language="python">&gt;&gt;&gt; # Example of a function that takes in a torch.device
&gt;&gt;&gt; cuda1 = torch.device('cuda:1')
&gt;&gt;&gt; torch.randn((2,3), device=cuda1)
</pre> <pre data-language="python">&gt;&gt;&gt; # You can substitute the torch.device with a string
&gt;&gt;&gt; torch.randn((2,3), device='cuda:1')
</pre> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For legacy reasons, a device can be constructed via a single device ordinal, which is treated as a cuda device. This matches <a class="reference internal" href="generated/torch.tensor.get_device.html#torch.Tensor.get_device" title="torch.Tensor.get_device"><code>Tensor.get_device()</code></a>, which returns an ordinal for cuda tensors and is not supported for cpu tensors.</p> <pre data-language="python">&gt;&gt;&gt; torch.device(1)
device(type='cuda', index=1)
</pre> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Methods which take a device will generally accept a (properly formatted) string or (legacy) integer device ordinal, i.e. the following are all equivalent:</p> <pre data-language="python">&gt;&gt;&gt; torch.randn((2,3), device=torch.device('cuda:1'))
&gt;&gt;&gt; torch.randn((2,3), device='cuda:1')
&gt;&gt;&gt; torch.randn((2,3), device=1)  # legacy
</pre> </div>   <h2 id="layout-doc">torch.layout</h2> <dl class="py class" id="torch-layout"> <dt class="sig sig-object py" id="torch.layout">
<code>class torch.layout</code> </dt> 
</dl> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>The <code>torch.layout</code> class is in beta and subject to change.</p> </div> <p>A <a class="reference internal" href="#torch.layout" title="torch.layout"><code>torch.layout</code></a> is an object that represents the memory layout of a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>. Currently, we support <code>torch.strided</code> (dense Tensors) and have beta support for <code>torch.sparse_coo</code> (sparse COO Tensors).</p> <p><code>torch.strided</code> represents dense Tensors and is the memory layout that is most commonly used. Each strided tensor has an associated <code>torch.Storage</code>, which holds its data. These tensors provide multi-dimensional, <a class="reference external" href="https://en.wikipedia.org/wiki/Stride_of_an_array">strided</a> view of a storage. Strides are a list of integers: the k-th stride represents the jump in the memory necessary to go from one element to the next one in the k-th dimension of the Tensor. This concept makes it possible to perform many tensor operations efficiently.</p> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
&gt;&gt;&gt; x.stride()
(5, 1)

&gt;&gt;&gt; x.t().stride()
(1, 5)
</pre> <p>For more information on <code>torch.sparse_coo</code> tensors, see <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">torch.sparse</span></a>.</p>   <h2 id="torch-memory-format">torch.memory_format</h2> <dl class="py class"> <dt class="sig sig-object py" id="torch.memory_format">
<code>class torch.memory_format</code> </dt> 
</dl> <p>A <a class="reference internal" href="#torch.memory_format" title="torch.memory_format"><code>torch.memory_format</code></a> is an object representing the memory format on which a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> is or will be allocated.</p> <p>Possible values are:</p> <ul class="simple"> <li>
<code>torch.contiguous_format</code>: Tensor is or will be allocated in dense non-overlapping memory. Strides represented by values in decreasing order.</li> <li>
<code>torch.channels_last</code>: Tensor is or will be allocated in dense non-overlapping memory. Strides represented by values in <code>strides[0] &gt; strides[2] &gt; strides[3] &gt; strides[1] == 1</code> aka NHWC order.</li> <li>
<code>torch.channels_last_3d</code>: Tensor is or will be allocated in dense non-overlapping memory. Strides represented by values in <code>strides[0] &gt; strides[2] &gt; strides[3] &gt; strides[4] &gt; strides[1] == 1</code> aka NDHWC order.</li> <li>
<code>torch.preserve_format</code>: Used in functions like <code>clone</code> to preserve the memory format of the input tensor. If input tensor is allocated in dense non-overlapping memory, the output tensor strides will be copied from the input. Otherwise output strides will follow <code>torch.contiguous_format</code>
</li> </ul><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/tensor_attributes.html" class="_attribution-link">https://pytorch.org/docs/2.1/tensor_attributes.html</a>
  </p>
</div>
