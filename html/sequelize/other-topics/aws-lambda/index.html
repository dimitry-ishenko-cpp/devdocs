<h1>Using sequelize in AWS Lambda</h1>
<p><a href="https://aws.amazon.com/lambda/" target="_blank" rel="noopener noreferrer">AWS Lambda</a> is a serverless computing service that allows customers to run code without having to worry about the underlying servers. Using <code>sequelize</code> in AWS Lambda can be tricky if certain concepts are not properly understood and an appropriate configuration is not used. This guide seeks to clarify some of these concepts so users of the library can properly configure <code>sequelize</code> for AWS Lambda and troubleshoot issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tldr">TL;DR<a class="hash-link" href="#tldr" title="Direct link to heading">​</a>
</h2>
<p>If you just want to learn how to properly configure <code>sequelize</code> <a href="../connection-pool/index.html">connection pooling</a> for AWS Lambda, all you need to know is that <code>sequelize</code> connection pooling does not get along well with AWS Lambda's Node.js runtime and it ends up causing more problems than it solves. Therefore, the most appropriate configuration is to <strong>use pooling within the same invocation</strong> and <strong>avoid pooling across invocations</strong> (i.e. close all connections at the end):</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">const { Sequelize } = require("sequelize");

let sequelize = null;

async function loadSequelize() {
  const sequelize = new Sequelize(/* (...) */, {
    // (...)
    pool: {
      /*
       * Lambda functions process one request at a time but your code may issue multiple queries
       * concurrently. Be wary that `sequelize` has methods that issue 2 queries concurrently
       * (e.g. `Model.findAndCountAll()`). Using a value higher than 1 allows concurrent queries to
       * be executed in parallel rather than serialized. Careful with executing too many queries in
       * parallel per Lambda function execution since that can bring down your database with an
       * excessive number of connections.
       *
       * Ideally you want to choose a `max` number where this holds true:
       * max * EXPECTED_MAX_CONCURRENT_LAMBDA_INVOCATIONS &lt; MAX_ALLOWED_DATABASE_CONNECTIONS * 0.8
       */
      max: 2,
      /*
       * Set this value to 0 so connection pool eviction logic eventually cleans up all connections
       * in the event of a Lambda function timeout.
       */
      min: 0,
      /*
       * Set this value to 0 so connections are eligible for cleanup immediately after they're
       * returned to the pool.
       */
      idle: 0,
      // Choose a small enough value that fails fast if a connection takes too long to be established.
      acquire: 3000,
      /*
       * Ensures the connection pool attempts to be cleaned up automatically on the next Lambda
       * function invocation, if the previous invocation timed out.
       */
      evict: CURRENT_LAMBDA_FUNCTION_TIMEOUT
    }
  });

  // or `sequelize.sync()`
  await sequelize.authenticate();

  return sequelize;
}

module.exports.handler = async function (event, callback) {
  // re-use the sequelize instance across invocations to improve performance
  if (!sequelize) {
    sequelize = await loadSequelize();
  } else {
    // restart connection pool to ensure connections are not re-used across invocations
    sequelize.connectionManager.initPools();

    // restore `getConnection()` if it has been overwritten by `close()`
    if (sequelize.connectionManager.hasOwnProperty("getConnection")) {
      delete sequelize.connectionManager.getConnection;
    }
  }

  try {
    return await doSomethingWithSequelize(sequelize);
  } finally {
    // close any opened connections during the invocation
    // this will wait for any in-progress queries to finish before closing the connections
    await sequelize.connectionManager.close();
  }
};</pre>

</div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-aws-rds-proxy">Using AWS RDS Proxy<a class="hash-link" href="#using-aws-rds-proxy" title="Direct link to heading">​</a>
</h3>
<p>If your are using <a href="https://aws.amazon.com/rds/" target="_blank" rel="noopener noreferrer">AWS RDS</a> and you are using <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-proxy.html" target="_blank" rel="noopener noreferrer">Aurora</a> or a <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html" target="_blank" rel="noopener noreferrer">supported database engine</a>, then connect to your database using <a href="https://aws.amazon.com/rds/proxy/" target="_blank" rel="noopener noreferrer">AWS RDS Proxy</a>. This will make sure that opening/closing connections on each invocation is not an expensive operation for your underlying database server.</p>
<hr>
<p>If you want to understand why you must use sequelize this way in AWS Lambda, continue reading the rest of this document:</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-nodejs-event-loop">The Node.js event loop<a class="hash-link" href="#the-nodejs-event-loop" title="Direct link to heading">​</a>
</h2>
<p>The <a href="https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/" target="_blank" rel="noopener noreferrer">Node.js event loop</a> is:</p>
<blockquote><p>what allows Node.js to perform non-blocking I/O operations — despite the fact that JavaScript is single-threaded —</p></blockquote>
<p>While the event loop implementation is in C++, here's a simplified JavaScript pseudo-implementation that illustrates how Node.js would execute a script named <code>index.js</code>:</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">// see: https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/
// see: https://www.youtube.com/watch?v=P9csgxBgaZ8
// see: https://www.youtube.com/watch?v=PNa9OMajw9w
const process = require('process');

/*
 * counter of pending events
 *
 * reference counter is increased for every:
 *
 * 1. scheduled timer: `setTimeout()`, `setInterval()`, etc.
 * 2. scheduled immediate: `setImmediate()`.
 * 3. syscall of non-blocking IO: `require('net').Server.listen()`, etc.
 * 4. scheduled task to the thread pool: `require('fs').WriteStream.write()`, etc.
 *
 * reference counter is decreased for every:
 *
 * 1. elapsed timer
 * 2. executed immediate
 * 3. completed non-blocking IO
 * 4. completed thread pool task
 *
 * references can be explicitly decreased by invoking `.unref()` on some
 * objects like: `require('net').Socket.unref()`
 */
let refs = 0;

/*
 * a heap of timers, sorted by next ocurrence
 *
 * whenever `setTimeout()` or `setInterval()` is invoked, a timer gets added here
 */
const timersHeap = /* (...) */;

/*
 * a FIFO queue of immediates
 *
 * whenever `setImmediate()` is invoked, it gets added here
 */
const immediates = /* (...) */;

/*
 * a FIFO queue of next tick callbacks
 *
 * whenever `require('process').nextTick()` is invoked, the callback gets added here
 */
const nextTickCallbacks = [];

/*
 * a heap of Promise-related callbacks, sorted by promise constructors callbacks first,
 * and then resolved/rejected callbacks
 *
 * whenever a new Promise instance is created via `new Promise` or a promise resolves/rejects
 * the appropriate callback (if any) gets added here
 */
const promiseCallbacksHeap = /* ... */;

function execTicksAndPromises() {
  while (nextTickCallbacks.length || promiseCallbacksHeap.size()) {
    // execute all callbacks scheduled with `process.nextTick()`
    while (nextTickCallbacks.length) {
      const callback = nextTickCallbacks.shift();
      callback();
    }

    // execute all promise-related callbacks
    while (promiseCallbacksHeap.size()) {
      const callback = promiseCallbacksHeap.pop();
      callback();
    }
  }
}

try {
  // execute index.js
  require('./index');
  execTicksAndPromises();

  do {
    // timers phase: executes all elapsed timers
    getElapsedTimerCallbacks(timersHeap).forEach(callback =&gt; {
      callback();
      execTicksAndPromises();
    });

    // pending callbacks phase: executes some system operations (like `TCP errors`) that are not
    //                          executed in the poll phase
    getPendingCallbacks().forEach(callback =&gt; {
      callback();
      execTicksAndPromises();
    })

    // poll phase: gets completed non-blocking I/O events or thread pool tasks and invokes the
    //             corresponding callbacks; if there are none and there's no pending immediates,
    //             it blocks waiting for events/completed tasks for a maximum of `maxWait`
    const maxWait = computeWhenNextTimerElapses(timersHeap);
    pollForEventsFromKernelOrThreadPool(maxWait, immediates).forEach(callback =&gt; {
      callback();
      execTicksAndPromises();
    });

    // check phase: execute available immediates; if an immediate callback invokes `setImmediate()`
    //              it will be invoked on the next event loop iteration
    getImmediateCallbacks(immediates).forEach(callback =&gt; {
      callback();
      execTicksAndPromises();
    });

    // close callbacks phase: execute special `.on('close')` callbacks
    getCloseCallbacks().forEach(callback =&gt; {
      callback();
      execTicksAndPromises();
    });

    if (refs === 0) {
      // listeners of this event may execute code that increments `refs`
      process.emit('beforeExit');
    }
  } while (refs &gt; 0);
} catch (err) {
  if (!process.listenerCount('uncaughtException')) {
    // default behavior: print stack and exit with status code 1
    console.error(err.stack);
    process.exit(1);
  } else {
    // there are listeners: emit the event and exit using `process.exitCode || 0`
    process.emit('uncaughtException');
    process.exit();
  }
}</pre>

</div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="aws-lambda-function-handler-types-in-nodejs">AWS Lambda function handler types in Node.js<a class="hash-link" href="#aws-lambda-function-handler-types-in-nodejs" title="Direct link to heading">​</a>
</h2>
<p>AWS Lambda handlers come in two flavors in Node.js:</p>
<p><a href="https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html#nodejs-handler-sync" target="_blank" rel="noopener noreferrer">Non-async handlers</a> (i.e. <code>callback</code>):</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">module.exports.handler = function (event, context, callback) {
  try {
    doSomething();
    callback(null, "Hello World!"); // Lambda returns "Hello World!"
  } catch (err) {
    // try/catch is not required, uncaught exceptions invoke `callback(err)` implicitly
    callback(err); // Lambda fails with `err`
  }
};</pre>

</div></div>
<p><a href="https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html#nodejs-handler-async" target="_blank" rel="noopener noreferrer">Async handlers</a> (i.e. use <code>async</code>/<code>await</code> or <code>Promise</code>s):</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">// async/await
module.exports.handler = async function (event, context) {
  try {
    await doSomethingAsync();
    return "Hello World!"; // equivalent of: callback(null, "Hello World!");
  } catch (err) {
    // try/cath is not required, async functions always return a Promise
    throw err; // equivalent of: callback(err);
  }
};

// Promise
module.exports.handler = function (event, context) {
  /*
   * must return a `Promise` to be considered an async handler
   *
   * an uncaught exception that prevents a `Promise` to be returned
   * by the handler will "downgrade" the handler to non-async
   */
  return Promise.resolve()
    .then(() =&gt; doSomethingAsync())
    .then(() =&gt; "Hello World!");
};</pre>

</div></div>
<p>While at first glance it seems like async VS non-async handlers are simply a code styling choice, there is a fundamental difference between the two:</p>
<ul>
<li>In async handlers, a Lambda function execution finishes when the <code>Promise</code> returned by the handler resolves or rejects, regardless of whether the event loop is empty or not.</li>
<li>In non-async handlers, a Lambda function execution finishes when one of the following conditions occur:<ul>
<li>The event loop is empty (<a href="https://nodejs.org/dist/latest-v12.x/docs/api/process.html#process_event_beforeexit" target="_blank" rel="noopener noreferrer">process <code>'beforeExit'</code> event</a> is used to detect this).</li>
<li>The <code>callback</code> argument is invoked and <a href="https://docs.aws.amazon.com/lambda/latest/dg/nodejs-context.html" target="_blank" rel="noopener noreferrer"><code>context.callbackWaitsForEmptyEventLoop</code></a> is set to <code>false</code>.</li>
</ul>
</li>
</ul>
<p>This fundamental difference is very important to understand in order to rationalize how <code>sequelize</code> may be affected by it. Here are a few examples to illustrate the difference:</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">// no callback invoked
module.exports.handler = function () {
  // Lambda finishes AFTER `doSomething()` is invoked
  setTimeout(() =&gt; doSomething(), 1000);
};

// callback invoked
module.exports.handler = function (event, context, callback) {
  // Lambda finishes AFTER `doSomething()` is invoked
  setTimeout(() =&gt; doSomething(), 1000);
  callback(null, "Hello World!");
};

// callback invoked, context.callbackWaitsForEmptyEventLoop = false
module.exports.handler = function (event, context, callback) {
  // Lambda finishes BEFORE `doSomething()` is invoked
  context.callbackWaitsForEmptyEventLoop = false;
  setTimeout(() =&gt; doSomething(), 2000);
  setTimeout(() =&gt; callback(null, "Hello World!"), 1000);
};

// async/await
module.exports.handler = async function () {
  // Lambda finishes BEFORE `doSomething()` is invoked
  setTimeout(() =&gt; doSomething(), 1000);
  return "Hello World!";
};

// Promise
module.exports.handler = function () {
  // Lambda finishes BEFORE `doSomething()` is invoked
  setTimeout(() =&gt; doSomething(), 1000);
  return Promise.resolve("Hello World!");
};</pre>

</div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="aws-lambda-execution-environments-ie-containers">AWS Lambda execution environments (i.e. containers)<a class="hash-link" href="#aws-lambda-execution-environments-ie-containers" title="Direct link to heading">​</a>
</h2>
<p>AWS Lambda function handlers are invoked by built-in or custom <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html" target="_blank" rel="noopener noreferrer">runtimes</a> which run in execution environments (i.e. containers) that <a href="https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/" target="_blank" rel="noopener noreferrer">may or may not be re-used</a> across invocations. Containers can only process <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html" target="_blank" rel="noopener noreferrer">one request at a time</a>. Concurrent invocations of a Lambda function means that a container instance will be created for each concurrent request.</p>
<p>In practice, this means that Lambda functions should be designed to be stateless but developers can use state for caching purposes:</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">let sequelize = null;

module.exports.handler = async function () {
  /*
   * sequelize will already be loaded if the container is re-used
   *
   * containers are never re-used when a Lambda function's code change
   *
   * while the time elapsed between Lambda invocations is used as a factor to determine whether
   * a container is re-used, no assumptions should be made of when a container is actually re-used
   *
   * AWS does not publicly document the rules of container re-use "by design" since containers
   * can be recycled in response to internal AWS Lambda events (e.g. a Lambda function container
   * may be recycled even if the function is constanly invoked)
   */
  if (!sequelize) {
    sequelize = await loadSequelize();
  }

  return await doSomethingWithSequelize(sequelize);
};</pre>

</div></div>
<p>When a Lambda function doesn't wait for the event loop to be empty and a container is re-used, the event loop will be "paused" until the next invocation occurs. For example:</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">let counter = 0;

module.exports.handler = function (event, context, callback) {
  /*
   * The first invocation (i.e. container initialized) will:
   * - log:
   *   - Fast timeout invoked. Request id: 00000000-0000-0000-0000-000000000000 | Elapsed ms: 5XX
   * - return: 1
   *
   * Wait 3 seconds and invoke the Lambda again. The invocation (i.e. container re-used) will:
   * - log:
   *   - Slow timeout invoked. Request id: 00000000-0000-0000-0000-000000000000 | Elapsed ms: 3XXX
   *   - Fast timeout invoked. Request id: 11111111-1111-1111-1111-111111111111 | Elapsed ms: 5XX
   * - return: 3
   */
  const now = Date.now();

  context.callbackWaitsForEmptyEventLoop = false;

  setTimeout(() =&gt; {
    console.log(
      "Slow timeout invoked. Request id:",
      context.awsRequestId,
      "| Elapsed ms:",
      Date.now() - now
    );
    counter++;
  }, 1000);

  setTimeout(() =&gt; {
    console.log(
      "Fast timeout invoked. Request id:",
      context.awsRequestId,
      "| Elapsed ms:",
      Date.now() - now
    );
    counter++;
    callback(null, counter);
  }, 500);
};</pre>

</div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="sequelize-connection-pooling-in-aws-lambda">Sequelize connection pooling in AWS Lambda<a class="hash-link" href="#sequelize-connection-pooling-in-aws-lambda" title="Direct link to heading">​</a>
</h2>
<p><code>sequelize</code> uses connection pooling for optimizing usage of database connections. The connection pool used by <code>sequelize</code> is implemented using <code>setTimeout()</code> callbacks (which are processed by the Node.js event loop).</p>
<p>Given the fact that AWS Lambda containers process one request at a time, one would be tempted to configure <code>sequelize</code> as follows:</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">const { Sequelize } = require('sequelize');

const sequelize = new Sequelize(/* (...) */, {
  // (...)
  pool: { min: 1, max: 1 }
});</pre>

</div></div>
<p>This configuration prevents Lambda containers from overwhelming the database server with an excessive number of connections (since each container takes at most 1 connection). It also makes sure that the container's connection is not garbage collected when idle so the connection does not need to be re-established when the Lambda container is re-used. Unfortunately, this configuration presents a set of issues:</p>
<ol>
<li>Lambdas that wait for the event loop to be empty will always time out. <code>sequelize</code> connection pools schedule a <code>setTimeout</code> every <a href="https://sequelize.org/api/v6/class/src/sequelize.js~Sequelize.html#instance-constructor-constructor" target="_blank" rel="noopener noreferrer"><code>options.pool.evict</code></a> ms until <strong>all idle connections have been closed</strong>. However, since <code>min</code> is set to <code>1</code>, there will always be at least one idle connection in the pool, resulting in an infinite event loop.</li>
<li>Some operations like <a href="https://sequelize.org/api/v6/class/src/model.js~Model.html#static-method-findAndCountAll" target="_blank" rel="noopener noreferrer"><code>Model.findAndCountAll()</code></a> execute multiple queries asynchronously (e.g. <a href="https://sequelize.org/api/v6/class/src/model.js~Model.html#static-method-count" target="_blank" rel="noopener noreferrer"><code>Model.count()</code></a> and <a href="https://sequelize.org/api/v6/class/src/model.js~Model.html#static-method-findAll" target="_blank" rel="noopener noreferrer"><code>Model.findAll()</code></a>). Using a maximum of one connection forces the queries to be exectued serially (rather than in parallel using two connections). While this may be an acceptable performance compromise in order to maintain a manageable number of database connections, long running queries may result in <a href="https://sequelize.org/api/v6/class/src/errors/connection/connection-acquire-timeout-error.js~ConnectionAcquireTimeoutError.html" target="_blank" rel="noopener noreferrer"><code>ConnectionAcquireTimeoutError</code></a> if a query takes more than the default or configured <a href="https://sequelize.org/api/v6/class/src/sequelize.js~Sequelize.html#instance-constructor-constructor" target="_blank" rel="noopener noreferrer"><code>options.pool.acquire</code></a> timeout to complete. This is because the serialized query will be stuck waiting on the pool until the connection used by the other query is released.</li>
<li>If the AWS Lambda function times out (i.e. the configured AWS Lambda timeout is exceeded), the Node.js event loop will be "paused" regardless of its state. This can cause race conditions that result in connection errors. For example, you may encounter situations where a very expensive query causes a Lambda function to time out, the event loop is "paused" before the expensive query finishes and the connection is released back to the pool, and subsequent Lambda invocations fail with a <code>ConnectionAcquireTimeoutError</code> if the container is re-used and the connection has not been returned after <code>options.pool.acquire</code> ms.</li>
</ol>
<p>You can attempt to mitigate issue <strong>#2</strong> by using <code>{ min: 1, max: 2 }</code>. However, this will still suffer from issues <strong>#1</strong> and <strong>#3</strong> whilst introducing additional ones:</p>
<ol>
<li>Race conditions may occur where the even loop "pauses" before a connection pool eviction callback executes or more than <code>options.pool.evict</code> time elapses between Lambda invocations. This can result in timeout errors, handshake errors, and other connection-related errors.</li>
<li>If you use an operation like <code>Model.findAndCountAll()</code> and either the underlying <code>Model.count()</code> or <code>Model.findAll()</code> queries fail, you won't be able to ensure that the other query has finished executing (and the connection is put back into the pool) before the Lambda function execution finishes and the event loop is "paused". This can leave connections in a stale state which can result in prematurely closed TCP connections and other connection-related errors.</li>
</ol>
<p>Using <code>{ min: 2, max: 2 }</code> mitigates additional issue <strong>#1</strong>. However, the configuration still suffers from all the other issues (original <strong>#1</strong>, <strong>#3</strong>, and additional <strong>#2</strong>).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="detailed-race-condition-example">Detailed race condition example<a class="hash-link" href="#detailed-race-condition-example" title="Direct link to heading">​</a>
</h3>
<p>In order to make sense of the example, you'll need a bit more context of how certain parts of Lambda and <code>sequelize</code> are implemented.</p>
<p>The built-in AWS Lambda runtime for <code>nodejs.12x</code> is implemented in Node.js. You can access the entire source code of the runtime by reading the contents of <code>/var/runtime/</code> inside a Node.js Lambda function. The relevant subset of the code is as follows:</p>
<p><strong>runtime/Runtime.js</strong></p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">class Runtime {
  // (...)

  // each iteration is executed in the event loop `check` phase
  scheduleIteration() {
    setImmediate(() =&gt; this.handleOnce().then(/* (...) */));
  }

  async handleOnce() {
    // get next invocation. see: https://docs.aws.amazon.com/lambda/latest/dg/runtimes-api.html#runtimes-api-next
    let { bodyJson, headers } = await this.client.nextInvocation();

    // prepare `context` handler parameter
    let invokeContext = new InvokeContext(headers);
    invokeContext.updateLoggingContext();

    // prepare `callback` handler parameter
    let [callback, callbackContext] = CallbackContext.build(
      this.client,
      invokeContext.invokeId,
      this.scheduleIteration.bind(this)
    );

    try {
      // this listener is subscribed to process.on('beforeExit')
      // so that when when `context.callbackWaitsForEmptyEventLoop === true`
      // the Lambda execution finishes after the event loop is empty
      this._setDefaultExitListener(invokeContext.invokeId);

      // execute handler
      const result = this.handler(
        JSON.parse(bodyJson),
        invokeContext.attachEnvironmentData(callbackContext),
        callback
      );

      // finish the execution if the handler is async
      if (_isPromise(result)) {
        result
          .then(callbackContext.succeed, callbackContext.fail)
          .catch(callbackContext.fail);
      }
    } catch (err) {
      callback(err);
    }
  }
}</pre>

</div></div>
<p>The runtime schedules an iteration at the end of the initialization code:</p>
<p><strong>runtime/index.js</strong></p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">// (...)

new Runtime(client, handler, errorCallbacks).scheduleIteration();</pre>

</div></div>
<p>All SQL queries invoked by a Lambda handler using <code>sequelize</code> are ultimately executed using <a href="https://sequelize.org/api/v6/class/src/sequelize.js~Sequelize.html#instance-method-query" target="_blank" rel="noopener noreferrer">Sequelize.prototype.query()</a>. This method is responsible for obtaining a connection from the pool, executing the query, and releasing the connection back to the pool when the query completes. The following snippet shows a simplification of the method's logic for queries without transactions:</p>
<p><strong>sequelize.js</strong></p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">class Sequelize {
  // (...)

  query(sql, options) {
    // (...)

    const connection = await this.connectionManager.getConnection(options);
    const query = new this.dialect.Query(connection, this, options);

    try {
      return await query.run(sql, bindParameters);
    } finally {
      await this.connectionManager.releaseConnection(connection);
    }
  }
}</pre>

</div></div>
<p>The field <code>this.connectionManager</code> is an instance of a dialect-specific <code>ConnectionManager</code> class. All dialect-specific managers inherit from an abstract <code>ConnectionManager</code> class which initializes the connection pool and configures it to invoke the dialect-specific class' <code>connect()</code> method everytime a new connection needs to be created. The following snippet shows a simplification of the <code>mysql</code> dialect <code>connect()</code> method:</p>
<p><strong>mysql/connection-manager.js</strong></p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">class ConnectionManager {
  // (...)

  async connect(config) {
    // (...)
    return await new Promise((resolve, reject) =&gt; {
      // uses mysql2's `new Connection()`
      const connection = this.lib.createConnection(connectionConfig);

      const errorHandler = (e) =&gt; {
        connection.removeListener("connect", connectHandler);
        connection.removeListener("error", connectHandler);
        reject(e);
      };

      const connectHandler = () =&gt; {
        connection.removeListener("error", errorHandler);
        resolve(connection);
      };

      connection.on("error", errorHandler);
      connection.once("connect", connectHandler);
    });
  }
}</pre>

</div></div>
<p>The field <code>this.lib</code> refers to <a href="https://www.npmjs.com/package/mysql2" target="_blank" rel="noopener noreferrer"><code>mysql2</code></a> and the function <code>createConnection()</code> creates a connection by creating an instance of a <code>Connection</code> class. The relevant subset of this class is as follows:</p>
<p><strong>mysql2/connection.js</strong></p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex">
<pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" data-language="js">class Connection extends EventEmitter {
  constructor(opts) {
    // (...)

    // create Socket
    this.stream = /* (...) */;

    // when data is received, clear timeout
    this.stream.on('data', data =&gt; {
      if (this.connectTimeout) {
        Timers.clearTimeout(this.connectTimeout);
        this.connectTimeout = null;
      }
      this.packetParser.execute(data);
    });

    // (...)

    // when handshake is completed, emit the 'connect' event
    handshakeCommand.on('end', () =&gt; {
      this.emit('connect', handshakeCommand.handshake);
    });

    // set a timeout to trigger if no data is received on the socket
    if (this.config.connectTimeout) {
      const timeoutHandler = this._handleTimeoutError.bind(this);
      this.connectTimeout = Timers.setTimeout(
        timeoutHandler,
        this.config.connectTimeout
      );
    }
  }

  // (...)

  _handleTimeoutError() {
    if (this.connectTimeout) {
      Timers.clearTimeout(this.connectTimeout);
      this.connectTimeout = null;
    }
    this.stream.destroy &amp;&amp; this.stream.destroy();
    const err = new Error('connect ETIMEDOUT');
    err.errorno = 'ETIMEDOUT';
    err.code = 'ETIMEDOUT';
    err.syscall = 'connect';

    // this will emit the 'error' event
    this._handleNetworkError(err);
  }
}</pre>

</div></div>
<p>Based on the previous code, the following sequence of events shows how a connection pooling race condition with <code>{ min: 1, max: 1 }</code> can result with in a <code>ETIMEDOUT</code> error:</p>
<ol>
<li>A Lambda invocation is received (new container):<ol>
<li>The event loop enters the <code>check</code> phase and <code>runtime/Runtime.js</code>'s <code>handleOnce()</code> method is invoked.<ol><li>The <code>handleOnce()</code> method invokes <code>await this.client.nextInvocation()</code> and waits.</li></ol>
</li>
<li>The event loop skips the <code>timers</code> phase since there no pending timers.</li>
<li>The event loop enters the <code>poll</code> phase and the <code>handleOnce()</code> method continues.</li>
<li>The Lambda handler is invoked.</li>
<li>The Lambda handler invokes <code>Model.count()</code> which invokes <code>sequelize.js</code>'s <code>query()</code> which invokes <code>connectionManager.getConnection()</code>.</li>
<li>The connection pool initializes a <code>setTimeout(..., config.pool.acquire)</code> for <code>Model.count()</code> and invokes <code>mysql/connection-manager.js</code>'s <code>connect()</code> to create a new connection.</li>
<li>
<code>mysql2/connection.js</code> creates the TCP socket and initializes a <code>setTimeout()</code> for failing the connection with <code>ETIMEDOUT</code>.</li>
<li>The promise returned by the handler rejects (for reasons not detailed here) so the Lambda function execution finishes and the Node.js event loop is "paused".</li>
</ol>
</li>
<li>Enough time elapses beween invocations so that:<ol>
<li>
<code>config.pool.acquire</code> timer elapses.</li>
<li>
<code>mysql2</code> connection timer has not elapsed yet but has almost elapsed (i.e. race condition).</li>
</ol>
</li>
<li>A second Lambda invocation is received (container re-used):<ol>
<li>The event loop is "resumed".</li>
<li>The event loop enters the <code>check</code> phase and <code>runtime/Runtime.js</code>'s <code>handleOnce()</code> method is invoked.</li>
<li>The event loop enters the <code>timers</code> phase and the <code>config.pool.acquire</code> timer elapses, causing the previous invocation's <code>Model.count()</code> promise to reject with <code>ConnectionAcquireTimeoutError</code>.</li>
<li>The event loop enters the <code>poll</code> phase and the <code>handleOnce()</code> method continues.</li>
<li>The Lambda handler is invoked.</li>
<li>The Lambda handler invokes <code>Model.count()</code> which invokes <code>sequelize.js</code>'s <code>query()</code> which invokes <code>connectionManager.getConnection()</code>.</li>
<li>The connection pool initializes a <code>setTimeout(..., config.pool.acquire)</code> for <code>Model.count()</code> and since <code>{ max : 1 }</code> it waits for the pending <code>connect()</code> promise to complete.</li>
<li>The event loop skips the <code>check</code> phase since there are no pending immediates.</li>
<li>
<strong>Race condition:</strong> The event loop enters the <code>timers</code> phase and the <code>mysql2</code> connection timeout elapses, resulting in a <code>ETIMEDOUT</code> error that is emitted using <code>connection.emit('error')</code>.</li>
<li>The emitted event rejects the promise in <code>mysql/connection-manager.js</code>'s <code>connect()</code> which in turn forwards the rejected promise to the <code>Model.count()</code> query's promise.</li>
<li>The lambda function fails with an <code>ETIMEDOUT</code> error.</li>
</ol>
</li>
</ol><div class="_attribution">
  <p class="_attribution-p">
    Copyright &copy; 2014&ndash;present Sequelize contributors<br>Licensed under the MIT License.<br>
    <a href="https://sequelize.org/docs/v6/other-topics/aws-lambda/" class="_attribution-link">https://sequelize.org/docs/v6/other-topics/aws-lambda/</a>
  </p>
</div>
