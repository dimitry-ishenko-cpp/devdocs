<h1>Linear algebra and decompositions</h1>      <div> <p>This page explains how to solve linear systems, compute various decompositions such as LU, QR, SVD, eigendecompositions... After reading this page, don't miss our <a href="group__topiclinearalgebradecompositions.html">catalogue </a> of dense matrix decompositions.</p> <h1>
<a id="TutorialLinAlgBasicSolve"></a> Basic linear solving</h1> <p><b>The</b> <b>problem:</b> You have a system of equations, that you have written as a single matrix equation </p>
<p> \[ Ax \: = \: b \] </p> <p> Where <em>A</em> and <em>b</em> are matrices (<em>b</em> could be a vector, as a special case). You want to find a solution <em>x</em>.</p> <p><b>The</b> <b>solution:</b> You can choose between various decompositions, depending on the properties of your matrix <em>A</em>, and depending on whether you favor speed or accuracy. However, let's start with an example that works in all cases, and is a good compromise: </p>
<table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix3f A;
   Vector3f b;
   A &lt;&lt; 1,2,3,  4,5,6,  7,8,10;
   b &lt;&lt; 3, 3, 4;
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   cout &lt;&lt; <span>"Here is the vector b:\n"</span> &lt;&lt; b &lt;&lt; endl;
   Vector3f x = A.colPivHouseholderQr().solve(b);
   cout &lt;&lt; <span>"The solution is:\n"</span> &lt;&lt; x &lt;&lt; endl;
}</pre> </td>
<td>
<pre>Here is the matrix A:
 1  2  3
 4  5  6
 7  8 10
Here is the vector b:
3
3
4
The solution is:
-2
 1
 1
</pre> </td>
</tr> </table> <p>In this example, the colPivHouseholderQr() method returns an object of class <a href="classeigen_1_1colpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with column-pivoting.">ColPivHouseholderQR</a>. Since here the matrix is of type Matrix3f, this line could have been replaced by: </p>
<pre data-language="cpp">ColPivHouseholderQR&lt;Matrix3f&gt; dec(A);
Vector3f x = dec.solve(b);
</pre>
<p>Here, <a href="classeigen_1_1colpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with column-pivoting.">ColPivHouseholderQR</a> is a QR decomposition with column pivoting. It's a good compromise for this tutorial, as it works for all matrices while being quite fast. Here is a table of some other decompositions that you can choose from, depending on your matrix, the problem you are trying to solve, and the trade-off you want to make:</p> <table> <tr> <th>Decomposition </th>
<th>Method </th>
<th>Requirements<br> on the matrix </th>
<th>Speed<br> (small-to-medium) </th>
<th>Speed<br> (large) </th>
<th>Accuracy </th>
</tr> <tr> <td>
<a href="classeigen_1_1partialpivlu.html" title="LU decomposition of a matrix with partial pivoting, and related features.">PartialPivLU</a> </td>
<td>partialPivLu() </td>
<td>Invertible </td>
<td>++ </td>
<td>++ </td>
<td>+ </td>
</tr> <tr> <td>
<a href="classeigen_1_1fullpivlu.html" title="LU decomposition of a matrix with complete pivoting, and related features.">FullPivLU</a> </td>
<td>fullPivLu() </td>
<td>None </td>
<td>- </td>
<td>- - </td>
<td>+++ </td>
</tr> <tr> <td>
<a href="classeigen_1_1householderqr.html" title="Householder QR decomposition of a matrix.">HouseholderQR</a> </td>
<td>householderQr() </td>
<td>None </td>
<td>++ </td>
<td>++ </td>
<td>+ </td>
</tr> <tr> <td>
<a href="classeigen_1_1colpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with column-pivoting.">ColPivHouseholderQR</a> </td>
<td>colPivHouseholderQr() </td>
<td>None </td>
<td>+ </td>
<td>- </td>
<td>+++ </td>
</tr> <tr> <td>
<a href="classeigen_1_1fullpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with full pivoting.">FullPivHouseholderQR</a> </td>
<td>fullPivHouseholderQr() </td>
<td>None </td>
<td>- </td>
<td>- - </td>
<td>+++ </td>
</tr> <tr> <td>
<a href="classeigen_1_1completeorthogonaldecomposition.html" title="Complete orthogonal decomposition (COD) of a matrix.">CompleteOrthogonalDecomposition</a> </td>
<td>completeOrthogonalDecomposition() </td>
<td>None </td>
<td>+ </td>
<td>- </td>
<td>+++ </td>
</tr> <tr> <td>
<a href="classeigen_1_1llt.html" title="Standard Cholesky decomposition (LL^T) of a matrix and associated features.">LLT</a> </td>
<td>llt() </td>
<td>Positive definite </td>
<td>+++ </td>
<td>+++ </td>
<td>+ </td>
</tr> <tr> <td>
<a href="classeigen_1_1ldlt.html" title="Robust Cholesky decomposition of a matrix with pivoting.">LDLT</a> </td>
<td>ldlt() </td>
<td>Positive or negative<br> semidefinite </td>
<td>+++ </td>
<td>+ </td>
<td>++ </td>
</tr> <tr> <td>
<a href="classeigen_1_1bdcsvd.html" title="class Bidiagonal Divide and Conquer SVD">BDCSVD</a> </td>
<td>bdcSvd() </td>
<td>None </td>
<td>- </td>
<td>- </td>
<td>+++ </td>
</tr> <tr> <td>
<a href="classeigen_1_1jacobisvd.html" title="Two-sided Jacobi SVD decomposition of a rectangular matrix.">JacobiSVD</a> </td>
<td>jacobiSvd() </td>
<td>None </td>
<td>- </td>
<td>- - - </td>
<td>+++ </td>
</tr> </table> <p>To get an overview of the true relative speed of the different decompositions, check this <a href="group__densedecompositionbenchmark.html">benchmark </a>.</p> <p>All of these decompositions offer a solve() method that works as in the above example.</p> <p>If you know more about the properties of your matrix, you can use the above table to select the best method. For example, a good choice for solving linear systems with a non-symmetric matrix of full rank is <a href="classeigen_1_1partialpivlu.html" title="LU decomposition of a matrix with partial pivoting, and related features.">PartialPivLU</a>. If you know that your matrix is also symmetric and positive definite, the above table says that a very good choice is the <a href="classeigen_1_1llt.html" title="Standard Cholesky decomposition (LL^T) of a matrix and associated features.">LLT</a> or <a href="classeigen_1_1ldlt.html" title="Robust Cholesky decomposition of a matrix with pivoting.">LDLT</a> decomposition. Here's an example, also demonstrating that using a general matrix (not a vector) as right hand side is possible:</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix2f A, b;
   A &lt;&lt; 2, -1, -1, 3;
   b &lt;&lt; 1, 2, 3, 1;
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   cout &lt;&lt; <span>"Here is the right hand side b:\n"</span> &lt;&lt; b &lt;&lt; endl;
   Matrix2f x = A.ldlt().solve(b);
   cout &lt;&lt; <span>"The solution is:\n"</span> &lt;&lt; x &lt;&lt; endl;
}
</pre> </td>
<td>
<pre>Here is the matrix A:
 2 -1
-1  3
Here is the right hand side b:
1 2
3 1
The solution is:
1.2 1.4
1.4 0.8
</pre> </td>
</tr> </table> <p>For a <a href="group__topiclinearalgebradecompositions.html">much more complete table</a> comparing all decompositions supported by <a href="namespaceeigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> (notice that <a href="namespaceeigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> supports many other decompositions), see our special page on <a href="group__topiclinearalgebradecompositions.html">this topic</a>.</p> <h1>
<a id="TutorialLinAlgLeastsquares"></a> Least squares solving</h1> <p>The most general and accurate method to solve under- or over-determined linear systems in the least squares sense, is the SVD decomposition. <a href="namespaceeigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> provides two implementations. The recommended one is the <a href="classeigen_1_1bdcsvd.html" title="class Bidiagonal Divide and Conquer SVD">BDCSVD</a> class, which scales well for large problems and automatically falls back to the <a href="classeigen_1_1jacobisvd.html" title="Two-sided Jacobi SVD decomposition of a rectangular matrix.">JacobiSVD</a> class for smaller problems. For both classes, their solve() method solved the linear system in the least-squares sense.</p> <p>Here is an example: </p>
<table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   MatrixXf A = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXf::Random</a>(3, 2);
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   VectorXf b = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">VectorXf::Random</a>(3);
   cout &lt;&lt; <span>"Here is the right hand side b:\n"</span> &lt;&lt; b &lt;&lt; endl;
   cout &lt;&lt; <span>"The least-squares solution is:\n"</span>
        &lt;&lt; A.bdcSvd(<a href="group__enums.html#ggae3e239fb70022eb8747994cf5d68b4a9aa7fb4e98834788d0b1b0f2b8467d2527">ComputeThinU</a> | <a href="group__enums.html#ggae3e239fb70022eb8747994cf5d68b4a9a540036417bfecf2e791a70948c227f47">ComputeThinV</a>).solve(b) &lt;&lt; endl;
}</pre> </td>
<td>
<pre>Here is the matrix A:
  0.68  0.597
-0.211  0.823
 0.566 -0.605
Here is the right hand side b:
 -0.33
 0.536
-0.444
The least-squares solution is:
-0.67
0.314
</pre> </td>
</tr> </table> <p>An alternative to the SVD, which is usually faster and about as accurate, is <a href="classeigen_1_1completeorthogonaldecomposition.html" title="Complete orthogonal decomposition (COD) of a matrix.">CompleteOrthogonalDecomposition</a>.</p> <p>Again, if you know more about the problem, the table above contains methods that are potentially faster. If your matrix is full rank, HouseHolderQR is the method of choice. If your matrix is full rank and well conditioned, using the Cholesky decomposition (<a href="classeigen_1_1llt.html" title="Standard Cholesky decomposition (LL^T) of a matrix and associated features.">LLT</a>) on the matrix of the normal equations can be faster still. Our page on <a href="group__leastsquares.html">least squares solving </a> has more details.</p> <h1>
<a id="TutorialLinAlgSolutionExists"></a> Checking if a matrix is singular</h1> <p>Only you know what error margin you want to allow for a solution to be considered valid. So <a href="namespaceeigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> lets you do this computation for yourself, if you want to, as in this example:</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   MatrixXd A = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXd::Random</a>(100,100);
   MatrixXd b = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXd::Random</a>(100,50);
   MatrixXd x = A.fullPivLu().solve(b);
   <span>double</span> relative_error = (A*x - b).norm() / b.norm(); <span>// norm() is L2 norm</span>
   cout &lt;&lt; <span>"The relative error is:\n"</span> &lt;&lt; relative_error &lt;&lt; endl;
}
</pre> </td>
<td>
<pre>The relative error is:
2.31495e-14
</pre> </td>
</tr> </table> <h1>
<a id="TutorialLinAlgEigensolving"></a> Computing eigenvalues and eigenvectors</h1> <p>You need an eigendecomposition here, see available such decompositions on <a href="group__topiclinearalgebradecompositions.html">this page</a>. Make sure to check if your matrix is self-adjoint, as is often the case in these problems. Here's an example using <a href="classeigen_1_1selfadjointeigensolver.html" title="Computes eigenvalues and eigenvectors of selfadjoint matrices.">SelfAdjointEigenSolver</a>, it could easily be adapted to general matrices using <a href="classeigen_1_1eigensolver.html" title="Computes eigenvalues and eigenvectors of general matrices.">EigenSolver</a> or <a href="classeigen_1_1complexeigensolver.html" title="Computes eigenvalues and eigenvectors of general complex matrices.">ComplexEigenSolver</a>.</p> <p>The computation of eigenvalues and eigenvectors does not necessarily converge, but such failure to converge is very rare. The call to info() is to check for this possibility.</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix2f A;
   A &lt;&lt; 1, 2, 2, 3;
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   SelfAdjointEigenSolver&lt;Matrix2f&gt; eigensolver(A);
   <span>if</span> (eigensolver.info() != <a href="group__enums.html#gga85fad7b87587764e5cf6b513a9e0ee5ea671a2aeb0f527802806a441d58a80fcf">Success</a>) abort();
   cout &lt;&lt; <span>"The eigenvalues of A are:\n"</span> &lt;&lt; eigensolver.eigenvalues() &lt;&lt; endl;
   cout &lt;&lt; <span>"Here's a matrix whose columns are eigenvectors of A \n"</span>
        &lt;&lt; <span>"corresponding to these eigenvalues:\n"</span>
        &lt;&lt; eigensolver.eigenvectors() &lt;&lt; endl;
}</pre> </td>
<td>
<pre>Here is the matrix A:
1 2
2 3
The eigenvalues of A are:
-0.236
  4.24
Here's a matrix whose columns are eigenvectors of A 
corresponding to these eigenvalues:
-0.851 -0.526
 0.526 -0.851
</pre> </td>
</tr> </table> <h1>
<a id="TutorialLinAlgInverse"></a> Computing inverse and determinant</h1> <p>First of all, make sure that you really want this. While inverse and determinant are fundamental mathematical concepts, in <em>numerical</em> linear algebra they are not as useful as in pure mathematics. <a href="classeigen_1_1inverse.html" title="Expression of the inverse of another expression.">Inverse</a> computations are often advantageously replaced by solve() operations, and the determinant is often <em>not</em> a good way of checking if a matrix is invertible.</p> <p>However, for <em>very</em> <em>small</em> matrices, the above may not be true, and inverse and determinant can be very useful.</p> <p>While certain decompositions, such as <a href="classeigen_1_1partialpivlu.html" title="LU decomposition of a matrix with partial pivoting, and related features.">PartialPivLU</a> and <a href="classeigen_1_1fullpivlu.html" title="LU decomposition of a matrix with complete pivoting, and related features.">FullPivLU</a>, offer <a href="namespaceeigen.html#ae9de9064c3b832ee804c0e0957e80334">inverse()</a> and determinant() methods, you can also call <a href="namespaceeigen.html#ae9de9064c3b832ee804c0e0957e80334">inverse()</a> and determinant() directly on a matrix. If your matrix is of a very small fixed size (at most 4x4) this allows <a href="namespaceeigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> to avoid performing a LU decomposition, and instead use formulas that are more efficient on such small matrices.</p> <p>Here is an example: </p>
<table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix3f A;
   A &lt;&lt; 1, 2, 1,
        2, 1, 0,
        -1, 1, 2;
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   cout &lt;&lt; <span>"The determinant of A is "</span> &lt;&lt; A.determinant() &lt;&lt; endl;
   cout &lt;&lt; <span>"The inverse of A is:\n"</span> &lt;&lt; A.inverse() &lt;&lt; endl;
}
</pre> </td>
<td>
<pre>Here is the matrix A:
 1  2  1
 2  1  0
-1  1  2
The determinant of A is -3
The inverse of A is:
-0.667      1  0.333
  1.33     -1 -0.667
    -1      1      1
</pre> </td>
</tr> </table> <h1>
<a id="TutorialLinAlgSeparateComputation"></a> Separating the computation from the construction</h1> <p>In the above examples, the decomposition was computed at the same time that the decomposition object was constructed. There are however situations where you might want to separate these two things, for example if you don't know, at the time of the construction, the matrix that you will want to decompose; or if you want to reuse an existing decomposition object.</p> <p>What makes this possible is that: </p>
<ul> <li>all decompositions have a default constructor, </li> <li>all decompositions have a compute(matrix) method that does the computation, and that may be called again on an already-computed decomposition, reinitializing it.</li> </ul> <p>For example:</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix2f A, b;
   LLT&lt;Matrix2f&gt; llt;
   A &lt;&lt; 2, -1, -1, 3;
   b &lt;&lt; 1, 2, 3, 1;
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   cout &lt;&lt; <span>"Here is the right hand side b:\n"</span> &lt;&lt; b &lt;&lt; endl;
   cout &lt;&lt; <span>"Computing LLT decomposition..."</span> &lt;&lt; endl;
   llt.compute(A);
   cout &lt;&lt; <span>"The solution is:\n"</span> &lt;&lt; llt.solve(b) &lt;&lt; endl;
   A(1,1)++;
   cout &lt;&lt; <span>"The matrix A is now:\n"</span> &lt;&lt; A &lt;&lt; endl;
   cout &lt;&lt; <span>"Computing LLT decomposition..."</span> &lt;&lt; endl;
   llt.compute(A);
   cout &lt;&lt; <span>"The solution is now:\n"</span> &lt;&lt; llt.solve(b) &lt;&lt; endl;
}
</pre> </td>
<td>
<pre>Here is the matrix A:
 2 -1
-1  3
Here is the right hand side b:
1 2
3 1
Computing LLT decomposition...
The solution is:
1.2 1.4
1.4 0.8
The matrix A is now:
 2 -1
-1  4
Computing LLT decomposition...
The solution is now:
    1  1.29
    1 0.571
</pre> </td>
</tr> </table> <p>Finally, you can tell the decomposition constructor to preallocate storage for decomposing matrices of a given size, so that when you subsequently decompose such matrices, no dynamic memory allocation is performed (of course, if you are using fixed-size matrices, no dynamic memory allocation happens at all). This is done by just passing the size to the decomposition constructor, as in this example: </p>
<pre data-language="cpp">HouseholderQR&lt;MatrixXf&gt; qr(50,50);
MatrixXf A = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXf::Random</a>(50,50);
qr.compute(A); <span>// no dynamic memory allocation</span>
</pre>
<h1>
<a id="TutorialLinAlgRankRevealing"></a> Rank-revealing decompositions</h1> <p>Certain decompositions are rank-revealing, i.e. are able to compute the rank of a matrix. These are typically also the decompositions that behave best in the face of a non-full-rank matrix (which in the square case means a singular matrix). On <a href="group__topiclinearalgebradecompositions.html">this table</a> you can see for all our decompositions whether they are rank-revealing or not.</p> <p>Rank-revealing decompositions offer at least a rank() method. They can also offer convenience methods such as isInvertible(), and some are also providing methods to compute the kernel (null-space) and image (column-space) of the matrix, as is the case with <a href="classeigen_1_1fullpivlu.html" title="LU decomposition of a matrix with complete pivoting, and related features.">FullPivLU</a>:</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix3f A;
   A &lt;&lt; 1, 2, 5,
        2, 1, 4,
        3, 0, 3;
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   FullPivLU&lt;Matrix3f&gt; lu_decomp(A);
   cout &lt;&lt; <span>"The rank of A is "</span> &lt;&lt; lu_decomp.rank() &lt;&lt; endl;
   cout &lt;&lt; <span>"Here is a matrix whose columns form a basis of the null-space of A:\n"</span>
        &lt;&lt; lu_decomp.kernel() &lt;&lt; endl;
   cout &lt;&lt; <span>"Here is a matrix whose columns form a basis of the column-space of A:\n"</span>
        &lt;&lt; lu_decomp.image(A) &lt;&lt; endl; <span>// yes, have to pass the original A</span>
}
</pre> </td>
<td>
<pre>Here is the matrix A:
1 2 5
2 1 4
3 0 3
The rank of A is 2
Here is a matrix whose columns form a basis of the null-space of A:
 0.5
   1
-0.5
Here is a matrix whose columns form a basis of the column-space of A:
5 1
4 2
3 3
</pre> </td>
</tr> </table> <p>Of course, any rank computation depends on the choice of an arbitrary threshold, since practically no floating-point matrix is <em>exactly</em> rank-deficient. <a href="namespaceeigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> picks a sensible default threshold, which depends on the decomposition but is typically the diagonal size times machine epsilon. While this is the best default we could pick, only you know what is the right threshold for your application. You can set this by calling setThreshold() on your decomposition object before calling rank() or any other method that needs to use such a threshold. The decomposition itself, i.e. the compute() method, is independent of the threshold. You don't need to recompute the decomposition after you've changed the threshold.</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   Matrix2d A;
   A &lt;&lt; 2, 1,
        2, 0.9999999999;
   FullPivLU&lt;Matrix2d&gt; lu(A);
   cout &lt;&lt; <span>"By default, the rank of A is found to be "</span> &lt;&lt; lu.rank() &lt;&lt; endl;
   lu.setThreshold(1e-5);
   cout &lt;&lt; <span>"With threshold 1e-5, the rank of A is found to be "</span> &lt;&lt; lu.rank() &lt;&lt; endl;
}
</pre> </td>
<td>
<pre>By default, the rank of A is found to be 2
With threshold 1e-5, the rank of A is found to be 1
</pre> </td>
</tr> </table> </div> <div class="_attribution">
  <p class="_attribution-p">
    &copy; Eigen.<br>Licensed under the MPL2 License.<br>
    <a href="https://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html" class="_attribution-link">https://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html</a>
  </p>
</div>
