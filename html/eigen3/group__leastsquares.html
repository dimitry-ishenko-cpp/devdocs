<h1>Solving linear least squares systems</h1>      <div> <p>This page describes how to solve linear least squares systems using Eigen. An overdetermined system of equations, say <em>Ax</em> = <em>b</em>, has no solutions. In this case, it makes sense to search for the vector <em>x</em> which is closest to being a solution, in the sense that the difference <em>Ax</em> - <em>b</em> is as small as possible. This <em>x</em> is called the least square solution (if the Euclidean norm is used).</p> <p>The three methods discussed on this page are the SVD decomposition, the QR decomposition and normal equations. Of these, the SVD decomposition is generally the most accurate but the slowest, normal equations is the fastest but least accurate, and the QR decomposition is in between.</p> <h1>
<a id="LeastSquaresSVD"></a> Using the SVD decomposition</h1> <p>The <a href="classeigen_1_1svdbase.html#ab28499936c0764fe5b56b9f4de701e26">solve() </a> method in the <a href="classeigen_1_1bdcsvd.html" title="class Bidiagonal Divide and Conquer SVD">BDCSVD</a> class can be directly used to solve linear squares systems. It is not enough to compute only the singular values (the default for this class); you also need the singular vectors but the thin SVD decomposition suffices for computing least squares solutions:</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp"><span>#include &lt;iostream&gt;</span>
<span>#include &lt;Eigen/Dense&gt;</span>
 
<span>using namespace </span>std;
<span>using namespace </span><a href="namespaceeigen.html">Eigen</a>;
 
<span>int</span> main()
{
   MatrixXf A = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXf::Random</a>(3, 2);
   cout &lt;&lt; <span>"Here is the matrix A:\n"</span> &lt;&lt; A &lt;&lt; endl;
   VectorXf b = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">VectorXf::Random</a>(3);
   cout &lt;&lt; <span>"Here is the right hand side b:\n"</span> &lt;&lt; b &lt;&lt; endl;
   cout &lt;&lt; <span>"The least-squares solution is:\n"</span>
        &lt;&lt; A.bdcSvd(<a href="group__enums.html#ggae3e239fb70022eb8747994cf5d68b4a9aa7fb4e98834788d0b1b0f2b8467d2527">ComputeThinU</a> | <a href="group__enums.html#ggae3e239fb70022eb8747994cf5d68b4a9a540036417bfecf2e791a70948c227f47">ComputeThinV</a>).solve(b) &lt;&lt; endl;
}</pre> </td>
<td>
<pre>Here is the matrix A:
  0.68  0.597
-0.211  0.823
 0.566 -0.605
Here is the right hand side b:
 -0.33
 0.536
-0.444
The least-squares solution is:
-0.67
0.314
</pre> </td>
</tr> </table> <p>This is example from the page <a href="group__tutoriallinearalgebra.html">Linear algebra and decompositions </a>. If you just need to solve the least squares problem, but are not interested in the SVD per se, a faster alternative method is <a href="classeigen_1_1completeorthogonaldecomposition.html" title="Complete orthogonal decomposition (COD) of a matrix.">CompleteOrthogonalDecomposition</a>.</p> <h1>
<a id="LeastSquaresQR"></a> Using the QR decomposition</h1> <p>The solve() method in QR decomposition classes also computes the least squares solution. There are three QR decomposition classes: <a href="classeigen_1_1householderqr.html" title="Householder QR decomposition of a matrix.">HouseholderQR</a> (no pivoting, fast but unstable if your matrix is not rull rank), <a href="classeigen_1_1colpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with column-pivoting.">ColPivHouseholderQR</a> (column pivoting, thus a bit slower but more stable) and <a href="classeigen_1_1fullpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with full pivoting.">FullPivHouseholderQR</a> (full pivoting, so slowest and slightly more stable than <a href="classeigen_1_1colpivhouseholderqr.html" title="Householder rank-revealing QR decomposition of a matrix with column-pivoting.">ColPivHouseholderQR</a>). Here is an example with column pivoting:</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp">MatrixXf A = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXf::Random</a>(3, 2);
VectorXf b = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">VectorXf::Random</a>(3);
cout &lt;&lt; <span>"The solution using the QR decomposition is:\n"</span>
     &lt;&lt; A.colPivHouseholderQr().solve(b) &lt;&lt; endl;
</pre> </td>
<td>
<pre>The solution using the QR decomposition is:
-0.67
0.314
</pre> </td>
</tr> </table> <h1>
<a id="LeastSquaresNormalEquations"></a> Using normal equations</h1> <p>Finding the least squares solution of <em>Ax</em> = <em>b</em> is equivalent to solving the normal equation <em>A</em><sup>T</sup><em>Ax</em> = <em>A</em><sup>T</sup><em>b</em>. This leads to the following code</p> <table> <tr> <th>Example:</th>
<th>Output: </th>
</tr> <tr> <td>
<pre data-language="cpp">MatrixXf A = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">MatrixXf::Random</a>(3, 2);
VectorXf b = <a href="classeigen_1_1densebase.html#ae814abb451b48ed872819192dc188c19">VectorXf::Random</a>(3);
cout &lt;&lt; <span>"The solution using normal equations is:\n"</span>
     &lt;&lt; (A.transpose() * A).ldlt().solve(A.transpose() * b) &lt;&lt; endl;
</pre> </td>
<td>
<pre>The solution using normal equations is:
-0.67
0.314
</pre> </td>
</tr> </table> <p>This method is usually the fastest, especially when <em>A</em> is "tall and skinny". However, if the matrix <em>A</em> is even mildly ill-conditioned, this is not a good method, because the condition number of <em>A</em><sup>T</sup><em>A</em> is the square of the condition number of <em>A</em>. This means that you lose roughly twice as many digits of accuracy using the normal equation, compared to the more stable methods mentioned above. </p> </div> <div class="_attribution">
  <p class="_attribution-p">
    &copy; Eigen.<br>Licensed under the MPL2 License.<br>
    <a href="https://eigen.tuxfamily.org/dox/group__LeastSquares.html" class="_attribution-link">https://eigen.tuxfamily.org/dox/group__LeastSquares.html</a>
  </p>
</div>
