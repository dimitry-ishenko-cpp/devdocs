<h1>Quick reference guide for sparse matrices</h1>      <div> <hr> <p>In this page, we give a quick summary of the main operations available for sparse matrices in the class <a href="classeigen_1_1sparsematrix.html" title="A versatible sparse matrix representation.">SparseMatrix</a>. First, it is recommended to read the introductory tutorial at <a href="group__tutorialsparse.html">Sparse matrix manipulations</a>. The important point to have in mind when working on sparse matrices is how they are stored : i.e either row major or column major. The default is column major. Most arithmetic operations on sparse matrices will assert that they have the same storage order.</p> <h1>
<a id="SparseMatrixInit"></a> Sparse Matrix Initialization</h1> <table> <tr> <th>Category </th>
<th>Operations </th>
<th>Notes </th>
</tr> <tr> <td>Constructor </td>
<td>
<pre data-language="cpp">SparseMatrix&lt;double&gt; sm1(1000,1000); 
SparseMatrix&lt;std::complex&lt;double&gt;,<a href="group__enums.html#ggaacded1a18ae58b0f554751f6cdf9eb13a77c993a8d9f6efe5c1159fb2ab07dd4f">RowMajor</a>&gt; sm2;</pre> </td>
<td>Default is ColMajor </td>
</tr> <tr> <td>Resize/Reserve </td>
<td>
<pre data-language="cpp">sm1.resize(m,n);      <span>// Change sm1 to a m x n matrix.</span>
sm1.reserve(nnz);     <span>// Allocate room for nnz nonzeros elements.   </span>
</pre> </td>
<td>Note that when calling reserve(), it is not required that nnz is the exact number of nonzero elements in the final matrix. However, an exact estimation will avoid multiple reallocations during the insertion phase. </td>
</tr> <tr> <td>Assignment </td>
<td>
<pre data-language="cpp"> SparseMatrix&lt;double,Colmajor&gt; sm1;
<span>// Initialize sm2 with sm1.</span>
 SparseMatrix&lt;double,Rowmajor&gt; sm2(sm1), sm3;        
 <span>// Assignment and evaluations modify the storage order.</span>
 sm3 = sm1; 
</pre> </td>
<td>The copy constructor can be used to convert from a storage order to another </td>
</tr> <tr> <td>Element-wise Insertion </td>
<td>
<pre data-language="cpp"><span>// Insert a new element; </span>
 sm1.insert(i, j) = v_ij;  
 
<span>// Update the value v_ij</span>
 sm1.coeffRef(i,j) = v_ij;
 sm1.coeffRef(i,j) += v_ij;
 sm1.coeffRef(i,j) -= v_ij;
</pre> </td>
<td>insert() assumes that the element does not already exist; otherwise, use coeffRef() </td>
</tr> <tr> <td>Batch insertion </td>
<td>
<pre data-language="cpp">std::vector&lt; Eigen::Triplet&lt;double&gt; &gt; tripletList;
tripletList.reserve(estimation_of_entries);
<span>// -- Fill tripletList with nonzero elements...</span>
sm1.setFromTriplets(TripletList.begin(), TripletList.end());
</pre> </td>
<td>A complete example is available at <a href="group__tutorialsparse.html#TutorialSparseFilling">Triplet Insertion </a>. </td>
</tr> <tr> <td>Constant or Random Insertion </td>
<td>
<pre data-language="cpp">sm1.setZero();
</pre> </td>
<td>Remove all non-zero coefficients </td>
</tr> </table> <h1>
<a id="SparseBasicInfos"></a> Matrix properties</h1> <p>Beyond the basic functions rows() and cols(), there are some useful functions that are available to easily get some information from the matrix. </p>
<table> <tr> <td>
<pre data-language="cpp">sm1.rows();         <span>// Number of rows</span>
sm1.cols();         <span>// Number of columns </span>
sm1.nonZeros();     <span>// Number of non zero values   </span>
sm1.outerSize();    <span>// Number of columns (resp. rows) for a column major (resp. row major )</span>
sm1.innerSize();    <span>// Number of rows (resp. columns) for a row major (resp. column major)</span>
sm1.norm();         <span>// Euclidian norm of the matrix</span>
sm1.squaredNorm();  <span>// Squared norm of the matrix</span>
sm1.blueNorm();
sm1.isVector();     <span>// Check if sm1 is a sparse vector or a sparse matrix</span>
sm1.isCompressed(); <span>// Check if sm1 is in compressed form</span>
...
</pre> </td>
</tr> </table> <h1>
<a id="SparseBasicOps"></a> Arithmetic operations</h1> <p>It is easy to perform arithmetic operations on sparse matrices provided that the dimensions are adequate and that the matrices have the same storage order. Note that the evaluation can always be done in a matrix with a different storage order. In the following, <b>sm</b> denotes a sparse matrix, <b>dm</b> a dense matrix and <b>dv</b> a dense vector. </p>
<table> <tr> <th>Operations </th>
<th>Code </th>
<th>
<p>Notes </p> <p></p> </th>
</tr> <tr> <td>add subtract </td>
<td>
<pre data-language="cpp">sm3 = sm1 + sm2; 
sm3 = sm1 - sm2;
sm2 += sm1; 
sm2 -= sm1; 
</pre> </td>
<td>
<p>sm1 and sm2 should have the same storage order </p> <p></p> </td>
</tr> <tr> <td>scalar product</td>
<td>
<pre data-language="cpp">sm3 = sm1 * s1;   sm3 *= s1; 
sm3 = s1 * sm1 + s2 * sm2; sm3 /= s1;
</pre> </td>
<td>
<p>Many combinations are possible if the dimensions and the storage order agree. </p> <p></p> </td>
</tr> <tr> <td>Sparse Product </td>
<td>
<pre data-language="cpp">sm3 = sm1 * sm2;
dm2 = sm1 * dm1;
dv2 = sm1 * dv1;
</pre> </td>
<td>
<p></p> <p></p> </td>
</tr> <tr> <td>transposition, adjoint </td>
<td>
<pre data-language="cpp">sm2 = sm1.transpose();
sm2 = sm1.adjoint();
</pre> </td>
<td>Note that the transposition change the storage order. There is no support for transposeInPlace(). </td>
</tr> <tr> <td>Permutation </td>
<td>
<pre data-language="cpp">perm.indices();      <span>// Reference to the vector of indices</span>
sm1.twistedBy(perm); <span>// Permute rows and columns</span>
sm2 = sm1 * perm;    <span>// Permute the columns</span>
sm2 = perm * sm1;    <span>// Permute the columns</span>
</pre> </td>
<td>
<p></p> <p></p> </td>
</tr> <tr> <td>Component-wise ops </td>
<td>
<pre data-language="cpp">sm1.cwiseProduct(sm2);
sm1.cwiseQuotient(sm2);
sm1.cwiseMin(sm2);
sm1.cwiseMax(sm2);
sm1.cwiseAbs();
sm1.cwiseSqrt();
</pre> </td>
<td>sm1 and sm2 should have the same storage order </td>
</tr> </table> <h1>
<a id="sparseotherops"></a> Other supported operations</h1> <table> <tr> <th style="min-width:initial">Code </th>
<th>Notes </th>
</tr> <tr> <td colspan="2">Sub-matrices </td>
</tr> <tr> <td>
<pre data-language="cpp">sm1.block(startRow, startCol, rows, cols); 
sm1.block(startRow, startCol); 
sm1.topLeftCorner(rows, cols); 
sm1.topRightCorner(rows, cols);
sm1.bottomLeftCorner( rows, cols);
sm1.bottomRightCorner( rows, cols);
</pre> </td>
<td>Contrary to dense matrices, here <b>all these methods are read-only</b>.<br> See <a href="group__tutorialsparse.html#TutorialSparse_SubMatrices">Block operations</a> and below for read-write sub-matrices. </td>
</tr> <tr> <td colspan="2">Range </td>
</tr> <tr> <td>
<pre data-language="cpp">sm1.innerVector(outer);           <span>// RW</span>
sm1.innerVectors(start, size);    <span>// RW</span>
sm1.leftCols(size);               <span>// RW</span>
sm2.rightCols(size);              <span>// RO because sm2 is row-major</span>
sm1.middleRows(start, numRows);   <span>// RO because sm1 is column-major</span>
sm1.middleCols(start, numCols);   <span>// RW</span>
sm1.col(j);                       <span>// RW</span>
</pre> </td>
<td>A inner vector is either a row (for row-major) or a column (for column-major).<br> As stated earlier, for a read-write sub-matrix (RW), the evaluation can be done in a matrix with different storage order. </td>
</tr> <tr> <td colspan="2">Triangular and selfadjoint views </td>
</tr> <tr> <td>
<pre data-language="cpp">sm2 = sm1.triangularview&lt;<a href="group__enums.html#gga39e3366ff5554d731e7dc8bb642f83cdaf581029282d421eee5aae14238c6f749">Lower</a>&gt;();
sm2 = sm1.selfadjointview&lt;<a href="group__enums.html#gga39e3366ff5554d731e7dc8bb642f83cdaf581029282d421eee5aae14238c6f749">Lower</a>&gt;();</pre> </td>
<td>Several combination between triangular views and blocks views are possible <pre data-language="cpp"></pre> </td>
</tr> <tr> <td colspan="2">Triangular solve </td>
</tr> <tr> <td>
<pre data-language="cpp">dv2 = sm1.triangularView&lt;<a href="group__enums.html#gga39e3366ff5554d731e7dc8bb642f83cdafca2ccebb604f171656deb53e8c083c1">Upper</a>&gt;().solve(dv1);
dv2 = sm1.topLeftCorner(size, size)
         .triangularView&lt;<a href="group__enums.html#gga39e3366ff5554d731e7dc8bb642f83cdaf581029282d421eee5aae14238c6f749">Lower</a>&gt;().solve(dv1);</pre> </td>
<td>For general sparse solve, Use any suitable module described at <a href="group__topicsparsesystems.html">Solving Sparse Linear Systems</a> </td>
</tr> <tr> <td colspan="2">Low-level API </td>
</tr> <tr> <td>
<pre data-language="cpp">sm1.valuePtr();      <span>// Pointer to the values</span>
sm1.innerIndexPtr();  <span>// Pointer to the indices.</span>
sm1.outerIndexPtr(); <span>// Pointer to the beginning of each inner vector</span>
</pre> </td>
<td>If the matrix is not in compressed form, makeCompressed() should be called before.<br> Note that these functions are mostly provided for interoperability purposes with external libraries.<br> A better access to the values of the matrix is done by using the InnerIterator class as described in <a href="group__tutorialsparse.html">the Tutorial Sparse </a> section </td>
</tr> <tr> <td colspan="2">Mapping external buffers </td>
</tr> <tr> <td>
<pre data-language="cpp"><span>int</span> outerIndexPtr[cols+1];
<span>int</span> innerIndices[nnz];
<span>double</span> values[nnz];
Map&lt;SparseMatrix&lt;double&gt; &gt; sm1(rows,cols,nnz,outerIndexPtr, <span>// read-write</span>
                               innerIndices,values);
Map&lt;const SparseMatrix&lt;double&gt; &gt; sm2(...);                  <span>// read-only</span>
</pre> </td>
<td>As for dense matrices, class <a href="classeigen_1_1map_3_01sparsematrixtype_01_4.html" title="Specialization of class Map for SparseMatrix-like storage.">Map&lt;SparseMatrixType&gt;</a> can be used to see external buffers as an Eigen's <a href="classeigen_1_1sparsematrix.html" title="A versatible sparse matrix representation.">SparseMatrix</a> object. </td>
</tr> </table> </div> <div class="_attribution">
  <p class="_attribution-p">
    &copy; Eigen.<br>Licensed under the MPL2 License.<br>
    <a href="https://eigen.tuxfamily.org/dox/group__SparseQuickRefPage.html" class="_attribution-link">https://eigen.tuxfamily.org/dox/group__SparseQuickRefPage.html</a>
  </p>
</div>
