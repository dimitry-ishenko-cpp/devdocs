<h1>Development guide</h1>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#code_layout">Code layout</a></li>
<li><a href="#include_files">Include files</a></li>
<li><a href="#integers">Integers</a></li>
<li><a href="#common_return_codes">Common return codes</a></li>
<li><a href="#error_handling">Error handling</a></li>
<li><a href="#strings">Strings</a></li>
<li><a href="#string_overview">Overview</a></li>
<li><a href="#formatting">Formatting</a></li>
<li><a href="#numeric_conversion">Numeric conversion</a></li>
<li><a href="#regex">Regular expressions</a></li>
<li><a href="#time">Time</a></li>
<li><a href="#containers">Containers</a></li>
<li><a href="#array">Array</a></li>
<li><a href="#list">List</a></li>
<li><a href="#queue">Queue</a></li>
<li><a href="#red_black_tree">Red-Black tree</a></li>
<li><a href="#hash">Hash</a></li>
<li><a href="#memory_management">Memory management</a></li>
<li><a href="#heap">Heap</a></li>
<li><a href="#pool">Pool</a></li>
<li><a href="#shared_memory">Shared memory</a></li>
<li><a href="#logging">Logging</a></li>
<li><a href="#cycle">Cycle</a></li>
<li><a href="#buffer">Buffer</a></li>
<li><a href="#networking">Networking</a></li>
<li><a href="#connection">Connection</a></li>
<li><a href="#events">Events</a></li>
<li><a href="#event">Event</a></li>
<li><a href="#i_o_events">I/O events</a></li>
<li><a href="#timer_events">Timer events</a></li>
<li><a href="#posted_events">Posted events</a></li>
<li><a href="#event_loop">Event loop</a></li>
<li><a href="#processes">Processes</a></li>
<li><a href="#threads">Threads</a></li>
<li><a href="#Modules">Modules</a></li>
<li><a href="#adding_new_modules">Adding new modules</a></li>
<li><a href="#core_modules">Core Modules</a></li>
<li><a href="#config_directives">Configuration Directives</a></li>
<li><a href="#http">HTTP</a></li>
<li><a href="#http_connection">Connection</a></li>
<li><a href="#http_request">Request</a></li>
<li><a href="#http_conf">Configuration</a></li>
<li><a href="#http_phases">Phases</a></li>
<li><a href="#http_variables">Variables</a></li>
<li><a href="#http_complex_values">Complex values</a></li>
<li><a href="#http_request_redirection">Request redirection</a></li>
<li><a href="#http_subrequests">Subrequests</a></li>
<li><a href="#http_request_finalization">Request finalization</a></li>
<li><a href="#http_request_body">Request body</a></li>
<li><a href="#http_request_body_filters">Request body filters</a></li>
<li><a href="#http_response">Response</a></li>
<li><a href="#http_response_body">Response body</a></li>
<li><a href="#http_response_body_filters">Response body filters</a></li>
<li><a href="#http_building_filter_modules">Building filter modules</a></li>
<li><a href="#http_body_buffers_reuse">Buffer reuse</a></li>
<li><a href="#http_load_balancing">Load balancing</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#code_style">Code style</a></li>
<li><a href="#code_style_general_rules">General rules</a></li>
<li><a href="#code_style_files">Files</a></li>
<li><a href="#code_style_comments">Comments</a></li>
<li><a href="#code_style_preprocessor">Preprocessor</a></li>
<li><a href="#code_style_types">Types</a></li>
<li><a href="#code_style_variables">Variables</a></li>
<li><a href="#code_style_functions">Functions</a></li>
<li><a href="#code_style_expressions">Expressions</a></li>
<li><a href="#code_style_conditionals_and_loops">Conditionals and Loops</a></li>
<li><a href="#code_style_labels">Labels</a></li>
<li><a href="#debug_memory">Debugging memory issues</a></li>
<li><a href="#common_pitfals">Common Pitfalls</a></li>
<li><a href="#module_pitfall">Writing a C module</a></li>
<li><a href="#c_strings">C Strings</a></li>
<li><a href="#global_variables">Global Variables</a></li>
<li><a href="#manual_memory_management">Manual Memory Management</a></li>
<li><a href="#threads_pitfalls">Threads</a></li>
<li><a href="#libraries">Blocking Libraries</a></li>
<li><a href="#http_requests_to_ext">HTTP Requests to External Services</a></li>
</ul>
<h4 id="introduction">Introduction</h4>
<h4 id="code_layout">Code layout</h4>
<ul class="compact"> <li> <code>auto</code> — Build scripts </li> <li> <code>src</code> <ul class="compact"> <li> <code>core</code> — Basic types and functions — string, array, log, pool, etc. </li> <li> <code>event</code> — Event core <ul class="compact"> <li> <code>modules</code> — Event notification modules: <code>epoll</code>, <code>kqueue</code>, <code>select</code> etc. </li> </ul> </li> <li> <code>http</code> — Core HTTP module and common code <ul class="compact"> <li> <code>modules</code> — Other HTTP modules </li> <li> <code>v2</code> — HTTP/2 </li> </ul> </li> <li> <code>mail</code> — Mail modules </li> <li> <code>os</code> — Platform-specific code <ul class="compact"> <li> <code>unix</code> </li> <li> <code>win32</code> </li> </ul> </li> <li> <code>stream</code> — Stream modules </li> </ul> </li> </ul>
<h4 id="include_files">Include files</h4>
<p> The following two <code>#include</code> statements must appear at the beginning of every nginx file: </p>
<pre data-language="nginx">
#include &lt;ngx_config.h&gt;
#include &lt;ngx_core.h&gt;
</pre>
<p> In addition to that, HTTP code should include </p>
<pre data-language="nginx">
#include &lt;ngx_http.h&gt;
</pre>
<p> Mail code should include </p>
<pre data-language="nginx">
#include &lt;ngx_mail.h&gt;
</pre>
<p> Stream code should include </p>
<pre data-language="nginx">
#include &lt;ngx_stream.h&gt;
</pre>
<h4 id="integers">Integers</h4>
<p> For general purposes, nginx code uses two integer types, <code>ngx_int_t</code> and <code>ngx_uint_t</code>, which are typedefs for <code>intptr_t</code> and <code>uintptr_t</code> respectively. </p>
<h4 id="common_return_codes">Common return codes</h4>
<p> Most functions in nginx return the following codes: </p>
<ul class="compact"> <li> <code>NGX_OK</code> — Operation succeeded. </li> <li> <code>NGX_ERROR</code> — Operation failed. </li> <li> <code>NGX_AGAIN</code> — Operation incomplete; call the function again. </li> <li> <code>NGX_DECLINED</code> — Operation rejected, for example, because it is disabled in the configuration. This is never an error. </li> <li> <code>NGX_BUSY</code> — Resource is not available. </li> <li> <code>NGX_DONE</code> — Operation complete or continued elsewhere. Also used as an alternative success code. </li> <li> <code>NGX_ABORT</code> — Function was aborted. Also used as an alternative error code. </li> </ul>
<h4 id="error_handling">Error handling</h4>
<p> The <code>ngx_errno</code> macro returns the last system error code. It's mapped to <code>errno</code> on POSIX platforms and to <code>GetLastError()</code> call in Windows. The <code>ngx_socket_errno</code> macro returns the last socket error number. Like the <code>ngx_errno</code> macro, it's mapped to <code>errno</code> on POSIX platforms. It's mapped to the <code>WSAGetLastError()</code> call on Windows. Accessing the values of <code>ngx_errno</code> or <code>ngx_socket_errno</code> more than once in a row can cause performance issues. If the error value might be used multiple times, store it in a local variable of type <code>ngx_err_t</code>. To set errors, use the <code>ngx_set_errno(errno)</code> and <code>ngx_set_socket_errno(errno)</code> macros. </p>
<p> The values of <code>ngx_errno</code> and <code>ngx_socket_errno</code> can be passed to the logging functions <code>ngx_log_error()</code> and <code>ngx_log_debugX()</code>, in which case system error text is added to the log message. </p>
<p> Example using <code>ngx_errno</code>: </p>
<pre data-language="nginx">
ngx_int_t
ngx_my_kill(ngx_pid_t pid, ngx_log_t *log, int signo)
{
    ngx_err_t  err;

    if (kill(pid, signo) == -1) {
        err = ngx_errno;

        ngx_log_error(NGX_LOG_ALERT, log, err, "kill(%P, %d) failed", pid, signo);

        if (err == NGX_ESRCH) {
            return 2;
        }

        return 1;
    }

    return 0;
}
</pre>
<h4 id="strings">Strings</h4>
<h4 id="string_overview">Overview</h4>
<p> For C strings, nginx uses the unsigned character type pointer <code>u_char *</code>. </p>
<p> The nginx string type <code>ngx_str_t</code> is defined as follows: </p>
<pre data-language="nginx">
typedef struct {
    size_t      len;
    u_char     *data;
} ngx_str_t;
</pre>
<p> The <code>len</code> field holds the string length and <code>data</code> holds the string data. The string, held in <code>ngx_str_t</code>, may or may not be null-terminated after the <code>len</code> bytes. In most cases it’s not. However, in certain parts of the code (for example, when parsing configuration), <code>ngx_str_t</code> objects are known to be null-terminated, which simplifies string comparison and makes it easier to pass the strings to syscalls. </p>
<p> The string operations in nginx are declared in <code>src/core/ngx_string.h</code> Some of them are wrappers around standard C functions: </p>
 <ul class="compact"> <li> <code>ngx_strcmp()</code> </li> <li> <code>ngx_strncmp()</code> </li> <li> <code>ngx_strstr()</code> </li> <li> <code>ngx_strlen()</code> </li> <li> <code>ngx_strchr()</code> </li> <li> <code>ngx_memcmp()</code> </li> <li> <code>ngx_memset()</code> </li> <li> <code>ngx_memcpy()</code> </li> <li> <code>ngx_memmove()</code> </li> </ul>

<p> Other string functions are nginx-specific </p>
 <ul class="compact"> <li> <code>ngx_memzero()</code> — Fills memory with zeroes. </li> <li> <code>ngx_explicit_memzero()</code> — Does the same as <code>ngx_memzero()</code>, but this call is never removed by the compiler's dead store elimination optimization. This function can be used to clear sensitive data such as passwords and keys. </li> <li> <code>ngx_cpymem()</code> — Does the same as <code>ngx_memcpy()</code>, but returns the final destination address This one is handy for appending multiple strings in a row. </li> <li> <code>ngx_movemem()</code> — Does the same as <code>ngx_memmove()</code>, but returns the final destination address. </li> <li> <code>ngx_strlchr()</code> — Searches for a character in a string, delimited by two pointers. </li> </ul>

<p> The following functions perform case conversion and comparison: </p>
 <ul class="compact"> <li> <code>ngx_tolower()</code> </li> <li> <code>ngx_toupper()</code> </li> <li> <code>ngx_strlow()</code> </li> <li> <code>ngx_strcasecmp()</code> </li> <li> <code>ngx_strncasecmp()</code> </li> </ul>

<p> The following macros simplify string initialization: </p>
<ul class="compact"> <li> <code>ngx_string(text)</code> — static initializer for the <code>ngx_str_t</code> type from the C string literal <code>text</code> </li> <li> <code>ngx_null_string</code> — static empty string initializer for the <code>ngx_str_t</code> type </li> <li> <code>ngx_str_set(str, text)</code> — initializes string <code>str</code> of <code>ngx_str_t *</code> type with the C string literal <code>text</code> </li> <li> <code>ngx_str_null(str)</code> — initializes string <code>str</code> of <code>ngx_str_t *</code> type with the empty string </li> </ul>
<h4 id="formatting">Formatting</h4>
<p> The following formatting functions support nginx-specific types: </p>
 <ul class="compact"> <li> <code>ngx_sprintf(buf, fmt, ...)</code> </li> <li> <code>ngx_snprintf(buf, max, fmt, ...)</code> </li> <li> <code>ngx_slprintf(buf, last, fmt, ...)</code> </li> <li> <code>ngx_vslprintf(buf, last, fmt, args)</code> </li> <li> <code>ngx_vsnprintf(buf, max, fmt, args)</code> </li> </ul>

<p> The full list of formatting options, supported by these functions is in <code>src/core/ngx_string.c</code>. Some of them are: </p>
<ul class="compact"> <li> <code>%O</code> — <code>off_t</code> </li> <li> <code>%T</code> — <code>time_t</code> </li> <li> <code>%z</code> — <code>ssize_t</code> </li> <li> <code>%i</code> — <code>ngx_int_t</code> </li> <li> <code>%p</code> — <code>void *</code> </li> <li> <code>%V</code> — <code>ngx_str_t *</code> </li> <li> <code>%s</code> — <code>u_char *</code> (null-terminated) </li> <li> <code>%*s</code> — <code>size_t + u_char *</code> </li> </ul>
<p> You can prepend <code>u</code> on most types to make them unsigned. To convert output to hex, use <code>X</code> or <code>x</code>. </p>
<p> For example: </p> <pre data-language="nginx">
u_char      buf[NGX_INT_T_LEN];
size_t      len;
ngx_uint_t  n;

/* set n here */

len = ngx_sprintf(buf, "%ui", n) — buf;
</pre>

<h4 id="numeric_conversion">Numeric conversion</h4>
<p> Several functions for numeric conversion are implemented in nginx. The first four each convert a string of given length to a positive integer of the indicated type. They return <code>NGX_ERROR</code> on error. </p> <ul class="compact"> <li> <code>ngx_atoi(line, n)</code> — <code>ngx_int_t</code> </li> <li> <code>ngx_atosz(line, n)</code> — <code>ssize_t</code> </li> <li> <code>ngx_atoof(line, n)</code> — <code>off_t</code> </li> <li> <code>ngx_atotm(line, n)</code> — <code>time_t</code> </li> </ul>

<p> There are two additional numeric conversion functions. Like the first four, they return <code>NGX_ERROR</code> on error. </p> <ul class="compact"> <li> <code>ngx_atofp(line, n, point)</code> — Converts a fixed point floating number of given length to a positive integer of type <code>ngx_int_t</code>. The result is shifted left by <code>point</code> decimal positions. The string representation of the number is expected to have no more than <code>points</code> fractional digits. For example, <code>ngx_atofp("10.5", 4, 2)</code> returns <code>1050</code>. </li> <li> <code>ngx_hextoi(line, n)</code> — Converts a hexadecimal representation of a positive integer to <code>ngx_int_t</code>. </li> </ul>

<h4 id="regex">Regular expressions</h4>
<p> The regular expressions interface in nginx is a wrapper around the <a href="http://www.pcre.org">PCRE</a> library. The corresponding header file is <code>src/core/ngx_regex.h</code>. </p>
<p> To use a regular expression for string matching, it first needs to be compiled, which is usually done at the configuration phase. Note that since PCRE support is optional, all code using the interface must be protected by the surrounding <code>NGX_PCRE</code> macro: </p> <pre data-language="nginx">
#if (NGX_PCRE)
ngx_regex_t          *re;
ngx_regex_compile_t   rc;

u_char                errstr[NGX_MAX_CONF_ERRSTR];

ngx_str_t  value = ngx_string("message (\\d\\d\\d).*Codeword is '(?&lt;cw&gt;\\w+)'");

ngx_memzero(&amp;rc, sizeof(ngx_regex_compile_t));

rc.pattern = value;
rc.pool = cf-&gt;pool;
rc.err.len = NGX_MAX_CONF_ERRSTR;
rc.err.data = errstr;
/* rc.options can be set to NGX_REGEX_CASELESS */

if (ngx_regex_compile(&amp;rc) != NGX_OK) {
    ngx_conf_log_error(NGX_LOG_EMERG, cf, 0, "%V", &amp;rc.err);
    return NGX_CONF_ERROR;
}

re = rc.regex;
#endif
</pre>
<p> After successful compilation, the <code>captures</code> and <code>named_captures</code> fields in the <code>ngx_regex_compile_t</code> structure contain the count of all captures and named captures, respectively, found in the regular expression. </p>
<p> The compiled regular expression can then be used for matching against strings: </p> <pre data-language="nginx">
ngx_int_t  n;
int        captures[(1 + rc.captures) * 3];

ngx_str_t input = ngx_string("This is message 123. Codeword is 'foobar'.");

n = ngx_regex_exec(re, &amp;input, captures, (1 + rc.captures) * 3);
if (n &gt;= 0) {
    /* string matches expression */

} else if (n == NGX_REGEX_NO_MATCHED) {
    /* no match was found */

} else {
    /* some error */
    ngx_log_error(NGX_LOG_ALERT, log, 0, ngx_regex_exec_n " failed: %i", n);
}
</pre>
<p> The arguments to <code>ngx_regex_exec()</code> are the compiled regular expression <code>re</code>, the string to match <code>input</code>, an optional array of integers to hold any <code>captures</code> that are found, and the array's <code>size</code>. The size of the <code>captures</code> array must be a multiple of three, as required by the <a href="http://www.pcre.org/original/doc/html/pcreapi.html">PCRE API</a>. In the example, the size is calculated from the total number of captures plus one for the matched string itself. </p>
<p> If there are matches, captures can be accessed as follows: </p> <pre data-language="nginx">
u_char     *p;
size_t      size;
ngx_str_t   name, value;

/* all captures */
for (i = 0; i &lt; n * 2; i += 2) {
    value.data = input.data + captures[i];
    value.len = captures[i + 1] — captures[i];
}

/* accessing named captures */

size = rc.name_size;
p = rc.names;

for (i = 0; i &lt; rc.named_captures; i++, p += size) {

    /* capture name */
    name.data = &amp;p[2];
    name.len = ngx_strlen(name.data);

    n = 2 * ((p[0] &lt;&lt; 8) + p[1]);

    /* captured value */
    value.data = &amp;input.data[captures[n]];
    value.len = captures[n + 1] — captures[n];
}
</pre>

<p> The <code>ngx_regex_exec_array()</code> function accepts the array of <code>ngx_regex_elt_t</code> elements (which are just compiled regular expressions with associated names), a string to match, and a log. The function applies expressions from the array to the string until either a match is found or no more expressions are left. The return value is <code>NGX_OK</code> when there is a match and <code>NGX_DECLINED</code> otherwise, or <code>NGX_ERROR</code> in case of error. </p>
<h4 id="time">Time</h4>
<p> The <code>ngx_time_t</code> structure represents time with three separate types for seconds, milliseconds, and the GMT offset: </p> <pre data-language="nginx">
typedef struct {
    time_t      sec;
    ngx_uint_t  msec;
    ngx_int_t   gmtoff;
} ngx_time_t;
</pre>
<p> The <code>ngx_tm_t</code> structure is an alias for <code>struct tm</code> on UNIX platforms and <code>SYSTEMTIME</code> on Windows. </p>
<p> To obtain the current time, it is usually sufficient to access one of the available global variables, representing the cached time value in the desired format. </p>
<p> The available string representations are: </p> <ul class="compact"> <li> <code>ngx_cached_err_log_time</code> — Used in error log entries: <code>"1970/09/28 12:00:00"</code> </li> <li> <code>ngx_cached_http_log_time</code> — Used in HTTP access log entries: <code>"28/Sep/1970:12:00:00 +0600"</code> </li> <li> <code>ngx_cached_syslog_time</code> — Used in syslog entries: <code>"Sep 28 12:00:00"</code> </li> <li> <code>ngx_cached_http_time</code> — Used in HTTP headers: <code>"Mon, 28 Sep 1970 06:00:00 GMT"</code> </li> <li> <code>ngx_cached_http_log_iso8601</code> — The ISO 8601 standard format: <code>"1970-09-28T12:00:00+06:00"</code> </li> </ul>

<p> The <code>ngx_time()</code> and <code>ngx_timeofday()</code> macros return the current time value in seconds and are the preferred way to access the cached time value. </p>
<p> To obtain the time explicitly, use <code>ngx_gettimeofday()</code>, which updates its argument (pointer to <code>struct timeval</code>). The time is always updated when nginx returns to the event loop from system calls. To update the time immediately, call <code>ngx_time_update()</code>, or <code>ngx_time_sigsafe_update()</code> if updating the time in the signal handler context. </p>
<p> The following functions convert <code>time_t</code> into the indicated broken-down time representation. The first function in each pair converts <code>time_t</code> to <code>ngx_tm_t</code> and the second (with the <code>_libc_</code> infix) to <code>struct tm</code>: </p> <ul class="compact"> <li> <code>ngx_gmtime(), ngx_libc_gmtime()</code> — Time expressed as UTC </li> <li> <code>ngx_localtime(), ngx_libc_localtime()</code> — Time expressed relative to the local time zone </li> </ul>
<p> The <code>ngx_http_time(buf, time)</code> function returns a string representation suitable for use in HTTP headers (for example, <code>"Mon, 28 Sep 1970 06:00:00 GMT"</code>). The <code>ngx_http_cookie_time(buf, time)</code> returns a string representation function returns a string representation suitable for HTTP cookies (<code>"Thu, 31-Dec-37 23:55:55 GMT"</code>). </p>
<h4 id="containers">Containers</h4>
<h4 id="array">Array</h4>
<p> The nginx array type <code>ngx_array_t</code> is defined as follows </p>
<pre data-language="nginx">
typedef struct {
    void        *elts;
    ngx_uint_t   nelts;
    size_t       size;
    ngx_uint_t   nalloc;
    ngx_pool_t  *pool;
} ngx_array_t;
</pre>
<p> The elements of the array are available in the <code>elts</code> field. The <code>nelts</code> field holds the number of elements. The <code>size</code> field holds the size of a single element and is set when the array is initialized. </p>
<p> Use the <code>ngx_array_create(pool, n, size)</code> call to create an array in a pool, and the <code>ngx_array_init(array, pool, n, size)</code> call to initialize an array object that has already been allocated. </p>
<pre data-language="nginx">
ngx_array_t  *a, b;

/* create an array of strings with preallocated memory for 10 elements */
a = ngx_array_create(pool, 10, sizeof(ngx_str_t));

/* initialize string array for 10 elements */
ngx_array_init(&amp;b, pool, 10, sizeof(ngx_str_t));
</pre>
<p> Use the following functions to add elements to an array: </p>
 <ul class="compact"> <li> <code>ngx_array_push(a)</code> adds one tail element and returns pointer to it </li> <li> <code>ngx_array_push_n(a, n)</code> adds <code>n</code> tail elements and returns pointer to the first one </li> </ul>

<p> If the currently allocated amount of memory is not large enough to accommodate the new elements, a new block of memory is allocated and the existing elements are copied to it. The new memory block is normally twice as large as the existing one. </p>
<pre data-language="nginx">
s = ngx_array_push(a);
ss = ngx_array_push_n(&amp;b, 3);
</pre>
<h4 id="list">List</h4>
<p> In nginx a list is a sequence of arrays, optimized for inserting a potentially large number of items. The <code>ngx_list_t</code> list type is defined as follows: </p>
<pre data-language="nginx">
typedef struct {
    ngx_list_part_t  *last;
    ngx_list_part_t   part;
    size_t            size;
    ngx_uint_t        nalloc;
    ngx_pool_t       *pool;
} ngx_list_t;
</pre>
<p> The actual items are stored in list parts, which are defined as follows: </p>
<pre data-language="nginx">
typedef struct ngx_list_part_s  ngx_list_part_t;

struct ngx_list_part_s {
    void             *elts;
    ngx_uint_t        nelts;
    ngx_list_part_t  *next;
};
</pre>
<p> Before use, a list must be initialized by calling <code>ngx_list_init(list, pool, n, size)</code> or created by calling <code>ngx_list_create(pool, n, size)</code>. Both functions take as arguments the size of a single item and a number of items per list part. To add an item to a list, use the <code>ngx_list_push(list)</code> function. To iterate over the items, directly access the list fields as shown in the example: </p>
<pre data-language="nginx">
ngx_str_t        *v;
ngx_uint_t        i;
ngx_list_t       *list;
ngx_list_part_t  *part;

list = ngx_list_create(pool, 100, sizeof(ngx_str_t));
if (list == NULL) { /* error */ }

/* add items to the list */

v = ngx_list_push(list);
if (v == NULL) { /* error */ }
ngx_str_set(v, "foo");

v = ngx_list_push(list);
if (v == NULL) { /* error */ }
ngx_str_set(v, "bar");

/* iterate over the list */

part = &amp;list-&gt;part;
v = part-&gt;elts;

for (i = 0; /* void */; i++) {

    if (i &gt;= part-&gt;nelts) {
        if (part-&gt;next == NULL) {
            break;
        }

        part = part-&gt;next;
        v = part-&gt;elts;
        i = 0;
    }

    ngx_do_smth(&amp;v[i]);
}
</pre>
<p> Lists are primarily used for HTTP input and output headers. </p>
<p> Lists do not support item removal. However, when needed, items can internally be marked as missing without actually being removed from the list. For example, to mark HTTP output headers (which are stored as <code>ngx_table_elt_t</code> objects) as missing, set the <code>hash</code> field in <code>ngx_table_elt_t</code> to zero. Items marked in this way are explicitly skipped when the headers are iterated over. </p>
<h4 id="queue">Queue</h4>
<p> In nginx a queue is an intrusive doubly linked list, with each node defined as follows: </p>
<pre data-language="nginx">
typedef struct ngx_queue_s  ngx_queue_t;

struct ngx_queue_s {
    ngx_queue_t  *prev;
    ngx_queue_t  *next;
};
</pre>
<p> The head queue node is not linked with any data. Use the <code>ngx_queue_init(q)</code> call to initialize the list head before use. Queues support the following operations: </p>
 <ul class="compact"> <li> <code>ngx_queue_insert_head(h, x)</code>, <code>ngx_queue_insert_tail(h, x)</code> — Insert a new node </li> <li> <code>ngx_queue_remove(x)</code> — Remove a queue node </li> <li> <code>ngx_queue_split(h, q, n)</code> — Split a queue at a node, returning the queue tail in a separate queue </li> <li> <code>ngx_queue_add(h, n)</code> — Add a second queue to the first queue </li> <li> <code>ngx_queue_head(h)</code>, <code>ngx_queue_last(h)</code> — Get first or last queue node </li> <li> <code>ngx_queue_sentinel(h)</code> - Get a queue sentinel object to end iteration at </li> <li> <code>ngx_queue_data(q, type, link)</code> — Get a reference to the beginning of a queue node data structure, considering the queue field offset in it </li> </ul>

<p> An example: </p>
<pre data-language="nginx">
typedef struct {
    ngx_str_t    value;
    ngx_queue_t  queue;
} ngx_foo_t;

ngx_foo_t    *f;
ngx_queue_t   values, *q;

ngx_queue_init(&amp;values);

f = ngx_palloc(pool, sizeof(ngx_foo_t));
if (f == NULL) { /* error */ }
ngx_str_set(&amp;f-&gt;value, "foo");

ngx_queue_insert_tail(&amp;values, &amp;f-&gt;queue);

/* insert more nodes here */

for (q = ngx_queue_head(&amp;values);
     q != ngx_queue_sentinel(&amp;values);
     q = ngx_queue_next(q))
{
    f = ngx_queue_data(q, ngx_foo_t, queue);

    ngx_do_smth(&amp;f-&gt;value);
}
</pre>
<h4 id="red_black_tree">Red-Black tree</h4>
<p> The <code>src/core/ngx_rbtree.h</code> header file provides access to the effective implementation of red-black trees. </p>
<pre data-language="nginx">
typedef struct {
    ngx_rbtree_t       rbtree;
    ngx_rbtree_node_t  sentinel;

    /* custom per-tree data here */
} my_tree_t;

typedef struct {
    ngx_rbtree_node_t  rbnode;

    /* custom per-node data */
    foo_t              val;
} my_node_t;
</pre>
<p> To deal with a tree as a whole, you need two nodes: root and sentinel. Typically, they are added to a custom structure, allowing you to organize your data into a tree in which the leaves contain a link to or embed your data. </p>
<p> To initialize a tree: </p>
<pre data-language="nginx">
my_tree_t  root;

ngx_rbtree_init(&amp;root.rbtree, &amp;root.sentinel, insert_value_function);
</pre>
<p> To traverse a tree and insert new values, use the "<code>insert_value</code>" functions. For example, the <code>ngx_str_rbtree_insert_value</code> function deals with the <code>ngx_str_t</code> type. Its arguments are pointers to a root node of an insertion, the newly created node to be added, and a tree sentinel. </p>
<pre data-language="nginx">
void ngx_str_rbtree_insert_value(ngx_rbtree_node_t *temp,
                                 ngx_rbtree_node_t *node,
                                 ngx_rbtree_node_t *sentinel)
</pre>
<p> The traversal is pretty straightforward and can be demonstrated with the following lookup function pattern: </p>
<pre data-language="nginx">
my_node_t *
my_rbtree_lookup(ngx_rbtree_t *rbtree, foo_t *val, uint32_t hash)
{
    ngx_int_t           rc;
    my_node_t          *n;
    ngx_rbtree_node_t  *node, *sentinel;

    node = rbtree-&gt;root;
    sentinel = rbtree-&gt;sentinel;

    while (node != sentinel) {

        n = (my_node_t *) node;

        if (hash != node-&gt;key) {
            node = (hash &lt; node-&gt;key) ? node-&gt;left : node-&gt;right;
            continue;
        }

        rc = compare(val, node-&gt;val);

        if (rc &lt; 0) {
            node = node-&gt;left;
            continue;
        }

        if (rc &gt; 0) {
            node = node-&gt;right;
            continue;
        }

        return n;
    }

    return NULL;
}
</pre>
<p> The <code>compare()</code> function is a classic comparator function that returns a value less than, equal to, or greater than zero. To speed up lookups and avoid comparing user objects that can be big, an integer hash field is used. </p>
<p> To add a node to a tree, allocate a new node, initialize it and call <code>ngx_rbtree_insert()</code>: </p>
<pre data-language="nginx">
    my_node_t          *my_node;
    ngx_rbtree_node_t  *node;

    my_node = ngx_palloc(...);
    init_custom_data(&amp;my_node-&gt;val);

    node = &amp;my_node-&gt;rbnode;
    node-&gt;key = create_key(my_node-&gt;val);

    ngx_rbtree_insert(&amp;root-&gt;rbtree, node);
</pre>
<p> To remove a node, call the <code>ngx_rbtree_delete()</code> function: </p>
<pre data-language="nginx">
ngx_rbtree_delete(&amp;root-&gt;rbtree, node);
</pre>
<h4 id="hash">Hash</h4>
<p> Hash table functions are declared in <code>src/core/ngx_hash.h</code>. Both exact and wildcard matching are supported. The latter requires extra setup and is described in a separate section below. </p>
<p> Before initializing a hash, you need to know the number of elements it will hold so that nginx can build it optimally. Two parameters that need to be configured are <code>max_size</code> and <code>bucket_size</code>, as detailed in a separate <a href="../hash.html">document</a>. They are usually configurable by the user. Hash initialization settings are stored with the <code>ngx_hash_init_t</code> type, and the hash itself is <code>ngx_hash_t</code>: </p> <pre data-language="nginx">
ngx_hash_t       foo_hash;
ngx_hash_init_t  hash;

hash.hash = &amp;foo_hash;
hash.key = ngx_hash_key;
hash.max_size = 512;
hash.bucket_size = ngx_align(64, ngx_cacheline_size);
hash.name = "foo_hash";
hash.pool = cf-&gt;pool;
hash.temp_pool = cf-&gt;temp_pool;
</pre>
<p> The <code>key</code> is a pointer to a function that creates the hash integer key from a string. There are two generic key-creation functions: <code>ngx_hash_key(data, len)</code> and <code>ngx_hash_key_lc(data, len)</code>. The latter converts a string to all lowercase characters, so the passed string must be writable. If that is not true, pass the <code>NGX_HASH_READONLY_KEY</code> flag to the function, initializing the key array (see below). </p>
<p> The hash keys are stored in <code>ngx_hash_keys_arrays_t</code> and are initialized with <code>ngx_hash_keys_array_init(arr, type)</code>: The second parameter (<code>type</code>) controls the amount of resources preallocated for the hash and can be either <code>NGX_HASH_SMALL</code> or <code>NGX_HASH_LARGE</code>. The latter is appropriate if you expect the hash to contain thousands of elements. </p> <pre data-language="nginx">
ngx_hash_keys_arrays_t  foo_keys;

foo_keys.pool = cf-&gt;pool;
foo_keys.temp_pool = cf-&gt;temp_pool;

ngx_hash_keys_array_init(&amp;foo_keys, NGX_HASH_SMALL);
</pre>

<p> To insert keys into a hash keys array, use the <code>ngx_hash_add_key(keys_array, key, value, flags)</code> function: </p> <pre data-language="nginx">
ngx_str_t k1 = ngx_string("key1");
ngx_str_t k2 = ngx_string("key2");

ngx_hash_add_key(&amp;foo_keys, &amp;k1, &amp;my_data_ptr_1, NGX_HASH_READONLY_KEY);
ngx_hash_add_key(&amp;foo_keys, &amp;k2, &amp;my_data_ptr_2, NGX_HASH_READONLY_KEY);
</pre>

<p> To build the hash table, call the <code>ngx_hash_init(hinit, key_names, nelts)</code> function: </p> <pre data-language="nginx">
ngx_hash_init(&amp;hash, foo_keys.keys.elts, foo_keys.keys.nelts);
</pre>
<p> The function fails if <code>max_size</code> or <code>bucket_size</code> parameters are not big enough. </p>
<p> When the hash is built, use the <code>ngx_hash_find(hash, key, name, len)</code> function to look up elements: </p> <pre data-language="nginx">
my_data_t   *data;
ngx_uint_t   key;

key = ngx_hash_key(k1.data, k1.len);

data = ngx_hash_find(&amp;foo_hash, key, k1.data, k1.len);
if (data == NULL) {
    /* key not found */
}
</pre>

<h4 id="wildcard_matching">Wildcard matching</h4>
<p> To create a hash that works with wildcards, use the <code>ngx_hash_combined_t</code> type. It includes the hash type described above and has two additional keys arrays: <code>dns_wc_head</code> and <code>dns_wc_tail</code>. The initialization of basic properties is similar to a regular hash: </p> <pre data-language="nginx">
ngx_hash_init_t      hash
ngx_hash_combined_t  foo_hash;

hash.hash = &amp;foo_hash.hash;
hash.key = ...;
</pre>

<p> It is possible to add wildcard keys using the <code>NGX_HASH_WILDCARD_KEY</code> flag: </p> <pre data-language="nginx">
/* k1 = ".example.org"; */
/* k2 = "foo.*";        */
ngx_hash_add_key(&amp;foo_keys, &amp;k1, &amp;data1, NGX_HASH_WILDCARD_KEY);
ngx_hash_add_key(&amp;foo_keys, &amp;k2, &amp;data2, NGX_HASH_WILDCARD_KEY);
</pre>
<p> The function recognizes wildcards and adds keys into the corresponding arrays. Please refer to the <a href="../http/ngx_http_map_module.html#map">map</a> module documentation for the description of the wildcard syntax and the matching algorithm. </p>
<p> Depending on the contents of added keys, you may need to initialize up to three key arrays: one for exact matching (described above), and two more to enable matching starting from the head or tail of a string: </p> <pre data-language="nginx">
if (foo_keys.dns_wc_head.nelts) {

    ngx_qsort(foo_keys.dns_wc_head.elts,
              (size_t) foo_keys.dns_wc_head.nelts,
              sizeof(ngx_hash_key_t),
              cmp_dns_wildcards);

    hash.hash = NULL;
    hash.temp_pool = pool;

    if (ngx_hash_wildcard_init(&amp;hash, foo_keys.dns_wc_head.elts,
                               foo_keys.dns_wc_head.nelts)
        != NGX_OK)
    {
        return NGX_ERROR;
    }

    foo_hash.wc_head = (ngx_hash_wildcard_t *) hash.hash;
}
</pre>
<p> The keys array needs to be sorted, and initialization results must be added to the combined hash. The initialization of <code>dns_wc_tail</code> array is done similarly. </p>
<p> The lookup in a combined hash is handled by the <code>ngx_hash_find_combined(chash, key, name, len)</code>: </p> <pre data-language="nginx">
/* key = "bar.example.org"; — will match ".example.org" */
/* key = "foo.example.com"; — will match "foo.*"        */

hkey = ngx_hash_key(key.data, key.len);
res = ngx_hash_find_combined(&amp;foo_hash, hkey, key.data, key.len);
</pre>

<h4 id="memory_management">Memory management</h4>
<h4 id="heap">Heap</h4>
<p> To allocate memory from system heap, use the following functions: </p>
 <ul class="compact"> <li> <code>ngx_alloc(size, log)</code> — Allocate memory from system heap. This is a wrapper around <code>malloc()</code> with logging support. Allocation error and debugging information is logged to <code>log</code>. </li> <li> <code>ngx_calloc(size, log)</code> — Allocate memory from system heap like <code>ngx_alloc()</code>, but fill memory with zeros after allocation. </li> <li> <code>ngx_memalign(alignment, size, log)</code> — Allocate aligned memory from system heap. This is a wrapper around <code>posix_memalign()</code> on those platforms that provide that function. Otherwise implementation falls back to <code>ngx_alloc()</code> which provides maximum alignment. </li> <li> <code>ngx_free(p)</code> — Free allocated memory. This is a wrapper around <code>free()</code> </li> </ul>

<h4 id="pool">Pool</h4>
<p> Most nginx allocations are done in pools. Memory allocated in an nginx pool is freed automatically when the pool is destroyed. This provides good allocation performance and makes memory control easy. </p>
<p> A pool internally allocates objects in continuous blocks of memory. Once a block is full, a new one is allocated and added to the pool memory block list. When the requested allocation is too large to fit into a block, the request is forwarded to the system allocator and the returned pointer is stored in the pool for further deallocation. </p>
<p> The type for nginx pools is <code>ngx_pool_t</code>. The following operations are supported: </p>
 <ul class="compact"> <li> <code>ngx_create_pool(size, log)</code> — Create a pool with specified block size. The pool object returned is allocated in the pool as well. The <code>size</code> should be at least <code>NGX_MIN_POOL_SIZE</code> and a multiple of <code>NGX_POOL_ALIGNMENT</code>. </li> <li> <code>ngx_destroy_pool(pool)</code> — Free all pool memory, including the pool object itself. </li> <li> <code>ngx_palloc(pool, size)</code> — Allocate aligned memory from the specified pool. </li> <li> <code>ngx_pcalloc(pool, size)</code> — Allocate aligned memory from the specified pool and fill it with zeroes. </li> <li> <code>ngx_pnalloc(pool, size)</code> — Allocate unaligned memory from the specified pool. Mostly used for allocating strings. </li> <li> <code>ngx_pfree(pool, p)</code> — Free memory that was previously allocated in the specified pool. Only allocations that result from requests forwarded to the system allocator can be freed. </li> </ul>

<pre data-language="nginx">
u_char      *p;
ngx_str_t   *s;
ngx_pool_t  *pool;

pool = ngx_create_pool(1024, log);
if (pool == NULL) { /* error */ }

s = ngx_palloc(pool, sizeof(ngx_str_t));
if (s == NULL) { /* error */ }
ngx_str_set(s, "foo");

p = ngx_pnalloc(pool, 3);
if (p == NULL) { /* error */ }
ngx_memcpy(p, "foo", 3);
</pre>
<p> Chain links (<code>ngx_chain_t</code>) are actively used in nginx, so the nginx pool implementation provides a way to reuse them. The <code>chain</code> field of <code>ngx_pool_t</code> keeps a list of previously allocated links ready for reuse. For efficient allocation of a chain link in a pool, use the <code>ngx_alloc_chain_link(pool)</code> function. This function looks up a free chain link in the pool list and allocates a new chain link if the pool list is empty. To free a link, call the <code>ngx_free_chain(pool, cl)</code> function. </p>
<p> Cleanup handlers can be registered in a pool. A cleanup handler is a callback with an argument which is called when pool is destroyed. A pool is usually tied to a specific nginx object (like an HTTP request) and is destroyed when the object reaches the end of its lifetime. Registering a pool cleanup is a convenient way to release resources, close file descriptors or make final adjustments to the shared data associated with the main object. </p>
<p> To register a pool cleanup, call <code>ngx_pool_cleanup_add(pool, size)</code>, which returns a <code>ngx_pool_cleanup_t</code> pointer to be filled in by the caller. Use the <code>size</code> argument to allocate context for the cleanup handler. </p>
<pre data-language="nginx">
ngx_pool_cleanup_t  *cln;

cln = ngx_pool_cleanup_add(pool, 0);
if (cln == NULL) { /* error */ }

cln-&gt;handler = ngx_my_cleanup;
cln-&gt;data = "foo";

...

static void
ngx_my_cleanup(void *data)
{
    u_char  *msg = data;

    ngx_do_smth(msg);
}
</pre>
<h4 id="shared_memory">Shared memory</h4>
<p> Shared memory is used by nginx to share common data between processes. The <code>ngx_shared_memory_add(cf, name, size, tag)</code> function adds a new shared memory entry <code>ngx_shm_zone_t</code> to a cycle. The function receives the <code>name</code> and <code>size</code> of the zone. Each shared zone must have a unique name. If a shared zone entry with the provided <code>name</code> and <code>tag</code> already exists, the existing zone entry is reused. The function fails with an error if an existing entry with the same name has a different tag. Usually, the address of the module structure is passed as <code>tag</code>, making it possible to reuse shared zones by name within one nginx module. </p>
<p> The shared memory entry structure <code>ngx_shm_zone_t</code> has the following fields: </p>
 <ul class="compact"> <li> <code>init</code> — Initialization callback, called after the shared zone is mapped to actual memory </li> <li> <code>data</code> — Data context, used to pass arbitrary data to the <code>init</code> callback </li> <li> <code>noreuse</code> — Flag that disables reuse of a shared zone from the old cycle </li> <li> <code>tag</code> — Shared zone tag </li> <li> <code>shm</code> — Platform-specific object of type <code>ngx_shm_t</code>, having at least the following fields: <ul class="compact"> <li> <code>addr</code> — Mapped shared memory address, initially NULL </li> <li> <code>size</code> — Shared memory size </li> <li> <code>name</code> — Shared memory name </li> <li> <code>log</code> — Shared memory log </li> <li> <code>exists</code> — Flag that indicates shared memory was inherited from the master process (Windows-specific) </li> </ul> </li> </ul>

<p> Shared zone entries are mapped to actual memory in <code>ngx_init_cycle()</code> after the configuration is parsed. On POSIX systems, the <code>mmap()</code> syscall is used to create the shared anonymous mapping. On Windows, the <code>CreateFileMapping()</code>/ <code>MapViewOfFileEx()</code> pair is used. </p>
<p> For allocating in shared memory, nginx provides the slab pool <code>ngx_slab_pool_t</code> type. A slab pool for allocating memory is automatically created in each nginx shared zone. The pool is located in the beginning of the shared zone and can be accessed by the expression <code>(ngx_slab_pool_t *) shm_zone-&gt;shm.addr</code>. To allocate memory in a shared zone, call either <code>ngx_slab_alloc(pool, size)</code> or <code>ngx_slab_calloc(pool, size)</code>. To free memory, call <code>ngx_slab_free(pool, p)</code>. </p>
<p> Slab pool divides all shared zone into pages. Each page is used for allocating objects of the same size. The specified size must be a power of 2, and greater than the minimum size of 8 bytes. Nonconforming values are rounded up. A bitmask for each page tracks which blocks are in use and which are free for allocation. For sizes greater than a half page (which is usually 2048 bytes), allocation is done an entire page at a time </p>
<p> To protect data in shared memory from concurrent access, use the mutex available in the <code>mutex</code> field of <code>ngx_slab_pool_t</code>. A mutex is most commonly used by the slab pool while allocating and freeing memory, but it can be used to protect any other user data structures allocated in the shared zone. To lock or unlock a mutex, call <code>ngx_shmtx_lock(&amp;shpool-&gt;mutex)</code> or <code>ngx_shmtx_unlock(&amp;shpool-&gt;mutex)</code> respectively. </p>
<pre data-language="nginx">
ngx_str_t        name;
ngx_foo_ctx_t   *ctx;
ngx_shm_zone_t  *shm_zone;

ngx_str_set(&amp;name, "foo");

/* allocate shared zone context */
ctx = ngx_pcalloc(cf-&gt;pool, sizeof(ngx_foo_ctx_t));
if (ctx == NULL) {
    /* error */
}

/* add an entry for 64k shared zone */
shm_zone = ngx_shared_memory_add(cf, &amp;name, 65536, &amp;ngx_foo_module);
if (shm_zone == NULL) {
    /* error */
}

/* register init callback and context */
shm_zone-&gt;init = ngx_foo_init_zone;
shm_zone-&gt;data = ctx;


...


static ngx_int_t
ngx_foo_init_zone(ngx_shm_zone_t *shm_zone, void *data)
{
    ngx_foo_ctx_t  *octx = data;

    size_t            len;
    ngx_foo_ctx_t    *ctx;
    ngx_slab_pool_t  *shpool;

    value = shm_zone-&gt;data;

    if (octx) {
        /* reusing a shared zone from old cycle */
        ctx-&gt;value = octx-&gt;value;
        return NGX_OK;
    }

    shpool = (ngx_slab_pool_t *) shm_zone-&gt;shm.addr;

    if (shm_zone-&gt;shm.exists) {
        /* initialize shared zone context in Windows nginx worker */
        ctx-&gt;value = shpool-&gt;data;
        return NGX_OK;
    }

    /* initialize shared zone */

    ctx-&gt;value = ngx_slab_alloc(shpool, sizeof(ngx_uint_t));
    if (ctx-&gt;value == NULL) {
        return NGX_ERROR;
    }

    shpool-&gt;data = ctx-&gt;value;

    return NGX_OK;
}
</pre>
<h4 id="logging">Logging</h4>
<p> For logging nginx uses <code>ngx_log_t</code> objects. The nginx logger supports several types of output: </p> <ul class="compact"> <li> stderr — Logging to standard error (stderr) </li> <li> file — Logging to a file </li> <li> syslog — Logging to syslog </li> <li> memory — Logging to internal memory storage for development purposes; the memory can be accessed later with a debugger </li> </ul>

<p> A logger instance can be a chain of loggers, linked to each other with the <code>next</code> field. In this case, each message is written to all loggers in the chain. </p>
<p> For each logger, a severity level controls which messages are written to the log (only events assigned that level or higher are logged). The following severity levels are supported: </p>
 <ul class="compact"> <li> <code>NGX_LOG_EMERG</code> </li> <li> <code>NGX_LOG_ALERT</code> </li> <li> <code>NGX_LOG_CRIT</code> </li> <li> <code>NGX_LOG_ERR</code> </li> <li> <code>NGX_LOG_WARN</code> </li> <li> <code>NGX_LOG_NOTICE</code> </li> <li> <code>NGX_LOG_INFO</code> </li> <li> <code>NGX_LOG_DEBUG</code> </li> </ul>

<p> For debug logging, the debug mask is checked as well. The debug masks are: </p>
 <ul class="compact"> <li> <code>NGX_LOG_DEBUG_CORE</code> </li> <li> <code>NGX_LOG_DEBUG_ALLOC</code> </li> <li> <code>NGX_LOG_DEBUG_MUTEX</code> </li> <li> <code>NGX_LOG_DEBUG_EVENT</code> </li> <li> <code>NGX_LOG_DEBUG_HTTP</code> </li> <li> <code>NGX_LOG_DEBUG_MAIL</code> </li> <li> <code>NGX_LOG_DEBUG_STREAM</code> </li> </ul>

<p> Normally, loggers are created by existing nginx code from <code>error_log</code> directives and are available at nearly every stage of processing in cycle, configuration, client connection and other objects. </p>
<p> Nginx provides the following logging macros: </p>
 <ul class="compact"> <li> <code>ngx_log_error(level, log, err, fmt, ...)</code> — Error logging </li> <li> <code>ngx_log_debug0(level, log, err, fmt)</code>, <code>ngx_log_debug1(level, log, err, fmt, arg1)</code> etc — Debug logging with up to eight supported formatting arguments </li> </ul>

<p> A log message is formatted in a buffer of size <code>NGX_MAX_ERROR_STR</code> (currently, 2048 bytes) on stack. The message is prepended with the severity level, process ID (PID), connection ID (stored in <code>log-&gt;connection</code>), and the system error text. For non-debug messages <code>log-&gt;handler</code> is called as well to prepend more specific information to the log message. HTTP module sets <code>ngx_http_log_error()</code> function as log handler to log client and server addresses, current action (stored in <code>log-&gt;action</code>), client request line, server name etc. </p>
<pre data-language="nginx">
/* specify what is currently done */
log-&gt;action = "sending mp4 to client";

/* error and debug log */
ngx_log_error(NGX_LOG_INFO, c-&gt;log, 0, "client prematurely
              closed connection");

ngx_log_debug2(NGX_LOG_DEBUG_HTTP, mp4-&gt;file.log, 0,
               "mp4 start:%ui, length:%ui", mp4-&gt;start, mp4-&gt;length);
</pre>
<p> The example above results in log entries like these: </p>
<pre data-language="nginx">
2016/09/16 22:08:52 [info] 17445#0: *1 client prematurely closed connection while
sending mp4 to client, client: 127.0.0.1, server: , request: "GET /file.mp4 HTTP/1.1"
2016/09/16 23:28:33 [debug] 22140#0: *1 mp4 start:0, length:10000
</pre>
<h4 id="cycle">Cycle</h4>
<p> A cycle object stores the nginx runtime context created from a specific configuration. Its type is <code>ngx_cycle_t</code>. The current cycle is referenced by the <code>ngx_cycle</code> global variable and inherited by nginx workers as they start. Each time the nginx configuration is reloaded, a new cycle is created from the new nginx configuration; the old cycle is usually deleted after the new one is successfully created. </p>
<p> A cycle is created by the <code>ngx_init_cycle()</code> function, which takes the previous cycle as its argument. The function locates the previous cycle's configuration file and inherits as many resources as possible from the previous cycle. A placeholder cycle called "init cycle" is created as nginx start, then is replaced by an actual cycle built from configuration. </p>
<p> Members of the cycle include: </p>
 <ul class="compact"> <li> <code>pool</code> — Cycle pool. Created for each new cycle. </li> <li> <code>log</code> — Cycle log. Initially inherited from the old cycle, it is set to point to <code>new_log</code> after the configuration is read. </li> <li> <code>new_log</code> — Cycle log, created by the configuration. It's affected by the root-scope <code>error_log</code> directive. </li> <li> <code>connections</code>, <code>connection_n</code> — Array of connections of type <code>ngx_connection_t</code>, created by the event module while initializing each nginx worker. The <code>worker_connections</code> directive in the nginx configuration sets the number of connections <code>connection_n</code>. </li> <li> <code>free_connections</code>, <code>free_connection_n</code> — List and number of currently available connections. If no connections are available, an nginx worker refuses to accept new clients or connect to upstream servers. </li> <li> <code>files</code>, <code>files_n</code> — Array for mapping file descriptors to nginx connections. This mapping is used by the event modules, having the <code>NGX_USE_FD_EVENT</code> flag (currently, it's <code>poll</code> and <code>devpoll</code>). </li> <li> <code>conf_ctx</code> — Array of core module configurations. The configurations are created and filled during reading of nginx configuration files. </li> <li> <code>modules</code>, <code>modules_n</code> — Array of modules of type <code>ngx_module_t</code>, both static and dynamic, loaded by the current configuration. </li> <li> <code>listening</code> — Array of listening objects of type <code>ngx_listening_t</code>. Listening objects are normally added by the <code>listen</code> directive of different modules which call the <code>ngx_create_listening()</code> function. Listen sockets are created based on the listening objects. </li> <li> <code>paths</code> — Array of paths of type <code>ngx_path_t</code>. Paths are added by calling the function <code>ngx_add_path()</code> from modules which are going to operate on certain directories. These directories are created by nginx after reading configuration, if missing. Moreover, two handlers can be added for each path: <ul class="compact"> <li> path loader — Executes only once in 60 seconds after starting or reloading nginx. Normally, the loader reads the directory and stores data in nginx shared memory. The handler is called from the dedicated nginx process “nginx cache loader”. </li> <li> path manager — Executes periodically. Normally, the manager removes old files from the directory and updates nginx memory to reflect the changes. The handler is called from the dedicated “nginx cache manager” process. </li> </ul> </li> <li> <code>open_files</code> — List of open file objects of type <code>ngx_open_file_t</code>, which are created by calling the function <code>ngx_conf_open_file()</code>. Currently, nginx uses this kind of open files for logging. After reading the configuration, nginx opens all files in the <code>open_files</code> list and stores each file descriptor in the object's <code>fd</code> field. The files are opened in append mode and are created if missing. The files in the list are reopened by nginx workers upon receiving the reopen signal (most often <code>USR1</code>). In this case the descriptor in the <code>fd</code> field is changed to a new value. </li> <li> <code>shared_memory</code> — List of shared memory zones, each added by calling the <code>ngx_shared_memory_add()</code> function. Shared zones are mapped to the same address range in all nginx processes and are used to share common data, for example the HTTP cache in-memory tree. </li> </ul>

<h4 id="buffer">Buffer</h4>
<p> For input/output operations, nginx provides the buffer type <code>ngx_buf_t</code>. Normally, it's used to hold data to be written to a destination or read from a source. A buffer can reference data in memory or in a file and it's technically possible for a buffer to reference both at the same time. Memory for the buffer is allocated separately and is not related to the buffer structure <code>ngx_buf_t</code>. </p>
<p> The <code>ngx_buf_t</code> structure has the following fields: </p>
 <ul class="compact"> <li> <code>start</code>, <code>end</code> — The boundaries of the memory block allocated for the buffer. </li> <li> <code>pos</code>, <code>last</code> — The boundaries of the memory buffer; normally a subrange of <code>start</code> .. <code>end</code>. </li> <li> <code>file_pos</code>, <code>file_last</code> — The boundaries of a file buffer, expressed as offsets from the beginning of the file. </li> <li> <code>tag</code> — Unique value used to distinguish buffers; created by different nginx modules, usually for the purpose of buffer reuse. </li> <li> <code>file</code> — File object. </li> <li> <code>temporary</code> — Flag indicating that the buffer references writable memory. </li> <li> <code>memory</code> — Flag indicating that the buffer references read-only memory. </li> <li> <code>in_file</code> — Flag indicating that the buffer references data in a file. </li> <li> <code>flush</code> — Flag indicating that all data prior to the buffer need to be flushed. </li> <li> <code>recycled</code> — Flag indicating that the buffer can be reused and needs to be consumed as soon as possible. </li> <li> <code>sync</code> — Flag indicating that the buffer carries no data or special signal like <code>flush</code> or <code>last_buf</code>. By default nginx considers such buffers an error condition, but this flag tells nginx to skip the error check. </li> <li> <code>last_buf</code> — Flag indicating that the buffer is the last in output. </li> <li> <code>last_in_chain</code> — Flag indicating that there are no more data buffers in a request or subrequest. </li> <li> <code>shadow</code> — Reference to another ("shadow") buffer related to the current buffer, usually in the sense that the buffer uses data from the shadow. When the buffer is consumed, the shadow buffer is normally also marked as consumed. </li> <li> <code>last_shadow</code> — Flag indicating that the buffer is the last one that references a particular shadow buffer. </li> <li> <code>temp_file</code> — Flag indicating that the buffer is in a temporary file. </li> </ul>

<p> For input and output operations buffers are linked in chains. A chain is a sequence of chain links of type <code>ngx_chain_t</code>, defined as follows: </p>
<pre data-language="nginx">
typedef struct ngx_chain_s  ngx_chain_t;

struct ngx_chain_s {
    ngx_buf_t    *buf;
    ngx_chain_t  *next;
};
</pre>
<p> Each chain link keeps a reference to its buffer and a reference to the next chain link. </p>
<p> An example of using buffers and chains: </p>
<pre data-language="nginx">
ngx_chain_t *
ngx_get_my_chain(ngx_pool_t *pool)
{
    ngx_buf_t    *b;
    ngx_chain_t  *out, *cl, **ll;

    /* first buf */
    cl = ngx_alloc_chain_link(pool);
    if (cl == NULL) { /* error */ }

    b = ngx_calloc_buf(pool);
    if (b == NULL) { /* error */ }

    b-&gt;start = (u_char *) "foo";
    b-&gt;pos = b-&gt;start;
    b-&gt;end = b-&gt;start + 3;
    b-&gt;last = b-&gt;end;
    b-&gt;memory = 1; /* read-only memory */

    cl-&gt;buf = b;
    out = cl;
    ll = &amp;cl-&gt;next;

    /* second buf */
    cl = ngx_alloc_chain_link(pool);
    if (cl == NULL) { /* error */ }

    b = ngx_create_temp_buf(pool, 3);
    if (b == NULL) { /* error */ }

    b-&gt;last = ngx_cpymem(b-&gt;last, "foo", 3);

    cl-&gt;buf = b;
    cl-&gt;next = NULL;
    *ll = cl;

    return out;
}
</pre>
<h4 id="networking">Networking</h4>
<h4 id="connection">Connection</h4>
<p> The connection type <code>ngx_connection_t</code> is a wrapper around a socket descriptor. It includes the following fields: </p>
 <ul class="compact"> <li> <code>fd</code> — Socket descriptor </li> <li> <code>data</code> — Arbitrary connection context. Normally, it is a pointer to a higher-level object built on top of the connection, such as an HTTP request or a Stream session. </li> <li> <code>read</code>, <code>write</code> — Read and write events for the connection. </li> <li> <code>recv</code>, <code>send</code>, <code>recv_chain</code>, <code>send_chain</code> — I/O operations for the connection. </li> <li> <code>pool</code> — Connection pool. </li> <li> <code>log</code> — Connection log. </li> <li> <code>sockaddr</code>, <code>socklen</code>, <code>addr_text</code> — Remote socket address in binary and text forms. </li> <li> <code>local_sockaddr</code>, <code>local_socklen</code> — Local socket address in binary form. Initially, these fields are empty. Use the <code>ngx_connection_local_sockaddr()</code> function to get the local socket address. </li> <li> <code>proxy_protocol_addr</code>, <code>proxy_protocol_port</code> - PROXY protocol client address and port, if the PROXY protocol is enabled for the connection. </li> <li> <code>ssl</code> — SSL context for the connection. </li> <li> <code>reusable</code> — Flag indicating the connection is in a state that makes it eligible for reuse. </li> <li> <code>close</code> — Flag indicating that the connection is being reused and needs to be closed. </li> </ul>

<p> An nginx connection can transparently encapsulate the SSL layer. In this case the connection's <code>ssl</code> field holds a pointer to an <code>ngx_ssl_connection_t</code> structure, keeping all SSL-related data for the connection, including <code>SSL_CTX</code> and <code>SSL</code>. The <code>recv</code>, <code>send</code>, <code>recv_chain</code>, and <code>send_chain</code> handlers are set to SSL-enabled functions as well. </p>
<p> The <code>worker_connections</code> directive in the nginx configuration limits the number of connections per nginx worker. All connection structures are precreated when a worker starts and stored in the <code>connections</code> field of the cycle object. To retrieve a connection structure, use the <code>ngx_get_connection(s, log)</code> function. It takes as its <code>s</code> argument a socket descriptor, which needs to be wrapped in a connection structure. </p>
<p> Because the number of connections per worker is limited, nginx provides a way to grab connections that are currently in use. To enable or disable reuse of a connection, call the <code>ngx_reusable_connection(c, reusable)</code> function. Calling <code>ngx_reusable_connection(c, 1)</code> sets the <code>reuse</code> flag in the connection structure and inserts the connection into the <code>reusable_connections_queue</code> of the cycle. Whenever <code>ngx_get_connection()</code> finds out there are no available connections in the cycle's <code>free_connections</code> list, it calls <code>ngx_drain_connections()</code> to release a specific number of reusable connections. For each such connection, the <code>close</code> flag is set and its read handler is called which is supposed to free the connection by calling <code>ngx_close_connection(c)</code> and make it available for reuse. To exit the state when a connection can be reused <code>ngx_reusable_connection(c, 0)</code> is called. HTTP client connections are an example of reusable connections in nginx; they are marked as reusable until the first request byte is received from the client. </p>
<h4 id="events">Events</h4>
<h4 id="event">Event</h4>
<p> Event object <code>ngx_event_t</code> in nginx provides a mechanism for notification that a specific event has occurred. </p>
<p> Fields in <code>ngx_event_t</code> include: </p>
 <ul class="compact"> <li> <code>data</code> — Arbitrary event context used in event handlers, usually as pointer to a connection related to the event. </li> <li> <code>handler</code> — Callback function to be invoked when the event happens. </li> <li> <code>write</code> — Flag indicating a write event. Absence of the flag indicates a read event. </li> <li> <code>active</code> — Flag indicating that the event is registered for receiving I/O notifications, normally from notification mechanisms like <code>epoll</code>, <code>kqueue</code>, <code>poll</code>. </li> <li> <code>ready</code> — Flag indicating that the event has received an I/O notification. </li> <li> <code>delayed</code> — Flag indicating that I/O is delayed due to rate limiting. </li> <li> <code>timer</code> — Red-black tree node for inserting the event into the timer tree. </li> <li> <code>timer_set</code> — Flag indicating that the event timer is set and not yet expired. </li> <li> <code>timedout</code> — Flag indicating that the event timer has expired. </li> <li> <code>eof</code> — Flag indicating that EOF occurred while reading data. </li> <li> <code>pending_eof</code> — Flag indicating that EOF is pending on the socket, even though there may be some data available before it. The flag is delivered via the <code>EPOLLRDHUP</code> <code>epoll</code> event or <code>EV_EOF</code> <code>kqueue</code> flag. </li> <li> <code>error</code> — Flag indicating that an error occurred during reading (for a read event) or writing (for a write event). </li> <li> <code>cancelable</code> — Timer event flag indicating that the event should be ignored while shutting down the worker. Graceful worker shutdown is delayed until there are no non-cancelable timer events scheduled. </li> <li> <code>posted</code> — Flag indicating that the event is posted to a queue. </li> <li> <code>queue</code> — Queue node for posting the event to a queue. </li> </ul>

<h4 id="i_o_events">I/O events</h4>
<p> Each connection obtained by calling the <code>ngx_get_connection()</code> function has two attached events, <code>c-&gt;read</code> and <code>c-&gt;write</code>, which are used for receiving notification that the socket is ready for reading or writing. All such events operate in Edge-Triggered mode, meaning that they only trigger notifications when the state of the socket changes. For example, doing a partial read on a socket does not make nginx deliver a repeated read notification until more data arrives on the socket. Even when the underlying I/O notification mechanism is essentially Level-Triggered (<code>poll</code>, <code>select</code> etc), nginx converts the notifications to Edge-Triggered. To make nginx event notifications consistent across all notifications systems on different platforms, the functions <code>ngx_handle_read_event(rev, flags)</code> and <code>ngx_handle_write_event(wev, lowat)</code> must be called after handling an I/O socket notification or calling any I/O functions on that socket. Normally, the functions are called once at the end of each read or write event handler. </p>
<h4 id="timer_events">Timer events</h4>
<p> An event can be set to send a notification when a timeout expires. The timer used by events counts milliseconds since some unspecified point in the past truncated to <code>ngx_msec_t</code> type. Its current value can be obtained from the <code>ngx_current_msec</code> variable. </p>
<p> The function <code>ngx_add_timer(ev, timer)</code> sets a timeout for an event, <code>ngx_del_timer(ev)</code> deletes a previously set timeout. The global timeout red-black tree <code>ngx_event_timer_rbtree</code> stores all timeouts currently set. The key in the tree is of type <code>ngx_msec_t</code> and is the time when the event occurs. The tree structure enables fast insertion and deletion operations, as well as access to the nearest timeouts, which nginx uses to find out how long to wait for I/O events and for expiring timeout events. </p>
<h4 id="posted_events">Posted events</h4>
<p> An event can be posted which means that its handler will be called at some point later within the current event loop iteration. Posting events is a good practice for simplifying code and escaping stack overflows. Posted events are held in a post queue. The <code>ngx_post_event(ev, q)</code> macro posts the event <code>ev</code> to the post queue <code>q</code>. The <code>ngx_delete_posted_event(ev)</code> macro deletes the event <code>ev</code> from the queue it's currently posted in. Normally, events are posted to the <code>ngx_posted_events</code> queue, which is processed late in the event loop — after all I/O and timer events are already handled. The function <code>ngx_event_process_posted()</code> is called to process an event queue. It calls event handlers until the queue is not empty. This means that a posted event handler can post more events to be processed within the current event loop iteration. </p>
<p> An example: </p>
<pre data-language="nginx">
void
ngx_my_connection_read(ngx_connection_t *c)
{
    ngx_event_t  *rev;

    rev = c-&gt;read;

    ngx_add_timer(rev, 1000);

    rev-&gt;handler = ngx_my_read_handler;

    ngx_my_read(rev);
}


void
ngx_my_read_handler(ngx_event_t *rev)
{
    ssize_t            n;
    ngx_connection_t  *c;
    u_char             buf[256];

    if (rev-&gt;timedout) { /* timeout expired */ }

    c = rev-&gt;data;

    while (rev-&gt;ready) {
        n = c-&gt;recv(c, buf, sizeof(buf));

        if (n == NGX_AGAIN) {
            break;
        }

        if (n == NGX_ERROR) { /* error */ }

        /* process buf */
    }

    if (ngx_handle_read_event(rev, 0) != NGX_OK) { /* error */ }
}
</pre>
<h4 id="event_loop">Event loop</h4>
<p> Except for the nginx master process, all nginx processes do I/O and so have an event loop. (The nginx master process instead spends most of its time in the <code>sigsuspend()</code> call waiting for signals to arrive.) The nginx event loop is implemented in the <code>ngx_process_events_and_timers()</code> function, which is called repeatedly until the process exits. </p>
<p> The event loop has the following stages: </p> <ul class="compact"> <li> Find the timeout that is closest to expiring, by calling <code>ngx_event_find_timer()</code>. This function finds the leftmost node in the timer tree and returns the number of milliseconds until the node expires. </li> <li> Process I/O events by calling a handler, specific to the event notification mechanism, chosen by nginx configuration. This handler waits for at least one I/O event to happen, but only until the next timeout expires. When a read or write event occurs, the <code>ready</code> flag is set and the event's handler is called. For Linux, the <code>ngx_epoll_process_events()</code> handler is normally used, which calls <code>epoll_wait()</code> to wait for I/O events. </li> <li> Expire timers by calling <code>ngx_event_expire_timers()</code>. The timer tree is iterated from the leftmost element to the right until an unexpired timeout is found. For each expired node the <code>timedout</code> event flag is set, the <code>timer_set</code> flag is reset, and the event handler is called </li> <li> Process posted events by calling <code>ngx_event_process_posted()</code>. The function repeatedly removes the first element from the posted events queue and calls the element's handler, until the queue is empty. </li> </ul>

<p> All nginx processes handle signals as well. Signal handlers only set global variables which are checked after the <code>ngx_process_events_and_timers()</code> call. </p>
<h4 id="processes">Processes</h4>
<p> There are several types of processes in nginx. The type of a process is kept in the <code>ngx_process</code> global variable, and is one of the following: </p>
<ul class="compact"> <li> <p> <code>NGX_PROCESS_MASTER</code> — The master process, which reads the NGINX configuration, creates cycles, and starts and controls child processes. It does not perform any I/O and responds only to signals. Its cycle function is <code>ngx_master_process_cycle()</code>. </p> </li> <li> <p> <code>NGX_PROCESS_WORKER</code> — The worker process, which handles client connections. It is started by the master process and responds to its signals and channel commands as well. Its cycle function is <code>ngx_worker_process_cycle()</code>. There can be multiple worker processes, as configured by the <code>worker_processes</code> directive. </p> </li> <li> <p> <code>NGX_PROCESS_SINGLE</code> — The single process, which exists only in <code>master_process off</code> mode, and is the only process running in that mode. It creates cycles (like the master process does) and handles client connections (like the worker process does). Its cycle function is <code>ngx_single_process_cycle()</code>. </p> </li> <li> <p> <code>NGX_PROCESS_HELPER</code> — The helper process, of which currently there are two types: cache manager and cache loader. The cycle function for both is <code>ngx_cache_manager_process_cycle()</code>. </p> </li> </ul>
<p> The nginx processes handle the following signals: </p>
<ul class="compact"> <li> <p> <code>NGX_SHUTDOWN_SIGNAL</code> (<code>SIGQUIT</code> on most systems) — Gracefully shutdown. Upon receiving this signal, the master process sends a shutdown signal to all child processes. When no child processes are left, the master destroys the cycle pool and exits. When a worker process receives this signal, it closes all listening sockets and waits until there are no non-cancelable events scheduled, then destroys the cycle pool and exits. When the cache manager or the cache loader process receives this signal, it exits immediately. The <code>ngx_quit</code> variable is set to <code>1</code> when a process receives this signal, and is immediately reset after being processed. The <code>ngx_exiting</code> variable is set to <code>1</code> while a worker process is in the shutdown state. </p> </li> <li> <p> <code>NGX_TERMINATE_SIGNAL</code> (<code>SIGTERM</code> on most systems) — Terminate. Upon receiving this signal, the master process sends a terminate signal to all child processes. If a child process does not exit within 1 second, the master process sends the <code>SIGKILL</code> signal to kill it. When no child processes are left, the master process destroys the cycle pool and exits. When a worker process, the cache manager process or the cache loader process receives this signal, it destroys the cycle pool and exits. The variable <code>ngx_terminate</code> is set to <code>1</code> when this signal is received. </p> </li> <li> <p> <code>NGX_NOACCEPT_SIGNAL</code> (<code>SIGWINCH</code> on most systems) - Shut down all worker and helper processes. Upon receiving this signal, the master process shuts down its child processes. If a previously started new nginx binary exits, the child processes of the old master are started again. When a worker process receives this signal, it shuts down in debug mode set by the <code>debug_points</code> directive. </p> </li> <li> <p> <code>NGX_RECONFIGURE_SIGNAL</code> (<code>SIGHUP</code> on most systems) - Reconfigure. Upon receiving this signal, the master process re-reads the configuration and creates a new cycle based on it. If the new cycle is created successfully, the old cycle is deleted and new child processes are started. Meanwhile, the old child processes receive the <code>NGX_SHUTDOWN_SIGNAL</code> signal. In single-process mode, nginx creates a new cycle, but keeps the old one until there are no longer clients with active connections tied to it. The worker and helper processes ignore this signal. </p> </li> <li> <p> <code>NGX_REOPEN_SIGNAL</code> (<code>SIGUSR1</code> on most systems) — Reopen files. The master process sends this signal to workers, which reopen all <code>open_files</code> related to the cycle. </p> </li> <li> <p> <code>NGX_CHANGEBIN_SIGNAL</code> (<code>SIGUSR2</code> on most systems) — Change the nginx binary. The master process starts a new nginx binary and passes in a list of all listen sockets. The text-format list, passed in the <code>“NGINX”</code> environment variable, consists of descriptor numbers separated with semicolons. The new nginx binary reads the <code>“NGINX”</code> variable and adds the sockets to its init cycle. Other processes ignore this signal. </p> </li> </ul>
<p> While all nginx worker processes are able to receive and properly handle POSIX signals, the master process does not use the standard <code>kill()</code> syscall to pass signals to workers and helpers. Instead, nginx uses inter-process socket pairs which allow sending messages between all nginx processes. Currently, however, messages are only sent from the master to its children. The messages carry the standard signals. </p>
<h4 id="threads">Threads</h4>
<p> It is possible to offload into a separate thread tasks that would otherwise block the nginx worker process. For example, nginx can be configured to use threads to perform <a href="../http/ngx_http_core_module.html#aio">file I/O</a>. Another use case is a library that doesn't have asynchronous interface and thus cannot be normally used with nginx. Keep in mind that the threads interface is a helper for the existing asynchronous approach to processing client connections, and by no means intended as a replacement. </p>
<p> To deal with synchronization, the following wrappers over <code>pthreads</code> primitives are available: </p> <ul class="compact"> <li> <code>typedef pthread_mutex_t  ngx_thread_mutex_t;</code> <ul class="compact"> <li> <code>ngx_int_t
ngx_thread_mutex_create(ngx_thread_mutex_t *mtx, ngx_log_t *log);</code> </li> <li> <code>ngx_int_t
ngx_thread_mutex_destroy(ngx_thread_mutex_t *mtx, ngx_log_t *log);</code> </li> <li> <code>ngx_int_t
ngx_thread_mutex_lock(ngx_thread_mutex_t *mtx, ngx_log_t *log);</code> </li> <li> <code>ngx_int_t
ngx_thread_mutex_unlock(ngx_thread_mutex_t *mtx, ngx_log_t *log);</code> </li> </ul> </li> <li> <code>typedef pthread_cond_t  ngx_thread_cond_t;</code> <ul class="compact"> <li> <code>ngx_int_t
ngx_thread_cond_create(ngx_thread_cond_t *cond, ngx_log_t *log);</code> </li> <li> <code>ngx_int_t
ngx_thread_cond_destroy(ngx_thread_cond_t *cond, ngx_log_t *log);</code> </li> <li> <code>ngx_int_t
ngx_thread_cond_signal(ngx_thread_cond_t *cond, ngx_log_t *log);</code> </li> <li> <code>ngx_int_t
ngx_thread_cond_wait(ngx_thread_cond_t *cond, ngx_thread_mutex_t *mtx,
ngx_log_t *log);</code> </li> </ul> </li> </ul>

<p> Instead of creating a new thread for each task, nginx implements a <a href="../ngx_core_module.html#thread_pool">thread_pool</a> strategy. Multiple thread pools may be configured for different purposes (for example, performing I/O on different sets of disks). Each thread pool is created at startup and contains a limited number of threads that process a queue of tasks. When a task is completed, a predefined completion handler is called. </p>
<p> The <code>src/core/ngx_thread_pool.h</code> header file contains relevant definitions: </p> <pre data-language="nginx">
struct ngx_thread_task_s {
    ngx_thread_task_t   *next;
    ngx_uint_t           id;
    void                *ctx;
    void               (*handler)(void *data, ngx_log_t *log);
    ngx_event_t          event;
};

typedef struct ngx_thread_pool_s  ngx_thread_pool_t;

ngx_thread_pool_t *ngx_thread_pool_add(ngx_conf_t *cf, ngx_str_t *name);
ngx_thread_pool_t *ngx_thread_pool_get(ngx_cycle_t *cycle, ngx_str_t *name);

ngx_thread_task_t *ngx_thread_task_alloc(ngx_pool_t *pool, size_t size);
ngx_int_t ngx_thread_task_post(ngx_thread_pool_t *tp, ngx_thread_task_t *task);

</pre>
<p> At configuration time, a module willing to use threads has to obtain a reference to a thread pool by calling <code>ngx_thread_pool_add(cf, name)</code>, which either creates a new thread pool with the given <code>name</code> or returns a reference to the pool with that name if it already exists. </p>
<p> To add a <code>task</code> into a queue of a specified thread pool <code>tp</code> at runtime, use the <code>ngx_thread_task_post(tp, task)</code> function. To execute a function in a thread, pass parameters and setup a completion handler using the <code>ngx_thread_task_t</code> structure: </p> <pre data-language="nginx">
typedef struct {
    int    foo;
} my_thread_ctx_t;


static void
my_thread_func(void *data, ngx_log_t *log)
{
    my_thread_ctx_t *ctx = data;

    /* this function is executed in a separate thread */
}


static void
my_thread_completion(ngx_event_t *ev)
{
    my_thread_ctx_t *ctx = ev-&gt;data;

    /* executed in nginx event loop */
}


ngx_int_t
my_task_offload(my_conf_t *conf)
{
    my_thread_ctx_t    *ctx;
    ngx_thread_task_t  *task;

    task = ngx_thread_task_alloc(conf-&gt;pool, sizeof(my_thread_ctx_t));
    if (task == NULL) {
        return NGX_ERROR;
    }

    ctx = task-&gt;ctx;

    ctx-&gt;foo = 42;

    task-&gt;handler = my_thread_func;
    task-&gt;event.handler = my_thread_completion;
    task-&gt;event.data = ctx;

    if (ngx_thread_task_post(conf-&gt;thread_pool, task) != NGX_OK) {
        return NGX_ERROR;
    }

    return NGX_OK;
}
</pre>

<h4 id="Modules">Modules</h4>
<h4 id="adding_new_modules">Adding new modules</h4>
<p> Each standalone nginx module resides in a separate directory that contains at least two files: <code>config</code> and a file with the module source code. The <code>config</code> file contains all information needed for nginx to integrate the module, for example: </p> <pre data-language="nginx">
ngx_module_type=CORE
ngx_module_name=ngx_foo_module
ngx_module_srcs="$ngx_addon_dir/ngx_foo_module.c"

. auto/module

ngx_addon_name=$ngx_module_name
</pre>
<p> The <code>config</code> file is a POSIX shell script that can set and access the following variables: </p> <ul class="compact"> <li> <code>ngx_module_type</code> — Type of module to build. Possible values are <code>CORE</code>, <code>HTTP</code>, <code>HTTP_FILTER</code>, <code>HTTP_INIT_FILTER</code>, <code>HTTP_AUX_FILTER</code>, <code>MAIL</code>, <code>STREAM</code>, or <code>MISC</code>. </li> <li> <code>ngx_module_name</code> — Module names. To build multiple modules from a set of source files, specify a whitespace-separated list of names. The first name indicates the name of the output binary for the dynamic module. The names in the list must match the names used in the source code. </li> <li> <code>ngx_addon_name</code> — Name of the module as it appears in output on the console from the configure script. </li> <li> <code>ngx_module_srcs</code> — Whitespace-separated list of source files used to compile the module. The <code>$ngx_addon_dir</code> variable can be used to represent the path to the module directory. </li> <li> <code>ngx_module_incs</code> — Include paths required to build the module </li> <li> <code>ngx_module_deps</code> — Whitespace-separated list of the module's dependencies. Usually, it is the list of header files. </li> <li> <code>ngx_module_libs</code> — Whitespace-separated list of libraries to link with the module. For example, use <code>ngx_module_libs=-lpthread</code> to link <code>libpthread</code> library. The following macros can be used to link against the same libraries as nginx: <code>LIBXSLT</code>, <code>LIBGD</code>, <code>GEOIP</code>, <code>PCRE</code>, <code>OPENSSL</code>, <code>MD5</code>, <code>SHA1</code>, <code>ZLIB</code>, and <code>PERL</code>. </li> <li> <code>ngx_module_link</code> — Variable set by the build system to <code>DYNAMIC</code> for a dynamic module or <code>ADDON</code> for a static module and used to determine different actions to perform depending on linking type. </li> <li> <code>ngx_module_order</code> — Load order for the module; useful for the <code>HTTP_FILTER</code> and <code>HTTP_AUX_FILTER</code> module types. The format for this option is a whitespace-separated list of modules. All modules in the list following the current module's name end up after it in the global list of modules, which sets up the order for modules initialization. For filter modules later initialization means earlier execution. <p> The following modules are typically used as references. The <code>ngx_http_copy_filter_module</code> reads the data for other filter modules and is placed near the bottom of the list so that it is one of the first to be executed. The <code>ngx_http_write_filter_module</code> writes the data to the client socket and is placed near the top of the list, and is the last to be executed. </p> <p> By default, filter modules are placed before the <code>ngx_http_copy_filter</code> in the module list so that the filter handler is executed after the copy filter handler. For other module types the default is the empty string. </p> </li> </ul>
<p> To compile a module into nginx statically, use the <code>--add-module=/path/to/module</code> argument to the configure script. To compile a module for later dynamic loading into nginx, use the <code>--add-dynamic-module=/path/to/module</code> argument. </p>
<h4 id="core_modules">Core Modules</h4>
<p> Modules are the building blocks of nginx, and most of its functionality is implemented as modules. The module source file must contain a global variable of type <code>ngx_module_t</code>, which is defined as follows: </p> <pre data-language="nginx">
struct ngx_module_s {

    /* private part is omitted */

    void                 *ctx;
    ngx_command_t        *commands;
    ngx_uint_t            type;

    ngx_int_t           (*init_master)(ngx_log_t *log);

    ngx_int_t           (*init_module)(ngx_cycle_t *cycle);

    ngx_int_t           (*init_process)(ngx_cycle_t *cycle);
    ngx_int_t           (*init_thread)(ngx_cycle_t *cycle);
    void                (*exit_thread)(ngx_cycle_t *cycle);
    void                (*exit_process)(ngx_cycle_t *cycle);

    void                (*exit_master)(ngx_cycle_t *cycle);

    /* stubs for future extensions are omitted */
};
</pre>
<p> The omitted private part includes the module version and a signature and is filled using the predefined macro <code>NGX_MODULE_V1</code>. </p>
<p> Each module keeps its private data in the <code>ctx</code> field, recognizes the configuration directives, specified in the <code>commands</code> array, and can be invoked at certain stages of nginx lifecycle. The module lifecycle consists of the following events: </p> <ul class="compact"> <li> Configuration directive handlers are called as they appear in configuration files in the context of the master process. </li> <li> After the configuration is parsed successfully, <code>init_module</code> handler is called in the context of the master process. The <code>init_module</code> handler is called in the master process each time a configuration is loaded. </li> <li> The master process creates one or more worker processes and the <code>init_process</code> handler is called in each of them. </li> <li> When a worker process receives the shutdown or terminate command from the master, it invokes the <code>exit_process</code> handler. </li> <li> The master process calls the <code>exit_master</code> handler before exiting. </li> </ul>
<p> Because threads are used in nginx only as a supplementary I/O facility with its own API, <code>init_thread</code> and <code>exit_thread</code> handlers are not currently called. There is also no <code>init_master</code> handler, because it would be unnecessary overhead. </p>
<p> The module <code>type</code> defines exactly what is stored in the <code>ctx</code> field. Its value is one of the following types: </p> <ul class="compact"> <li><code>NGX_CORE_MODULE</code></li> <li><code>NGX_EVENT_MODULE</code></li> <li><code>NGX_HTTP_MODULE</code></li> <li><code>NGX_MAIL_MODULE</code></li> <li><code>NGX_STREAM_MODULE</code></li> </ul>
<p> The <code>NGX_CORE_MODULE</code> is the most basic and thus the most generic and most low-level type of module. The other module types are implemented on top of it and provide a more convenient way to deal with corresponding domains, like handling events or HTTP requests. </p>
<p> The set of core modules includes <code>ngx_core_module</code>, <code>ngx_errlog_module</code>, <code>ngx_regex_module</code>, <code>ngx_thread_pool_module</code> and <code>ngx_openssl_module</code> modules. The HTTP module, the stream module, the mail module and event modules are core modules too. The context of a core module is defined as: </p> <pre data-language="nginx">
typedef struct {
    ngx_str_t             name;
    void               *(*create_conf)(ngx_cycle_t *cycle);
    char               *(*init_conf)(ngx_cycle_t *cycle, void *conf);
} ngx_core_module_t;
</pre>
<p> where the <code>name</code> is a module name string, <code>create_conf</code> and <code>init_conf</code> are pointers to functions that create and initialize module configuration respectively. For core modules, nginx calls <code>create_conf</code> before parsing a new configuration and <code>init_conf</code> after all configuration is parsed successfully. The typical <code>create_conf</code> function allocates memory for the configuration and sets default values. </p>
<p> For example, a simplistic module called <code>ngx_foo_module</code> might look like this: </p> <pre data-language="nginx">
/*
 * Copyright (C) Author.
 */


#include &lt;ngx_config.h&gt;
#include &lt;ngx_core.h&gt;


typedef struct {
    ngx_flag_t  enable;
} ngx_foo_conf_t;


static void *ngx_foo_create_conf(ngx_cycle_t *cycle);
static char *ngx_foo_init_conf(ngx_cycle_t *cycle, void *conf);

static char *ngx_foo_enable(ngx_conf_t *cf, void *post, void *data);
static ngx_conf_post_t  ngx_foo_enable_post = { ngx_foo_enable };


static ngx_command_t  ngx_foo_commands[] = {

    { ngx_string("foo_enabled"),
      NGX_MAIN_CONF|NGX_DIRECT_CONF|NGX_CONF_FLAG,
      ngx_conf_set_flag_slot,
      0,
      offsetof(ngx_foo_conf_t, enable),
      &amp;ngx_foo_enable_post },

      ngx_null_command
};


static ngx_core_module_t  ngx_foo_module_ctx = {
    ngx_string("foo"),
    ngx_foo_create_conf,
    ngx_foo_init_conf
};


ngx_module_t  ngx_foo_module = {
    NGX_MODULE_V1,
    &amp;ngx_foo_module_ctx,                   /* module context */
    ngx_foo_commands,                      /* module directives */
    NGX_CORE_MODULE,                       /* module type */
    NULL,                                  /* init master */
    NULL,                                  /* init module */
    NULL,                                  /* init process */
    NULL,                                  /* init thread */
    NULL,                                  /* exit thread */
    NULL,                                  /* exit process */
    NULL,                                  /* exit master */
    NGX_MODULE_V1_PADDING
};


static void *
ngx_foo_create_conf(ngx_cycle_t *cycle)
{
    ngx_foo_conf_t  *fcf;

    fcf = ngx_pcalloc(cycle-&gt;pool, sizeof(ngx_foo_conf_t));
    if (fcf == NULL) {
        return NULL;
    }

    fcf-&gt;enable = NGX_CONF_UNSET;

    return fcf;
}


static char *
ngx_foo_init_conf(ngx_cycle_t *cycle, void *conf)
{
    ngx_foo_conf_t *fcf = conf;

    ngx_conf_init_value(fcf-&gt;enable, 0);

    return NGX_CONF_OK;
}


static char *
ngx_foo_enable(ngx_conf_t *cf, void *post, void *data)
{
    ngx_flag_t  *fp = data;

    if (*fp == 0) {
        return NGX_CONF_OK;
    }

    ngx_log_error(NGX_LOG_NOTICE, cf-&gt;log, 0, "Foo Module is enabled");

    return NGX_CONF_OK;
}
</pre>

<h4 id="config_directives">Configuration Directives</h4>
<p> The <code>ngx_command_t</code> type defines a single configuration directive. Each module that supports configuration provides an array of such structures that describe how to process arguments and what handlers to call: </p> <pre data-language="nginx">
typedef struct ngx_command_s  ngx_command_t;

struct ngx_command_s {
    ngx_str_t             name;
    ngx_uint_t            type;
    char               *(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
    ngx_uint_t            conf;
    ngx_uint_t            offset;
    void                 *post;
};
</pre>
<p> Terminate the array with the special value <code>ngx_null_command</code>. The <code>name</code> is the name of a directive as it appears in the configuration file, for example "worker_processes" or "listen". The <code>type</code> is a bit-field of flags that specify the number of arguments the directive takes, its type, and the context in which it appears. The flags are: </p> <ul class="compact"> <li> <code>NGX_CONF_NOARGS</code> — Directive takes no arguments. </li> <li> <code>NGX_CONF_1MORE</code> — Directive takes one or more arguments. </li> <li> <code>NGX_CONF_2MORE</code> — Directive takes two or more arguments. </li> <li> <code>NGX_CONF_TAKE1</code>..<code>NGX_CONF_TAKE7</code> — Directive takes exactly the indicated number of arguments. </li> <li> <code>NGX_CONF_TAKE12</code>, <code>NGX_CONF_TAKE13</code>, <code>NGX_CONF_TAKE23</code>, <code>NGX_CONF_TAKE123</code>, <code>NGX_CONF_TAKE1234</code> — Directive may take different number of arguments. Options are limited to the given numbers. For example, <code>NGX_CONF_TAKE12</code> means it takes one or two arguments. </li> </ul>
<p> The flags for directive types are: </p> <ul class="compact"> <li> <code>NGX_CONF_BLOCK</code> — Directive is a block, that is, it can contain other directives within its opening and closing braces, or even implement its own parser to handle contents inside. </li> <li> <code>NGX_CONF_FLAG</code> — Directive takes a boolean value, either <code>on</code> or <code>off</code>. </li> </ul>
<p> A directive's context defines where it may appear in the configuration: </p> <ul class="compact"> <li> <code>NGX_MAIN_CONF</code> — In the top level context. </li> <li> <code>NGX_HTTP_MAIN_CONF</code> — In the <code>http</code> block. </li> <li> <code>NGX_HTTP_SRV_CONF</code> — In a <code>server</code> block within the <code>http</code> block. </li> <li> <code>NGX_HTTP_LOC_CONF</code> — In a <code>location</code> block within the <code>http</code> block. </li> <li> <code>NGX_HTTP_UPS_CONF</code> — In an <code>upstream</code> block within the <code>http</code> block. </li> <li> <code>NGX_HTTP_SIF_CONF</code> — In an <code>if</code> block within a <code>server</code> block in the <code>http</code> block. </li> <li> <code>NGX_HTTP_LIF_CONF</code> — In an <code>if</code> block within a <code>location</code> block in the <code>http</code> block. </li> <li> <code>NGX_HTTP_LMT_CONF</code> — In a <code>limit_except</code> block within the <code>http</code> block. </li> <li> <code>NGX_STREAM_MAIN_CONF</code> — In the <code>stream</code> block. </li> <li> <code>NGX_STREAM_SRV_CONF</code> — In a <code>server</code> block within the <code>stream</code> block. </li> <li> <code>NGX_STREAM_UPS_CONF</code> — In an <code>upstream</code> block within the <code>stream</code> block. </li> <li> <code>NGX_MAIL_MAIN_CONF</code> — In the <code>mail</code> block. </li> <li> <code>NGX_MAIL_SRV_CONF</code> — In a <code>server</code> block within the <code>mail</code> block. </li> <li> <code>NGX_EVENT_CONF</code> — In the <code>event</code> block. </li> <li> <code>NGX_DIRECT_CONF</code> — Used by modules that don't create a hierarchy of contexts and only have one global configuration. This configuration is passed to the handler as the <code>conf</code> argument. </li> </ul>
<p> The configuration parser uses these flags to throw an error in case of a misplaced directive and calls directive handlers supplied with a proper configuration pointer, so that the same directives in different locations can store their values in distinct places. </p>
<p> The <code>set</code> field defines a handler that processes a directive and stores parsed values into the corresponding configuration. There's a number of functions that perform common conversions: </p> <ul class="compact"> <li> <code>ngx_conf_set_flag_slot</code> — Converts the literal strings <code>on</code> and <code>off</code> into an <code>ngx_flag_t</code> value with values 1 or 0, respectively. </li> <li> <code>ngx_conf_set_str_slot</code> — Stores a string as a value of the <code>ngx_str_t</code> type. </li> <li> <code>ngx_conf_set_str_array_slot</code> — Appends a value to an array <code>ngx_array_t</code> of strings <code>ngx_str_t</code>. The array is created if does not already exist. </li> <li> <code>ngx_conf_set_keyval_slot</code> — Appends a key-value pair to an array <code>ngx_array_t</code> of key-value pairs <code>ngx_keyval_t</code>. The first string becomes the key and the second the value. The array is created if it does not already exist. </li> <li> <code>ngx_conf_set_num_slot</code> — Converts a directive's argument to an <code>ngx_int_t</code> value. </li> <li> <code>ngx_conf_set_size_slot</code> — Converts a <a href="../syntax.html">size</a> to a <code>size_t</code> value expressed in bytes. </li> <li> <code>ngx_conf_set_off_slot</code> — Converts an <a href="../syntax.html">offset</a> to an <code>off_t</code> value expressed in bytes. </li> <li> <code>ngx_conf_set_msec_slot</code> — Converts a <a href="../syntax.html">time</a> to an <code>ngx_msec_t</code> value expressed in milliseconds. </li> <li> <code>ngx_conf_set_sec_slot</code> — Converts a <a href="../syntax.html">time</a> to a <code>time_t</code> value expressed in in seconds. </li> <li> <code>ngx_conf_set_bufs_slot</code> — Converts the two supplied arguments into an <code>ngx_bufs_t</code> object that holds the number and <a href="../syntax.html">size</a> of buffers. </li> <li> <code>ngx_conf_set_enum_slot</code> — Converts the supplied argument into an <code>ngx_uint_t</code> value. The null-terminated array of <code>ngx_conf_enum_t</code> passed in the <code>post</code> field defines the acceptable strings and corresponding integer values. </li> <li> <code>ngx_conf_set_bitmask_slot</code> — Converts the supplied arguments into an <code>ngx_uint_t</code> value. The mask values for each argument are ORed producing the result. The null-terminated array of <code>ngx_conf_bitmask_t</code> passed in the <code>post</code> field defines the acceptable strings and corresponding mask values. </li> <li> <code>set_path_slot</code> — Converts the supplied arguments to an <code>ngx_path_t</code> value and performs all required initializations. For details, see the documentation for the <a href="../http/ngx_http_proxy_module.html#proxy_temp_path"> proxy_temp_path</a> directive. </li> <li> <code>set_access_slot</code> — Converts the supplied arguments to a file permissions mask. For details, see the documentation for the <a href="../http/ngx_http_proxy_module.html#proxy_store_access"> proxy_store_access</a> directive. </li> </ul>

<p> The <code>conf</code> field defines which configuration structure is passed to the directory handler. Core modules only have the global configuration and set <code>NGX_DIRECT_CONF</code> flag to access it. Modules like HTTP, Stream or Mail create hierarchies of configurations. For example, a module's configuration is created for <code>server</code>, <code>location</code> and <code>if</code> scopes. </p> <ul class="compact"> <li> <code>NGX_HTTP_MAIN_CONF_OFFSET</code> — Configuration for the <code>http</code> block. </li> <li> <code>NGX_HTTP_SRV_CONF_OFFSET</code> — Configuration for a <code>server</code> block within the <code>http</code> block. </li> <li> <code>NGX_HTTP_LOC_CONF_OFFSET</code> — Configuration for a <code>location</code> block within the <code>http</code>. </li> <li> <code>NGX_STREAM_MAIN_CONF_OFFSET</code> — Configuration for the <code>stream</code> block. </li> <li> <code>NGX_STREAM_SRV_CONF_OFFSET</code> — Configuration for a <code>server</code> block within the <code>stream</code> block. </li> <li> <code>NGX_MAIL_MAIN_CONF_OFFSET</code> — Configuration for the <code>mail</code> block. </li> <li> <code>NGX_MAIL_SRV_CONF_OFFSET</code> — Configuration for a <code>server</code> block within the <code>mail</code> block. </li> </ul>

<p> The <code>offset</code> defines the offset of a field in a module configuration structure that holds values for this particular directive. The typical use is to employ the <code>offsetof()</code> macro. </p>
<p> The <code>post</code> field has two purposes: it may be used to define a handler to be called after the main handler has completed, or to pass additional data to the main handler. In the first case, the <code>ngx_conf_post_t</code> structure needs to be initialized with a pointer to the handler, for example: </p> <pre data-language="nginx">
static char *ngx_do_foo(ngx_conf_t *cf, void *post, void *data);
static ngx_conf_post_t  ngx_foo_post = { ngx_do_foo };
</pre>
<p> The <code>post</code> argument is the <code>ngx_conf_post_t</code> object itself, and the <code>data</code> is a pointer to the value, converted from arguments by the main handler with the appropriate type. </p>
<h4 id="http">HTTP</h4>
<h4 id="http_connection">Connection</h4>
<p> Each HTTP client connection runs through the following stages: </p>
<ul class="compact"> <li> <code>ngx_event_accept()</code> accepts a client TCP connection. This handler is called in response to a read notification on a listen socket. A new <code>ngx_connection_t</code> object is created at this stage to wrap the newly accepted client socket. Each nginx listener provides a handler to pass the new connection object to. For HTTP connections it's <code>ngx_http_init_connection(c)</code>. </li> <li> <code>ngx_http_init_connection()</code> performs early initialization of the HTTP connection. At this stage an <code>ngx_http_connection_t</code> object is created for the connection and its reference is stored in the connection's <code>data</code> field. Later it will be replaced by an HTTP request object. A PROXY protocol parser and the SSL handshake are started at this stage as well. </li> <li> <code>ngx_http_wait_request_handler()</code> read event handler is called when data is available on the client socket. At this stage an HTTP request object <code>ngx_http_request_t</code> is created and set to the connection's <code>data</code> field. </li> <li> <code>ngx_http_process_request_line()</code> read event handler reads client request line. The handler is set by <code>ngx_http_wait_request_handler()</code>. The data is read into connection's <code>buffer</code>. The size of the buffer is initially set by the directive <a href="../http/ngx_http_core_module.html#client_header_buffer_size">client_header_buffer_size</a>. The entire client header is supposed to fit in the buffer. If the initial size is not sufficient, a bigger buffer is allocated, with the capacity set by the <code>large_client_header_buffers</code> directive. </li> <li> <code>ngx_http_process_request_headers()</code> read event handler, is set after <code>ngx_http_process_request_line()</code> to read the client request header. </li> <li> <code>ngx_http_core_run_phases()</code> is called when the request header is completely read and parsed. This function runs request phases from <code>NGX_HTTP_POST_READ_PHASE</code> to <code>NGX_HTTP_CONTENT_PHASE</code>. The last phase is intended to generate a response and pass it along the filter chain. The response is not necessarily sent to the client at this phase. It might remain buffered and be sent at the finalization stage. </li> <li> <code>ngx_http_finalize_request()</code> is usually called when the request has generated all the output or produced an error. In the latter case an appropriate error page is looked up and used as the response. If the response is not completely sent to the client by this point, an HTTP writer <code>ngx_http_writer()</code> is activated to finish sending outstanding data. </li> <li> <code>ngx_http_finalize_connection()</code> is called when the complete response has been sent to the client and the request can be destroyed. If the client connection keepalive feature is enabled, <code>ngx_http_set_keepalive()</code> is called, which destroys the current request and waits for the next request on the connection. Otherwise, <code>ngx_http_close_request()</code> destroys both the request and the connection. </li> </ul>
<h4 id="http_request">Request</h4>
<p> For each client HTTP request the <code>ngx_http_request_t</code> object is created. Some of the fields of this object are: </p>
<ul class="compact"> <li> <p> <code>connection</code> — Pointer to a <code>ngx_connection_t</code> client connection object. Several requests can reference the same connection object at the same time - one main request and its subrequests. After a request is deleted, a new request can be created on the same connection. </p> <p> Note that for HTTP connections <code>ngx_connection_t</code>'s <code>data</code> field points back to the request. Such requests are called active, as opposed to the other requests tied to the connection. An active request is used to handle client connection events and is allowed to output its response to the client. Normally, each request becomes active at some point so that it can send its output. </p> </li> <li> <p> <code>ctx</code> — Array of HTTP module contexts. Each module of type <code>NGX_HTTP_MODULE</code> can store any value (normally, a pointer to a structure) in the request. The value is stored in the <code>ctx</code> array at the module's <code>ctx_index</code> position. The following macros provide a convenient way to get and set request contexts: </p> <ul class="compact"> <li> <code>ngx_http_get_module_ctx(r, module)</code> — Returns the <code>module</code>'s context </li> <li> <code>ngx_http_set_ctx(r, c, module)</code> — Sets <code>c</code> as the <code>module</code>'s context </li> </ul> </li> <li> <code>main_conf</code>, <code>srv_conf</code>, <code>loc_conf</code> — Arrays of current request configurations. Configurations are stored at the module's <code>ctx_index</code> positions. </li> <li> <code>read_event_handler</code>, <code>write_event_handler</code> - Read and write event handlers for the request. Normally, both the read and write event handlers for an HTTP connection are set to <code>ngx_http_request_handler()</code>. This function calls the <code>read_event_handler</code> and <code>write_event_handler</code> handlers for the currently active request. </li> <li> <code>cache</code> — Request cache object for caching the upstream response. </li> <li> <code>upstream</code> — Request upstream object for proxying. </li> <li> <code>pool</code> — Request pool. The request object itself is allocated in this pool, which is destroyed when the request is deleted. For allocations that need to be available throughout the client connection's lifetime, use <code>ngx_connection_t</code>'s pool instead. </li> <li> <code>header_in</code> — Buffer into which the client HTTP request header is read. </li> <li> <code>headers_in</code>, <code>headers_out</code> — Input and output HTTP headers objects. Both objects contain the <code>headers</code> field of type <code>ngx_list_t</code> for keeping the raw list of headers. In addition to that, specific headers are available for getting and setting as separate fields, for example <code>content_length_n</code>, <code>status</code> etc. </li> <li> <code>request_body</code> — Client request body object. </li> <li> <code>start_sec</code>, <code>start_msec</code> — Time point when the request was created, used for tracking request duration. </li> <li> <code>method</code>, <code>method_name</code> — Numeric and text representation of the client HTTP request method. Numeric values for methods are defined in <code>src/http/ngx_http_request.h</code> with the macros <code>NGX_HTTP_GET</code>, <code>NGX_HTTP_HEAD</code>, <code>NGX_HTTP_POST</code>, etc. </li> <li> <code>http_protocol</code> — Client HTTP protocol version in its original text form (“HTTP/1.0”, “HTTP/1.1” etc). </li> <li> <code>http_version</code> — Client HTTP protocol version in numeric form (<code>NGX_HTTP_VERSION_10</code>, <code>NGX_HTTP_VERSION_11</code>, etc.). </li> <li> <code>http_major</code>, <code>http_minor</code> — Client HTTP protocol version in numeric form split into major and minor parts. </li> <li> <code>request_line</code>, <code>unparsed_uri</code> — Request line and URI in the original client request. </li> <li> <code>uri</code>, <code>args</code>, <code>exten</code> — URI, arguments and file extension for the current request. The URI value here might differ from the original URI sent by the client due to normalization. Throughout request processing, these values can change as internal redirects are performed. </li> <li> <code>main</code> — Pointer to a main request object. This object is created to process a client HTTP request, as opposed to subrequests, which are created to perform a specific subtask within the main request. </li> <li> <code>parent</code> — Pointer to the parent request of a subrequest. </li> <li> <code>postponed</code> — List of output buffers and subrequests, in the order in which they are sent and created. The list is used by the postpone filter to provide consistent request output when parts of it are created by subrequests. </li> <li> <code>post_subrequest</code> — Pointer to a handler with the context to be called when a subrequest gets finalized. Unused for main requests. </li> <li> <p> <code>posted_requests</code> — List of requests to be started or resumed, which is done by calling the request's <code>write_event_handler</code>. Normally, this handler holds the request main function, which at first runs request phases and then produces the output. </p> <p> A request is usually posted by the <code>ngx_http_post_request(r, NULL)</code> call. It is always posted to the main request <code>posted_requests</code> list. The function <code>ngx_http_run_posted_requests(c)</code> runs all requests that are posted in the main request of the passed connection's active request. All event handlers call <code>ngx_http_run_posted_requests</code>, which can lead to new posted requests. Normally, it is called after invoking a request's read or write handler. </p> </li> <li> <code>phase_handler</code> — Index of current request phase. </li> <li> <code>ncaptures</code>, <code>captures</code>, <code>captures_data</code> — Regex captures produced by the last regex match of the request. A regex match can occur at a number of places during request processing: map lookup, server lookup by SNI or HTTP Host, rewrite, proxy_redirect, etc. Captures produced by a lookup are stored in the above mentioned fields. The field <code>ncaptures</code> holds the number of captures, <code>captures</code> holds captures boundaries and <code>captures_data</code> holds the string against which the regex was matched and which is used to extract captures. After each new regex match, request captures are reset to hold new values. </li> <li> <code>count</code> — Request reference counter. The field only makes sense for the main request. Increasing the counter is done by simple <code>r-&gt;main-&gt;count++</code>. To decrease the counter, call <code>ngx_http_finalize_request(r, rc)</code>. Creating of a subrequest and running the request body read process both increment the counter. </li> <li> <code>subrequests</code> — Current subrequest nesting level. Each subrequest inherits its parent's nesting level, decreased by one. An error is generated if the value reaches zero. The value for the main request is defined by the <code>NGX_HTTP_MAX_SUBREQUESTS</code> constant. </li> <li> <code>uri_changes</code> — Number of URI changes remaining for the request. The total number of times a request can change its URI is limited by the <code>NGX_HTTP_MAX_URI_CHANGES</code> constant. With each change the value is decremented until it reaches zero, at which time an error is generated. Rewrites and internal redirects to normal or named locations are considered URI changes. </li> <li> <code>blocked</code> — Counter of blocks held on the request. While this value is non-zero, the request cannot be terminated. Currently, this value is increased by pending AIO operations (POSIX AIO and thread operations) and active cache lock. </li> <li> <code>buffered</code> — Bitmask showing which modules have buffered the output produced by the request. A number of filters can buffer output; for example, sub_filter can buffer data because of a partial string match, copy filter can buffer data because of the lack of free output buffers etc. As long as this value is non-zero, the request is not finalized pending the flush. </li> <li> <code>header_only</code> — Flag indicating that the output does not require a body. For example, this flag is used by HTTP HEAD requests. </li> <li> <p> <code>keepalive</code> — Flag indicating whether client connection keepalive is supported. The value is inferred from the HTTP version and the value of the “Connection” header. </p> </li> <li> <code>header_sent</code> — Flag indicating that the output header has already been sent by the request. </li> <li> <code>internal</code> — Flag indicating that the current request is internal. To enter the internal state, a request must pass through an internal redirect or be a subrequest. Internal requests are allowed to enter internal locations. </li> <li> <code>allow_ranges</code> — Flag indicating that a partial response can be sent to the client, as requested by the HTTP Range header. </li> <li> <code>subrequest_ranges</code> — Flag indicating that a partial response can be sent while a subrequest is being processed. </li> <li> <code>single_range</code> — Flag indicating that only a single continuous range of output data can be sent to the client. This flag is usually set when sending a stream of data, for example from a proxied server, and the entire response is not available in one buffer. </li> <li> <code>main_filter_need_in_memory</code>, <code>filter_need_in_memory</code> — Flags requesting that the output produced in memory buffers rather than files. This is a signal to the copy filter to read data from file buffers even if sendfile is enabled. The difference between the two flags is the location of the filter modules that set them. Filters called before the postpone filter in the filter chain set <code>filter_need_in_memory</code>, requesting that only the current request output come in memory buffers. Filters called later in the filter chain set <code>main_filter_need_in_memory</code>, requesting that both the main request and all subrequests read files in memory while sending output. </li> <li> <code>filter_need_temporary</code> — Flag requesting that the request output be produced in temporary buffers, but not in readonly memory buffers or file buffers. This is used by filters which may change output directly in the buffers where it's sent.</li> </ul>
<h4 id="http_conf">Configuration</h4>
<p> Each HTTP module can have three types of configuration: </p>
<ul class="compact"> <li> Main configuration — Applies to the entire <code>http</code> block. Functions as global settings for a module. </li> <li> Server configuration — Applies to a single <code>server</code> block. Functions as server-specific settings for a module. </li> <li> Location configuration — Applies to a single <code>location</code>, <code>if</code> or <code>limit_except</code> block. Functions as location-specific settings for a module. </li> </ul>
<p> Configuration structures are created at the nginx configuration stage by calling functions, which allocate the structures, initialize them and merge them. The following example shows how to create a simple location configuration for a module. The configuration has one setting, <code>foo</code>, of type unsigned integer. </p>
<pre data-language="nginx">
typedef struct {
    ngx_uint_t  foo;
} ngx_http_foo_loc_conf_t;


static ngx_http_module_t  ngx_http_foo_module_ctx = {
    NULL,                                  /* preconfiguration */
    NULL,                                  /* postconfiguration */

    NULL,                                  /* create main configuration */
    NULL,                                  /* init main configuration */

    NULL,                                  /* create server configuration */
    NULL,                                  /* merge server configuration */

    ngx_http_foo_create_loc_conf,          /* create location configuration */
    ngx_http_foo_merge_loc_conf            /* merge location configuration */
};


static void *
ngx_http_foo_create_loc_conf(ngx_conf_t *cf)
{
    ngx_http_foo_loc_conf_t  *conf;

    conf = ngx_pcalloc(cf-&gt;pool, sizeof(ngx_http_foo_loc_conf_t));
    if (conf == NULL) {
        return NULL;
    }

    conf-&gt;foo = NGX_CONF_UNSET_UINT;

    return conf;
}


static char *
ngx_http_foo_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child)
{
    ngx_http_foo_loc_conf_t *prev = parent;
    ngx_http_foo_loc_conf_t *conf = child;

    ngx_conf_merge_uint_value(conf-&gt;foo, prev-&gt;foo, 1);
}
</pre>
<p> As seen in the example, the <code>ngx_http_foo_create_loc_conf()</code> function creates a new configuration structure, and <code>ngx_http_foo_merge_loc_conf()</code> merges a configuration with configuration from a higher level. In fact, server and location configuration do not exist only at the server and location levels, but are also created for all levels above them. Specifically, a server configuration is also created at the main level and location configurations are created at the main, server, and location levels. These configurations make it possible to specify server- and location-specific settings at any level of an nginx configuration file. Eventually configurations are merged down. A number of macros like <code>NGX_CONF_UNSET</code> and <code>NGX_CONF_UNSET_UINT</code> are provided for indicating a missing setting and ignoring it while merging. Standard nginx merge macros like <code>ngx_conf_merge_value()</code> and <code>ngx_conf_merge_uint_value()</code> provide a convenient way to merge a setting and set the default value if none of the configurations provided an explicit value. For complete list of macros for different types, see <code>src/core/ngx_conf_file.h</code>. </p>
<p> The following macros are available. for accessing configuration for HTTP modules at configuration time. They all take <code>ngx_conf_t</code> reference as the first argument. </p>
<ul class="compact"> <li> <code>ngx_http_conf_get_module_main_conf(cf, module)</code> </li> <li> <code>ngx_http_conf_get_module_srv_conf(cf, module)</code> </li> <li> <code>ngx_http_conf_get_module_loc_conf(cf, module)</code> </li> </ul>
<p> The following example gets a pointer to a location configuration of standard nginx core module <a href="../http/ngx_http_core_module.html">ngx_http_core_module</a> and replaces the location content handler kept in the <code>handler</code> field of the structure. </p>
<pre data-language="nginx">
static ngx_int_t ngx_http_foo_handler(ngx_http_request_t *r);


static ngx_command_t  ngx_http_foo_commands[] = {

    { ngx_string("foo"),
      NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS,
      ngx_http_foo,
      0,
      0,
      NULL },

      ngx_null_command
};


static char *
ngx_http_foo(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)
{
    ngx_http_core_loc_conf_t  *clcf;

    clcf = ngx_http_conf_get_module_loc_conf(cf, ngx_http_core_module);
    clcf-&gt;handler = ngx_http_bar_handler;

    return NGX_CONF_OK;
}
</pre>
<p> The following macros are available for accessing configuration for HTTP modules at runtime. </p>
<ul class="compact"> <li> <code>ngx_http_get_module_main_conf(r, module)</code> </li> <li> <code>ngx_http_get_module_srv_conf(r, module)</code> </li> <li> <code>ngx_http_get_module_loc_conf(r, module)</code> </li> </ul>
<p> These macros receive a reference to an HTTP request <code>ngx_http_request_t</code>. The main configuration of a request never changes. Server configuration can change from the default after the virtual server for the request is chosen. Location configuration selected for processing a request can change multiple times as a result of a rewrite operation or internal redirect. The following example shows how to access a module's HTTP configuration at runtime. </p>
<pre data-language="nginx">
static ngx_int_t
ngx_http_foo_handler(ngx_http_request_t *r)
{
    ngx_http_foo_loc_conf_t  *flcf;

    flcf = ngx_http_get_module_loc_conf(r, ngx_http_foo_module);

    ...
}
</pre>
<h4 id="http_phases">Phases</h4>
<p> Each HTTP request passes through a sequence of phases. In each phase a distinct type of processing is performed on the request. Module-specific handlers can be registered in most phases, and many standard nginx modules register their phase handlers as a way to get called at a specific stage of request processing. Phases are processed successively and the phase handlers are called once the request reaches the phase. Following is the list of nginx HTTP phases. </p>
<ul class="compact"> <li> <code>NGX_HTTP_POST_READ_PHASE</code> — First phase. The <a href="../http/ngx_http_realip_module.html">ngx_http_realip_module</a> registers its handler at this phase to enable substitution of client addresses before any other module is invoked. </li> <li> <code>NGX_HTTP_SERVER_REWRITE_PHASE</code> — Phase where rewrite directives defined in a <code>server</code> block (but outside a <code>location</code> block) are processed. The <a href="../http/ngx_http_rewrite_module.html">ngx_http_rewrite_module</a> installs its handler at this phase. </li> <li> <code>NGX_HTTP_FIND_CONFIG_PHASE</code> — Special phase where a location is chosen based on the request URI. Before this phase, the default location for the relevant virtual server is assigned to the request, and any module requesting a location configuration receives the configuration for the default server location. This phase assigns a new location to the request. No additional handlers can be registered at this phase. </li> <li> <code>NGX_HTTP_REWRITE_PHASE</code> — Same as <code>NGX_HTTP_SERVER_REWRITE_PHASE</code>, but for rewrite rules defined in the location, chosen in the previous phase. </li> <li> <code>NGX_HTTP_POST_REWRITE_PHASE</code> — Special phase where the request is redirected to a new location if its URI changed during a rewrite. This is implemented by the request going through the <code>NGX_HTTP_FIND_CONFIG_PHASE</code> again. No additional handlers can be registered at this phase. </li> <li> <code>NGX_HTTP_PREACCESS_PHASE</code> — A common phase for different types of handlers, not associated with access control. The standard nginx modules <a href="../http/ngx_http_limit_conn_module.html">ngx_http_limit_conn_module </a> and <a href="../http/ngx_http_limit_req_module.html"> ngx_http_limit_req_module</a> register their handlers at this phase. </li> <li> <code>NGX_HTTP_ACCESS_PHASE</code> — Phase where it is verified that the client is authorized to make the request. Standard nginx modules such as <a href="../http/ngx_http_access_module.html">ngx_http_access_module</a> and <a href="../http/ngx_http_auth_basic_module.html">ngx_http_auth_basic_module </a> register their handlers at this phase. By default the client must pass the authorization check of all handlers registered at this phase for the request to continue to the next phase. The <a href="../http/ngx_http_core_module.html#satisfy">satisfy</a> directive, can be used to permit processing to continue if any of the phase handlers authorizes the client. </li> <li> <code>NGX_HTTP_POST_ACCESS_PHASE</code> — Special phase where the <a href="../http/ngx_http_core_module.html#satisfy">satisfy any</a> directive is processed. If some access phase handlers denied access and none explicitly allowed it, the request is finalized. No additional handlers can be registered at this phase. </li> <li> <code>NGX_HTTP_PRECONTENT_PHASE</code> — Phase for handlers to be called prior to generating content. Standard modules such as <a href="../http/ngx_http_core_module.html#try_files"> ngx_http_try_files_module</a> and <a href="../http/ngx_http_mirror_module.html">ngx_http_mirror_module</a> register their handlers at this phase. </li> <li> <code>NGX_HTTP_CONTENT_PHASE</code> — Phase where the response is normally generated. Multiple nginx standard modules register their handlers at this phase, including <a href="../http/ngx_http_index_module.html">ngx_http_index_module</a> or <code>ngx_http_static_module</code>. They are called sequentially until one of them produces the output. It's also possible to set content handlers on a per-location basis. If the <a href="../http/ngx_http_core_module.html">ngx_http_core_module</a>'s location configuration has <code>handler</code> set, it is called as the content handler and the handlers installed at this phase are ignored. </li> <li> <code>NGX_HTTP_LOG_PHASE</code> — Phase where request logging is performed. Currently, only the <a href="../http/ngx_http_log_module.html">ngx_http_log_module</a> registers its handler at this stage for access logging. Log phase handlers are called at the very end of request processing, right before freeing the request. </li> </ul>
<p> Following is the example of a preaccess phase handler. </p>
<pre data-language="nginx">
static ngx_http_module_t  ngx_http_foo_module_ctx = {
    NULL,                                  /* preconfiguration */
    ngx_http_foo_init,                     /* postconfiguration */

    NULL,                                  /* create main configuration */
    NULL,                                  /* init main configuration */

    NULL,                                  /* create server configuration */
    NULL,                                  /* merge server configuration */

    NULL,                                  /* create location configuration */
    NULL                                   /* merge location configuration */
};


static ngx_int_t
ngx_http_foo_handler(ngx_http_request_t *r)
{
    ngx_str_t  *ua;

    ua = r-&gt;headers_in-&gt;user_agent;

    if (ua == NULL) {
        return NGX_DECLINED;
    }

    /* reject requests with "User-Agent: foo" */
    if (ua-&gt;value.len == 3 &amp;&amp; ngx_strncmp(ua-&gt;value.data, "foo", 3) == 0) {
        return NGX_HTTP_FORBIDDEN;
    }

    return NGX_DECLINED;
}


static ngx_int_t
ngx_http_foo_init(ngx_conf_t *cf)
{
    ngx_http_handler_pt        *h;
    ngx_http_core_main_conf_t  *cmcf;

    cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module);

    h = ngx_array_push(&amp;cmcf-&gt;phases[NGX_HTTP_PREACCESS_PHASE].handlers);
    if (h == NULL) {
        return NGX_ERROR;
    }

    *h = ngx_http_foo_handler;

    return NGX_OK;
}
</pre>
<p> Phase handlers are expected to return specific codes: </p>
<ul class="compact"> <li> <code>NGX_OK</code> — Proceed to the next phase. </li> <li> <code>NGX_DECLINED</code> — Proceed to the next handler of the current phase. If the current handler is the last in the current phase, move to the next phase. </li> <li> <code>NGX_AGAIN</code>, <code>NGX_DONE</code> — Suspend phase handling until some future event which can be an asynchronous I/O operation or just a delay, for example. It is assumed, that phase handling will be resumed later by calling <code>ngx_http_core_run_phases()</code>. </li> <li> Any other value returned by the phase handler is treated as a request finalization code, in particular, an HTTP response code. The request is finalized with the code provided. </li> </ul>
<p> For some phases, return codes are treated in a slightly different way. At the content phase, any return code other that <code>NGX_DECLINED</code> is considered a finalization code. Any return code from the location content handlers is considered a finalization code. At the access phase, in <a href="../http/ngx_http_core_module.html#satisfy">satisfy any</a> mode, any return code other than <code>NGX_OK</code>, <code>NGX_DECLINED</code>, <code>NGX_AGAIN</code>, <code>NGX_DONE</code> is considered a denial. If no subsequent access handlers allow or deny access with a different code, the denial code will become the finalization code. </p>
<h4 id="http_variables">Variables</h4>
<h4 id="http_existing_variables">Accessing existing variables</h4>
<p> Variables can be referenced by index (this is the most common method) or name (see <a href="#http_creating_variables">below</a>). The index is created at configuration stage, when a variable is added to the configuration. To obtain the variable index, use <code>ngx_http_get_variable_index()</code>: </p> <pre data-language="nginx">
ngx_str_t  name;  /* ngx_string("foo") */
ngx_int_t  index;

index = ngx_http_get_variable_index(cf, &amp;name);
</pre>
<p> Here, <code>cf</code> is a pointer to nginx configuration and <code>name</code> points to a string containing the variable name. The function returns <code>NGX_ERROR</code> on error or a valid index otherwise, which is typically stored somewhere in the module's configuration for future use. </p>
<p> All HTTP variables are evaluated in the context of a given HTTP request, and results are specific to and cached in that HTTP request. All functions that evaluate variables return the <code>ngx_http_variable_value_t</code> type, representing the variable value: </p> <pre data-language="nginx">
typedef ngx_variable_value_t  ngx_http_variable_value_t;

typedef struct {
    unsigned    len:28;

    unsigned    valid:1;
    unsigned    no_cacheable:1;
    unsigned    not_found:1;
    unsigned    escape:1;

    u_char     *data;
} ngx_variable_value_t;
</pre>
<p> where: </p> <ul class="compact"> <li> <code>len</code> — The length of the value </li> <li> <code>data</code> — The value itself </li> <li> <code>valid</code> — The value is valid </li> <li> <code>not_found</code> — The variable was not found and thus the <code>data</code> and <code>len</code> fields are irrelevant; this can happen, for example, with variables like <code>$arg_foo</code> when a corresponding argument was not passed in a request </li> <li> <code>no_cacheable</code> — Do not cache result </li> <li> <code>escape</code> — Used internally by the logging module to mark values that require escaping on output. </li> </ul>

<p> The <code>ngx_http_get_flushed_variable()</code> and <code>ngx_http_get_indexed_variable()</code> functions are used to obtain the value of a variable. They have the same interface - accepting an HTTP request <code>r</code> as a context for evaluating the variable and an <code>index</code> that identifies it. An example of typical usage: </p> <pre data-language="nginx">
ngx_http_variable_value_t  *v;

v = ngx_http_get_flushed_variable(r, index);

if (v == NULL || v-&gt;not_found) {
    /* we failed to get value or there is no such variable, handle it */
    return NGX_ERROR;
}

/* some meaningful value is found */
</pre>
<p> The difference between functions is that the <code>ngx_http_get_indexed_variable()</code> returns a cached value and <code>ngx_http_get_flushed_variable()</code> flushes the cache for non-cacheable variables. </p>
<p> Some modules, such as SSI and Perl, need to deal with variables for which the name is not known at configuration time. An index therefore cannot be used to access them, but the <code>ngx_http_get_variable(r, name, key)</code> function is available. It searches for a variable with a given <code>name</code> and its hash <code>key</code> derived from the name. </p>
<h4 id="http_creating_variables">Creating variables</h4>
<p> To create a variable, use the <code>ngx_http_add_variable()</code> function. It takes as arguments a configuration (where the variable is registered), the variable name and flags that control the function's behaviour: </p> <ul class="compact"> <li>
<code>NGX_HTTP_VAR_CHANGEABLE</code> — Enables redefinition of the variable: there is no conflict if another module defines a variable with the same name. This allows the <a href="../http/ngx_http_rewrite_module.html#set">set</a> directive to override variables. </li> <li>
<code>NGX_HTTP_VAR_NOCACHEABLE</code> — Disables caching, which is useful for variables such as <code>$time_local</code>. </li> <li>
<code>NGX_HTTP_VAR_NOHASH</code> — Indicates that this variable is only accessible by index, not by name. This is a small optimization for use when it is known that the variable is not needed in modules like SSI or Perl. </li> <li>
<code>NGX_HTTP_VAR_PREFIX</code> — The name of the variable is a prefix. In this case, a handler must implement additional logic to obtain the value of a specific variable. For example, all “<code>arg_</code>” variables are processed by the same handler, which performs lookup in request arguments and returns the value of a specific argument. </li> </ul>
<p> The function returns NULL in case of error or a pointer to <code>ngx_http_variable_t</code> otherwise: </p> <pre data-language="nginx">
struct ngx_http_variable_s {
    ngx_str_t                     name;
    ngx_http_set_variable_pt      set_handler;
    ngx_http_get_variable_pt      get_handler;
    uintptr_t                     data;
    ngx_uint_t                    flags;
    ngx_uint_t                    index;
};
</pre>
<p> The <code>get</code> and <code>set</code> handlers are called to obtain or set the variable value, <code>data</code> is passed to variable handlers, and <code>index</code> holds assigned variable index used to reference the variable. </p>
<p> Usually, a null-terminated static array of <code>ngx_http_variable_t</code> structures is created by a module and processed at the preconfiguration stage to add variables into the configuration, for example: </p> <pre data-language="nginx">
static ngx_http_variable_t  ngx_http_foo_vars[] = {

    { ngx_string("foo_v1"), NULL, ngx_http_foo_v1_variable, 0, 0, 0 },

      ngx_http_null_variable
};

static ngx_int_t
ngx_http_foo_add_variables(ngx_conf_t *cf)
{
    ngx_http_variable_t  *var, *v;

    for (v = ngx_http_foo_vars; v-&gt;name.len; v++) {
        var = ngx_http_add_variable(cf, &amp;v-&gt;name, v-&gt;flags);
        if (var == NULL) {
            return NGX_ERROR;
        }

        var-&gt;get_handler = v-&gt;get_handler;
        var-&gt;data = v-&gt;data;
    }

    return NGX_OK;
}
</pre>
<p> This function in the example is used to initialize the <code>preconfiguration</code> field of the HTTP module context and is called before the parsing of HTTP configuration, so that the parser can refer to these variables. </p>
<p> The <code>get</code> handler is responsible for evaluating a variable in the context of a specific request, for example: </p> <pre data-language="nginx">
static ngx_int_t
ngx_http_variable_connection(ngx_http_request_t *r,
    ngx_http_variable_value_t *v, uintptr_t data)
{
    u_char  *p;

    p = ngx_pnalloc(r-&gt;pool, NGX_ATOMIC_T_LEN);
    if (p == NULL) {
        return NGX_ERROR;
    }

    v-&gt;len = ngx_sprintf(p, "%uA", r-&gt;connection-&gt;number) - p;
    v-&gt;valid = 1;
    v-&gt;no_cacheable = 0;
    v-&gt;not_found = 0;
    v-&gt;data = p;

    return NGX_OK;
}
</pre>
<p> It returns <code>NGX_ERROR</code> in case of internal error (for example, failed memory allocation) or <code>NGX_OK</code> otherwise. To learn the status of variable evaluation, inspect the flags in <code>ngx_http_variable_value_t</code> (see the description <a href="#http_existing_variables">above</a>). </p>
<p> The <code>set</code> handler allows setting the property referenced by the variable. For example, the set handler of the <code>$limit_rate</code> variable modifies the request's <code>limit_rate</code> field: </p> <pre data-language="nginx">
...
{ ngx_string("limit_rate"), ngx_http_variable_request_set_size,
  ngx_http_variable_request_get_size,
  offsetof(ngx_http_request_t, limit_rate),
  NGX_HTTP_VAR_CHANGEABLE|NGX_HTTP_VAR_NOCACHEABLE, 0 },
...

static void
ngx_http_variable_request_set_size(ngx_http_request_t *r,
    ngx_http_variable_value_t *v, uintptr_t data)
{
    ssize_t    s, *sp;
    ngx_str_t  val;

    val.len = v-&gt;len;
    val.data = v-&gt;data;

    s = ngx_parse_size(&amp;val);

    if (s == NGX_ERROR) {
        ngx_log_error(NGX_LOG_ERR, r-&gt;connection-&gt;log, 0,
                      "invalid size \"%V\"", &amp;val);
        return;
    }

    sp = (ssize_t *) ((char *) r + data);

    *sp = s;

    return;
}
</pre>

<h4 id="http_complex_values">Complex values</h4>
<p> A complex value, despite its name, provides an easy way to evaluate expressions which can contain text, variables, and their combination. </p>
<p> The complex value description in <code>ngx_http_compile_complex_value</code> is compiled at the configuration stage into <code>ngx_http_complex_value_t</code> which is used at runtime to obtain results of expression evaluation. </p> <pre data-language="nginx">
ngx_str_t                         *value;
ngx_http_complex_value_t           cv;
ngx_http_compile_complex_value_t   ccv;

value = cf-&gt;args-&gt;elts; /* directive arguments */

ngx_memzero(&amp;ccv, sizeof(ngx_http_compile_complex_value_t));

ccv.cf = cf;
ccv.value = &amp;value[1];
ccv.complex_value = &amp;cv;
ccv.zero = 1;
ccv.conf_prefix = 1;

if (ngx_http_compile_complex_value(&amp;ccv) != NGX_OK) {
    return NGX_CONF_ERROR;
}
</pre>
<p> Here, <code>ccv</code> holds all parameters that are required to initialize the complex value <code>cv</code>: </p> <ul class="compact"> <li> <code>cf</code> — Configuration pointer </li> <li> <code>value</code> — String to be parsed (input) </li> <li> <code>complex_value</code> — Compiled value (output) </li> <li> <code>zero</code> — Flag that enables zero-terminating value </li> <li> <code>conf_prefix</code> — Prefixes the result with the configuration prefix (the directory where nginx is currently looking for configuration) </li> <li> <code>root_prefix</code> — Prefixes the result with the root prefix (the normal nginx installation prefix) </li> </ul>
<p> The <code>zero</code> flag is useful when results are to be passed to libraries that require zero-terminated strings, and prefixes are handy when dealing with filenames. </p>
<p> Upon successful compilation, <code>cv.lengths</code> contains information about the presence of variables in the expression. The NULL value means that the expression contained static text only, and so can be stored in a simple string rather than as a complex value. </p>
<p> The <code>ngx_http_set_complex_value_slot()</code> is a convenient function used to initialize a complex value completely in the directive declaration itself. </p>
<p> At runtime, a complex value can be calculated using the <code>ngx_http_complex_value()</code> function: </p> <pre data-language="nginx">
ngx_str_t  res;

if (ngx_http_complex_value(r, &amp;cv, &amp;res) != NGX_OK) {
    return NGX_ERROR;
}
</pre>
<p> Given the request <code>r</code> and previously compiled value <code>cv</code>, the function evaluates the expression and writes the result to <code>res</code>. </p>
<h4 id="http_request_redirection">Request redirection</h4>
<p> An HTTP request is always connected to a location via the <code>loc_conf</code> field of the <code>ngx_http_request_t</code> structure. This means that at any point the location configuration of any module can be retrieved from the request by calling <code>ngx_http_get_module_loc_conf(r, module)</code>. Request location can change several times during the request's lifetime. Initially, a default server location of the default server is assigned to a request. If the request switches to a different server (chosen by the HTTP “Host” header or SSL SNI extension), the request switches to the default location of that server as well. The next change of the location takes place at the <code>NGX_HTTP_FIND_CONFIG_PHASE</code> request phase. At this phase a location is chosen by request URI among all non-named locations configured for the server. The <a href="../http/ngx_http_rewrite_module.html">ngx_http_rewrite_module</a> can change the request URI at the <code>NGX_HTTP_REWRITE_PHASE</code> request phase as a result of the <a href="../http/ngx_http_rewrite_module.html#rewrite">rewrite</a> directive and send the request back to the <code>NGX_HTTP_FIND_CONFIG_PHASE</code> phase for selection of a new location based on the new URI. </p>
<p> It is also possible to redirect a request to a new location at any point by calling one of <code>ngx_http_internal_redirect(r, uri, args)</code> or <code>ngx_http_named_location(r, name)</code>. </p>
<p> The <code>ngx_http_internal_redirect(r, uri, args)</code> function changes the request URI and returns the request to the <code>NGX_HTTP_SERVER_REWRITE_PHASE</code> phase. The request proceeds with a server default location. Later at <code>NGX_HTTP_FIND_CONFIG_PHASE</code> a new location is chosen based on the new request URI. </p>
<p> The following example performs an internal redirect with the new request arguments. </p>
<pre data-language="nginx">
ngx_int_t
ngx_http_foo_redirect(ngx_http_request_t *r)
{
    ngx_str_t  uri, args;

    ngx_str_set(&amp;uri, "/foo");
    ngx_str_set(&amp;args, "bar=1");

    return ngx_http_internal_redirect(r, &amp;uri, &amp;args);
}
</pre>
<p> The function <code>ngx_http_named_location(r, name)</code> redirects a request to a named location. The name of the location is passed as the argument. The location is looked up among all named locations of the current server, after which the requests switches to the <code>NGX_HTTP_REWRITE_PHASE</code> phase. </p>
<p> The following example performs a redirect to a named location @foo. </p>
<pre data-language="nginx">
ngx_int_t
ngx_http_foo_named_redirect(ngx_http_request_t *r)
{
    ngx_str_t  name;

    ngx_str_set(&amp;name, "foo");

    return ngx_http_named_location(r, &amp;name);
}
</pre>
<p> Both functions - <code>ngx_http_internal_redirect(r, uri, args)</code> and <code>ngx_http_named_location(r, name)</code> can be called when nginx modules have already stored some contexts in a request's <code>ctx</code> field. It's possible for these contexts to become inconsistent with the new location configuration. To prevent inconsistency, all request contexts are erased by both redirect functions. </p>
<p> Calling <code>ngx_http_internal_redirect(r, uri, args)</code> or <code>ngx_http_named_location(r, name)</code> increases the request <code>count</code>. For consistent request reference counting, call <code>ngx_http_finalize_request(r, NGX_DONE)</code> after redirecting the request. This will finalize current request code path and decrease the counter. </p>
<p> Redirected and rewritten requests become internal and can access the <a href="../http/ngx_http_core_module.html#internal">internal</a> locations. Internal requests have the <code>internal</code> flag set. </p>
<h4 id="http_subrequests">Subrequests</h4>
<p> Subrequests are primarily used to insert output of one request into another, possibly mixed with other data. A subrequest looks like a normal request, but shares some data with its parent. In particular, all fields related to client input are shared because a subrequest does not receive any other input from the client. The request field <code>parent</code> for a subrequest contains a link to its parent request and is NULL for the main request. The field <code>main</code> contains a link to the main request in a group of requests. </p>
<p> A subrequest starts in the <code>NGX_HTTP_SERVER_REWRITE_PHASE</code> phase. It passes through the same subsequent phases as a normal request and is assigned a location based on its own URI. </p>
<p> The output header in a subrequest is always ignored. The <code>ngx_http_postpone_filter</code> places the subrequest's output body in the right position relative to other data produced by the parent request. </p>
<p> Subrequests are related to the concept of active requests. A request <code>r</code> is considered active if <code>c-&gt;data == r</code>, where <code>c</code> is the client connection object. At any given point, only the active request in a request group is allowed to output its buffers to the client. An inactive request can still send its output to the filter chain, but it does not pass beyond the <code>ngx_http_postpone_filter</code> and remains buffered by that filter until the request becomes active. Here are some rules of request activation: </p>
<ul class="compact"> <li> Initially, the main request is active. </li> <li> The first subrequest of an active request becomes active right after creation. </li> <li> The <code>ngx_http_postpone_filter</code> activates the next request in the active request's subrequest list, once all data prior to that request are sent. </li> <li> When a request is finalized, its parent is activated. </li> </ul>
<p> Create a subrequest by calling the function <code>ngx_http_subrequest(r, uri, args, psr, ps, flags)</code>, where <code>r</code> is the parent request, <code>uri</code> and <code>args</code> are the URI and arguments of the subrequest, <code>psr</code> is the output parameter, which receives the newly created subrequest reference, <code>ps</code> is a callback object for notifying the parent request that the subrequest is being finalized, and <code>flags</code> is bitmask of flags. The following flags are available: </p>
<ul class="compact"> <li> <code>NGX_HTTP_SUBREQUEST_IN_MEMORY</code> - Output is not sent to the client, but rather stored in memory. The flag only affects subrequests which are processed by one of the proxying modules. After a subrequest is finalized its output is available in <code>r-&gt;out</code> of type <code>ngx_buf_t</code>. </li> <li> <code>NGX_HTTP_SUBREQUEST_WAITED</code> - The subrequest's <code>done</code> flag is set even if the subrequest is not active when it is finalized. This subrequest flag is used by the SSI filter. </li> <li> <code>NGX_HTTP_SUBREQUEST_CLONE</code> - The subrequest is created as a clone of its parent. It is started at the same location and proceeds from the same phase as the parent request. </li> </ul>
<p> The following example creates a subrequest with the URI of <code>/foo</code>. </p>
<pre data-language="nginx">
ngx_int_t            rc;
ngx_str_t            uri;
ngx_http_request_t  *sr;

...

ngx_str_set(&amp;uri, "/foo");

rc = ngx_http_subrequest(r, &amp;uri, NULL, &amp;sr, NULL, 0);
if (rc == NGX_ERROR) {
    /* error */
}
</pre>
<p> This example clones the current request and sets a finalization callback for the subrequest. </p>
<pre data-language="nginx">
ngx_int_t
ngx_http_foo_clone(ngx_http_request_t *r)
{
    ngx_http_request_t          *sr;
    ngx_http_post_subrequest_t  *ps;

    ps = ngx_palloc(r-&gt;pool, sizeof(ngx_http_post_subrequest_t));
    if (ps == NULL) {
        return NGX_ERROR;
    }

    ps-&gt;handler = ngx_http_foo_subrequest_done;
    ps-&gt;data = "foo";

    return ngx_http_subrequest(r, &amp;r-&gt;uri, &amp;r-&gt;args, &amp;sr, ps,
                               NGX_HTTP_SUBREQUEST_CLONE);
}


ngx_int_t
ngx_http_foo_subrequest_done(ngx_http_request_t *r, void *data, ngx_int_t rc)
{
    char  *msg = (char *) data;

    ngx_log_error(NGX_LOG_INFO, r-&gt;connection-&gt;log, 0,
                  "done subrequest r:%p msg:%s rc:%i", r, msg, rc);

    return rc;
}
</pre>
<p> Subrequests are normally created in a body filter, in which case their output can be treated like the output from any explicit request. This means that eventually the output of a subrequest is sent to the client, after all explicit buffers that are passed before subrequest creation and before any buffers that are passed after creation. This ordering is preserved even for large hierarchies of subrequests. The following example inserts output from a subrequest after all request data buffers, but before the final buffer with the <code>last_buf</code> flag. </p>
<pre data-language="nginx">
ngx_int_t
ngx_http_foo_body_filter(ngx_http_request_t *r, ngx_chain_t *in)
{
    ngx_int_t                   rc;
    ngx_buf_t                  *b;
    ngx_uint_t                  last;
    ngx_chain_t                *cl, out;
    ngx_http_request_t         *sr;
    ngx_http_foo_filter_ctx_t  *ctx;

    ctx = ngx_http_get_module_ctx(r, ngx_http_foo_filter_module);
    if (ctx == NULL) {
        return ngx_http_next_body_filter(r, in);
    }

    last = 0;

    for (cl = in; cl; cl = cl-&gt;next) {
        if (cl-&gt;buf-&gt;last_buf) {
            cl-&gt;buf-&gt;last_buf = 0;
            cl-&gt;buf-&gt;last_in_chain = 1;
            cl-&gt;buf-&gt;sync = 1;
            last = 1;
        }
    }

    /* Output explicit output buffers */

    rc = ngx_http_next_body_filter(r, in);

    if (rc == NGX_ERROR || !last) {
        return rc;
    }

    /*
     * Create the subrequest.  The output of the subrequest
     * will automatically be sent after all preceding buffers,
     * but before the last_buf buffer passed later in this function.
     */

    if (ngx_http_subrequest(r, ctx-&gt;uri, NULL, &amp;sr, NULL, 0) != NGX_OK) {
        return NGX_ERROR;
    }

    ngx_http_set_ctx(r, NULL, ngx_http_foo_filter_module);

    /* Output the final buffer with the last_buf flag */

    b = ngx_calloc_buf(r-&gt;pool);
    if (b == NULL) {
        return NGX_ERROR;
    }

    b-&gt;last_buf = 1;

    out.buf = b;
    out.next = NULL;

    return ngx_http_output_filter(r, &amp;out);
}
</pre>
<p> A subrequest can also be created for other purposes than data output. For example, the <a href="../http/ngx_http_auth_request_module.html"> ngx_http_auth_request_module</a> module creates a subrequest at the <code>NGX_HTTP_ACCESS_PHASE</code> phase. To disable output at this point, the <code>header_only</code> flag is set on the subrequest. This prevents the subrequest body from being sent to the client. Note that the subrequest's header is never sent to the client. The result of the subrequest can be analyzed in the callback handler. </p>
<h4 id="http_request_finalization">Request finalization</h4>
<p> An HTTP request is finalized by calling the function <code>ngx_http_finalize_request(r, rc)</code>. It is usually finalized by the content handler after all output buffers are sent to the filter chain. At this point all of the output might not be sent to the client, with some of it remaining buffered somewhere along the filter chain. If it is, the <code>ngx_http_finalize_request(r, rc)</code> function automatically installs a special handler <code>ngx_http_writer(r)</code> to finish sending the output. A request is also finalized in case of an error or if a standard HTTP response code needs to be returned to the client. </p>
<p> The function <code>ngx_http_finalize_request(r, rc)</code> expects the following <code>rc</code> values: </p>
<ul class="compact"> <li> <code>NGX_DONE</code> - Fast finalization. Decrement the request <code>count</code> and destroy the request if it reaches zero. The client connection can be used for more requests after the current request is destroyed. </li> <li> <code>NGX_ERROR</code>, <code>NGX_HTTP_REQUEST_TIME_OUT</code> (<code>408</code>), <code>NGX_HTTP_CLIENT_CLOSED_REQUEST</code> (<code>499</code>) - Error finalization. Terminate the request as soon as possible and close the client connection. </li> <li> <code>NGX_HTTP_CREATED</code> (<code>201</code>), <code>NGX_HTTP_NO_CONTENT</code> (<code>204</code>), codes greater than or equal to <code>NGX_HTTP_SPECIAL_RESPONSE</code> (<code>300</code>) - Special response finalization. For these values nginx either sends to the client a default response page for the code or performs the internal redirect to an <a href="../http/ngx_http_core_module.html#error_page">error_page</a> location if that is configured for the code. </li> <li> Other codes are considered successful finalization codes and might activate the request writer to finish sending the response body. Once the body is completely sent, the request <code>count</code> is decremented. If it reaches zero, the request is destroyed, but the client connection can still be used for other requests. If <code>count</code> is positive, there are unfinished activities within the request, which will be finalized at a later point. </li> </ul>
<h4 id="http_request_body">Request body</h4>
<p> For dealing with the body of a client request, nginx provides the <code>ngx_http_read_client_request_body(r, post_handler)</code> and <code>ngx_http_discard_request_body(r)</code> functions. The first function reads the request body and makes it available via the <code>request_body</code> request field. The second function instructs nginx to discard (read and ignore) the request body. One of these functions must be called for every request. Normally, the content handler makes the call. </p>
<p> Reading or discarding the client request body from a subrequest is not allowed. It must always be done in the main request. When a subrequest is created, it inherits the parent's <code>request_body</code> object which can be used by the subrequest if the main request has previously read the request body. </p>
<p> The function <code>ngx_http_read_client_request_body(r, post_handler)</code> starts the process of reading the request body. When the body is completely read, the <code>post_handler</code> callback is called to continue processing the request. If the request body is missing or has already been read, the callback is called immediately. The function <code>ngx_http_read_client_request_body(r, post_handler)</code> allocates the <code>request_body</code> request field of type <code>ngx_http_request_body_t</code>. The field <code>bufs</code> of this object keeps the result as a buffer chain. The body can be saved in memory buffers or file buffers, if the capacity specified by the <a href="../http/ngx_http_core_module.html#client_body_buffer_size">client_body_buffer_size</a> directive is not enough to fit the entire body in memory. </p>
<p> The following example reads a client request body and returns its size. </p>
<pre data-language="nginx">
ngx_int_t
ngx_http_foo_content_handler(ngx_http_request_t *r)
{
    ngx_int_t  rc;

    rc = ngx_http_read_client_request_body(r, ngx_http_foo_init);

    if (rc &gt;= NGX_HTTP_SPECIAL_RESPONSE) {
        /* error */
        return rc;
    }

    return NGX_DONE;
}


void
ngx_http_foo_init(ngx_http_request_t *r)
{
    off_t         len;
    ngx_buf_t    *b;
    ngx_int_t     rc;
    ngx_chain_t  *in, out;

    if (r-&gt;request_body == NULL) {
        ngx_http_finalize_request(r, NGX_HTTP_INTERNAL_SERVER_ERROR);
        return;
    }

    len = 0;

    for (in = r-&gt;request_body-&gt;bufs; in; in = in-&gt;next) {
        len += ngx_buf_size(in-&gt;buf);
    }

    b = ngx_create_temp_buf(r-&gt;pool, NGX_OFF_T_LEN);
    if (b == NULL) {
        ngx_http_finalize_request(r, NGX_HTTP_INTERNAL_SERVER_ERROR);
        return;
    }

    b-&gt;last = ngx_sprintf(b-&gt;pos, "%O", len);
    b-&gt;last_buf = (r == r-&gt;main) ? 1: 0;
    b-&gt;last_in_chain = 1;

    r-&gt;headers_out.status = NGX_HTTP_OK;
    r-&gt;headers_out.content_length_n = b-&gt;last - b-&gt;pos;

    rc = ngx_http_send_header(r);

    if (rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only) {
        ngx_http_finalize_request(r, rc);
        return;
    }

    out.buf = b;
    out.next = NULL;

    rc = ngx_http_output_filter(r, &amp;out);

    ngx_http_finalize_request(r, rc);
}
</pre>
<p> The following fields of the request determine how the request body is read: </p>
<ul class="compact"> <li> <code>request_body_in_single_buf</code> - Read the body to a single memory buffer. </li> <li> <code>request_body_in_file_only</code> - Always read the body to a file, even if fits in the memory buffer. </li> <li> <code>request_body_in_persistent_file</code> - Do not unlink the file immediately after creation. A file with this flag can be moved to another directory. </li> <li> <code>request_body_in_clean_file</code> - Unlink the file when the request is finalized. This can be useful when a file was supposed to be moved to another directory but was not moved for some reason. </li> <li> <code>request_body_file_group_access</code> - Enable group access to the file by replacing the default 0600 access mask with 0660. </li> <li> <code>request_body_file_log_level</code> - Severity level at which to log file errors. </li> <li> <code>request_body_no_buffering</code> - Read the request body without buffering. </li> </ul>
<p> The <code>request_body_no_buffering</code> flag enables the unbuffered mode of reading a request body. In this mode, after calling <code>ngx_http_read_client_request_body()</code>, the <code>bufs</code> chain might keep only a part of the body. To read the next part, call the <code>ngx_http_read_unbuffered_request_body(r)</code> function. The return value <code>NGX_AGAIN</code> and the request flag <code>reading_body</code> indicate that more data is available. If <code>bufs</code> is NULL after calling this function, there is nothing to read at the moment. The request callback <code>read_event_handler</code> will be called when the next part of request body is available. </p>
<h4 id="http_request_body_filters">Request body filters</h4>
<p> After a request body part is read, it's passed to the request body filter chain by calling the first body filter handler stored in the <code>ngx_http_top_request_body_filter</code> variable. It's assumed that every body handler calls the next handler in the chain until the final handler <code>ngx_http_request_body_save_filter(r, cl)</code> is called. This handler collects the buffers in <code>r-&gt;request_body-&gt;bufs</code> and writes them to a file if necessary. The last request body buffer has nonzero <code>last_buf</code> flag. </p>
<p> If a filter is planning to delay data buffers, it should set the flag <code>r-&gt;request_body-&gt;filter_need_buffering</code> to <code>1</code> when called for the first time. </p>
<p> Following is an example of a simple request body filter that delays request body by one second. </p>
<pre data-language="nginx">
#include &lt;ngx_config.h&gt;
#include &lt;ngx_core.h&gt;
#include &lt;ngx_http.h&gt;


#define NGX_HTTP_DELAY_BODY  1000


typedef struct {
    ngx_event_t   event;
    ngx_chain_t  *out;
} ngx_http_delay_body_ctx_t;


static ngx_int_t ngx_http_delay_body_filter(ngx_http_request_t *r,
    ngx_chain_t *in);
static void ngx_http_delay_body_cleanup(void *data);
static void ngx_http_delay_body_event_handler(ngx_event_t *ev);
static ngx_int_t ngx_http_delay_body_init(ngx_conf_t *cf);


static ngx_http_module_t  ngx_http_delay_body_module_ctx = {
    NULL,                          /* preconfiguration */
    ngx_http_delay_body_init,      /* postconfiguration */

    NULL,                          /* create main configuration */
    NULL,                          /* init main configuration */

    NULL,                          /* create server configuration */
    NULL,                          /* merge server configuration */

    NULL,                          /* create location configuration */
    NULL                           /* merge location configuration */
};


ngx_module_t  ngx_http_delay_body_filter_module = {
    NGX_MODULE_V1,
    &amp;ngx_http_delay_body_module_ctx, /* module context */
    NULL,                          /* module directives */
    NGX_HTTP_MODULE,               /* module type */
    NULL,                          /* init master */
    NULL,                          /* init module */
    NULL,                          /* init process */
    NULL,                          /* init thread */
    NULL,                          /* exit thread */
    NULL,                          /* exit process */
    NULL,                          /* exit master */
    NGX_MODULE_V1_PADDING
};


static ngx_http_request_body_filter_pt   ngx_http_next_request_body_filter;


static ngx_int_t
ngx_http_delay_body_filter(ngx_http_request_t *r, ngx_chain_t *in)
{
    ngx_int_t                   rc;
    ngx_chain_t                *cl, *ln;
    ngx_http_cleanup_t         *cln;
    ngx_http_delay_body_ctx_t  *ctx;

    ngx_log_debug0(NGX_LOG_DEBUG_HTTP, r-&gt;connection-&gt;log, 0,
                   "delay request body filter");

    ctx = ngx_http_get_module_ctx(r, ngx_http_delay_body_filter_module);

    if (ctx == NULL) {
        ctx = ngx_pcalloc(r-&gt;pool, sizeof(ngx_http_delay_body_ctx_t));
        if (ctx == NULL) {
            return NGX_HTTP_INTERNAL_SERVER_ERROR;
        }

        ngx_http_set_ctx(r, ctx, ngx_http_delay_body_filter_module);

        r-&gt;request_body-&gt;filter_need_buffering = 1;
    }

    if (ngx_chain_add_copy(r-&gt;pool, &amp;ctx-&gt;out, in) != NGX_OK) {
        return NGX_HTTP_INTERNAL_SERVER_ERROR;
    }

    if (!ctx-&gt;event.timedout) {
        if (!ctx-&gt;event.timer_set) {

            /* cleanup to remove the timer in case of abnormal termination */

            cln = ngx_http_cleanup_add(r, 0);
            if (cln == NULL) {
                return NGX_HTTP_INTERNAL_SERVER_ERROR;
            }

            cln-&gt;handler = ngx_http_delay_body_cleanup;
            cln-&gt;data = ctx;

            /* add timer */

            ctx-&gt;event.handler = ngx_http_delay_body_event_handler;
            ctx-&gt;event.data = r;
            ctx-&gt;event.log = r-&gt;connection-&gt;log;

            ngx_add_timer(&amp;ctx-&gt;event, NGX_HTTP_DELAY_BODY);
        }

        return ngx_http_next_request_body_filter(r, NULL);
    }

    rc = ngx_http_next_request_body_filter(r, ctx-&gt;out);

    for (cl = ctx-&gt;out; cl; /* void */) {
        ln = cl;
        cl = cl-&gt;next;
        ngx_free_chain(r-&gt;pool, ln);
    }

    ctx-&gt;out = NULL;

    return rc;
}


static void
ngx_http_delay_body_cleanup(void *data)
{
    ngx_http_delay_body_ctx_t *ctx = data;

    if (ctx-&gt;event.timer_set) {
        ngx_del_timer(&amp;ctx-&gt;event);
    }
}


static void
ngx_http_delay_body_event_handler(ngx_event_t *ev)
{
    ngx_connection_t    *c;
    ngx_http_request_t  *r;

    r = ev-&gt;data;
    c = r-&gt;connection;

    ngx_log_debug0(NGX_LOG_DEBUG_HTTP, c-&gt;log, 0,
                   "delay request body event");

    ngx_post_event(c-&gt;read, &amp;ngx_posted_events);
}


static ngx_int_t
ngx_http_delay_body_init(ngx_conf_t *cf)
{
    ngx_http_next_request_body_filter = ngx_http_top_request_body_filter;
    ngx_http_top_request_body_filter = ngx_http_delay_body_filter;

    return NGX_OK;
}
</pre>
<h4 id="http_response">Response</h4>
<p> In nginx an HTTP response is produced by sending the response header followed by the optional response body. Both header and body are passed through a chain of filters and eventually get written to the client socket. An nginx module can install its handler into the header or body filter chain and process the output coming from the previous handler. </p>
<h4 id="http_response_header">Response header</h4>
<p> The <code>ngx_http_send_header(r)</code> function sends the output header. Do not call this function until <code>r-&gt;headers_out</code> contains all of the data required to produce the HTTP response header. The <code>status</code> field in <code>r-&gt;headers_out</code> must always be set. If the response status indicates that a response body follows the header, <code>content_length_n</code> can be set as well. The default value for this field is <code>-1</code>, which means that the body size is unknown. In this case, chunked transfer encoding is used. To output an arbitrary header, append the <code>headers</code> list. </p>
<pre data-language="nginx">
static ngx_int_t
ngx_http_foo_content_handler(ngx_http_request_t *r)
{
    ngx_int_t         rc;
    ngx_table_elt_t  *h;

    /* send header */

    r-&gt;headers_out.status = NGX_HTTP_OK;
    r-&gt;headers_out.content_length_n = 3;

    /* X-Foo: foo */

    h = ngx_list_push(&amp;r-&gt;headers_out.headers);
    if (h == NULL) {
        return NGX_ERROR;
    }

    h-&gt;hash = 1;
    ngx_str_set(&amp;h-&gt;key, "X-Foo");
    ngx_str_set(&amp;h-&gt;value, "foo");

    rc = ngx_http_send_header(r);

    if (rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only) {
        return rc;
    }

    /* send body */

    ...
}
</pre>
<h4 id="http_header_filters">Header filters</h4>
<p> The <code>ngx_http_send_header(r)</code> function invokes the header filter chain by calling the first header filter handler stored in the <code>ngx_http_top_header_filter</code> variable. It's assumed that every header handler calls the next handler in the chain until the final handler <code>ngx_http_header_filter(r)</code> is called. The final header handler constructs the HTTP response based on <code>r-&gt;headers_out</code> and passes it to the <code>ngx_http_writer_filter</code> for output. </p>
<p> To add a handler to the header filter chain, store its address in the global variable <code>ngx_http_top_header_filter</code> at configuration time. The previous handler address is normally stored in a static variable in a module and is called by the newly added handler before exiting. </p>
<p> The following example of a header filter module adds the HTTP header "<code>X-Foo: foo</code>" to every response with status <code>200</code>. </p>
<pre data-language="nginx">
#include &lt;ngx_config.h&gt;
#include &lt;ngx_core.h&gt;
#include &lt;ngx_http.h&gt;


static ngx_int_t ngx_http_foo_header_filter(ngx_http_request_t *r);
static ngx_int_t ngx_http_foo_header_filter_init(ngx_conf_t *cf);


static ngx_http_module_t  ngx_http_foo_header_filter_module_ctx = {
    NULL,                                   /* preconfiguration */
    ngx_http_foo_header_filter_init,        /* postconfiguration */

    NULL,                                   /* create main configuration */
    NULL,                                   /* init main configuration */

    NULL,                                   /* create server configuration */
    NULL,                                   /* merge server configuration */

    NULL,                                   /* create location configuration */
    NULL                                    /* merge location configuration */
};


ngx_module_t  ngx_http_foo_header_filter_module = {
    NGX_MODULE_V1,
    &amp;ngx_http_foo_header_filter_module_ctx, /* module context */
    NULL,                                   /* module directives */
    NGX_HTTP_MODULE,                        /* module type */
    NULL,                                   /* init master */
    NULL,                                   /* init module */
    NULL,                                   /* init process */
    NULL,                                   /* init thread */
    NULL,                                   /* exit thread */
    NULL,                                   /* exit process */
    NULL,                                   /* exit master */
    NGX_MODULE_V1_PADDING
};


static ngx_http_output_header_filter_pt  ngx_http_next_header_filter;


static ngx_int_t
ngx_http_foo_header_filter(ngx_http_request_t *r)
{
    ngx_table_elt_t  *h;

    /*
     * The filter handler adds "X-Foo: foo" header
     * to every HTTP 200 response
     */

    if (r-&gt;headers_out.status != NGX_HTTP_OK) {
        return ngx_http_next_header_filter(r);
    }

    h = ngx_list_push(&amp;r-&gt;headers_out.headers);
    if (h == NULL) {
        return NGX_ERROR;
    }

    h-&gt;hash = 1;
    ngx_str_set(&amp;h-&gt;key, "X-Foo");
    ngx_str_set(&amp;h-&gt;value, "foo");

    return ngx_http_next_header_filter(r);
}


static ngx_int_t
ngx_http_foo_header_filter_init(ngx_conf_t *cf)
{
    ngx_http_next_header_filter = ngx_http_top_header_filter;
    ngx_http_top_header_filter = ngx_http_foo_header_filter;

    return NGX_OK;
}
</pre>
<h4 id="http_response_body">Response body</h4>
<p> To send the response body, call the <code>ngx_http_output_filter(r, cl)</code> function. The function can be called multiple times. Each time, it sends a part of the response body in the form of a buffer chain. Set the <code>last_buf</code> flag in the last body buffer. </p>
<p> The following example produces a complete HTTP response with "foo" as its body. For the example to work as subrequest as well as a main request, the <code>last_in_chain</code> flag is set in the last buffer of the output. The <code>last_buf</code> flag is set only for the main request because the last buffer for a subrequest does not end the entire output. </p>
<pre data-language="nginx">
static ngx_int_t
ngx_http_bar_content_handler(ngx_http_request_t *r)
{
    ngx_int_t     rc;
    ngx_buf_t    *b;
    ngx_chain_t   out;

    /* send header */

    r-&gt;headers_out.status = NGX_HTTP_OK;
    r-&gt;headers_out.content_length_n = 3;

    rc = ngx_http_send_header(r);

    if (rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only) {
        return rc;
    }

    /* send body */

    b = ngx_calloc_buf(r-&gt;pool);
    if (b == NULL) {
        return NGX_ERROR;
    }

    b-&gt;last_buf = (r == r-&gt;main) ? 1: 0;
    b-&gt;last_in_chain = 1;

    b-&gt;memory = 1;

    b-&gt;pos = (u_char *) "foo";
    b-&gt;last = b-&gt;pos + 3;

    out.buf = b;
    out.next = NULL;

    return ngx_http_output_filter(r, &amp;out);
}
</pre>
<h4 id="http_response_body_filters">Response body filters</h4>
<p> The function <code>ngx_http_output_filter(r, cl)</code> invokes the body filter chain by calling the first body filter handler stored in the <code>ngx_http_top_body_filter</code> variable. It's assumed that every body handler calls the next handler in the chain until the final handler <code>ngx_http_write_filter(r, cl)</code> is called. </p>
<p> A body filter handler receives a chain of buffers. The handler is supposed to process the buffers and pass a possibly new chain to the next handler. It's worth noting that the chain links <code>ngx_chain_t</code> of the incoming chain belong to the caller, and must not be reused or changed. Right after the handler completes, the caller can use its output chain links to keep track of the buffers it has sent. To save the buffer chain or to substitute some buffers before passing to the next filter, a handler needs to allocate its own chain links. </p>
<p> Following is an example of a simple body filter that counts the number of bytes in the body. The result is available as the <code>$counter</code> variable which can be used in the access log. </p>
<pre data-language="nginx">
#include &lt;ngx_config.h&gt;
#include &lt;ngx_core.h&gt;
#include &lt;ngx_http.h&gt;


typedef struct {
    off_t  count;
} ngx_http_counter_filter_ctx_t;


static ngx_int_t ngx_http_counter_body_filter(ngx_http_request_t *r,
    ngx_chain_t *in);
static ngx_int_t ngx_http_counter_variable(ngx_http_request_t *r,
    ngx_http_variable_value_t *v, uintptr_t data);
static ngx_int_t ngx_http_counter_add_variables(ngx_conf_t *cf);
static ngx_int_t ngx_http_counter_filter_init(ngx_conf_t *cf);


static ngx_http_module_t  ngx_http_counter_filter_module_ctx = {
    ngx_http_counter_add_variables,        /* preconfiguration */
    ngx_http_counter_filter_init,          /* postconfiguration */

    NULL,                                  /* create main configuration */
    NULL,                                  /* init main configuration */

    NULL,                                  /* create server configuration */
    NULL,                                  /* merge server configuration */

    NULL,                                  /* create location configuration */
    NULL                                   /* merge location configuration */
};


ngx_module_t  ngx_http_counter_filter_module = {
    NGX_MODULE_V1,
    &amp;ngx_http_counter_filter_module_ctx,   /* module context */
    NULL,                                  /* module directives */
    NGX_HTTP_MODULE,                       /* module type */
    NULL,                                  /* init master */
    NULL,                                  /* init module */
    NULL,                                  /* init process */
    NULL,                                  /* init thread */
    NULL,                                  /* exit thread */
    NULL,                                  /* exit process */
    NULL,                                  /* exit master */
    NGX_MODULE_V1_PADDING
};


static ngx_http_output_body_filter_pt  ngx_http_next_body_filter;

static ngx_str_t  ngx_http_counter_name = ngx_string("counter");


static ngx_int_t
ngx_http_counter_body_filter(ngx_http_request_t *r, ngx_chain_t *in)
{
    ngx_chain_t                    *cl;
    ngx_http_counter_filter_ctx_t  *ctx;

    ctx = ngx_http_get_module_ctx(r, ngx_http_counter_filter_module);
    if (ctx == NULL) {
        ctx = ngx_pcalloc(r-&gt;pool, sizeof(ngx_http_counter_filter_ctx_t));
        if (ctx == NULL) {
            return NGX_ERROR;
        }

        ngx_http_set_ctx(r, ctx, ngx_http_counter_filter_module);
    }

    for (cl = in; cl; cl = cl-&gt;next) {
        ctx-&gt;count += ngx_buf_size(cl-&gt;buf);
    }

    return ngx_http_next_body_filter(r, in);
}


static ngx_int_t
ngx_http_counter_variable(ngx_http_request_t *r, ngx_http_variable_value_t *v,
    uintptr_t data)
{
    u_char                         *p;
    ngx_http_counter_filter_ctx_t  *ctx;

    ctx = ngx_http_get_module_ctx(r, ngx_http_counter_filter_module);
    if (ctx == NULL) {
        v-&gt;not_found = 1;
        return NGX_OK;
    }

    p = ngx_pnalloc(r-&gt;pool, NGX_OFF_T_LEN);
    if (p == NULL) {
        return NGX_ERROR;
    }

    v-&gt;data = p;
    v-&gt;len = ngx_sprintf(p, "%O", ctx-&gt;count) - p;
    v-&gt;valid = 1;
    v-&gt;no_cacheable = 0;
    v-&gt;not_found = 0;

    return NGX_OK;
}


static ngx_int_t
ngx_http_counter_add_variables(ngx_conf_t *cf)
{
    ngx_http_variable_t  *var;

    var = ngx_http_add_variable(cf, &amp;ngx_http_counter_name, 0);
    if (var == NULL) {
        return NGX_ERROR;
    }

    var-&gt;get_handler = ngx_http_counter_variable;

    return NGX_OK;
}


static ngx_int_t
ngx_http_counter_filter_init(ngx_conf_t *cf)
{
    ngx_http_next_body_filter = ngx_http_top_body_filter;
    ngx_http_top_body_filter = ngx_http_counter_body_filter;

    return NGX_OK;
}
</pre>
<h4 id="http_building_filter_modules">Building filter modules</h4>
<p> When writing a body or header filter, pay special attention to the filter's position in the filter order. There's a number of header and body filters registered by nginx standard modules. The nginx standard modules register a number of head and body filters and it's important to register a new filter module in the right place with respect to them. Normally, modules register filters in their postconfiguration handlers. The order in which filters are called during processing is obviously the reverse of the order in which they are registered. </p>
<p> For third-party filter modules nginx provides a special slot <code>HTTP_AUX_FILTER_MODULES</code>. To register a filter module in this slot, set the <code>ngx_module_type</code> variable to <code>HTTP_AUX_FILTER</code> in the module's configuration. </p>
<p> The following example shows a filter module config file assuming for a module with just one source file, <code>ngx_http_foo_filter_module.c</code>. </p>
<pre data-language="nginx">
ngx_module_type=HTTP_AUX_FILTER
ngx_module_name=ngx_http_foo_filter_module
ngx_module_srcs="$ngx_addon_dir/ngx_http_foo_filter_module.c"

. auto/module
</pre>
<h4 id="http_body_buffers_reuse">Buffer reuse</h4>
<p> When issuing or altering a stream of buffers, it's often desirable to reuse the allocated buffers. A standard and widely adopted approach in nginx code is to keep two buffer chains for this purpose: <code>free</code> and <code>busy</code>. The <code>free</code> chain keeps all free buffers, which can be reused. The <code>busy</code> chain keeps all buffers sent by the current module that are still in use by some other filter handler. A buffer is considered in use if its size is greater than zero. Normally, when a buffer is consumed by a filter, its <code>pos</code> (or <code>file_pos</code> for a file buffer) is moved towards <code>last</code> (<code>file_last</code> for a file buffer). Once a buffer is completely consumed, it's ready to be reused. To add newly freed buffers to the <code>free</code> chain it's enough to iterate over the <code>busy</code> chain and move the zero size buffers at the head of it to <code>free</code>. This operation is so common that there is a special function for it, <code>ngx_chain_update_chains(free, busy, out, tag)</code>. The function appends the output chain <code>out</code> to <code>busy</code> and moves free buffers from the top of <code>busy</code> to <code>free</code>. Only the buffers with the specified <code>tag</code> are reused. This lets a module reuse only the buffers that it allocated itself. </p>
<p> The following example is a body filter that inserts the string “foo” before each incoming buffer. The new buffers allocated by the module are reused if possible. Note that for this example to work properly, setting up a <a href="#http_header_filters">header filter</a> and resetting <code>content_length_n</code> to <code>-1</code> is also required, but the relevant code is not provided here. </p>
<pre data-language="nginx">
typedef struct {
    ngx_chain_t  *free;
    ngx_chain_t  *busy;
}  ngx_http_foo_filter_ctx_t;


ngx_int_t
ngx_http_foo_body_filter(ngx_http_request_t *r, ngx_chain_t *in)
{
    ngx_int_t                   rc;
    ngx_buf_t                  *b;
    ngx_chain_t                *cl, *tl, *out, **ll;
    ngx_http_foo_filter_ctx_t  *ctx;

    ctx = ngx_http_get_module_ctx(r, ngx_http_foo_filter_module);
    if (ctx == NULL) {
        ctx = ngx_pcalloc(r-&gt;pool, sizeof(ngx_http_foo_filter_ctx_t));
        if (ctx == NULL) {
            return NGX_ERROR;
        }

        ngx_http_set_ctx(r, ctx, ngx_http_foo_filter_module);
    }

    /* create a new chain "out" from "in" with all the changes */

    ll = &amp;out;

    for (cl = in; cl; cl = cl-&gt;next) {

        /* append "foo" in a reused buffer if possible */

        tl = ngx_chain_get_free_buf(r-&gt;pool, &amp;ctx-&gt;free);
        if (tl == NULL) {
            return NGX_ERROR;
        }

        b = tl-&gt;buf;
        b-&gt;tag = (ngx_buf_tag_t) &amp;ngx_http_foo_filter_module;
        b-&gt;memory = 1;
        b-&gt;pos = (u_char *) "foo";
        b-&gt;last = b-&gt;pos + 3;

        *ll = tl;
        ll = &amp;tl-&gt;next;

        /* append the next incoming buffer */

        tl = ngx_alloc_chain_link(r-&gt;pool);
        if (tl == NULL) {
            return NGX_ERROR;
        }

        tl-&gt;buf = cl-&gt;buf;
        *ll = tl;
        ll = &amp;tl-&gt;next;
    }

    *ll = NULL;

    /* send the new chain */

    rc = ngx_http_next_body_filter(r, out);

    /* update "busy" and "free" chains for reuse */

    ngx_chain_update_chains(r-&gt;pool, &amp;ctx-&gt;free, &amp;ctx-&gt;busy, &amp;out,
                            (ngx_buf_tag_t) &amp;ngx_http_foo_filter_module);

    return rc;
}
</pre>
<h4 id="http_load_balancing">Load balancing</h4>
<p> The <a href="../http/ngx_http_upstream_module.html">ngx_http_upstream_module</a> provides the basic functionality needed to pass requests to remote servers. Modules that implement specific protocols, such as HTTP or FastCGI, use this functionality. The module also provides an interface for creating custom load-balancing modules and implements a default round-robin method. </p>
<p> The <a href="../http/ngx_http_upstream_module.html#least_conn">least_conn</a> and <a href="../http/ngx_http_upstream_module.html#hash">hash</a> modules implement alternative load-balancing methods, but are actually implemented as extensions of the upstream round-robin module and share a lot of code with it, such as the representation of a server group. The <a href="../http/ngx_http_upstream_module.html#keepalive">keepalive</a> module is an independent module that extends upstream functionality. </p>
<p> The <a href="../http/ngx_http_upstream_module.html">ngx_http_upstream_module</a> can be configured explicitly by placing the corresponding <a href="../http/ngx_http_upstream_module.html#upstream">upstream</a> block into the configuration file, or implicitly by using directives such as <a href="../http/ngx_http_proxy_module.html#proxy_pass">proxy_pass</a> that accept a URL that gets evaluated at some point into a list of servers. The alternative load-balancing methods are available only with an explicit upstream configuration. The upstream module configuration has its own directive context <code>NGX_HTTP_UPS_CONF</code>. The structure is defined as follows: </p> <pre data-language="nginx">
struct ngx_http_upstream_srv_conf_s {
    ngx_http_upstream_peer_t         peer;
    void                           **srv_conf;

    ngx_array_t                     *servers;  /* ngx_http_upstream_server_t */

    ngx_uint_t                       flags;
    ngx_str_t                        host;
    u_char                          *file_name;
    ngx_uint_t                       line;
    in_port_t                        port;
    ngx_uint_t                       no_port;  /* unsigned no_port:1 */

#if (NGX_HTTP_UPSTREAM_ZONE)
    ngx_shm_zone_t                  *shm_zone;
#endif
};
</pre>
 <ul class="compact"> <li> <code>srv_conf</code> — Configuration context of upstream modules. </li> <li> <code>servers</code> — Array of <code>ngx_http_upstream_server_t</code>, the result of parsing a set of <a href="../http/ngx_http_upstream_module.html#server">server</a> directives in the <code>upstream</code> block. </li> <li> <code>flags</code> — Flags that mostly mark which features are supported by the load-balancing method. The features are configured as parameters of the <a href="../http/ngx_http_upstream_module.html#server">server</a> directive: <ul class="compact"> <li> <code>NGX_HTTP_UPSTREAM_CREATE</code> — Distinguishes explicitly defined upstreams from those that are automatically created by the <a href="../http/ngx_http_proxy_module.html#proxy_pass">proxy_pass</a> directive and “friends” (FastCGI, SCGI, etc.) </li> <li> <code>NGX_HTTP_UPSTREAM_WEIGHT</code> — The “<code>weight</code>” parameter is supported </li> <li> <code>NGX_HTTP_UPSTREAM_MAX_FAILS</code> — The “<code>max_fails</code>” parameter is supported </li> <li> <code>NGX_HTTP_UPSTREAM_FAIL_TIMEOUT</code> — The “<code>fail_timeout</code>” parameter is supported </li> <li> <code>NGX_HTTP_UPSTREAM_DOWN</code> — The “<code>down</code>” parameter is supported </li> <li> <code>NGX_HTTP_UPSTREAM_BACKUP</code> — The “<code>backup</code>” parameter is supported </li> <li> <code>NGX_HTTP_UPSTREAM_MAX_CONNS</code> — The “<code>max_conns</code>” parameter is supported </li> </ul> </li> <li> <code>host</code> — Name of the upstream. </li> <li> <code>file_name, line</code> — Name of the configuration file and the line where the <code>upstream</code> block is located. </li> <li> <code>port</code> and <code>no_port</code> — Not used for explicitly defined upstream groups. </li> <li> <code>shm_zone</code> — Shared memory zone used by this upstream group, if any. </li> <li> <code>peer</code> — object that holds generic methods for initializing upstream configuration: <pre data-language="nginx">
typedef struct {
    ngx_http_upstream_init_pt        init_upstream;
    ngx_http_upstream_init_peer_pt   init;
    void                            *data;
} ngx_http_upstream_peer_t;
</pre> A module that implements a load-balancing algorithm must set these methods and initialize private <code>data</code>. If <code>init_upstream</code> was not initialized during configuration parsing, <code>ngx_http_upstream_module</code> sets it to the default <code>ngx_http_upstream_init_round_robin</code> algorithm. <ul class="compact"> <li> <code>init_upstream(cf, us)</code> — Configuration-time method responsible for initializing a group of servers and initializing the <code>init()</code> method in case of success. A typical load-balancing module uses a list of servers in the <code>upstream</code> block to create an efficient data structure that it uses and saves its own configuration to the <code>data</code> field. </li> <li> <code>init(r, us)</code> — Initializes a per-request <code>ngx_http_upstream_peer_t.peer</code> structure that is used for load balancing (not to be confused with the <code>ngx_http_upstream_srv_conf_t.peer</code> described above which is per-upstream). It is passed as the <code>data</code> argument to all callbacks that deal with server selection. </li> </ul> </li> </ul>

<p> When nginx has to pass a request to another host for processing, it uses the configured load-balancing method to obtain an address to connect to. The method is obtained from the <code>ngx_http_upstream_t.peer</code> object of type <code>ngx_peer_connection_t</code>: </p> <pre data-language="nginx">
struct ngx_peer_connection_s {
    ...

    struct sockaddr                 *sockaddr;
    socklen_t                        socklen;
    ngx_str_t                       *name;

    ngx_uint_t                       tries;

    ngx_event_get_peer_pt            get;
    ngx_event_free_peer_pt           free;
    ngx_event_notify_peer_pt         notify;
    void                            *data;

#if (NGX_SSL || NGX_COMPAT)
    ngx_event_set_peer_session_pt    set_session;
    ngx_event_save_peer_session_pt   save_session;
#endif

    ...
};
</pre>
<p> The structure has the following fields: </p> <ul class="compact"> <li> <code>sockaddr</code>, <code>socklen</code>, <code>name</code> — Address of the upstream server to connect to; this is the output parameter of a load-balancing method. </li> <li> <code>data</code> — The per-request data of a load-balancing method; keeps the state of the selection algorithm and usually includes the link to the upstream configuration. It is passed as an argument to all methods that deal with server selection (see <a href="#lb_method_get">below</a>). </li> <li> <code>tries</code> — Allowed <a href="../http/ngx_http_proxy_module.html#proxy_next_upstream_tries">number</a> of attempts to connect to an upstream server. </li> <li> <code>get</code>, <code>free</code>, <code>notify</code>, <code>set_session</code>, and <code>save_session</code> - Methods of the load-balancing module, described below. </li> </ul>

<p> All methods accept at least two arguments: a peer connection object <code>pc</code> and the <code>data</code> created by <code>ngx_http_upstream_srv_conf_t.peer.init()</code>. Note that it might differ from <code>pc.data</code> due to “chaining” of load-balancing modules. </p>
 <ul class="compact"> <li id="lb_method_get"> <code>get(pc, data)</code> — The method called when the upstream module is ready to pass a request to an upstream server and needs to know its address. The method has to fill the <code>sockaddr</code>, <code>socklen</code>, and <code>name</code> fields of <code>ngx_peer_connection_t</code> structure. The return is one of: <ul class="compact"> <li> <code>NGX_OK</code> — Server was selected. </li> <li> <code>NGX_ERROR</code> — Internal error occurred. </li> <li> <code>NGX_BUSY</code> — no servers are currently available. This can happen due to many reasons, including: the dynamic server group is empty, all servers in the group are in the failed state, or all servers in the group are already handling the maximum number of connections. </li> <li> <code>NGX_DONE</code> — the underlying connection was reused and there is no need to create a new connection to the upstream server. This value is set by the <code>keepalive</code> module. </li> </ul> </li> <li> <code>free(pc, data, state)</code> — The method called when an upstream module has finished work with a particular server. The <code>state</code> argument is the completion status of the upstream connection, a bitmask with the following possible values: <ul class="compact"> <li> <code>NGX_PEER_FAILED</code> — Attempt was <a href="../http/ngx_http_upstream_module.html#max_fails">unsuccessful</a> </li> <li> <code>NGX_PEER_NEXT</code> — A special case when upstream server returns codes <code>403</code> or <code>404</code>, which are not considered a <a href="../http/ngx_http_upstream_module.html#max_fails">failure</a>. </li> <li> <code>NGX_PEER_KEEPALIVE</code> — Currently unused </li> </ul> This method also decrements the <code>tries</code> counter. </li> <li> <code>notify(pc, data, type)</code> — Currently unused in the OSS version. </li> <li> <code>set_session(pc, data)</code> and <code>save_session(pc, data)</code> — SSL-specific methods that enable caching sessions to upstream servers. The implementation is provided by the round-robin balancing method. </li> </ul>

<h4 id="examples">Examples</h4>
<p> The <a href="http://hg.nginx.org/nginx-dev-examples">nginx-dev-examples</a> repository provides nginx module examples. </p>
<h4 id="code_style">Code style</h4>
<h4 id="code_style_general_rules">General rules</h4>
 <ul class="compact"> <li> maximum text width is 80 characters </li> <li> indentation is 4 spaces </li> <li> no tabs, no trailing spaces </li> <li> list elements on the same line are separated with spaces </li> <li> hexadecimal literals are lowercase </li> <li> file names, function and type names, and global variables have the <code>ngx_</code> or more specific prefix such as <code>ngx_http_</code> and <code>ngx_mail_</code> </li> </ul>
 <pre data-language="nginx">
size_t
ngx_utf8_length(u_char *p, size_t n)
{
    u_char  c, *last;
    size_t  len;

    last = p + n;

    for (len = 0; p &lt; last; len++) {

        c = *p;

        if (c &lt; 0x80) {
            p++;
            continue;
        }

        if (ngx_utf8_decode(&amp;p, last - p) &gt; 0x10ffff) {
            /* invalid UTF-8 */
            return n;
        }
    }

    return len;
}
</pre>

<h4 id="code_style_files">Files</h4>
<p> A typical source file may contain the following sections separated by two empty lines: </p> <ul class="compact"> <li> copyright statements </li> <li> includes </li> <li> preprocessor definitions </li> <li> type definitions </li> <li> function prototypes </li> <li> variable definitions </li> <li> function definitions </li> </ul>

<p> Copyright statements look like this: </p> <pre data-language="nginx">
/*
 * Copyright (C) Author Name
 * Copyright (C) Organization, Inc.
 */
</pre>
<p> If the file is modified significantly, the list of authors should be updated, the new author is added to the top. </p>
<p> The <code>ngx_config.h</code> and <code>ngx_core.h</code> files are always included first, followed by one of <code>ngx_http.h</code>, <code>ngx_stream.h</code>, or <code>ngx_mail.h</code>. Then follow optional external header files: </p> <pre data-language="nginx">
#include &lt;ngx_config.h&gt;
#include &lt;ngx_core.h&gt;
#include &lt;ngx_http.h&gt;

#include &lt;libxml/parser.h&gt;
#include &lt;libxml/tree.h&gt;
#include &lt;libxslt/xslt.h&gt;

#if (NGX_HAVE_EXSLT)
#include &lt;libexslt/exslt.h&gt;
#endif
</pre>

<p> Header files should include the so called "header protection": </p> <pre data-language="nginx">
#ifndef _NGX_PROCESS_CYCLE_H_INCLUDED_
#define _NGX_PROCESS_CYCLE_H_INCLUDED_
...
#endif /* _NGX_PROCESS_CYCLE_H_INCLUDED_ */
</pre>

<h4 id="code_style_comments">Comments</h4>
 <ul class="compact"> <li> “<code>//</code>” comments are not used </li> <li> text is written in English, American spelling is preferred </li> <li> multi-line comments are formatted like this: <pre data-language="nginx">
/*
 * The red-black tree code is based on the algorithm described in
 * the "Introduction to Algorithms" by Cormen, Leiserson and Rivest.
 */
</pre> <pre data-language="nginx">
/* find the server configuration for the address:port */
</pre> </li> </ul>

<h4 id="code_style_preprocessor">Preprocessor</h4>
<p> Macro names start from <code>ngx_</code> or <code>NGX_</code> (or more specific) prefix. Macro names for constants are uppercase. Parameterized macros and macros for initializers are lowercase. The macro name and value are separated by at least two spaces: </p> <pre data-language="nginx">
#define NGX_CONF_BUFFER  4096

#define ngx_buf_in_memory(b)  (b-&gt;temporary || b-&gt;memory || b-&gt;mmap)

#define ngx_buf_size(b)                                                      \
    (ngx_buf_in_memory(b) ? (off_t) (b-&gt;last - b-&gt;pos):                      \
                            (b-&gt;file_last - b-&gt;file_pos))

#define ngx_null_string  { 0, NULL }
</pre>
<p> Conditions are inside parentheses, negation is outside: </p> <pre data-language="nginx">
#if (NGX_HAVE_KQUEUE)
...
#elif ((NGX_HAVE_DEVPOLL &amp;&amp; !(NGX_TEST_BUILD_DEVPOLL)) \
       || (NGX_HAVE_EVENTPORT &amp;&amp; !(NGX_TEST_BUILD_EVENTPORT)))
...
#elif (NGX_HAVE_EPOLL &amp;&amp; !(NGX_TEST_BUILD_EPOLL))
...
#elif (NGX_HAVE_POLL)
...
#else /* select */
...
#endif /* NGX_HAVE_KQUEUE */
</pre>

<h4 id="code_style_types">Types</h4>
<p> Type names end with the “<code>_t</code>” suffix. A defined type name is separated by at least two spaces: </p> <pre data-language="nginx">
typedef ngx_uint_t  ngx_rbtree_key_t;
</pre>

<p> Structure types are defined using <code>typedef</code>. Inside structures, member types and names are aligned: </p> <pre data-language="nginx">
typedef struct {
    size_t      len;
    u_char     *data;
} ngx_str_t;
</pre>
<p> Keep alignment identical among different structures in the file. A structure that points to itself has the name, ending with “<code>_s</code>”. Adjacent structure definitions are separated with two empty lines: </p> <pre data-language="nginx">
typedef struct ngx_list_part_s  ngx_list_part_t;

struct ngx_list_part_s {
    void             *elts;
    ngx_uint_t        nelts;
    ngx_list_part_t  *next;
};


typedef struct {
    ngx_list_part_t  *last;
    ngx_list_part_t   part;
    size_t            size;
    ngx_uint_t        nalloc;
    ngx_pool_t       *pool;
} ngx_list_t;
</pre>
<p> Each structure member is declared on its own line: </p> <pre data-language="nginx">
typedef struct {
    ngx_uint_t        hash;
    ngx_str_t         key;
    ngx_str_t         value;
    u_char           *lowcase_key;
} ngx_table_elt_t;
</pre>

<p> Function pointers inside structures have defined types ending with “<code>_pt</code>”: </p> <pre data-language="nginx">
typedef ssize_t (*ngx_recv_pt)(ngx_connection_t *c, u_char *buf, size_t size);
typedef ssize_t (*ngx_recv_chain_pt)(ngx_connection_t *c, ngx_chain_t *in,
    off_t limit);
typedef ssize_t (*ngx_send_pt)(ngx_connection_t *c, u_char *buf, size_t size);
typedef ngx_chain_t *(*ngx_send_chain_pt)(ngx_connection_t *c, ngx_chain_t *in,
    off_t limit);

typedef struct {
    ngx_recv_pt        recv;
    ngx_recv_chain_pt  recv_chain;
    ngx_recv_pt        udp_recv;
    ngx_send_pt        send;
    ngx_send_pt        udp_send;
    ngx_send_chain_pt  udp_send_chain;
    ngx_send_chain_pt  send_chain;
    ngx_uint_t         flags;
} ngx_os_io_t;
</pre>

<p> Enumerations have types ending with “<code>_e</code>”: </p> <pre data-language="nginx">
typedef enum {
    ngx_http_fastcgi_st_version = 0,
    ngx_http_fastcgi_st_type,
    ...
    ngx_http_fastcgi_st_padding
} ngx_http_fastcgi_state_e;
</pre>

<h4 id="code_style_variables">Variables</h4>
<p> Variables are declared sorted by length of a base type, then alphabetically. Type names and variable names are aligned. The type and name “columns” are separated with two spaces. Large arrays are put at the end of a declaration block: </p> <pre data-language="nginx">
u_char                      |  | *rv, *p;
ngx_conf_t                  |  | *cf;
ngx_uint_t                  |  |  i, j, k;
unsigned int                |  |  len;
struct sockaddr             |  | *sa;
const unsigned char         |  | *data;
ngx_peer_connection_t       |  | *pc;
ngx_http_core_srv_conf_t    |  |**cscfp;
ngx_http_upstream_srv_conf_t|  | *us, *uscf;
u_char                      |  |  text[NGX_SOCKADDR_STRLEN];
</pre>

<p> Static and global variables may be initialized on declaration: </p> <pre data-language="nginx">
static ngx_str_t  ngx_http_memcached_key = ngx_string("memcached_key");
</pre>
 <pre data-language="nginx">
static ngx_uint_t  mday[] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 };
</pre>
 <pre data-language="nginx">
static uint32_t  ngx_crc32_table16[] = {
    0x00000000, 0x1db71064, 0x3b6e20c8, 0x26d930ac,
    ...
    0x9b64c2b0, 0x86d3d2d4, 0xa00ae278, 0xbdbdf21c
};
</pre>

<p> There is a bunch of commonly used type/name combinations: </p> <pre data-language="nginx">
u_char                        *rv;
ngx_int_t                      rc;
ngx_conf_t                    *cf;
ngx_connection_t              *c;
ngx_http_request_t            *r;
ngx_peer_connection_t         *pc;
ngx_http_upstream_srv_conf_t  *us, *uscf;
</pre>

<h4 id="code_style_functions">Functions</h4>
<p> All functions (even static ones) should have prototypes. Prototypes include argument names. Long prototypes are wrapped with a single indentation on continuation lines: </p> <pre data-language="nginx">
static char *ngx_http_block(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
static ngx_int_t ngx_http_init_phases(ngx_conf_t *cf,
    ngx_http_core_main_conf_t *cmcf);

static char *ngx_http_merge_servers(ngx_conf_t *cf,
    ngx_http_core_main_conf_t *cmcf, ngx_http_module_t *module,
    ngx_uint_t ctx_index);
</pre>
<p> The function name in a definition starts with a new line. The function body opening and closing braces are on separate lines. The body of a function is indented. There are two empty lines between functions: </p> <pre data-language="nginx">
static ngx_int_t
ngx_http_find_virtual_server(ngx_http_request_t *r, u_char *host, size_t len)
{
    ...
}


static ngx_int_t
ngx_http_add_addresses(ngx_conf_t *cf, ngx_http_core_srv_conf_t *cscf,
    ngx_http_conf_port_t *port, ngx_http_listen_opt_t *lsopt)
{
    ...
}
</pre>
<p> There is no space after the function name and opening parenthesis. Long function calls are wrapped such that continuation lines start from the position of the first function argument. If this is impossible, format the first continuation line such that it ends at position 79: </p> <pre data-language="nginx">
ngx_log_debug2(NGX_LOG_DEBUG_HTTP, r-&gt;connection-&gt;log, 0,
               "http header: \"%V: %V\"",
               &amp;h-&gt;key, &amp;h-&gt;value);

hc-&gt;busy = ngx_palloc(r-&gt;connection-&gt;pool,
                  cscf-&gt;large_client_header_buffers.num * sizeof(ngx_buf_t *));
</pre>
<p> The <code>ngx_inline</code> macro should be used instead of <code>inline</code>: </p> <pre data-language="nginx">
static ngx_inline void ngx_cpuid(uint32_t i, uint32_t *buf);
</pre>

<h4 id="code_style_expressions">Expressions</h4>
<p> Binary operators except “<code>.</code>” and “<code>−&gt;</code>” should be separated from their operands by one space. Unary operators and subscripts are not separated from their operands by spaces: </p> <pre data-language="nginx">
width = width * 10 + (*fmt++ - '0');
</pre>
 <pre data-language="nginx">
ch = (u_char) ((decoded &lt;&lt; 4) + (ch - '0'));
</pre>
 <pre data-language="nginx">
r-&gt;exten.data = &amp;r-&gt;uri.data[i + 1];
</pre>

<p> Type casts are separated by one space from casted expressions. An asterisk inside type cast is separated with space from type name: </p> <pre data-language="nginx">
len = ngx_sock_ntop((struct sockaddr *) sin6, p, len, 1);
</pre>

<p> If an expression does not fit into single line, it is wrapped. The preferred point to break a line is a binary operator. The continuation line is lined up with the start of expression: </p> <pre data-language="nginx">
if (status == NGX_HTTP_MOVED_PERMANENTLY
    || status == NGX_HTTP_MOVED_TEMPORARILY
    || status == NGX_HTTP_SEE_OTHER
    || status == NGX_HTTP_TEMPORARY_REDIRECT
    || status == NGX_HTTP_PERMANENT_REDIRECT)
{
    ...
}
</pre>
 <pre data-language="nginx">
p-&gt;temp_file-&gt;warn = "an upstream response is buffered "
                     "to a temporary file";
</pre>
<p> As a last resort, it is possible to wrap an expression so that the continuation line ends at position 79: </p> <pre data-language="nginx">
hinit-&gt;hash = ngx_pcalloc(hinit-&gt;pool, sizeof(ngx_hash_wildcard_t)
                                     + size * sizeof(ngx_hash_elt_t *));
</pre>
<p> The above rules also apply to sub-expressions, where each sub-expression has its own indentation level: </p> <pre data-language="nginx">
if (((u-&gt;conf-&gt;cache_use_stale &amp; NGX_HTTP_UPSTREAM_FT_UPDATING)
     || c-&gt;stale_updating) &amp;&amp; !r-&gt;background
    &amp;&amp; u-&gt;conf-&gt;cache_background_update)
{
    ...
}
</pre>
<p> Sometimes, it is convenient to wrap an expression after a cast. In this case, the continuation line is indented: </p> <pre data-language="nginx">
node = (ngx_rbtree_node_t *)
           ((u_char *) lr - offsetof(ngx_rbtree_node_t, color));
</pre>

<p> Pointers are explicitly compared to <code>NULL</code> (not <code>0</code>): </p> <pre data-language="nginx">
if (ptr != NULL) {
    ...
}
</pre>

<h4 id="code_style_conditionals_and_loops">Conditionals and Loops</h4>
<p> The “<code>if</code>” keyword is separated from the condition by one space. Opening brace is located on the same line, or on a dedicated line if the condition takes several lines. Closing brace is located on a dedicated line, optionally followed by “<code>else if</code> / <code>else</code>”. Usually, there is an empty line before the “<code>else if</code> / <code>else</code>” part: </p> <pre data-language="nginx">
if (node-&gt;left == sentinel) {
    temp = node-&gt;right;
    subst = node;

} else if (node-&gt;right == sentinel) {
    temp = node-&gt;left;
    subst = node;

} else {
    subst = ngx_rbtree_min(node-&gt;right, sentinel);

    if (subst-&gt;left != sentinel) {
        temp = subst-&gt;left;

    } else {
        temp = subst-&gt;right;
    }
}
</pre>

<p> Similar formatting rules are applied to “<code>do</code>” and “<code>while</code>” loops: </p> <pre data-language="nginx">
while (p &lt; last &amp;&amp; *p == ' ') {
    p++;
}
</pre>
 <pre data-language="nginx">
do {
    ctx-&gt;node = rn;
    ctx = ctx-&gt;next;
} while (ctx);
</pre>

<p> The “<code>switch</code>” keyword is separated from the condition by one space. Opening brace is located on the same line. Closing brace is located on a dedicated line. The “<code>case</code>” keywords are lined up with “<code>switch</code>”: </p> <pre data-language="nginx">
switch (ch) {
case '!':
    looked = 2;
    state = ssi_comment0_state;
    break;

case '&lt;':
    copy_end = p;
    break;

default:
    copy_end = p;
    looked = 0;
    state = ssi_start_state;
    break;
}
</pre>

<p> Most “<code>for</code>” loops are formatted like this: </p> <pre data-language="nginx">
for (i = 0; i &lt; ccf-&gt;env.nelts; i++) {
    ...
}
</pre>
 <pre data-language="nginx">
for (q = ngx_queue_head(locations);
     q != ngx_queue_sentinel(locations);
     q = ngx_queue_next(q))
{
    ...
}
</pre>
<p> If some part of the “<code>for</code>” statement is omitted, this is indicated by the “<code>/* void */</code>” comment: </p> <pre data-language="nginx">
for (i = 0; /* void */ ; i++) {
    ...
}
</pre>
<p> A loop with an empty body is also indicated by the “<code>/* void */</code>” comment which may be put on the same line: </p> <pre data-language="nginx">
for (cl = *busy; cl-&gt;next; cl = cl-&gt;next) { /* void */ }
</pre>
<p> An endless loop looks like this: </p> <pre data-language="nginx">
for ( ;; ) {
    ...
}
</pre>

<h4 id="code_style_labels">Labels</h4>
<p> Labels are surrounded with empty lines and are indented at the previous level: </p> <pre data-language="nginx">
    if (i == 0) {
        u-&gt;err = "host not found";
        goto failed;
    }

    u-&gt;addrs = ngx_pcalloc(pool, i * sizeof(ngx_addr_t));
    if (u-&gt;addrs == NULL) {
        goto failed;
    }

    u-&gt;naddrs = i;

    ...

    return NGX_OK;

failed:

    freeaddrinfo(res);
    return NGX_ERROR;
</pre>

<h4 id="debug_memory">Debugging memory issues</h4>
<p> To debug memory issues such as buffer overruns or use-after-free errors, you can use the <a href="https://en.wikipedia.org/wiki/AddressSanitizer"> AddressSanitizer</a> (ASan) supported by some modern compilers. To enable ASan with <code>gcc</code> and <code>clang</code>, use the <code>-fsanitize=address</code> compiler and linker option. When building nginx, this can be done by adding the option to <code>--with-cc-opt</code> and <code>--with-ld-opt</code> parameters of the <code>configure</code> script. </p>
<p> Since most allocations in nginx are made from nginx internal <a href="#pool">pool</a>, enabling ASan may not always be enough to debug memory issues. The internal pool allocates a big chunk of memory from the system and cuts smaller allocations from it. However, this mechanism can be disabled by setting the <code>NGX_DEBUG_PALLOC</code> macro to <code>1</code>. In this case, allocations are passed directly to the system allocator giving it full control over the buffers boundaries. </p>
<p> The following configuration line summarizes the information provided above. It is recommended while developing third-party modules and testing nginx on different platforms. </p>
<pre data-language="nginx">
auto/configure --with-cc-opt='-fsanitize=address -DNGX_DEBUG_PALLOC=1'
               --with-ld-opt=-fsanitize=address
</pre>
<h4 id="common_pitfals">Common Pitfalls</h4>
<h4 id="module_pitfall">Writing a C module</h4>
<p> The most common pitfall is an attempt to write a full-fledged C module when it can be avoided. In most cases your task can be accomplished by creating a proper configuration. If writing a module is inevitable, try to make it as small and simple as possible. For example, a module can only export some <a href="#http_variables">variables</a>. </p>
<p> Before starting a module, consider the following questions: </p> <ul class="compact"> <li> Is it possible to implement a desired feature using already <a href="../index.html">available modules</a>? </li> <li> Is it possible to solve an issue using built-in scripting languages, such as <a href="../http/ngx_http_perl_module.html">Perl</a> or <a href="../njs/index.html">njs</a>? </li> </ul>

<h4 id="c_strings">C Strings</h4>
<p> The most used string type in nginx, <a href="#string_overview">ngx_str_t</a> is not a C-Style zero-terminated string. You cannot pass the data to standard C library functions such as <code>strlen()</code> or <code>strstr()</code>. Instead, nginx <a href="#string_overview">counterparts</a> that accept either <code>ngx_str_t</code> should be used or pointer to data and a length. However, there is a case when <code>ngx_str_t</code> holds a pointer to a zero-terminated string: strings that come as a result of configuration file parsing are zero-terminated. </p>
<h4 id="global_variables">Global Variables</h4>
<p> Avoid using global variables in your modules. Most likely this is an error to have a global variable. Any global data should be tied to a <a href="#cycle">configuration cycle</a> and be allocated from the corresponding <a href="#pool">memory pool</a>. This allows nginx to perform graceful configuration reloads. An attempt to use global variables will likely break this feature, because it will be impossible to have two configurations at the same time and get rid of them. Sometimes global variables are required. In this case, special attention is needed to manage reconfiguration properly. Also, check if libraries used by your code have implicit global state that may be broken on reload. </p>
<h4 id="manual_memory_management">Manual Memory Management</h4>
<p> Instead of dealing with malloc/free approach which is error prone, learn how to use nginx <a href="#pool">pools</a>. A pool is created and tied to an object - <a href="#http_conf">configuration</a>, <a href="#cycle">cycle</a>, <a href="#connection">connection</a>, or <a href="#http_request">HTTP request</a>. When the object is destroyed, the associated pool is destroyed too. So when working with an object, it is possible to allocate the amount needed from the corresponding pool and don't care about freeing memory even in case of errors. </p>
<h4 id="threads_pitfalls">Threads</h4>
<p> It is recommended to avoid using threads in nginx because it will definitely break things: most nginx functions are not thread-safe. It is expected that a thread will be executing only system calls and thread-safe library functions. If you need to run some code that is not related to client request processing, the proper way is to schedule a timer in the <code>init_process</code> module handler and perform required actions in timer handler. Internally nginx makes use of <a href="#threads">threads</a> to boost IO-related operations, but this is a special case with a lot of limitations. </p>
<h4 id="libraries">Blocking Libraries</h4>
<p> A common mistake is to use libraries that are blocking internally. Most libraries out there are synchronous and blocking by nature. In other words, they perform one operation at a time and waste time waiting for response from other peer. As a result, when a request is processed with such library, whole nginx worker is blocked, thus destroying performance. Use only libraries that provide asynchronous interface and don't block whole process. </p>
<h4 id="http_requests_to_ext">HTTP Requests to External Services</h4>
<p> Often modules need to perform an HTTP call to some external service. A common mistake is to use some external library, such as libcurl, to perform the HTTP request. It is absolutely unnecessary to bring a huge amount of external (probably <a href="#using_libraries">blocking</a>!) code for the task which can be accomplished by nginx itself. </p>
<p> There are two basic usage scenarios when an external request is needed: </p> <ul class="compact"> <li> in the context of processing a client request (for example, in content handler) </li> <li> in the context of a worker process (for example, timer handler) </li> </ul>

<p> In the first case, the best is to use <a href="#http_subrequests">subrequests API</a>. Instead of directly accessing external service, you declare a location in nginx configuration and direct your subrequest to this location. This location is not limited to <a href="../http/ngx_http_proxy_module.html#proxy_pass">proxying</a> requests, but may contain other nginx directives. An example of such approach is the <a href="../http/ngx_http_auth_request_module.html#auth_request">auth_request</a> directive implemented in <a href="http://hg.nginx.org/nginx/file/tip/src/http/modules/ngx_http_auth_request_module.c">ngx_http_auth_request module</a>. </p>
<p> For the second case, it is possible to use basic HTTP client functionality available in nginx. For example, <a href="http://hg.nginx.org/nginx/file/tip/src/event/ngx_event_openssl_stapling.c">OCSP module</a> implements simple HTTP client. </p><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2002-2021 Igor Sysoev<br>&copy; 2011-2023 Nginx, Inc.<br>Licensed under the BSD License.<br>
    <a href="https://nginx.org/en/docs/dev/development_guide.html" class="_attribution-link">https://nginx.org/en/docs/dev/development_guide.html</a>
  </p>
</div>
