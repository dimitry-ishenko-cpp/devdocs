<h1 id="tensor-doc">torch.Tensor</h1> <p id="torch-tensor">A <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> is a multi-dimensional matrix containing elements of a single data type.</p>  <h2 id="data-types">Data types</h2> <p>Torch defines 10 tensor types with CPU and GPU variants which are as follows:</p> <table class="docutils colwidths-auto align-default"> <thead> <tr>
<th class="head"><p>Data type</p></th> <th class="head"><p>dtype</p></th> <th class="head"><p>CPU tensor</p></th> <th class="head"><p>GPU tensor</p></th> </tr> </thead>  <tr>
<td><p>32-bit floating point</p></td> <td><p><code>torch.float32</code> or <code>torch.float</code></p></td> <td><p><code>torch.FloatTensor</code></p></td> <td><p><code>torch.cuda.FloatTensor</code></p></td> </tr> <tr>
<td><p>64-bit floating point</p></td> <td><p><code>torch.float64</code> or <code>torch.double</code></p></td> <td><p><code>torch.DoubleTensor</code></p></td> <td><p><code>torch.cuda.DoubleTensor</code></p></td> </tr> <tr>
<td><p>16-bit floating point <a class="footnote-reference brackets" href="#id4" id="id1">1</a></p></td> <td><p><code>torch.float16</code> or <code>torch.half</code></p></td> <td><p><code>torch.HalfTensor</code></p></td> <td><p><code>torch.cuda.HalfTensor</code></p></td> </tr> <tr>
<td><p>16-bit floating point <a class="footnote-reference brackets" href="#id5" id="id2">2</a></p></td> <td><p><code>torch.bfloat16</code></p></td> <td><p><code>torch.BFloat16Tensor</code></p></td> <td><p><code>torch.cuda.BFloat16Tensor</code></p></td> </tr> <tr>
<td><p>32-bit complex</p></td> <td><p><code>torch.complex32</code> or <code>torch.chalf</code></p></td> <td></td> <td></td> </tr> <tr>
<td><p>64-bit complex</p></td> <td><p><code>torch.complex64</code> or <code>torch.cfloat</code></p></td> <td></td> <td></td> </tr> <tr>
<td><p>128-bit complex</p></td> <td><p><code>torch.complex128</code> or <code>torch.cdouble</code></p></td> <td></td> <td></td> </tr> <tr>
<td><p>8-bit integer (unsigned)</p></td> <td><p><code>torch.uint8</code></p></td> <td><p><code>torch.ByteTensor</code></p></td> <td><p><code>torch.cuda.ByteTensor</code></p></td> </tr> <tr>
<td><p>8-bit integer (signed)</p></td> <td><p><code>torch.int8</code></p></td> <td><p><code>torch.CharTensor</code></p></td> <td><p><code>torch.cuda.CharTensor</code></p></td> </tr> <tr>
<td><p>16-bit integer (signed)</p></td> <td><p><code>torch.int16</code> or <code>torch.short</code></p></td> <td><p><code>torch.ShortTensor</code></p></td> <td><p><code>torch.cuda.ShortTensor</code></p></td> </tr> <tr>
<td><p>32-bit integer (signed)</p></td> <td><p><code>torch.int32</code> or <code>torch.int</code></p></td> <td><p><code>torch.IntTensor</code></p></td> <td><p><code>torch.cuda.IntTensor</code></p></td> </tr> <tr>
<td><p>64-bit integer (signed)</p></td> <td><p><code>torch.int64</code> or <code>torch.long</code></p></td> <td><p><code>torch.LongTensor</code></p></td> <td><p><code>torch.cuda.LongTensor</code></p></td> </tr> <tr>
<td><p>Boolean</p></td> <td><p><code>torch.bool</code></p></td> <td><p><code>torch.BoolTensor</code></p></td> <td><p><code>torch.cuda.BoolTensor</code></p></td> </tr> <tr>
<td><p>quantized 8-bit integer (unsigned)</p></td> <td><p><code>torch.quint8</code></p></td> <td><p><code>torch.ByteTensor</code></p></td> <td><p>/</p></td> </tr> <tr>
<td><p>quantized 8-bit integer (signed)</p></td> <td><p><code>torch.qint8</code></p></td> <td><p><code>torch.CharTensor</code></p></td> <td><p>/</p></td> </tr> <tr>
<td><p>quantized 32-bit integer (signed)</p></td> <td><p><code>torch.qint32</code></p></td> <td><p><code>torch.IntTensor</code></p></td> <td><p>/</p></td> </tr> <tr>
<td><p>quantized 4-bit integer (unsigned) <a class="footnote-reference brackets" href="#id6" id="id3">3</a></p></td> <td><p><code>torch.quint4x2</code></p></td> <td><p><code>torch.ByteTensor</code></p></td> <td><p>/</p></td> </tr>  </table> <dl class="footnote brackets"> <dt class="label" id="id4">
<code>1</code> </dt> <dd>
<p>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important at the expense of range.</p> </dd> <dt class="label" id="id5">
<code>2</code> </dt> <dd>
<p>Sometimes referred to as Brain Floating Point: uses 1 sign, 8 exponent, and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as <code>float32</code></p> </dd> <dt class="label" id="id6">
<code>3</code> </dt> <dd>
<p>quantized 4-bit integer is stored as a 8-bit signed integer. Currently it’s only supported in EmbeddingBag operator.</p> </dd> </dl> <p><a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> is an alias for the default tensor type (<code>torch.FloatTensor</code>).</p>   <h2 id="initializing-and-basic-operations">Initializing and basic operations</h2> <p>A tensor can be constructed from a Python <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code>list</code></a> or sequence using the <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> constructor:</p> <pre data-language="python">&gt;&gt;&gt; torch.tensor([[1., -1.], [1., -1.]])
tensor([[ 1.0000, -1.0000],
        [ 1.0000, -1.0000]])
&gt;&gt;&gt; torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))
tensor([[ 1,  2,  3],
        [ 4,  5,  6]])
</pre> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p><a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> always copies <code>data</code>. If you have a Tensor <code>data</code> and just want to change its <code>requires_grad</code> flag, use <a class="reference internal" href="generated/torch.tensor.requires_grad_.html#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> or <a class="reference internal" href="generated/torch.tensor.detach.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>detach()</code></a> to avoid a copy. If you have a numpy array and want to avoid a copy, use <a class="reference internal" href="generated/torch.as_tensor.html#torch.as_tensor" title="torch.as_tensor"><code>torch.as_tensor()</code></a>.</p> </div> <p>A tensor of specific data type can be constructed by passing a <a class="reference internal" href="tensor_attributes.html#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> and/or a <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code>torch.device</code></a> to a constructor or tensor creation op:</p> <pre data-language="python">&gt;&gt;&gt; torch.zeros([2, 4], dtype=torch.int32)
tensor([[ 0,  0,  0,  0],
        [ 0,  0,  0,  0]], dtype=torch.int32)
&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; torch.ones([2, 4], dtype=torch.float64, device=cuda0)
tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],
        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device='cuda:0')
</pre> <p>For more information about building Tensors, see <a class="reference internal" href="torch.html#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a></p> <p>The contents of a tensor can be accessed and modified using Python’s indexing and slicing notation:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6]])
&gt;&gt;&gt; print(x[1][2])
tensor(6)
&gt;&gt;&gt; x[0][1] = 8
&gt;&gt;&gt; print(x)
tensor([[ 1,  8,  3],
        [ 4,  5,  6]])
</pre> <p>Use <a class="reference internal" href="generated/torch.tensor.item.html#torch.Tensor.item" title="torch.Tensor.item"><code>torch.Tensor.item()</code></a> to get a Python number from a tensor containing a single value:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1]])
&gt;&gt;&gt; x
tensor([[ 1]])
&gt;&gt;&gt; x.item()
1
&gt;&gt;&gt; x = torch.tensor(2.5)
&gt;&gt;&gt; x
tensor(2.5000)
&gt;&gt;&gt; x.item()
2.5
</pre> <p>For more information about indexing, see <a class="reference internal" href="torch.html#indexing-slicing-joining"><span class="std std-ref">Indexing, Slicing, Joining, Mutating Ops</span></a></p> <p>A tensor can be created with <code>requires_grad=True</code> so that <a class="reference internal" href="autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> records operations on them for automatic differentiation.</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)
&gt;&gt;&gt; out = x.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; x.grad
tensor([[ 2.0000, -2.0000],
        [ 2.0000,  2.0000]])
</pre> <p>Each tensor has an associated <code>torch.Storage</code>, which holds its data. The tensor class also provides multi-dimensional, <a class="reference external" href="https://en.wikipedia.org/wiki/Stride_of_an_array">strided</a> view of a storage and defines numeric operations on it.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For more information on tensor views, see <a class="reference internal" href="tensor_view.html#tensor-view-doc"><span class="std std-ref">Tensor Views</span></a>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For more information on the <a class="reference internal" href="tensor_attributes.html#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code>torch.device</code></a>, and <a class="reference internal" href="tensor_attributes.html#torch.layout" title="torch.layout"><code>torch.layout</code></a> attributes of a <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>, see <a class="reference internal" href="tensor_attributes.html#tensor-attributes-doc"><span class="std std-ref">Tensor Attributes</span></a>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Methods which mutate a tensor are marked with an underscore suffix. For example, <code>torch.FloatTensor.abs_()</code> computes the absolute value in-place and returns the modified tensor, while <code>torch.FloatTensor.abs()</code> computes the result in a new tensor.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>To change an existing tensor’s <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code>torch.device</code></a> and/or <a class="reference internal" href="tensor_attributes.html#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, consider using <a class="reference internal" href="generated/torch.tensor.to.html#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> method on the tensor.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>Current implementation of <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> introduces memory overhead, thus it might lead to unexpectedly high memory usage in the applications with many tiny tensors. If this is your case, consider using one large structure.</p> </div>   <h2 id="tensor-class-reference">Tensor class reference</h2> <dl class="py class"> <dt class="sig sig-object py" id="torch.Tensor">
<code>class torch.Tensor</code> </dt> <dd>
<p>There are a few main ways to create a tensor, depending on your use case.</p> <ul class="simple"> <li>To create a tensor with pre-existing data, use <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a>.</li> <li>To create a tensor with specific size, use <code>torch.*</code> tensor creation ops (see <a class="reference internal" href="torch.html#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a>).</li> <li>To create a tensor with the same size (and similar types) as another tensor, use <code>torch.*_like</code> tensor creation ops (see <a class="reference internal" href="torch.html#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a>).</li> <li>To create a tensor with similar type but different size as another tensor, use <code>tensor.new_*</code> creation ops.</li> </ul> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.T">
<code>Tensor.T</code> </dt> <dd>
<p>Returns a view of this tensor with its dimensions reversed.</p> <p>If <code>n</code> is the number of dimensions in <code>x</code>, <code>x.T</code> is equivalent to <code>x.permute(n-1, n-2, ..., 0)</code>.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>The use of <a class="reference internal" href="#torch.Tensor.T" title="torch.Tensor.T"><code>Tensor.T()</code></a> on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider <a class="reference internal" href="#torch.Tensor.mT" title="torch.Tensor.mT"><code>mT</code></a> to transpose batches of matrices or <code>x.permute(*torch.arange(x.ndim - 1, -1, -1))</code> to reverse the dimensions of a tensor.</p> </div> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.H">
<code>Tensor.H</code> </dt> <dd>
<p>Returns a view of a matrix (2-D tensor) conjugated and transposed.</p> <p><code>x.H</code> is equivalent to <code>x.transpose(0, 1).conj()</code> for complex matrices and <code>x.transpose(0, 1)</code> for real matrices.</p> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="#torch.Tensor.mH" title="torch.Tensor.mH"><code>mH</code></a>: An attribute that also works on batches of matrices.</p> </div> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.mT">
<code>Tensor.mT</code> </dt> <dd>
<p>Returns a view of this tensor with the last two dimensions transposed.</p> <p><code>x.mT</code> is equivalent to <code>x.transpose(-2, -1)</code>.</p> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.mH">
<code>Tensor.mH</code> </dt> <dd>
<p>Accessing this property is equivalent to calling <a class="reference internal" href="generated/torch.adjoint.html#torch.adjoint" title="torch.adjoint"><code>adjoint()</code></a>.</p> </dd>
</dl> <table class="autosummary longtable docutils colwidths-auto align-default">  <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_tensor.html#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>Tensor.new_tensor</code></a></p></td> <td><p>Returns a new Tensor with <code>data</code> as the tensor data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_full.html#torch.Tensor.new_full" title="torch.Tensor.new_full"><code>Tensor.new_full</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with <code>fill_value</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_empty.html#torch.Tensor.new_empty" title="torch.Tensor.new_empty"><code>Tensor.new_empty</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with uninitialized data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_ones.html#torch.Tensor.new_ones" title="torch.Tensor.new_ones"><code>Tensor.new_ones</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with <code>1</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_zeros.html#torch.Tensor.new_zeros" title="torch.Tensor.new_zeros"><code>Tensor.new_zeros</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with <code>0</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_cuda.html#torch.Tensor.is_cuda" title="torch.Tensor.is_cuda"><code>Tensor.is_cuda</code></a></p></td> <td><p>Is <code>True</code> if the Tensor is stored on the GPU, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_quantized.html#torch.Tensor.is_quantized" title="torch.Tensor.is_quantized"><code>Tensor.is_quantized</code></a></p></td> <td><p>Is <code>True</code> if the Tensor is quantized, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_meta.html#torch.Tensor.is_meta" title="torch.Tensor.is_meta"><code>Tensor.is_meta</code></a></p></td> <td><p>Is <code>True</code> if the Tensor is a meta tensor, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.device.html#torch.Tensor.device" title="torch.Tensor.device"><code>Tensor.device</code></a></p></td> <td><p>Is the <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code>torch.device</code></a> where this Tensor is.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.grad.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>Tensor.grad</code></a></p></td> <td><p>This attribute is <code>None</code> by default and becomes a Tensor the first time a call to <code>backward()</code> computes gradients for <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ndim.html#torch.Tensor.ndim" title="torch.Tensor.ndim"><code>Tensor.ndim</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.dim.html#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.real.html#torch.Tensor.real" title="torch.Tensor.real"><code>Tensor.real</code></a></p></td> <td><p>Returns a new tensor containing real values of the <code>self</code> tensor for a complex-valued input tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.imag.html#torch.Tensor.imag" title="torch.Tensor.imag"><code>Tensor.imag</code></a></p></td> <td><p>Returns a new tensor containing imaginary values of the <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nbytes.html#torch.Tensor.nbytes" title="torch.Tensor.nbytes"><code>Tensor.nbytes</code></a></p></td> <td><p>Returns the number of bytes consumed by the "view" of elements of the Tensor if the Tensor does not use sparse storage layout.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.itemsize.html#torch.Tensor.itemsize" title="torch.Tensor.itemsize"><code>Tensor.itemsize</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.element_size.html#torch.Tensor.element_size" title="torch.Tensor.element_size"><code>element_size()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.abs.html#torch.Tensor.abs" title="torch.Tensor.abs"><code>Tensor.abs</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.abs.html#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.abs_.html#torch.Tensor.abs_" title="torch.Tensor.abs_"><code>Tensor.abs_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.abs.html#torch.Tensor.abs" title="torch.Tensor.abs"><code>abs()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.absolute.html#torch.Tensor.absolute" title="torch.Tensor.absolute"><code>Tensor.absolute</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.abs.html#torch.abs" title="torch.abs"><code>abs()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.absolute_.html#torch.Tensor.absolute_" title="torch.Tensor.absolute_"><code>Tensor.absolute_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.absolute.html#torch.Tensor.absolute" title="torch.Tensor.absolute"><code>absolute()</code></a> Alias for <code>abs_()</code></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acos.html#torch.Tensor.acos" title="torch.Tensor.acos"><code>Tensor.acos</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.acos.html#torch.acos" title="torch.acos"><code>torch.acos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acos_.html#torch.Tensor.acos_" title="torch.Tensor.acos_"><code>Tensor.acos_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.acos.html#torch.Tensor.acos" title="torch.Tensor.acos"><code>acos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccos.html#torch.Tensor.arccos" title="torch.Tensor.arccos"><code>Tensor.arccos</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arccos.html#torch.arccos" title="torch.arccos"><code>torch.arccos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccos_.html#torch.Tensor.arccos_" title="torch.Tensor.arccos_"><code>Tensor.arccos_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arccos.html#torch.Tensor.arccos" title="torch.Tensor.arccos"><code>arccos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.add.html#torch.Tensor.add" title="torch.Tensor.add"><code>Tensor.add</code></a></p></td> <td><p>Add a scalar or tensor to <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.add_.html#torch.Tensor.add_" title="torch.Tensor.add_"><code>Tensor.add_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.add.html#torch.Tensor.add" title="torch.Tensor.add"><code>add()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addbmm.html#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>Tensor.addbmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addbmm.html#torch.addbmm" title="torch.addbmm"><code>torch.addbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addbmm_.html#torch.Tensor.addbmm_" title="torch.Tensor.addbmm_"><code>Tensor.addbmm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addbmm.html#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>addbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcdiv.html#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>Tensor.addcdiv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addcdiv.html#torch.addcdiv" title="torch.addcdiv"><code>torch.addcdiv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcdiv_.html#torch.Tensor.addcdiv_" title="torch.Tensor.addcdiv_"><code>Tensor.addcdiv_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addcdiv.html#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>addcdiv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcmul.html#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>Tensor.addcmul</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addcmul.html#torch.addcmul" title="torch.addcmul"><code>torch.addcmul()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcmul_.html#torch.Tensor.addcmul_" title="torch.Tensor.addcmul_"><code>Tensor.addcmul_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addcmul.html#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>addcmul()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmm.html#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>Tensor.addmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addmm.html#torch.addmm" title="torch.addmm"><code>torch.addmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmm_.html#torch.Tensor.addmm_" title="torch.Tensor.addmm_"><code>Tensor.addmm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addmm.html#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>addmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sspaddmm.html#torch.Tensor.sspaddmm" title="torch.Tensor.sspaddmm"><code>Tensor.sspaddmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sspaddmm.html#torch.sspaddmm" title="torch.sspaddmm"><code>torch.sspaddmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmv.html#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>Tensor.addmv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addmv.html#torch.addmv" title="torch.addmv"><code>torch.addmv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmv_.html#torch.Tensor.addmv_" title="torch.Tensor.addmv_"><code>Tensor.addmv_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addmv.html#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>addmv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addr.html#torch.Tensor.addr" title="torch.Tensor.addr"><code>Tensor.addr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addr.html#torch.addr" title="torch.addr"><code>torch.addr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addr_.html#torch.Tensor.addr_" title="torch.Tensor.addr_"><code>Tensor.addr_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addr.html#torch.Tensor.addr" title="torch.Tensor.addr"><code>addr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.adjoint.html#torch.Tensor.adjoint" title="torch.Tensor.adjoint"><code>Tensor.adjoint</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.adjoint.html#torch.adjoint" title="torch.adjoint"><code>adjoint()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.allclose.html#torch.Tensor.allclose" title="torch.Tensor.allclose"><code>Tensor.allclose</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.allclose.html#torch.allclose" title="torch.allclose"><code>torch.allclose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.amax.html#torch.Tensor.amax" title="torch.Tensor.amax"><code>Tensor.amax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.amax.html#torch.amax" title="torch.amax"><code>torch.amax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.amin.html#torch.Tensor.amin" title="torch.Tensor.amin"><code>Tensor.amin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.amin.html#torch.amin" title="torch.amin"><code>torch.amin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.aminmax.html#torch.Tensor.aminmax" title="torch.Tensor.aminmax"><code>Tensor.aminmax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.aminmax.html#torch.aminmax" title="torch.aminmax"><code>torch.aminmax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.angle.html#torch.Tensor.angle" title="torch.Tensor.angle"><code>Tensor.angle</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.angle.html#torch.angle" title="torch.angle"><code>torch.angle()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.apply_.html#torch.Tensor.apply_" title="torch.Tensor.apply_"><code>Tensor.apply_</code></a></p></td> <td><p>Applies the function <code>callable</code> to each element in the tensor, replacing each element with the value returned by <code>callable</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argmax.html#torch.Tensor.argmax" title="torch.Tensor.argmax"><code>Tensor.argmax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argmax.html#torch.argmax" title="torch.argmax"><code>torch.argmax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argmin.html#torch.Tensor.argmin" title="torch.Tensor.argmin"><code>Tensor.argmin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argmin.html#torch.argmin" title="torch.argmin"><code>torch.argmin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argsort.html#torch.Tensor.argsort" title="torch.Tensor.argsort"><code>Tensor.argsort</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argsort.html#torch.argsort" title="torch.argsort"><code>torch.argsort()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argwhere.html#torch.Tensor.argwhere" title="torch.Tensor.argwhere"><code>Tensor.argwhere</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argwhere.html#torch.argwhere" title="torch.argwhere"><code>torch.argwhere()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asin.html#torch.Tensor.asin" title="torch.Tensor.asin"><code>Tensor.asin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.asin.html#torch.asin" title="torch.asin"><code>torch.asin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asin_.html#torch.Tensor.asin_" title="torch.Tensor.asin_"><code>Tensor.asin_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.asin.html#torch.Tensor.asin" title="torch.Tensor.asin"><code>asin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsin.html#torch.Tensor.arcsin" title="torch.Tensor.arcsin"><code>Tensor.arcsin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arcsin.html#torch.arcsin" title="torch.arcsin"><code>torch.arcsin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsin_.html#torch.Tensor.arcsin_" title="torch.Tensor.arcsin_"><code>Tensor.arcsin_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arcsin.html#torch.Tensor.arcsin" title="torch.Tensor.arcsin"><code>arcsin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.as_strided.html#torch.Tensor.as_strided" title="torch.Tensor.as_strided"><code>Tensor.as_strided</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.as_strided.html#torch.as_strided" title="torch.as_strided"><code>torch.as_strided()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan.html#torch.Tensor.atan" title="torch.Tensor.atan"><code>Tensor.atan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.atan.html#torch.atan" title="torch.atan"><code>torch.atan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan_.html#torch.Tensor.atan_" title="torch.Tensor.atan_"><code>Tensor.atan_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.atan.html#torch.Tensor.atan" title="torch.Tensor.atan"><code>atan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan.html#torch.Tensor.arctan" title="torch.Tensor.arctan"><code>Tensor.arctan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arctan.html#torch.arctan" title="torch.arctan"><code>torch.arctan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan_.html#torch.Tensor.arctan_" title="torch.Tensor.arctan_"><code>Tensor.arctan_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arctan.html#torch.Tensor.arctan" title="torch.Tensor.arctan"><code>arctan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan2.html#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>Tensor.atan2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.atan2.html#torch.atan2" title="torch.atan2"><code>torch.atan2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan2_.html#torch.Tensor.atan2_" title="torch.Tensor.atan2_"><code>Tensor.atan2_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.atan2.html#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>atan2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan2.html#torch.Tensor.arctan2" title="torch.Tensor.arctan2"><code>Tensor.arctan2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arctan2.html#torch.arctan2" title="torch.arctan2"><code>torch.arctan2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan2_.html#torch.Tensor.arctan2_" title="torch.Tensor.arctan2_"><code>Tensor.arctan2_</code></a></p></td> <td><p>atan2_(other) -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.all.html#torch.Tensor.all" title="torch.Tensor.all"><code>Tensor.all</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.all.html#torch.all" title="torch.all"><code>torch.all()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.any.html#torch.Tensor.any" title="torch.Tensor.any"><code>Tensor.any</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.any.html#torch.any" title="torch.any"><code>torch.any()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.backward.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>Tensor.backward</code></a></p></td> <td><p>Computes the gradient of current tensor wrt graph leaves.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.baddbmm.html#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>Tensor.baddbmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.baddbmm.html#torch.baddbmm" title="torch.baddbmm"><code>torch.baddbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.baddbmm_.html#torch.Tensor.baddbmm_" title="torch.Tensor.baddbmm_"><code>Tensor.baddbmm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.baddbmm.html#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>baddbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bernoulli.html#torch.Tensor.bernoulli" title="torch.Tensor.bernoulli"><code>Tensor.bernoulli</code></a></p></td> <td><p>Returns a result tensor where each <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="monospace">result[i]</mtext></mrow><annotation encoding="application/x-tex">\texttt{result[i]}</annotation></semantics></math></span></span></span> is independently sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Bernoulli</mtext><mo stretchy="false">(</mo><mtext mathvariant="monospace">self[i]</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Bernoulli}(\texttt{self[i]})</annotation></semantics></math></span></span></span>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bernoulli_.html#torch.Tensor.bernoulli_" title="torch.Tensor.bernoulli_"><code>Tensor.bernoulli_</code></a></p></td> <td><p>Fills each location of <code>self</code> with an independent sample from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Bernoulli</mtext><mo stretchy="false">(</mo><mtext mathvariant="monospace">p</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Bernoulli}(\texttt{p})</annotation></semantics></math></span></span></span>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bfloat16.html#torch.Tensor.bfloat16" title="torch.Tensor.bfloat16"><code>Tensor.bfloat16</code></a></p></td> <td><p><code>self.bfloat16()</code> is equivalent to <code>self.to(torch.bfloat16)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bincount.html#torch.Tensor.bincount" title="torch.Tensor.bincount"><code>Tensor.bincount</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bincount.html#torch.bincount" title="torch.bincount"><code>torch.bincount()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_not.html#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code>Tensor.bitwise_not</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_not.html#torch.bitwise_not" title="torch.bitwise_not"><code>torch.bitwise_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_not_.html#torch.Tensor.bitwise_not_" title="torch.Tensor.bitwise_not_"><code>Tensor.bitwise_not_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_not.html#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code>bitwise_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_and.html#torch.Tensor.bitwise_and" title="torch.Tensor.bitwise_and"><code>Tensor.bitwise_and</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_and.html#torch.bitwise_and" title="torch.bitwise_and"><code>torch.bitwise_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_and_.html#torch.Tensor.bitwise_and_" title="torch.Tensor.bitwise_and_"><code>Tensor.bitwise_and_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_and.html#torch.Tensor.bitwise_and" title="torch.Tensor.bitwise_and"><code>bitwise_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_or.html#torch.Tensor.bitwise_or" title="torch.Tensor.bitwise_or"><code>Tensor.bitwise_or</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_or.html#torch.bitwise_or" title="torch.bitwise_or"><code>torch.bitwise_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_or_.html#torch.Tensor.bitwise_or_" title="torch.Tensor.bitwise_or_"><code>Tensor.bitwise_or_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_or.html#torch.Tensor.bitwise_or" title="torch.Tensor.bitwise_or"><code>bitwise_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_xor.html#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code>Tensor.bitwise_xor</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_xor.html#torch.bitwise_xor" title="torch.bitwise_xor"><code>torch.bitwise_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_xor_.html#torch.Tensor.bitwise_xor_" title="torch.Tensor.bitwise_xor_"><code>Tensor.bitwise_xor_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_xor.html#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code>bitwise_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_left_shift.html#torch.Tensor.bitwise_left_shift" title="torch.Tensor.bitwise_left_shift"><code>Tensor.bitwise_left_shift</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift" title="torch.bitwise_left_shift"><code>torch.bitwise_left_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_left_shift_.html#torch.Tensor.bitwise_left_shift_" title="torch.Tensor.bitwise_left_shift_"><code>Tensor.bitwise_left_shift_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_left_shift.html#torch.Tensor.bitwise_left_shift" title="torch.Tensor.bitwise_left_shift"><code>bitwise_left_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_right_shift.html#torch.Tensor.bitwise_right_shift" title="torch.Tensor.bitwise_right_shift"><code>Tensor.bitwise_right_shift</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift" title="torch.bitwise_right_shift"><code>torch.bitwise_right_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_right_shift_.html#torch.Tensor.bitwise_right_shift_" title="torch.Tensor.bitwise_right_shift_"><code>Tensor.bitwise_right_shift_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_right_shift.html#torch.Tensor.bitwise_right_shift" title="torch.Tensor.bitwise_right_shift"><code>bitwise_right_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bmm.html#torch.Tensor.bmm" title="torch.Tensor.bmm"><code>Tensor.bmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bmm.html#torch.bmm" title="torch.bmm"><code>torch.bmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bool.html#torch.Tensor.bool" title="torch.Tensor.bool"><code>Tensor.bool</code></a></p></td> <td><p><code>self.bool()</code> is equivalent to <code>self.to(torch.bool)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.byte.html#torch.Tensor.byte" title="torch.Tensor.byte"><code>Tensor.byte</code></a></p></td> <td><p><code>self.byte()</code> is equivalent to <code>self.to(torch.uint8)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.broadcast_to.html#torch.Tensor.broadcast_to" title="torch.Tensor.broadcast_to"><code>Tensor.broadcast_to</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.broadcast_to.html#torch.broadcast_to" title="torch.broadcast_to"><code>torch.broadcast_to()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cauchy_.html#torch.Tensor.cauchy_" title="torch.Tensor.cauchy_"><code>Tensor.cauchy_</code></a></p></td> <td><p>Fills the tensor with numbers drawn from the Cauchy distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ceil.html#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>Tensor.ceil</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ceil.html#torch.ceil" title="torch.ceil"><code>torch.ceil()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ceil_.html#torch.Tensor.ceil_" title="torch.Tensor.ceil_"><code>Tensor.ceil_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ceil.html#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>ceil()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.char.html#torch.Tensor.char" title="torch.Tensor.char"><code>Tensor.char</code></a></p></td> <td><p><code>self.char()</code> is equivalent to <code>self.to(torch.int8)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cholesky.html#torch.Tensor.cholesky" title="torch.Tensor.cholesky"><code>Tensor.cholesky</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cholesky.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cholesky_inverse.html#torch.Tensor.cholesky_inverse" title="torch.Tensor.cholesky_inverse"><code>Tensor.cholesky_inverse</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cholesky_inverse.html#torch.cholesky_inverse" title="torch.cholesky_inverse"><code>torch.cholesky_inverse()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cholesky_solve.html#torch.Tensor.cholesky_solve" title="torch.Tensor.cholesky_solve"><code>Tensor.cholesky_solve</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cholesky_solve.html#torch.cholesky_solve" title="torch.cholesky_solve"><code>torch.cholesky_solve()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.chunk.html#torch.Tensor.chunk" title="torch.Tensor.chunk"><code>Tensor.chunk</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.chunk.html#torch.chunk" title="torch.chunk"><code>torch.chunk()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clamp.html#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>Tensor.clamp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.clamp.html#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clamp_.html#torch.Tensor.clamp_" title="torch.Tensor.clamp_"><code>Tensor.clamp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.clamp.html#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clip.html#torch.Tensor.clip" title="torch.Tensor.clip"><code>Tensor.clip</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.clamp.html#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clip_.html#torch.Tensor.clip_" title="torch.Tensor.clip_"><code>Tensor.clip_</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.clamp_.html#torch.Tensor.clamp_" title="torch.Tensor.clamp_"><code>clamp_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clone.html#torch.Tensor.clone" title="torch.Tensor.clone"><code>Tensor.clone</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.clone.html#torch.clone" title="torch.clone"><code>torch.clone()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.contiguous.html#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>Tensor.contiguous</code></a></p></td> <td><p>Returns a contiguous in memory tensor containing the same data as <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.copy_.html#torch.Tensor.copy_" title="torch.Tensor.copy_"><code>Tensor.copy_</code></a></p></td> <td><p>Copies the elements from <code>src</code> into <code>self</code> tensor and returns <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.conj.html#torch.Tensor.conj" title="torch.Tensor.conj"><code>Tensor.conj</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.conj.html#torch.conj" title="torch.conj"><code>torch.conj()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.conj_physical.html#torch.Tensor.conj_physical" title="torch.Tensor.conj_physical"><code>Tensor.conj_physical</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.conj_physical.html#torch.conj_physical" title="torch.conj_physical"><code>torch.conj_physical()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.conj_physical_.html#torch.Tensor.conj_physical_" title="torch.Tensor.conj_physical_"><code>Tensor.conj_physical_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.conj_physical.html#torch.Tensor.conj_physical" title="torch.Tensor.conj_physical"><code>conj_physical()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resolve_conj.html#torch.Tensor.resolve_conj" title="torch.Tensor.resolve_conj"><code>Tensor.resolve_conj</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.resolve_conj.html#torch.resolve_conj" title="torch.resolve_conj"><code>torch.resolve_conj()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resolve_neg.html#torch.Tensor.resolve_neg" title="torch.Tensor.resolve_neg"><code>Tensor.resolve_neg</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.resolve_neg.html#torch.resolve_neg" title="torch.resolve_neg"><code>torch.resolve_neg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.copysign.html#torch.Tensor.copysign" title="torch.Tensor.copysign"><code>Tensor.copysign</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.copysign.html#torch.copysign" title="torch.copysign"><code>torch.copysign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.copysign_.html#torch.Tensor.copysign_" title="torch.Tensor.copysign_"><code>Tensor.copysign_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.copysign.html#torch.Tensor.copysign" title="torch.Tensor.copysign"><code>copysign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cos.html#torch.Tensor.cos" title="torch.Tensor.cos"><code>Tensor.cos</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cos.html#torch.cos" title="torch.cos"><code>torch.cos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cos_.html#torch.Tensor.cos_" title="torch.Tensor.cos_"><code>Tensor.cos_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cos.html#torch.Tensor.cos" title="torch.Tensor.cos"><code>cos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cosh.html#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>Tensor.cosh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cosh.html#torch.cosh" title="torch.cosh"><code>torch.cosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cosh_.html#torch.Tensor.cosh_" title="torch.Tensor.cosh_"><code>Tensor.cosh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cosh.html#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>cosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.corrcoef.html#torch.Tensor.corrcoef" title="torch.Tensor.corrcoef"><code>Tensor.corrcoef</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.corrcoef.html#torch.corrcoef" title="torch.corrcoef"><code>torch.corrcoef()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.count_nonzero.html#torch.Tensor.count_nonzero" title="torch.Tensor.count_nonzero"><code>Tensor.count_nonzero</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.count_nonzero.html#torch.count_nonzero" title="torch.count_nonzero"><code>torch.count_nonzero()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cov.html#torch.Tensor.cov" title="torch.Tensor.cov"><code>Tensor.cov</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cov.html#torch.cov" title="torch.cov"><code>torch.cov()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acosh.html#torch.Tensor.acosh" title="torch.Tensor.acosh"><code>Tensor.acosh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.acosh.html#torch.acosh" title="torch.acosh"><code>torch.acosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acosh_.html#torch.Tensor.acosh_" title="torch.Tensor.acosh_"><code>Tensor.acosh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.acosh.html#torch.Tensor.acosh" title="torch.Tensor.acosh"><code>acosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccosh.html#torch.Tensor.arccosh" title="torch.Tensor.arccosh"><code>Tensor.arccosh</code></a></p></td> <td><p>acosh() -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccosh_.html#torch.Tensor.arccosh_" title="torch.Tensor.arccosh_"><code>Tensor.arccosh_</code></a></p></td> <td><p>acosh_() -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cpu.html#torch.Tensor.cpu" title="torch.Tensor.cpu"><code>Tensor.cpu</code></a></p></td> <td><p>Returns a copy of this object in CPU memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cross.html#torch.Tensor.cross" title="torch.Tensor.cross"><code>Tensor.cross</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cross.html#torch.cross" title="torch.cross"><code>torch.cross()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cuda.html#torch.Tensor.cuda" title="torch.Tensor.cuda"><code>Tensor.cuda</code></a></p></td> <td><p>Returns a copy of this object in CUDA memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logcumsumexp.html#torch.Tensor.logcumsumexp" title="torch.Tensor.logcumsumexp"><code>Tensor.logcumsumexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logcumsumexp.html#torch.logcumsumexp" title="torch.logcumsumexp"><code>torch.logcumsumexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cummax.html#torch.Tensor.cummax" title="torch.Tensor.cummax"><code>Tensor.cummax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cummax.html#torch.cummax" title="torch.cummax"><code>torch.cummax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cummin.html#torch.Tensor.cummin" title="torch.Tensor.cummin"><code>Tensor.cummin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cummin.html#torch.cummin" title="torch.cummin"><code>torch.cummin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumprod.html#torch.Tensor.cumprod" title="torch.Tensor.cumprod"><code>Tensor.cumprod</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cumprod.html#torch.cumprod" title="torch.cumprod"><code>torch.cumprod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumprod_.html#torch.Tensor.cumprod_" title="torch.Tensor.cumprod_"><code>Tensor.cumprod_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cumprod.html#torch.Tensor.cumprod" title="torch.Tensor.cumprod"><code>cumprod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumsum.html#torch.Tensor.cumsum" title="torch.Tensor.cumsum"><code>Tensor.cumsum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cumsum.html#torch.cumsum" title="torch.cumsum"><code>torch.cumsum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumsum_.html#torch.Tensor.cumsum_" title="torch.Tensor.cumsum_"><code>Tensor.cumsum_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cumsum.html#torch.Tensor.cumsum" title="torch.Tensor.cumsum"><code>cumsum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.chalf.html#torch.Tensor.chalf" title="torch.Tensor.chalf"><code>Tensor.chalf</code></a></p></td> <td><p><code>self.chalf()</code> is equivalent to <code>self.to(torch.complex32)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cfloat.html#torch.Tensor.cfloat" title="torch.Tensor.cfloat"><code>Tensor.cfloat</code></a></p></td> <td><p><code>self.cfloat()</code> is equivalent to <code>self.to(torch.complex64)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cdouble.html#torch.Tensor.cdouble" title="torch.Tensor.cdouble"><code>Tensor.cdouble</code></a></p></td> <td><p><code>self.cdouble()</code> is equivalent to <code>self.to(torch.complex128)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.data_ptr.html#torch.Tensor.data_ptr" title="torch.Tensor.data_ptr"><code>Tensor.data_ptr</code></a></p></td> <td><p>Returns the address of the first element of <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.deg2rad.html#torch.Tensor.deg2rad" title="torch.Tensor.deg2rad"><code>Tensor.deg2rad</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.deg2rad.html#torch.deg2rad" title="torch.deg2rad"><code>torch.deg2rad()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dequantize.html#torch.Tensor.dequantize" title="torch.Tensor.dequantize"><code>Tensor.dequantize</code></a></p></td> <td><p>Given a quantized Tensor, dequantize it and return the dequantized float Tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.det.html#torch.Tensor.det" title="torch.Tensor.det"><code>Tensor.det</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.det.html#torch.det" title="torch.det"><code>torch.det()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dense_dim.html#torch.Tensor.dense_dim" title="torch.Tensor.dense_dim"><code>Tensor.dense_dim</code></a></p></td> <td><p>Return the number of dense dimensions in a <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.detach.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>Tensor.detach</code></a></p></td> <td><p>Returns a new Tensor, detached from the current graph.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.detach_.html#torch.Tensor.detach_" title="torch.Tensor.detach_"><code>Tensor.detach_</code></a></p></td> <td><p>Detaches the Tensor from the graph that created it, making it a leaf.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diag.html#torch.Tensor.diag" title="torch.Tensor.diag"><code>Tensor.diag</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diag.html#torch.diag" title="torch.diag"><code>torch.diag()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diag_embed.html#torch.Tensor.diag_embed" title="torch.Tensor.diag_embed"><code>Tensor.diag_embed</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diag_embed.html#torch.diag_embed" title="torch.diag_embed"><code>torch.diag_embed()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diagflat.html#torch.Tensor.diagflat" title="torch.Tensor.diagflat"><code>Tensor.diagflat</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diagflat.html#torch.diagflat" title="torch.diagflat"><code>torch.diagflat()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diagonal.html#torch.Tensor.diagonal" title="torch.Tensor.diagonal"><code>Tensor.diagonal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diagonal.html#torch.diagonal" title="torch.diagonal"><code>torch.diagonal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diagonal_scatter.html#torch.Tensor.diagonal_scatter" title="torch.Tensor.diagonal_scatter"><code>Tensor.diagonal_scatter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diagonal_scatter.html#torch.diagonal_scatter" title="torch.diagonal_scatter"><code>torch.diagonal_scatter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fill_diagonal_.html#torch.Tensor.fill_diagonal_" title="torch.Tensor.fill_diagonal_"><code>Tensor.fill_diagonal_</code></a></p></td> <td><p>Fill the main diagonal of a tensor that has at least 2-dimensions.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmax.html#torch.Tensor.fmax" title="torch.Tensor.fmax"><code>Tensor.fmax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fmax.html#torch.fmax" title="torch.fmax"><code>torch.fmax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmin.html#torch.Tensor.fmin" title="torch.Tensor.fmin"><code>Tensor.fmin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fmin.html#torch.fmin" title="torch.fmin"><code>torch.fmin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diff.html#torch.Tensor.diff" title="torch.Tensor.diff"><code>Tensor.diff</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diff.html#torch.diff" title="torch.diff"><code>torch.diff()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.digamma.html#torch.Tensor.digamma" title="torch.Tensor.digamma"><code>Tensor.digamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.digamma.html#torch.digamma" title="torch.digamma"><code>torch.digamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.digamma_.html#torch.Tensor.digamma_" title="torch.Tensor.digamma_"><code>Tensor.digamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.digamma.html#torch.Tensor.digamma" title="torch.Tensor.digamma"><code>digamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dim.html#torch.Tensor.dim" title="torch.Tensor.dim"><code>Tensor.dim</code></a></p></td> <td><p>Returns the number of dimensions of <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dim_order.html#torch.Tensor.dim_order" title="torch.Tensor.dim_order"><code>Tensor.dim_order</code></a></p></td> <td><p>Returns a tuple of int describing the dim order or physical layout of <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dist.html#torch.Tensor.dist" title="torch.Tensor.dist"><code>Tensor.dist</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.dist.html#torch.dist" title="torch.dist"><code>torch.dist()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.div.html#torch.Tensor.div" title="torch.Tensor.div"><code>Tensor.div</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.div.html#torch.div" title="torch.div"><code>torch.div()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.div_.html#torch.Tensor.div_" title="torch.Tensor.div_"><code>Tensor.div_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.div.html#torch.Tensor.div" title="torch.Tensor.div"><code>div()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.divide.html#torch.Tensor.divide" title="torch.Tensor.divide"><code>Tensor.divide</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.divide.html#torch.divide" title="torch.divide"><code>torch.divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.divide_.html#torch.Tensor.divide_" title="torch.Tensor.divide_"><code>Tensor.divide_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.divide.html#torch.Tensor.divide" title="torch.Tensor.divide"><code>divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dot.html#torch.Tensor.dot" title="torch.Tensor.dot"><code>Tensor.dot</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.dot.html#torch.dot" title="torch.dot"><code>torch.dot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.double.html#torch.Tensor.double" title="torch.Tensor.double"><code>Tensor.double</code></a></p></td> <td><p><code>self.double()</code> is equivalent to <code>self.to(torch.float64)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dsplit.html#torch.Tensor.dsplit" title="torch.Tensor.dsplit"><code>Tensor.dsplit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.dsplit.html#torch.dsplit" title="torch.dsplit"><code>torch.dsplit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.element_size.html#torch.Tensor.element_size" title="torch.Tensor.element_size"><code>Tensor.element_size</code></a></p></td> <td><p>Returns the size in bytes of an individual element.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.eq.html#torch.Tensor.eq" title="torch.Tensor.eq"><code>Tensor.eq</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.eq.html#torch.eq" title="torch.eq"><code>torch.eq()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.eq_.html#torch.Tensor.eq_" title="torch.Tensor.eq_"><code>Tensor.eq_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.eq.html#torch.Tensor.eq" title="torch.Tensor.eq"><code>eq()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.equal.html#torch.Tensor.equal" title="torch.Tensor.equal"><code>Tensor.equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.equal.html#torch.equal" title="torch.equal"><code>torch.equal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erf.html#torch.Tensor.erf" title="torch.Tensor.erf"><code>Tensor.erf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.erf.html#torch.erf" title="torch.erf"><code>torch.erf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erf_.html#torch.Tensor.erf_" title="torch.Tensor.erf_"><code>Tensor.erf_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.erf.html#torch.Tensor.erf" title="torch.Tensor.erf"><code>erf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfc.html#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>Tensor.erfc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.erfc.html#torch.erfc" title="torch.erfc"><code>torch.erfc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfc_.html#torch.Tensor.erfc_" title="torch.Tensor.erfc_"><code>Tensor.erfc_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.erfc.html#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>erfc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfinv.html#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>Tensor.erfinv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.erfinv.html#torch.erfinv" title="torch.erfinv"><code>torch.erfinv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfinv_.html#torch.Tensor.erfinv_" title="torch.Tensor.erfinv_"><code>Tensor.erfinv_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.erfinv.html#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>erfinv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.exp.html#torch.Tensor.exp" title="torch.Tensor.exp"><code>Tensor.exp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.exp.html#torch.exp" title="torch.exp"><code>torch.exp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.exp_.html#torch.Tensor.exp_" title="torch.Tensor.exp_"><code>Tensor.exp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.exp.html#torch.Tensor.exp" title="torch.Tensor.exp"><code>exp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expm1.html#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>Tensor.expm1</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.expm1.html#torch.expm1" title="torch.expm1"><code>torch.expm1()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expm1_.html#torch.Tensor.expm1_" title="torch.Tensor.expm1_"><code>Tensor.expm1_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.expm1.html#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>expm1()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expand.html#torch.Tensor.expand" title="torch.Tensor.expand"><code>Tensor.expand</code></a></p></td> <td><p>Returns a new view of the <code>self</code> tensor with singleton dimensions expanded to a larger size.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expand_as.html#torch.Tensor.expand_as" title="torch.Tensor.expand_as"><code>Tensor.expand_as</code></a></p></td> <td><p>Expand this tensor to the same size as <code>other</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.exponential_.html#torch.Tensor.exponential_" title="torch.Tensor.exponential_"><code>Tensor.exponential_</code></a></p></td> <td><p>Fills <code>self</code> tensor with elements drawn from the exponential distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fix.html#torch.Tensor.fix" title="torch.Tensor.fix"><code>Tensor.fix</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fix.html#torch.fix" title="torch.fix"><code>torch.fix()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fix_.html#torch.Tensor.fix_" title="torch.Tensor.fix_"><code>Tensor.fix_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.fix.html#torch.Tensor.fix" title="torch.Tensor.fix"><code>fix()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fill_.html#torch.Tensor.fill_" title="torch.Tensor.fill_"><code>Tensor.fill_</code></a></p></td> <td><p>Fills <code>self</code> tensor with the specified value.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.flatten.html#torch.Tensor.flatten" title="torch.Tensor.flatten"><code>Tensor.flatten</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.flatten.html#torch.flatten" title="torch.flatten"><code>torch.flatten()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.flip.html#torch.Tensor.flip" title="torch.Tensor.flip"><code>Tensor.flip</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.flip.html#torch.flip" title="torch.flip"><code>torch.flip()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fliplr.html#torch.Tensor.fliplr" title="torch.Tensor.fliplr"><code>Tensor.fliplr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fliplr.html#torch.fliplr" title="torch.fliplr"><code>torch.fliplr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.flipud.html#torch.Tensor.flipud" title="torch.Tensor.flipud"><code>Tensor.flipud</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.flipud.html#torch.flipud" title="torch.flipud"><code>torch.flipud()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.float.html#torch.Tensor.float" title="torch.Tensor.float"><code>Tensor.float</code></a></p></td> <td><p><code>self.float()</code> is equivalent to <code>self.to(torch.float32)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.float_power.html#torch.Tensor.float_power" title="torch.Tensor.float_power"><code>Tensor.float_power</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.float_power.html#torch.float_power" title="torch.float_power"><code>torch.float_power()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.float_power_.html#torch.Tensor.float_power_" title="torch.Tensor.float_power_"><code>Tensor.float_power_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.float_power.html#torch.Tensor.float_power" title="torch.Tensor.float_power"><code>float_power()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor.html#torch.Tensor.floor" title="torch.Tensor.floor"><code>Tensor.floor</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.floor.html#torch.floor" title="torch.floor"><code>torch.floor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor_.html#torch.Tensor.floor_" title="torch.Tensor.floor_"><code>Tensor.floor_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.floor.html#torch.Tensor.floor" title="torch.Tensor.floor"><code>floor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor_divide.html#torch.Tensor.floor_divide" title="torch.Tensor.floor_divide"><code>Tensor.floor_divide</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.floor_divide.html#torch.floor_divide" title="torch.floor_divide"><code>torch.floor_divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor_divide_.html#torch.Tensor.floor_divide_" title="torch.Tensor.floor_divide_"><code>Tensor.floor_divide_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.floor_divide.html#torch.Tensor.floor_divide" title="torch.Tensor.floor_divide"><code>floor_divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmod.html#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>Tensor.fmod</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fmod.html#torch.fmod" title="torch.fmod"><code>torch.fmod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmod_.html#torch.Tensor.fmod_" title="torch.Tensor.fmod_"><code>Tensor.fmod_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.fmod.html#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>fmod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.frac.html#torch.Tensor.frac" title="torch.Tensor.frac"><code>Tensor.frac</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.frac.html#torch.frac" title="torch.frac"><code>torch.frac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.frac_.html#torch.Tensor.frac_" title="torch.Tensor.frac_"><code>Tensor.frac_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.frac.html#torch.Tensor.frac" title="torch.Tensor.frac"><code>frac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.frexp.html#torch.Tensor.frexp" title="torch.Tensor.frexp"><code>Tensor.frexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.frexp.html#torch.frexp" title="torch.frexp"><code>torch.frexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gather.html#torch.Tensor.gather" title="torch.Tensor.gather"><code>Tensor.gather</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.gather.html#torch.gather" title="torch.gather"><code>torch.gather()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gcd.html#torch.Tensor.gcd" title="torch.Tensor.gcd"><code>Tensor.gcd</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.gcd.html#torch.gcd" title="torch.gcd"><code>torch.gcd()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gcd_.html#torch.Tensor.gcd_" title="torch.Tensor.gcd_"><code>Tensor.gcd_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.gcd.html#torch.Tensor.gcd" title="torch.Tensor.gcd"><code>gcd()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ge.html#torch.Tensor.ge" title="torch.Tensor.ge"><code>Tensor.ge</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ge.html#torch.ge" title="torch.ge"><code>torch.ge()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ge_.html#torch.Tensor.ge_" title="torch.Tensor.ge_"><code>Tensor.ge_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ge.html#torch.Tensor.ge" title="torch.Tensor.ge"><code>ge()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater_equal.html#torch.Tensor.greater_equal" title="torch.Tensor.greater_equal"><code>Tensor.greater_equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.greater_equal.html#torch.greater_equal" title="torch.greater_equal"><code>torch.greater_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater_equal_.html#torch.Tensor.greater_equal_" title="torch.Tensor.greater_equal_"><code>Tensor.greater_equal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.greater_equal.html#torch.Tensor.greater_equal" title="torch.Tensor.greater_equal"><code>greater_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.geometric_.html#torch.Tensor.geometric_" title="torch.Tensor.geometric_"><code>Tensor.geometric_</code></a></p></td> <td><p>Fills <code>self</code> tensor with elements drawn from the geometric distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.geqrf.html#torch.Tensor.geqrf" title="torch.Tensor.geqrf"><code>Tensor.geqrf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.geqrf.html#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ger.html#torch.Tensor.ger" title="torch.Tensor.ger"><code>Tensor.ger</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ger.html#torch.ger" title="torch.ger"><code>torch.ger()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.get_device.html#torch.Tensor.get_device" title="torch.Tensor.get_device"><code>Tensor.get_device</code></a></p></td> <td><p>For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gt.html#torch.Tensor.gt" title="torch.Tensor.gt"><code>Tensor.gt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.gt.html#torch.gt" title="torch.gt"><code>torch.gt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gt_.html#torch.Tensor.gt_" title="torch.Tensor.gt_"><code>Tensor.gt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.gt.html#torch.Tensor.gt" title="torch.Tensor.gt"><code>gt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater.html#torch.Tensor.greater" title="torch.Tensor.greater"><code>Tensor.greater</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.greater.html#torch.greater" title="torch.greater"><code>torch.greater()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater_.html#torch.Tensor.greater_" title="torch.Tensor.greater_"><code>Tensor.greater_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.greater.html#torch.Tensor.greater" title="torch.Tensor.greater"><code>greater()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.half.html#torch.Tensor.half" title="torch.Tensor.half"><code>Tensor.half</code></a></p></td> <td><p><code>self.half()</code> is equivalent to <code>self.to(torch.float16)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hardshrink.html#torch.Tensor.hardshrink" title="torch.Tensor.hardshrink"><code>Tensor.hardshrink</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nn.functional.hardshrink.html#torch.nn.functional.hardshrink" title="torch.nn.functional.hardshrink"><code>torch.nn.functional.hardshrink()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.heaviside.html#torch.Tensor.heaviside" title="torch.Tensor.heaviside"><code>Tensor.heaviside</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.heaviside.html#torch.heaviside" title="torch.heaviside"><code>torch.heaviside()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.histc.html#torch.Tensor.histc" title="torch.Tensor.histc"><code>Tensor.histc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.histc.html#torch.histc" title="torch.histc"><code>torch.histc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.histogram.html#torch.Tensor.histogram" title="torch.Tensor.histogram"><code>Tensor.histogram</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.histogram.html#torch.histogram" title="torch.histogram"><code>torch.histogram()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hsplit.html#torch.Tensor.hsplit" title="torch.Tensor.hsplit"><code>Tensor.hsplit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.hsplit.html#torch.hsplit" title="torch.hsplit"><code>torch.hsplit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hypot.html#torch.Tensor.hypot" title="torch.Tensor.hypot"><code>Tensor.hypot</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.hypot.html#torch.hypot" title="torch.hypot"><code>torch.hypot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hypot_.html#torch.Tensor.hypot_" title="torch.Tensor.hypot_"><code>Tensor.hypot_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.hypot.html#torch.Tensor.hypot" title="torch.Tensor.hypot"><code>hypot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.i0.html#torch.Tensor.i0" title="torch.Tensor.i0"><code>Tensor.i0</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.i0.html#torch.i0" title="torch.i0"><code>torch.i0()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.i0_.html#torch.Tensor.i0_" title="torch.Tensor.i0_"><code>Tensor.i0_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.i0.html#torch.Tensor.i0" title="torch.Tensor.i0"><code>i0()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igamma.html#torch.Tensor.igamma" title="torch.Tensor.igamma"><code>Tensor.igamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.igamma.html#torch.igamma" title="torch.igamma"><code>torch.igamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igamma_.html#torch.Tensor.igamma_" title="torch.Tensor.igamma_"><code>Tensor.igamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.igamma.html#torch.Tensor.igamma" title="torch.Tensor.igamma"><code>igamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igammac.html#torch.Tensor.igammac" title="torch.Tensor.igammac"><code>Tensor.igammac</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.igammac.html#torch.igammac" title="torch.igammac"><code>torch.igammac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igammac_.html#torch.Tensor.igammac_" title="torch.Tensor.igammac_"><code>Tensor.igammac_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.igammac.html#torch.Tensor.igammac" title="torch.Tensor.igammac"><code>igammac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_add_.html#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code>Tensor.index_add_</code></a></p></td> <td><p>Accumulate the elements of <code>alpha</code> times <code>source</code> into the <code>self</code> tensor by adding to the indices in the order given in <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_add.html#torch.Tensor.index_add" title="torch.Tensor.index_add"><code>Tensor.index_add</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.index_add_.html#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code>torch.Tensor.index_add_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_copy_.html#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code>Tensor.index_copy_</code></a></p></td> <td><p>Copies the elements of <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> into the <code>self</code> tensor by selecting the indices in the order given in <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_copy.html#torch.Tensor.index_copy" title="torch.Tensor.index_copy"><code>Tensor.index_copy</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.index_copy_.html#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code>torch.Tensor.index_copy_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_fill_.html#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code>Tensor.index_fill_</code></a></p></td> <td><p>Fills the elements of the <code>self</code> tensor with value <code>value</code> by selecting the indices in the order given in <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_fill.html#torch.Tensor.index_fill" title="torch.Tensor.index_fill"><code>Tensor.index_fill</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.index_fill_.html#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code>torch.Tensor.index_fill_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_put_.html#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code>Tensor.index_put_</code></a></p></td> <td><p>Puts values from the tensor <code>values</code> into the tensor <code>self</code> using the indices specified in <code>indices</code> (which is a tuple of Tensors).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_put.html#torch.Tensor.index_put" title="torch.Tensor.index_put"><code>Tensor.index_put</code></a></p></td> <td><p>Out-place version of <a class="reference internal" href="generated/torch.tensor.index_put_.html#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code>index_put_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_reduce_.html#torch.Tensor.index_reduce_" title="torch.Tensor.index_reduce_"><code>Tensor.index_reduce_</code></a></p></td> <td><p>Accumulate the elements of <code>source</code> into the <code>self</code> tensor by accumulating to the indices in the order given in <code>index</code> using the reduction given by the <code>reduce</code> argument.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_reduce.html#torch.Tensor.index_reduce" title="torch.Tensor.index_reduce"><code>Tensor.index_reduce</code></a></p></td> <td></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_select.html#torch.Tensor.index_select" title="torch.Tensor.index_select"><code>Tensor.index_select</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.index_select.html#torch.index_select" title="torch.index_select"><code>torch.index_select()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.indices.html#torch.Tensor.indices" title="torch.Tensor.indices"><code>Tensor.indices</code></a></p></td> <td><p>Return the indices tensor of a <a class="reference internal" href="sparse.html#sparse-coo-docs"><span class="std std-ref">sparse COO tensor</span></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.inner.html#torch.Tensor.inner" title="torch.Tensor.inner"><code>Tensor.inner</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.inner.html#torch.inner" title="torch.inner"><code>torch.inner()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.int.html#torch.Tensor.int" title="torch.Tensor.int"><code>Tensor.int</code></a></p></td> <td><p><code>self.int()</code> is equivalent to <code>self.to(torch.int32)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.int_repr.html#torch.Tensor.int_repr" title="torch.Tensor.int_repr"><code>Tensor.int_repr</code></a></p></td> <td><p>Given a quantized Tensor, <code>self.int_repr()</code> returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.inverse.html#torch.Tensor.inverse" title="torch.Tensor.inverse"><code>Tensor.inverse</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.inverse.html#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isclose.html#torch.Tensor.isclose" title="torch.Tensor.isclose"><code>Tensor.isclose</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isclose.html#torch.isclose" title="torch.isclose"><code>torch.isclose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isfinite.html#torch.Tensor.isfinite" title="torch.Tensor.isfinite"><code>Tensor.isfinite</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isfinite.html#torch.isfinite" title="torch.isfinite"><code>torch.isfinite()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isinf.html#torch.Tensor.isinf" title="torch.Tensor.isinf"><code>Tensor.isinf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isinf.html#torch.isinf" title="torch.isinf"><code>torch.isinf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isposinf.html#torch.Tensor.isposinf" title="torch.Tensor.isposinf"><code>Tensor.isposinf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isposinf.html#torch.isposinf" title="torch.isposinf"><code>torch.isposinf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isneginf.html#torch.Tensor.isneginf" title="torch.Tensor.isneginf"><code>Tensor.isneginf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isneginf.html#torch.isneginf" title="torch.isneginf"><code>torch.isneginf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isnan.html#torch.Tensor.isnan" title="torch.Tensor.isnan"><code>Tensor.isnan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isnan.html#torch.isnan" title="torch.isnan"><code>torch.isnan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_contiguous.html#torch.Tensor.is_contiguous" title="torch.Tensor.is_contiguous"><code>Tensor.is_contiguous</code></a></p></td> <td><p>Returns True if <code>self</code> tensor is contiguous in memory in the order specified by memory format.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_complex.html#torch.Tensor.is_complex" title="torch.Tensor.is_complex"><code>Tensor.is_complex</code></a></p></td> <td><p>Returns True if the data type of <code>self</code> is a complex data type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_conj.html#torch.Tensor.is_conj" title="torch.Tensor.is_conj"><code>Tensor.is_conj</code></a></p></td> <td><p>Returns True if the conjugate bit of <code>self</code> is set to true.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_floating_point.html#torch.Tensor.is_floating_point" title="torch.Tensor.is_floating_point"><code>Tensor.is_floating_point</code></a></p></td> <td><p>Returns True if the data type of <code>self</code> is a floating point data type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_inference.html#torch.Tensor.is_inference" title="torch.Tensor.is_inference"><code>Tensor.is_inference</code></a></p></td> <td><p>See <code>torch.is_inference()</code></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_leaf.html#torch.Tensor.is_leaf" title="torch.Tensor.is_leaf"><code>Tensor.is_leaf</code></a></p></td> <td><p>All Tensors that have <code>requires_grad</code> which is <code>False</code> will be leaf Tensors by convention.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_pinned.html#torch.Tensor.is_pinned" title="torch.Tensor.is_pinned"><code>Tensor.is_pinned</code></a></p></td> <td><p>Returns true if this tensor resides in pinned memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_set_to.html#torch.Tensor.is_set_to" title="torch.Tensor.is_set_to"><code>Tensor.is_set_to</code></a></p></td> <td><p>Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_shared.html#torch.Tensor.is_shared" title="torch.Tensor.is_shared"><code>Tensor.is_shared</code></a></p></td> <td><p>Checks if tensor is in shared memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_signed.html#torch.Tensor.is_signed" title="torch.Tensor.is_signed"><code>Tensor.is_signed</code></a></p></td> <td><p>Returns True if the data type of <code>self</code> is a signed data type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_sparse.html#torch.Tensor.is_sparse" title="torch.Tensor.is_sparse"><code>Tensor.is_sparse</code></a></p></td> <td><p>Is <code>True</code> if the Tensor uses sparse COO storage layout, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.istft.html#torch.Tensor.istft" title="torch.Tensor.istft"><code>Tensor.istft</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.istft.html#torch.istft" title="torch.istft"><code>torch.istft()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isreal.html#torch.Tensor.isreal" title="torch.Tensor.isreal"><code>Tensor.isreal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isreal.html#torch.isreal" title="torch.isreal"><code>torch.isreal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.item.html#torch.Tensor.item" title="torch.Tensor.item"><code>Tensor.item</code></a></p></td> <td><p>Returns the value of this tensor as a standard Python number.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.kthvalue.html#torch.Tensor.kthvalue" title="torch.Tensor.kthvalue"><code>Tensor.kthvalue</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.kthvalue.html#torch.kthvalue" title="torch.kthvalue"><code>torch.kthvalue()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lcm.html#torch.Tensor.lcm" title="torch.Tensor.lcm"><code>Tensor.lcm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lcm.html#torch.lcm" title="torch.lcm"><code>torch.lcm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lcm_.html#torch.Tensor.lcm_" title="torch.Tensor.lcm_"><code>Tensor.lcm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lcm.html#torch.Tensor.lcm" title="torch.Tensor.lcm"><code>lcm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ldexp.html#torch.Tensor.ldexp" title="torch.Tensor.ldexp"><code>Tensor.ldexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ldexp.html#torch.ldexp" title="torch.ldexp"><code>torch.ldexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ldexp_.html#torch.Tensor.ldexp_" title="torch.Tensor.ldexp_"><code>Tensor.ldexp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ldexp.html#torch.Tensor.ldexp" title="torch.Tensor.ldexp"><code>ldexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.le.html#torch.Tensor.le" title="torch.Tensor.le"><code>Tensor.le</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.le.html#torch.le" title="torch.le"><code>torch.le()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.le_.html#torch.Tensor.le_" title="torch.Tensor.le_"><code>Tensor.le_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.le.html#torch.Tensor.le" title="torch.Tensor.le"><code>le()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less_equal.html#torch.Tensor.less_equal" title="torch.Tensor.less_equal"><code>Tensor.less_equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.less_equal.html#torch.less_equal" title="torch.less_equal"><code>torch.less_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less_equal_.html#torch.Tensor.less_equal_" title="torch.Tensor.less_equal_"><code>Tensor.less_equal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.less_equal.html#torch.Tensor.less_equal" title="torch.Tensor.less_equal"><code>less_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lerp.html#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>Tensor.lerp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lerp.html#torch.lerp" title="torch.lerp"><code>torch.lerp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lerp_.html#torch.Tensor.lerp_" title="torch.Tensor.lerp_"><code>Tensor.lerp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lerp.html#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>lerp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lgamma.html#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code>Tensor.lgamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lgamma.html#torch.lgamma" title="torch.lgamma"><code>torch.lgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lgamma_.html#torch.Tensor.lgamma_" title="torch.Tensor.lgamma_"><code>Tensor.lgamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lgamma.html#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code>lgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log.html#torch.Tensor.log" title="torch.Tensor.log"><code>Tensor.log</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log.html#torch.log" title="torch.log"><code>torch.log()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log_.html#torch.Tensor.log_" title="torch.Tensor.log_"><code>Tensor.log_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log.html#torch.Tensor.log" title="torch.Tensor.log"><code>log()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logdet.html#torch.Tensor.logdet" title="torch.Tensor.logdet"><code>Tensor.logdet</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logdet.html#torch.logdet" title="torch.logdet"><code>torch.logdet()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log10.html#torch.Tensor.log10" title="torch.Tensor.log10"><code>Tensor.log10</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log10.html#torch.log10" title="torch.log10"><code>torch.log10()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log10_.html#torch.Tensor.log10_" title="torch.Tensor.log10_"><code>Tensor.log10_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log10.html#torch.Tensor.log10" title="torch.Tensor.log10"><code>log10()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log1p.html#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>Tensor.log1p</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log1p.html#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log1p_.html#torch.Tensor.log1p_" title="torch.Tensor.log1p_"><code>Tensor.log1p_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log1p.html#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>log1p()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log2.html#torch.Tensor.log2" title="torch.Tensor.log2"><code>Tensor.log2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log2.html#torch.log2" title="torch.log2"><code>torch.log2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log2_.html#torch.Tensor.log2_" title="torch.Tensor.log2_"><code>Tensor.log2_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log2.html#torch.Tensor.log2" title="torch.Tensor.log2"><code>log2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log_normal_.html#torch.Tensor.log_normal_" title="torch.Tensor.log_normal_"><code>Tensor.log_normal_</code></a></p></td> <td><p>Fills <code>self</code> tensor with numbers samples from the log-normal distribution parameterized by the given mean <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span></span></span> and standard deviation <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span></span></span>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logaddexp.html#torch.Tensor.logaddexp" title="torch.Tensor.logaddexp"><code>Tensor.logaddexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logaddexp.html#torch.logaddexp" title="torch.logaddexp"><code>torch.logaddexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logaddexp2.html#torch.Tensor.logaddexp2" title="torch.Tensor.logaddexp2"><code>Tensor.logaddexp2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logaddexp2.html#torch.logaddexp2" title="torch.logaddexp2"><code>torch.logaddexp2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logsumexp.html#torch.Tensor.logsumexp" title="torch.Tensor.logsumexp"><code>Tensor.logsumexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logsumexp.html#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_and.html#torch.Tensor.logical_and" title="torch.Tensor.logical_and"><code>Tensor.logical_and</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_and.html#torch.logical_and" title="torch.logical_and"><code>torch.logical_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_and_.html#torch.Tensor.logical_and_" title="torch.Tensor.logical_and_"><code>Tensor.logical_and_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_and.html#torch.Tensor.logical_and" title="torch.Tensor.logical_and"><code>logical_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_not.html#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code>Tensor.logical_not</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_not.html#torch.logical_not" title="torch.logical_not"><code>torch.logical_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_not_.html#torch.Tensor.logical_not_" title="torch.Tensor.logical_not_"><code>Tensor.logical_not_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_not.html#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code>logical_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_or.html#torch.Tensor.logical_or" title="torch.Tensor.logical_or"><code>Tensor.logical_or</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_or.html#torch.logical_or" title="torch.logical_or"><code>torch.logical_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_or_.html#torch.Tensor.logical_or_" title="torch.Tensor.logical_or_"><code>Tensor.logical_or_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_or.html#torch.Tensor.logical_or" title="torch.Tensor.logical_or"><code>logical_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_xor.html#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code>Tensor.logical_xor</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_xor.html#torch.logical_xor" title="torch.logical_xor"><code>torch.logical_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_xor_.html#torch.Tensor.logical_xor_" title="torch.Tensor.logical_xor_"><code>Tensor.logical_xor_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_xor.html#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code>logical_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logit.html#torch.Tensor.logit" title="torch.Tensor.logit"><code>Tensor.logit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logit.html#torch.logit" title="torch.logit"><code>torch.logit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logit_.html#torch.Tensor.logit_" title="torch.Tensor.logit_"><code>Tensor.logit_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logit.html#torch.Tensor.logit" title="torch.Tensor.logit"><code>logit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.long.html#torch.Tensor.long" title="torch.Tensor.long"><code>Tensor.long</code></a></p></td> <td><p><code>self.long()</code> is equivalent to <code>self.to(torch.int64)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lt.html#torch.Tensor.lt" title="torch.Tensor.lt"><code>Tensor.lt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lt.html#torch.lt" title="torch.lt"><code>torch.lt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lt_.html#torch.Tensor.lt_" title="torch.Tensor.lt_"><code>Tensor.lt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lt.html#torch.Tensor.lt" title="torch.Tensor.lt"><code>lt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less.html#torch.Tensor.less" title="torch.Tensor.less"><code>Tensor.less</code></a></p></td> <td><p>lt(other) -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less_.html#torch.Tensor.less_" title="torch.Tensor.less_"><code>Tensor.less_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.less.html#torch.Tensor.less" title="torch.Tensor.less"><code>less()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lu.html#torch.Tensor.lu" title="torch.Tensor.lu"><code>Tensor.lu</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lu.html#torch.lu" title="torch.lu"><code>torch.lu()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lu_solve.html#torch.Tensor.lu_solve" title="torch.Tensor.lu_solve"><code>Tensor.lu_solve</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lu_solve.html#torch.lu_solve" title="torch.lu_solve"><code>torch.lu_solve()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.as_subclass.html#torch.Tensor.as_subclass" title="torch.Tensor.as_subclass"><code>Tensor.as_subclass</code></a></p></td> <td><p>Makes a <code>cls</code> instance with the same data pointer as <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.map_.html#torch.Tensor.map_" title="torch.Tensor.map_"><code>Tensor.map_</code></a></p></td> <td><p>Applies <code>callable</code> for each element in <code>self</code> tensor and the given <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> and stores the results in <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_scatter_.html#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code>Tensor.masked_scatter_</code></a></p></td> <td><p>Copies elements from <code>source</code> into <code>self</code> tensor at positions where the <code>mask</code> is True.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_scatter.html#torch.Tensor.masked_scatter" title="torch.Tensor.masked_scatter"><code>Tensor.masked_scatter</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.masked_scatter_.html#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code>torch.Tensor.masked_scatter_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_fill_.html#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code>Tensor.masked_fill_</code></a></p></td> <td><p>Fills elements of <code>self</code> tensor with <code>value</code> where <code>mask</code> is True.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_fill.html#torch.Tensor.masked_fill" title="torch.Tensor.masked_fill"><code>Tensor.masked_fill</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.masked_fill_.html#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code>torch.Tensor.masked_fill_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_select.html#torch.Tensor.masked_select" title="torch.Tensor.masked_select"><code>Tensor.masked_select</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.masked_select.html#torch.masked_select" title="torch.masked_select"><code>torch.masked_select()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.matmul.html#torch.Tensor.matmul" title="torch.Tensor.matmul"><code>Tensor.matmul</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.matmul.html#torch.matmul" title="torch.matmul"><code>torch.matmul()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.matrix_power.html#torch.Tensor.matrix_power" title="torch.Tensor.matrix_power"><code>Tensor.matrix_power</code></a></p></td> <td>

<div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="generated/torch.tensor.matrix_power.html#torch.Tensor.matrix_power" title="torch.Tensor.matrix_power"><code>matrix_power()</code></a> is deprecated, use <a class="reference internal" href="generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power" title="torch.linalg.matrix_power"><code>torch.linalg.matrix_power()</code></a> instead.</p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.matrix_exp.html#torch.Tensor.matrix_exp" title="torch.Tensor.matrix_exp"><code>Tensor.matrix_exp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.matrix_exp.html#torch.matrix_exp" title="torch.matrix_exp"><code>torch.matrix_exp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.max.html#torch.Tensor.max" title="torch.Tensor.max"><code>Tensor.max</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.max.html#torch.max" title="torch.max"><code>torch.max()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.maximum.html#torch.Tensor.maximum" title="torch.Tensor.maximum"><code>Tensor.maximum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.maximum.html#torch.maximum" title="torch.maximum"><code>torch.maximum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mean.html#torch.Tensor.mean" title="torch.Tensor.mean"><code>Tensor.mean</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mean.html#torch.mean" title="torch.mean"><code>torch.mean()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nanmean.html#torch.Tensor.nanmean" title="torch.Tensor.nanmean"><code>Tensor.nanmean</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nanmean.html#torch.nanmean" title="torch.nanmean"><code>torch.nanmean()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.median.html#torch.Tensor.median" title="torch.Tensor.median"><code>Tensor.median</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.median.html#torch.median" title="torch.median"><code>torch.median()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nanmedian.html#torch.Tensor.nanmedian" title="torch.Tensor.nanmedian"><code>Tensor.nanmedian</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nanmedian.html#torch.nanmedian" title="torch.nanmedian"><code>torch.nanmedian()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.min.html#torch.Tensor.min" title="torch.Tensor.min"><code>Tensor.min</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.min.html#torch.min" title="torch.min"><code>torch.min()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.minimum.html#torch.Tensor.minimum" title="torch.Tensor.minimum"><code>Tensor.minimum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.minimum.html#torch.minimum" title="torch.minimum"><code>torch.minimum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mm.html#torch.Tensor.mm" title="torch.Tensor.mm"><code>Tensor.mm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mm.html#torch.mm" title="torch.mm"><code>torch.mm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.smm.html#torch.Tensor.smm" title="torch.Tensor.smm"><code>Tensor.smm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.smm.html#torch.smm" title="torch.smm"><code>torch.smm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mode.html#torch.Tensor.mode" title="torch.Tensor.mode"><code>Tensor.mode</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mode.html#torch.mode" title="torch.mode"><code>torch.mode()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.movedim.html#torch.Tensor.movedim" title="torch.Tensor.movedim"><code>Tensor.movedim</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.movedim.html#torch.movedim" title="torch.movedim"><code>torch.movedim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.moveaxis.html#torch.Tensor.moveaxis" title="torch.Tensor.moveaxis"><code>Tensor.moveaxis</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.moveaxis.html#torch.moveaxis" title="torch.moveaxis"><code>torch.moveaxis()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.msort.html#torch.Tensor.msort" title="torch.Tensor.msort"><code>Tensor.msort</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.msort.html#torch.msort" title="torch.msort"><code>torch.msort()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mul.html#torch.Tensor.mul" title="torch.Tensor.mul"><code>Tensor.mul</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mul.html#torch.mul" title="torch.mul"><code>torch.mul()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mul_.html#torch.Tensor.mul_" title="torch.Tensor.mul_"><code>Tensor.mul_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.mul.html#torch.Tensor.mul" title="torch.Tensor.mul"><code>mul()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.multiply.html#torch.Tensor.multiply" title="torch.Tensor.multiply"><code>Tensor.multiply</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.multiply.html#torch.multiply" title="torch.multiply"><code>torch.multiply()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.multiply_.html#torch.Tensor.multiply_" title="torch.Tensor.multiply_"><code>Tensor.multiply_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.multiply.html#torch.Tensor.multiply" title="torch.Tensor.multiply"><code>multiply()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.multinomial.html#torch.Tensor.multinomial" title="torch.Tensor.multinomial"><code>Tensor.multinomial</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.multinomial.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mv.html#torch.Tensor.mv" title="torch.Tensor.mv"><code>Tensor.mv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mv.html#torch.mv" title="torch.mv"><code>torch.mv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mvlgamma.html#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>Tensor.mvlgamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mvlgamma.html#torch.mvlgamma" title="torch.mvlgamma"><code>torch.mvlgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mvlgamma_.html#torch.Tensor.mvlgamma_" title="torch.Tensor.mvlgamma_"><code>Tensor.mvlgamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.mvlgamma.html#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>mvlgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nansum.html#torch.Tensor.nansum" title="torch.Tensor.nansum"><code>Tensor.nansum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nansum.html#torch.nansum" title="torch.nansum"><code>torch.nansum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.narrow.html#torch.Tensor.narrow" title="torch.Tensor.narrow"><code>Tensor.narrow</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.narrow.html#torch.narrow" title="torch.narrow"><code>torch.narrow()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.narrow_copy.html#torch.Tensor.narrow_copy" title="torch.Tensor.narrow_copy"><code>Tensor.narrow_copy</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.narrow_copy.html#torch.narrow_copy" title="torch.narrow_copy"><code>torch.narrow_copy()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ndimension.html#torch.Tensor.ndimension" title="torch.Tensor.ndimension"><code>Tensor.ndimension</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.dim.html#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nan_to_num.html#torch.Tensor.nan_to_num" title="torch.Tensor.nan_to_num"><code>Tensor.nan_to_num</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nan_to_num.html#torch.nan_to_num" title="torch.nan_to_num"><code>torch.nan_to_num()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nan_to_num_.html#torch.Tensor.nan_to_num_" title="torch.Tensor.nan_to_num_"><code>Tensor.nan_to_num_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.nan_to_num.html#torch.Tensor.nan_to_num" title="torch.Tensor.nan_to_num"><code>nan_to_num()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ne.html#torch.Tensor.ne" title="torch.Tensor.ne"><code>Tensor.ne</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ne.html#torch.ne" title="torch.ne"><code>torch.ne()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ne_.html#torch.Tensor.ne_" title="torch.Tensor.ne_"><code>Tensor.ne_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ne.html#torch.Tensor.ne" title="torch.Tensor.ne"><code>ne()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.not_equal.html#torch.Tensor.not_equal" title="torch.Tensor.not_equal"><code>Tensor.not_equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.not_equal.html#torch.not_equal" title="torch.not_equal"><code>torch.not_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.not_equal_.html#torch.Tensor.not_equal_" title="torch.Tensor.not_equal_"><code>Tensor.not_equal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.not_equal.html#torch.Tensor.not_equal" title="torch.Tensor.not_equal"><code>not_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.neg.html#torch.Tensor.neg" title="torch.Tensor.neg"><code>Tensor.neg</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.neg.html#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.neg_.html#torch.Tensor.neg_" title="torch.Tensor.neg_"><code>Tensor.neg_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.neg.html#torch.Tensor.neg" title="torch.Tensor.neg"><code>neg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.negative.html#torch.Tensor.negative" title="torch.Tensor.negative"><code>Tensor.negative</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.negative.html#torch.negative" title="torch.negative"><code>torch.negative()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.negative_.html#torch.Tensor.negative_" title="torch.Tensor.negative_"><code>Tensor.negative_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.negative.html#torch.Tensor.negative" title="torch.Tensor.negative"><code>negative()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nelement.html#torch.Tensor.nelement" title="torch.Tensor.nelement"><code>Tensor.nelement</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.numel.html#torch.Tensor.numel" title="torch.Tensor.numel"><code>numel()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nextafter.html#torch.Tensor.nextafter" title="torch.Tensor.nextafter"><code>Tensor.nextafter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nextafter.html#torch.nextafter" title="torch.nextafter"><code>torch.nextafter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nextafter_.html#torch.Tensor.nextafter_" title="torch.Tensor.nextafter_"><code>Tensor.nextafter_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.nextafter.html#torch.Tensor.nextafter" title="torch.Tensor.nextafter"><code>nextafter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nonzero.html#torch.Tensor.nonzero" title="torch.Tensor.nonzero"><code>Tensor.nonzero</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nonzero.html#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.norm.html#torch.Tensor.norm" title="torch.Tensor.norm"><code>Tensor.norm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.norm.html#torch.norm" title="torch.norm"><code>torch.norm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.normal_.html#torch.Tensor.normal_" title="torch.Tensor.normal_"><code>Tensor.normal_</code></a></p></td> <td><p>Fills <code>self</code> tensor with elements samples from the normal distribution parameterized by <a class="reference internal" href="generated/torch.mean.html#torch.mean" title="torch.mean"><code>mean</code></a> and <a class="reference internal" href="generated/torch.std.html#torch.std" title="torch.std"><code>std</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.numel.html#torch.Tensor.numel" title="torch.Tensor.numel"><code>Tensor.numel</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.numel.html#torch.numel" title="torch.numel"><code>torch.numel()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.numpy.html#torch.Tensor.numpy" title="torch.Tensor.numpy"><code>Tensor.numpy</code></a></p></td> <td><p>Returns the tensor as a NumPy <code>ndarray</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.orgqr.html#torch.Tensor.orgqr" title="torch.Tensor.orgqr"><code>Tensor.orgqr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.orgqr.html#torch.orgqr" title="torch.orgqr"><code>torch.orgqr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ormqr.html#torch.Tensor.ormqr" title="torch.Tensor.ormqr"><code>Tensor.ormqr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ormqr.html#torch.ormqr" title="torch.ormqr"><code>torch.ormqr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.outer.html#torch.Tensor.outer" title="torch.Tensor.outer"><code>Tensor.outer</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.outer.html#torch.outer" title="torch.outer"><code>torch.outer()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.permute.html#torch.Tensor.permute" title="torch.Tensor.permute"><code>Tensor.permute</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.permute.html#torch.permute" title="torch.permute"><code>torch.permute()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pin_memory.html#torch.Tensor.pin_memory" title="torch.Tensor.pin_memory"><code>Tensor.pin_memory</code></a></p></td> <td><p>Copies the tensor to pinned memory, if it's not already pinned.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pinverse.html#torch.Tensor.pinverse" title="torch.Tensor.pinverse"><code>Tensor.pinverse</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.pinverse.html#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.polygamma.html#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code>Tensor.polygamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.polygamma.html#torch.polygamma" title="torch.polygamma"><code>torch.polygamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.polygamma_.html#torch.Tensor.polygamma_" title="torch.Tensor.polygamma_"><code>Tensor.polygamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.polygamma.html#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code>polygamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.positive.html#torch.Tensor.positive" title="torch.Tensor.positive"><code>Tensor.positive</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.positive.html#torch.positive" title="torch.positive"><code>torch.positive()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pow.html#torch.Tensor.pow" title="torch.Tensor.pow"><code>Tensor.pow</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.pow.html#torch.pow" title="torch.pow"><code>torch.pow()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pow_.html#torch.Tensor.pow_" title="torch.Tensor.pow_"><code>Tensor.pow_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.pow.html#torch.Tensor.pow" title="torch.Tensor.pow"><code>pow()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.prod.html#torch.Tensor.prod" title="torch.Tensor.prod"><code>Tensor.prod</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.prod.html#torch.prod" title="torch.prod"><code>torch.prod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.put_.html#torch.Tensor.put_" title="torch.Tensor.put_"><code>Tensor.put_</code></a></p></td> <td><p>Copies the elements from <code>source</code> into the positions specified by <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.qr.html#torch.Tensor.qr" title="torch.Tensor.qr"><code>Tensor.qr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.qr.html#torch.qr" title="torch.qr"><code>torch.qr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.qscheme.html#torch.Tensor.qscheme" title="torch.Tensor.qscheme"><code>Tensor.qscheme</code></a></p></td> <td><p>Returns the quantization scheme of a given QTensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.quantile.html#torch.Tensor.quantile" title="torch.Tensor.quantile"><code>Tensor.quantile</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.quantile.html#torch.quantile" title="torch.quantile"><code>torch.quantile()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nanquantile.html#torch.Tensor.nanquantile" title="torch.Tensor.nanquantile"><code>Tensor.nanquantile</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nanquantile.html#torch.nanquantile" title="torch.nanquantile"><code>torch.nanquantile()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_scale.html#torch.Tensor.q_scale" title="torch.Tensor.q_scale"><code>Tensor.q_scale</code></a></p></td> <td><p>Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer().</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_zero_point.html#torch.Tensor.q_zero_point" title="torch.Tensor.q_zero_point"><code>Tensor.q_zero_point</code></a></p></td> <td><p>Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer().</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_per_channel_scales.html#torch.Tensor.q_per_channel_scales" title="torch.Tensor.q_per_channel_scales"><code>Tensor.q_per_channel_scales</code></a></p></td> <td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_per_channel_zero_points.html#torch.Tensor.q_per_channel_zero_points" title="torch.Tensor.q_per_channel_zero_points"><code>Tensor.q_per_channel_zero_points</code></a></p></td> <td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_per_channel_axis.html#torch.Tensor.q_per_channel_axis" title="torch.Tensor.q_per_channel_axis"><code>Tensor.q_per_channel_axis</code></a></p></td> <td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rad2deg.html#torch.Tensor.rad2deg" title="torch.Tensor.rad2deg"><code>Tensor.rad2deg</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.rad2deg.html#torch.rad2deg" title="torch.rad2deg"><code>torch.rad2deg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.random_.html#torch.Tensor.random_" title="torch.Tensor.random_"><code>Tensor.random_</code></a></p></td> <td><p>Fills <code>self</code> tensor with numbers sampled from the discrete uniform distribution over <code>[from, to - 1]</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ravel.html#torch.Tensor.ravel" title="torch.Tensor.ravel"><code>Tensor.ravel</code></a></p></td> <td><p>see <a class="reference internal" href="generated/torch.ravel.html#torch.ravel" title="torch.ravel"><code>torch.ravel()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reciprocal.html#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>Tensor.reciprocal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.reciprocal.html#torch.reciprocal" title="torch.reciprocal"><code>torch.reciprocal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reciprocal_.html#torch.Tensor.reciprocal_" title="torch.Tensor.reciprocal_"><code>Tensor.reciprocal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.reciprocal.html#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>reciprocal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.record_stream.html#torch.Tensor.record_stream" title="torch.Tensor.record_stream"><code>Tensor.record_stream</code></a></p></td> <td><p>Ensures that the tensor memory is not reused for another tensor until all current work queued on <code>stream</code> are complete.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.register_hook.html#torch.Tensor.register_hook" title="torch.Tensor.register_hook"><code>Tensor.register_hook</code></a></p></td> <td><p>Registers a backward hook.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.register_post_accumulate_grad_hook.html#torch.Tensor.register_post_accumulate_grad_hook" title="torch.Tensor.register_post_accumulate_grad_hook"><code>Tensor.register_post_accumulate_grad_hook</code></a></p></td> <td><p>Registers a backward hook that runs after grad accumulation.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.remainder.html#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>Tensor.remainder</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.remainder.html#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.remainder_.html#torch.Tensor.remainder_" title="torch.Tensor.remainder_"><code>Tensor.remainder_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.remainder.html#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>remainder()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.renorm.html#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>Tensor.renorm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.renorm.html#torch.renorm" title="torch.renorm"><code>torch.renorm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.renorm_.html#torch.Tensor.renorm_" title="torch.Tensor.renorm_"><code>Tensor.renorm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.renorm.html#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>renorm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.repeat.html#torch.Tensor.repeat" title="torch.Tensor.repeat"><code>Tensor.repeat</code></a></p></td> <td><p>Repeats this tensor along the specified dimensions.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.repeat_interleave.html#torch.Tensor.repeat_interleave" title="torch.Tensor.repeat_interleave"><code>Tensor.repeat_interleave</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.repeat_interleave.html#torch.repeat_interleave" title="torch.repeat_interleave"><code>torch.repeat_interleave()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.requires_grad.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>Tensor.requires_grad</code></a></p></td> <td><p>Is <code>True</code> if gradients need to be computed for this Tensor, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.requires_grad_.html#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>Tensor.requires_grad_</code></a></p></td> <td><p>Change if autograd should record operations on this tensor: sets this tensor's <code>requires_grad</code> attribute in-place.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reshape.html#torch.Tensor.reshape" title="torch.Tensor.reshape"><code>Tensor.reshape</code></a></p></td> <td><p>Returns a tensor with the same data and number of elements as <code>self</code> but with the specified shape.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reshape_as.html#torch.Tensor.reshape_as" title="torch.Tensor.reshape_as"><code>Tensor.reshape_as</code></a></p></td> <td><p>Returns this tensor as the same shape as <code>other</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resize_.html#torch.Tensor.resize_" title="torch.Tensor.resize_"><code>Tensor.resize_</code></a></p></td> <td><p>Resizes <code>self</code> tensor to the specified size.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resize_as_.html#torch.Tensor.resize_as_" title="torch.Tensor.resize_as_"><code>Tensor.resize_as_</code></a></p></td> <td><p>Resizes the <code>self</code> tensor to be the same size as the specified <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code>tensor</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.retain_grad.html#torch.Tensor.retain_grad" title="torch.Tensor.retain_grad"><code>Tensor.retain_grad</code></a></p></td> <td><p>Enables this Tensor to have their <code>grad</code> populated during <code>backward()</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.retains_grad.html#torch.Tensor.retains_grad" title="torch.Tensor.retains_grad"><code>Tensor.retains_grad</code></a></p></td> <td><p>Is <code>True</code> if this Tensor is non-leaf and its <code>grad</code> is enabled to be populated during <code>backward()</code>, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.roll.html#torch.Tensor.roll" title="torch.Tensor.roll"><code>Tensor.roll</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.roll.html#torch.roll" title="torch.roll"><code>torch.roll()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rot90.html#torch.Tensor.rot90" title="torch.Tensor.rot90"><code>Tensor.rot90</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.rot90.html#torch.rot90" title="torch.rot90"><code>torch.rot90()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.round.html#torch.Tensor.round" title="torch.Tensor.round"><code>Tensor.round</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.round.html#torch.round" title="torch.round"><code>torch.round()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.round_.html#torch.Tensor.round_" title="torch.Tensor.round_"><code>Tensor.round_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.round.html#torch.Tensor.round" title="torch.Tensor.round"><code>round()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rsqrt.html#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>Tensor.rsqrt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.rsqrt.html#torch.rsqrt" title="torch.rsqrt"><code>torch.rsqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rsqrt_.html#torch.Tensor.rsqrt_" title="torch.Tensor.rsqrt_"><code>Tensor.rsqrt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.rsqrt.html#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>rsqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter.html#torch.Tensor.scatter" title="torch.Tensor.scatter"><code>Tensor.scatter</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>torch.Tensor.scatter_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>Tensor.scatter_</code></a></p></td> <td><p>Writes all values from the tensor <code>src</code> into <code>self</code> at the indices specified in the <code>index</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_add_.html#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>Tensor.scatter_add_</code></a></p></td> <td><p>Adds all values from the tensor <code>src</code> into <code>self</code> at the indices specified in the <code>index</code> tensor in a similar fashion as <a class="reference internal" href="generated/torch.tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>scatter_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_add.html#torch.Tensor.scatter_add" title="torch.Tensor.scatter_add"><code>Tensor.scatter_add</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.scatter_add_.html#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>torch.Tensor.scatter_add_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code>Tensor.scatter_reduce_</code></a></p></td> <td><p>Reduces all values from the <code>src</code> tensor to the indices specified in the <code>index</code> tensor in the <code>self</code> tensor using the applied reduction defined via the <code>reduce</code> argument (<code>"sum"</code>, <code>"prod"</code>, <code>"mean"</code>, <code>"amax"</code>, <code>"amin"</code>).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_reduce.html#torch.Tensor.scatter_reduce" title="torch.Tensor.scatter_reduce"><code>Tensor.scatter_reduce</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code>torch.Tensor.scatter_reduce_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.select.html#torch.Tensor.select" title="torch.Tensor.select"><code>Tensor.select</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.select.html#torch.select" title="torch.select"><code>torch.select()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.select_scatter.html#torch.Tensor.select_scatter" title="torch.Tensor.select_scatter"><code>Tensor.select_scatter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.select_scatter.html#torch.select_scatter" title="torch.select_scatter"><code>torch.select_scatter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.set_.html#torch.Tensor.set_" title="torch.Tensor.set_"><code>Tensor.set_</code></a></p></td> <td><p>Sets the underlying storage, size, and strides.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.share_memory_.html#torch.Tensor.share_memory_" title="torch.Tensor.share_memory_"><code>Tensor.share_memory_</code></a></p></td> <td><p>Moves the underlying storage to shared memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.short.html#torch.Tensor.short" title="torch.Tensor.short"><code>Tensor.short</code></a></p></td> <td><p><code>self.short()</code> is equivalent to <code>self.to(torch.int16)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sigmoid.html#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>Tensor.sigmoid</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sigmoid.html#torch.sigmoid" title="torch.sigmoid"><code>torch.sigmoid()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sigmoid_.html#torch.Tensor.sigmoid_" title="torch.Tensor.sigmoid_"><code>Tensor.sigmoid_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sigmoid.html#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>sigmoid()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sign.html#torch.Tensor.sign" title="torch.Tensor.sign"><code>Tensor.sign</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sign.html#torch.sign" title="torch.sign"><code>torch.sign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sign_.html#torch.Tensor.sign_" title="torch.Tensor.sign_"><code>Tensor.sign_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sign.html#torch.Tensor.sign" title="torch.Tensor.sign"><code>sign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.signbit.html#torch.Tensor.signbit" title="torch.Tensor.signbit"><code>Tensor.signbit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.signbit.html#torch.signbit" title="torch.signbit"><code>torch.signbit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sgn.html#torch.Tensor.sgn" title="torch.Tensor.sgn"><code>Tensor.sgn</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sgn.html#torch.sgn" title="torch.sgn"><code>torch.sgn()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sgn_.html#torch.Tensor.sgn_" title="torch.Tensor.sgn_"><code>Tensor.sgn_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sgn.html#torch.Tensor.sgn" title="torch.Tensor.sgn"><code>sgn()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sin.html#torch.Tensor.sin" title="torch.Tensor.sin"><code>Tensor.sin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sin.html#torch.sin" title="torch.sin"><code>torch.sin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sin_.html#torch.Tensor.sin_" title="torch.Tensor.sin_"><code>Tensor.sin_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sin.html#torch.Tensor.sin" title="torch.Tensor.sin"><code>sin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinc.html#torch.Tensor.sinc" title="torch.Tensor.sinc"><code>Tensor.sinc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sinc.html#torch.sinc" title="torch.sinc"><code>torch.sinc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinc_.html#torch.Tensor.sinc_" title="torch.Tensor.sinc_"><code>Tensor.sinc_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sinc.html#torch.Tensor.sinc" title="torch.Tensor.sinc"><code>sinc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinh.html#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>Tensor.sinh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sinh.html#torch.sinh" title="torch.sinh"><code>torch.sinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinh_.html#torch.Tensor.sinh_" title="torch.Tensor.sinh_"><code>Tensor.sinh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sinh.html#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>sinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asinh.html#torch.Tensor.asinh" title="torch.Tensor.asinh"><code>Tensor.asinh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.asinh.html#torch.asinh" title="torch.asinh"><code>torch.asinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asinh_.html#torch.Tensor.asinh_" title="torch.Tensor.asinh_"><code>Tensor.asinh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.asinh.html#torch.Tensor.asinh" title="torch.Tensor.asinh"><code>asinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsinh.html#torch.Tensor.arcsinh" title="torch.Tensor.arcsinh"><code>Tensor.arcsinh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arcsinh.html#torch.arcsinh" title="torch.arcsinh"><code>torch.arcsinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsinh_.html#torch.Tensor.arcsinh_" title="torch.Tensor.arcsinh_"><code>Tensor.arcsinh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arcsinh.html#torch.Tensor.arcsinh" title="torch.Tensor.arcsinh"><code>arcsinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.shape.html#torch.Tensor.shape" title="torch.Tensor.shape"><code>Tensor.shape</code></a></p></td> <td><p>Returns the size of the <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.size.html#torch.Tensor.size" title="torch.Tensor.size"><code>Tensor.size</code></a></p></td> <td><p>Returns the size of the <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.slogdet.html#torch.Tensor.slogdet" title="torch.Tensor.slogdet"><code>Tensor.slogdet</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.slogdet.html#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.slice_scatter.html#torch.Tensor.slice_scatter" title="torch.Tensor.slice_scatter"><code>Tensor.slice_scatter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.slice_scatter.html#torch.slice_scatter" title="torch.slice_scatter"><code>torch.slice_scatter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.softmax.html#torch.Tensor.softmax" title="torch.Tensor.softmax"><code>Tensor.softmax</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax"><code>torch.nn.functional.softmax()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sort.html#torch.Tensor.sort" title="torch.Tensor.sort"><code>Tensor.sort</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sort.html#torch.sort" title="torch.sort"><code>torch.sort()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.split.html#torch.Tensor.split" title="torch.Tensor.split"><code>Tensor.split</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.split.html#torch.split" title="torch.split"><code>torch.split()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sparse_mask.html#torch.Tensor.sparse_mask" title="torch.Tensor.sparse_mask"><code>Tensor.sparse_mask</code></a></p></td> <td><p>Returns a new <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> with values from a strided tensor <code>self</code> filtered by the indices of the sparse tensor <code>mask</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sparse_dim.html#torch.Tensor.sparse_dim" title="torch.Tensor.sparse_dim"><code>Tensor.sparse_dim</code></a></p></td> <td><p>Return the number of sparse dimensions in a <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sqrt.html#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>Tensor.sqrt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sqrt.html#torch.sqrt" title="torch.sqrt"><code>torch.sqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sqrt_.html#torch.Tensor.sqrt_" title="torch.Tensor.sqrt_"><code>Tensor.sqrt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sqrt.html#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>sqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.square.html#torch.Tensor.square" title="torch.Tensor.square"><code>Tensor.square</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.square.html#torch.square" title="torch.square"><code>torch.square()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.square_.html#torch.Tensor.square_" title="torch.Tensor.square_"><code>Tensor.square_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.square.html#torch.Tensor.square" title="torch.Tensor.square"><code>square()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.squeeze.html#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>Tensor.squeeze</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.squeeze.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.squeeze_.html#torch.Tensor.squeeze_" title="torch.Tensor.squeeze_"><code>Tensor.squeeze_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.squeeze.html#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>squeeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.std.html#torch.Tensor.std" title="torch.Tensor.std"><code>Tensor.std</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.std.html#torch.std" title="torch.std"><code>torch.std()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.stft.html#torch.Tensor.stft" title="torch.Tensor.stft"><code>Tensor.stft</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.stft.html#torch.stft" title="torch.stft"><code>torch.stft()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.storage.html#torch.Tensor.storage" title="torch.Tensor.storage"><code>Tensor.storage</code></a></p></td> <td><p>Returns the underlying <a class="reference internal" href="storage.html#torch.TypedStorage" title="torch.TypedStorage"><code>TypedStorage</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.untyped_storage.html#torch.Tensor.untyped_storage" title="torch.Tensor.untyped_storage"><code>Tensor.untyped_storage</code></a></p></td> <td><p>Returns the underlying <a class="reference internal" href="storage.html#torch.UntypedStorage" title="torch.UntypedStorage"><code>UntypedStorage</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.storage_offset.html#torch.Tensor.storage_offset" title="torch.Tensor.storage_offset"><code>Tensor.storage_offset</code></a></p></td> <td><p>Returns <code>self</code> tensor's offset in the underlying storage in terms of number of storage elements (not bytes).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.storage_type.html#torch.Tensor.storage_type" title="torch.Tensor.storage_type"><code>Tensor.storage_type</code></a></p></td> <td><p>Returns the type of the underlying storage.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.stride.html#torch.Tensor.stride" title="torch.Tensor.stride"><code>Tensor.stride</code></a></p></td> <td><p>Returns the stride of <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sub.html#torch.Tensor.sub" title="torch.Tensor.sub"><code>Tensor.sub</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sub.html#torch.sub" title="torch.sub"><code>torch.sub()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sub_.html#torch.Tensor.sub_" title="torch.Tensor.sub_"><code>Tensor.sub_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sub.html#torch.Tensor.sub" title="torch.Tensor.sub"><code>sub()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.subtract.html#torch.Tensor.subtract" title="torch.Tensor.subtract"><code>Tensor.subtract</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.subtract.html#torch.subtract" title="torch.subtract"><code>torch.subtract()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.subtract_.html#torch.Tensor.subtract_" title="torch.Tensor.subtract_"><code>Tensor.subtract_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.subtract.html#torch.Tensor.subtract" title="torch.Tensor.subtract"><code>subtract()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sum.html#torch.Tensor.sum" title="torch.Tensor.sum"><code>Tensor.sum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sum.html#torch.sum" title="torch.sum"><code>torch.sum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sum_to_size.html#torch.Tensor.sum_to_size" title="torch.Tensor.sum_to_size"><code>Tensor.sum_to_size</code></a></p></td> <td><p>Sum <code>this</code> tensor to <code>size</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.svd.html#torch.Tensor.svd" title="torch.Tensor.svd"><code>Tensor.svd</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.svd.html#torch.svd" title="torch.svd"><code>torch.svd()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.swapaxes.html#torch.Tensor.swapaxes" title="torch.Tensor.swapaxes"><code>Tensor.swapaxes</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.swapaxes.html#torch.swapaxes" title="torch.swapaxes"><code>torch.swapaxes()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.swapdims.html#torch.Tensor.swapdims" title="torch.Tensor.swapdims"><code>Tensor.swapdims</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.swapdims.html#torch.swapdims" title="torch.swapdims"><code>torch.swapdims()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.t.html#torch.Tensor.t" title="torch.Tensor.t"><code>Tensor.t</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.t.html#torch.t" title="torch.t"><code>torch.t()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.t_.html#torch.Tensor.t_" title="torch.Tensor.t_"><code>Tensor.t_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.t.html#torch.Tensor.t" title="torch.Tensor.t"><code>t()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tensor_split.html#torch.Tensor.tensor_split" title="torch.Tensor.tensor_split"><code>Tensor.tensor_split</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tensor_split.html#torch.tensor_split" title="torch.tensor_split"><code>torch.tensor_split()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tile.html#torch.Tensor.tile" title="torch.Tensor.tile"><code>Tensor.tile</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tile.html#torch.tile" title="torch.tile"><code>torch.tile()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to.html#torch.Tensor.to" title="torch.Tensor.to"><code>Tensor.to</code></a></p></td> <td><p>Performs Tensor dtype and/or device conversion.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_mkldnn.html#torch.Tensor.to_mkldnn" title="torch.Tensor.to_mkldnn"><code>Tensor.to_mkldnn</code></a></p></td> <td><p>Returns a copy of the tensor in <code>torch.mkldnn</code> layout.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.take.html#torch.Tensor.take" title="torch.Tensor.take"><code>Tensor.take</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.take.html#torch.take" title="torch.take"><code>torch.take()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.take_along_dim.html#torch.Tensor.take_along_dim" title="torch.Tensor.take_along_dim"><code>Tensor.take_along_dim</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.take_along_dim.html#torch.take_along_dim" title="torch.take_along_dim"><code>torch.take_along_dim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tan.html#torch.Tensor.tan" title="torch.Tensor.tan"><code>Tensor.tan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tan.html#torch.tan" title="torch.tan"><code>torch.tan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tan_.html#torch.Tensor.tan_" title="torch.Tensor.tan_"><code>Tensor.tan_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.tan.html#torch.Tensor.tan" title="torch.Tensor.tan"><code>tan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tanh.html#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>Tensor.tanh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tanh.html#torch.tanh" title="torch.tanh"><code>torch.tanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tanh_.html#torch.Tensor.tanh_" title="torch.Tensor.tanh_"><code>Tensor.tanh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.tanh.html#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>tanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atanh.html#torch.Tensor.atanh" title="torch.Tensor.atanh"><code>Tensor.atanh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.atanh.html#torch.atanh" title="torch.atanh"><code>torch.atanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atanh_.html#torch.Tensor.atanh_" title="torch.Tensor.atanh_"><code>Tensor.atanh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.atanh.html#torch.Tensor.atanh" title="torch.Tensor.atanh"><code>atanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctanh.html#torch.Tensor.arctanh" title="torch.Tensor.arctanh"><code>Tensor.arctanh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arctanh.html#torch.arctanh" title="torch.arctanh"><code>torch.arctanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctanh_.html#torch.Tensor.arctanh_" title="torch.Tensor.arctanh_"><code>Tensor.arctanh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arctanh.html#torch.Tensor.arctanh" title="torch.Tensor.arctanh"><code>arctanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tolist.html#torch.Tensor.tolist" title="torch.Tensor.tolist"><code>Tensor.tolist</code></a></p></td> <td><p>Returns the tensor as a (nested) list.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.topk.html#torch.Tensor.topk" title="torch.Tensor.topk"><code>Tensor.topk</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.topk.html#torch.topk" title="torch.topk"><code>torch.topk()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_dense.html#torch.Tensor.to_dense" title="torch.Tensor.to_dense"><code>Tensor.to_dense</code></a></p></td> <td><p>Creates a strided copy of <code>self</code> if <code>self</code> is not a strided tensor, otherwise returns <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse.html#torch.Tensor.to_sparse" title="torch.Tensor.to_sparse"><code>Tensor.to_sparse</code></a></p></td> <td><p>Returns a sparse copy of the tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_csr.html#torch.Tensor.to_sparse_csr" title="torch.Tensor.to_sparse_csr"><code>Tensor.to_sparse_csr</code></a></p></td> <td><p>Convert a tensor to compressed row storage format (CSR).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_csc.html#torch.Tensor.to_sparse_csc" title="torch.Tensor.to_sparse_csc"><code>Tensor.to_sparse_csc</code></a></p></td> <td><p>Convert a tensor to compressed column storage (CSC) format.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_bsr.html#torch.Tensor.to_sparse_bsr" title="torch.Tensor.to_sparse_bsr"><code>Tensor.to_sparse_bsr</code></a></p></td> <td><p>Convert a tensor to a block sparse row (BSR) storage format of given blocksize.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_bsc.html#torch.Tensor.to_sparse_bsc" title="torch.Tensor.to_sparse_bsc"><code>Tensor.to_sparse_bsc</code></a></p></td> <td><p>Convert a tensor to a block sparse column (BSC) storage format of given blocksize.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.trace.html#torch.Tensor.trace" title="torch.Tensor.trace"><code>Tensor.trace</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.trace.html#torch.trace" title="torch.trace"><code>torch.trace()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.transpose.html#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>Tensor.transpose</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.transpose.html#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.transpose_.html#torch.Tensor.transpose_" title="torch.Tensor.transpose_"><code>Tensor.transpose_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.transpose.html#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>transpose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.triangular_solve.html#torch.Tensor.triangular_solve" title="torch.Tensor.triangular_solve"><code>Tensor.triangular_solve</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.triangular_solve.html#torch.triangular_solve" title="torch.triangular_solve"><code>torch.triangular_solve()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tril.html#torch.Tensor.tril" title="torch.Tensor.tril"><code>Tensor.tril</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tril.html#torch.tril" title="torch.tril"><code>torch.tril()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tril_.html#torch.Tensor.tril_" title="torch.Tensor.tril_"><code>Tensor.tril_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.tril.html#torch.Tensor.tril" title="torch.Tensor.tril"><code>tril()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.triu.html#torch.Tensor.triu" title="torch.Tensor.triu"><code>Tensor.triu</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.triu.html#torch.triu" title="torch.triu"><code>torch.triu()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.triu_.html#torch.Tensor.triu_" title="torch.Tensor.triu_"><code>Tensor.triu_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.triu.html#torch.Tensor.triu" title="torch.Tensor.triu"><code>triu()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.true_divide.html#torch.Tensor.true_divide" title="torch.Tensor.true_divide"><code>Tensor.true_divide</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.true_divide.html#torch.true_divide" title="torch.true_divide"><code>torch.true_divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.true_divide_.html#torch.Tensor.true_divide_" title="torch.Tensor.true_divide_"><code>Tensor.true_divide_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.true_divide_.html#torch.Tensor.true_divide_" title="torch.Tensor.true_divide_"><code>true_divide_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.trunc.html#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>Tensor.trunc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.trunc.html#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.trunc_.html#torch.Tensor.trunc_" title="torch.Tensor.trunc_"><code>Tensor.trunc_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.trunc.html#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>trunc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.type.html#torch.Tensor.type" title="torch.Tensor.type"><code>Tensor.type</code></a></p></td> <td><p>Returns the type if <code>dtype</code> is not provided, else casts this object to the specified type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.type_as.html#torch.Tensor.type_as" title="torch.Tensor.type_as"><code>Tensor.type_as</code></a></p></td> <td><p>Returns this tensor cast to the type of the given tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unbind.html#torch.Tensor.unbind" title="torch.Tensor.unbind"><code>Tensor.unbind</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.unbind.html#torch.unbind" title="torch.unbind"><code>torch.unbind()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unflatten.html#torch.Tensor.unflatten" title="torch.Tensor.unflatten"><code>Tensor.unflatten</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.unflatten.html#torch.unflatten" title="torch.unflatten"><code>torch.unflatten()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unfold.html#torch.Tensor.unfold" title="torch.Tensor.unfold"><code>Tensor.unfold</code></a></p></td> <td><p>Returns a view of the original tensor which contains all slices of size <code>size</code> from <code>self</code> tensor in the dimension <code>dimension</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.uniform_.html#torch.Tensor.uniform_" title="torch.Tensor.uniform_"><code>Tensor.uniform_</code></a></p></td> <td><p>Fills <code>self</code> tensor with numbers sampled from the continuous uniform distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unique.html#torch.Tensor.unique" title="torch.Tensor.unique"><code>Tensor.unique</code></a></p></td> <td><p>Returns the unique elements of the input tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unique_consecutive.html#torch.Tensor.unique_consecutive" title="torch.Tensor.unique_consecutive"><code>Tensor.unique_consecutive</code></a></p></td> <td><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unsqueeze.html#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>Tensor.unsqueeze</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.unsqueeze.html#torch.unsqueeze" title="torch.unsqueeze"><code>torch.unsqueeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unsqueeze_.html#torch.Tensor.unsqueeze_" title="torch.Tensor.unsqueeze_"><code>Tensor.unsqueeze_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.unsqueeze.html#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>unsqueeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.values.html#torch.Tensor.values" title="torch.Tensor.values"><code>Tensor.values</code></a></p></td> <td><p>Return the values tensor of a <a class="reference internal" href="sparse.html#sparse-coo-docs"><span class="std std-ref">sparse COO tensor</span></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.var.html#torch.Tensor.var" title="torch.Tensor.var"><code>Tensor.var</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.var.html#torch.var" title="torch.var"><code>torch.var()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.vdot.html#torch.Tensor.vdot" title="torch.Tensor.vdot"><code>Tensor.vdot</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.vdot.html#torch.vdot" title="torch.vdot"><code>torch.vdot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.view.html#torch.Tensor.view" title="torch.Tensor.view"><code>Tensor.view</code></a></p></td> <td><p>Returns a new tensor with the same data as the <code>self</code> tensor but of a different <code>shape</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.view_as.html#torch.Tensor.view_as" title="torch.Tensor.view_as"><code>Tensor.view_as</code></a></p></td> <td><p>View this tensor as the same size as <code>other</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.vsplit.html#torch.Tensor.vsplit" title="torch.Tensor.vsplit"><code>Tensor.vsplit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.vsplit.html#torch.vsplit" title="torch.vsplit"><code>torch.vsplit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.where.html#torch.Tensor.where" title="torch.Tensor.where"><code>Tensor.where</code></a></p></td> <td><p><code>self.where(condition, y)</code> is equivalent to <code>torch.where(condition, self, y)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.xlogy.html#torch.Tensor.xlogy" title="torch.Tensor.xlogy"><code>Tensor.xlogy</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.xlogy.html#torch.xlogy" title="torch.xlogy"><code>torch.xlogy()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.xlogy_.html#torch.Tensor.xlogy_" title="torch.Tensor.xlogy_"><code>Tensor.xlogy_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.xlogy.html#torch.Tensor.xlogy" title="torch.Tensor.xlogy"><code>xlogy()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.zero_.html#torch.Tensor.zero_" title="torch.Tensor.zero_"><code>Tensor.zero_</code></a></p></td> <td><p>Fills <code>self</code> tensor with zeros.</p></td> </tr>  </table><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/tensors.html" class="_attribution-link">https://pytorch.org/docs/2.1/tensors.html</a>
  </p>
</div>
