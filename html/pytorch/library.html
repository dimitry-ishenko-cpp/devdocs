<h1 id="torch-library">torch.library</h1> <p>Python operator registration API provides capabilities for extending PyTorch’s core library of operators with user defined operators. Currently, this can be done in two ways:</p> <ol class="arabic"> <li>
<p>Creating new libraries</p> <ul> <li>
<p>Lets you to register <strong>new operators</strong> and kernels for various backends and functionalities by specifying the appropriate dispatch keys. For example,</p>  <ul class="simple"> <li>Consider registering a new operator <code>add</code> in your newly created namespace <code>foo</code>. You can access this operator using the <code>torch.ops</code> API and calling into by calling <code>torch.ops.foo.add</code>. You can also access specific registered overloads by calling <code>torch.ops.foo.add.{overload_name}</code>.</li> <li>If you registered a new kernel for the <code>CUDA</code> dispatch key for this operator, then your custom defined function will be called for CUDA tensor inputs.</li> </ul>  </li> <li>This can be done by creating Library class objects of <code>"DEF"</code> kind.</li> </ul> </li> <li>
<p>Extending existing C++ libraries (e.g., aten)</p> <ul> <li>Lets you register kernels for <strong>existing operators</strong> corresponding to various backends and functionalities by specifying the appropriate dispatch keys.</li> <li>
<p>This may come in handy to fill up spotty operator support for a feature implemented through a dispatch key. For example.,</p>  <ul class="simple"> <li>You can add operator support for Meta Tensors (by registering function to the <code>Meta</code> dispatch key).</li> </ul>  </li> <li>This can be done by creating Library class objects of <code>"IMPL"</code> kind.</li> </ul> </li> </ol> <p>A tutorial that walks you through some examples on how to use this API is available on <a class="reference external" href="https://colab.research.google.com/drive/1RRhSfk7So3Cn02itzLWE9K4Fam-8U011?usp=sharing">Google Colab</a>.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>Dispatcher is a complicated PyTorch concept and having a sound understanding of Dispatcher is crucial to be able to do anything advanced with this API. <a class="reference external" href="http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/">This blog post</a> is a good starting point to learn about Dispatcher.</p> </div> <dl class="py class"> <dt class="sig sig-object py" id="torch.library.Library">
<code>class torch.library.Library(ns, kind, dispatch_key='')</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/library.html#Library"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>A class to create libraries that can be used to register new operators or override operators in existing libraries from Python. A user can optionally pass in a dispatch keyname if they only want to register kernels corresponding to only one specific dispatch key.</p> <p>To create a library to override operators in an existing library (with name ns), set the kind to “IMPL”. To create a new library (with name ns) to register new operators, set the kind to “DEF”. To create a fragment of a possibly existing library to register operators (and bypass the limitation that there is only one library for a given namespace), set the kind to “FRAGMENT”.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>ns</strong> – library name</li> <li>
<strong>kind</strong> – “DEF”, “IMPL” (default: “IMPL”), “FRAGMENT”</li> <li>
<strong>dispatch_key</strong> – PyTorch dispatch key (default: “”)</li> </ul> </dd> </dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.library.Library.define">
<code>define(schema, alias_analysis='')</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/library.html#Library.define"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Defines a new operator and its semantics in the ns namespace.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>schema</strong> – function schema to define a new operator.</li> <li>
<strong>alias_analysis</strong> (<em>optional</em>) – Indicates if the aliasing properties of the operator arguments can be inferred from the schema (default behavior) or not (“CONSERVATIVE”).</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>name of the operator as inferred from the schema.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; my_lib = Library("foo", "DEF")
&gt;&gt;&gt; my_lib.define("sum(Tensor self) -&gt; Tensor")
</pre> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.library.Library.impl">
<code>impl(op_name, fn, dispatch_key='')</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/library.html#Library.impl"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Registers the function implementation for an operator defined in the library.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>op_name</strong> – operator name (along with the overload) or OpOverload object.</li> <li>
<strong>fn</strong> – function that’s the operator implementation for the input dispatch key or <a class="reference internal" href="#torch.library.fallthrough_kernel" title="torch.library.fallthrough_kernel"><code>fallthrough_kernel()</code></a> to register a fallthrough.</li> <li>
<strong>dispatch_key</strong> – dispatch key that the input function should be registered for. By default, it uses the dispatch key that the library was created with.</li> </ul> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; my_lib = Library("aten", "IMPL")
&gt;&gt;&gt; def div_cpu(self, other):
&gt;&gt;&gt;     return self * (1 / other)
&gt;&gt;&gt; my_lib.impl("div.Tensor", div_cpu, "CPU")
</pre> </dd> </dl> </dd>
</dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.library.fallthrough_kernel">
<code>torch.library.fallthrough_kernel()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/library.html#fallthrough_kernel"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>A dummy function to pass to <code>Library.impl</code> in order to register a fallthrough.</p> </dd>
</dl> <p>We have also added some function decorators to make it convenient to register functions for operators:</p> <ul class="simple"> <li><code>torch.library.impl()</code></li> <li><code>torch.library.define()</code></li> </ul><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/library.html" class="_attribution-link">https://pytorch.org/docs/2.1/library.html</a>
  </p>
</div>
