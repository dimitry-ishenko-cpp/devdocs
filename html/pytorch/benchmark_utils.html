<h1 id="benchmark-utils-torch-utils-benchmark">Benchmark Utils - torch.utils.benchmark</h1> <dl class="py class" id="module-torch.utils.benchmark"> <dt class="sig sig-object py" id="torch.utils.benchmark.Timer">
<code>class torch.utils.benchmark.Timer(stmt='pass', setup='pass', global_setup='', timer=&lt;built-in function perf_counter&gt;, globals=None, label=None, sub_label=None, description=None, env=None, num_threads=1, language=Language.PYTHON)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/timer.html#Timer"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Helper class for measuring execution time of PyTorch statements.</p> <p>For a full tutorial on how to use this class, see: <a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/benchmark.html">https://pytorch.org/tutorials/recipes/recipes/benchmark.html</a></p> <p>The PyTorch Timer is based on <code>timeit.Timer</code> (and in fact uses <code>timeit.Timer</code> internally), but with several key differences:</p> <ol class="arabic simple"> <li>
<dl class="simple"> <dt>Runtime aware:</dt>
<dd>
<p>Timer will perform warmups (important as some elements of PyTorch are lazily initialized), set threadpool size so that comparisons are apples-to-apples, and synchronize asynchronous CUDA functions when necessary.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>Focus on replicates:</dt>
<dd>
<p>When measuring code, and particularly complex kernels / models, run-to-run variation is a significant confounding factor. It is expected that all measurements should include replicates to quantify noise and allow median computation, which is more robust than mean. To that effect, this class deviates from the <code>timeit</code> API by conceptually merging <code>timeit.Timer.repeat</code> and <code>timeit.Timer.autorange</code>. (Exact algorithms are discussed in method docstrings.) The <code>timeit</code> method is replicated for cases where an adaptive strategy is not desired.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>Optional metadata:</dt>
<dd>
<p>When defining a Timer, one can optionally specify <code>label</code>, <code>sub_label</code>, <code>description</code>, and <code>env</code>. (Defined later) These fields are included in the representation of result object and by the <code>Compare</code> class to group and display results for comparison.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>Instruction counts</dt>
<dd>
<p>In addition to wall times, Timer can run a statement under Callgrind and report instructions executed.</p> </dd> </dl> </li> </ol> <p>Directly analogous to <code>timeit.Timer</code> constructor arguments:</p>  <p><code>stmt</code>, <code>setup</code>, <code>timer</code>, <code>globals</code></p>  <p>PyTorch Timer specific constructor arguments:</p>  <p><code>label</code>, <code>sub_label</code>, <code>description</code>, <code>env</code>, <code>num_threads</code></p>  <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>stmt</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>) – Code snippet to be run in a loop and timed.</li> <li>
<strong>setup</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>) – Optional setup code. Used to define variables used in <code>stmt</code>
</li> <li>
<strong>global_setup</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>) – (C++ only) Code which is placed at the top level of the file for things like <code>#include</code> statements.</li> <li>
<strong>timer</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.12)">Callable</a><em>[</em><em>[</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>]</em>) – Callable which returns the current time. If PyTorch was built without CUDA or there is no GPU present, this defaults to <code>timeit.default_timer</code>; otherwise it will synchronize CUDA before measuring the time.</li> <li>
<strong>globals</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.12)">Optional</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)">Dict</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)">Any</a><em>]</em><em>]</em>) – A dict which defines the global variables when <code>stmt</code> is being executed. This is the other method for providing variables which <code>stmt</code> needs.</li> <li>
<strong>label</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.12)">Optional</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>]</em>) – String which summarizes <code>stmt</code>. For instance, if <code>stmt</code> is “torch.nn.functional.relu(torch.add(x, 1, out=out))” one might set label to “ReLU(x + 1)” to improve readability.</li> <li>
<p><strong>sub_label</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.12)">Optional</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>]</em>) – </p>
<p>Provide supplemental information to disambiguate measurements with identical stmt or label. For instance, in our example above sub_label might be “float” or “int”, so that it is easy to differentiate: “ReLU(x + 1): (float)”</p> <p>”ReLU(x + 1): (int)” when printing Measurements or summarizing using <code>Compare</code>.</p> </li> <li>
<p><strong>description</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.12)">Optional</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>]</em>) – </p>
<p>String to distinguish measurements with identical label and sub_label. The principal use of <code>description</code> is to signal to <code>Compare</code> the columns of data. For instance one might set it based on the input size to create a table of the form:</p> <pre data-language="python">                        | n=1 | n=4 | ...
                        ------------- ...
ReLU(x + 1): (float)    | ... | ... | ...
ReLU(x + 1): (int)      | ... | ... | ...
</pre> <p>using <code>Compare</code>. It is also included when printing a Measurement.</p> </li> <li>
<strong>env</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.12)">Optional</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>]</em>) – This tag indicates that otherwise identical tasks were run in different environments, and are therefore not equivalent, for instance when A/B testing a change to a kernel. <code>Compare</code> will treat Measurements with different <code>env</code> specification as distinct when merging replicate runs.</li> <li>
<strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – The size of the PyTorch threadpool when executing <code>stmt</code>. Single threaded performance is important as both a key inference workload and a good indicator of intrinsic algorithmic efficiency, so the default is set to one. This is in contrast to the default PyTorch threadpool size which tries to utilize all cores.</li> </ul> </dd> </dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.Timer.blocked_autorange">
<code>blocked_autorange(callback=None, min_run_time=0.2)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/timer.html#Timer.blocked_autorange"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Measure many replicates while keeping timer overhead to a minimum.</p> <p>At a high level, blocked_autorange executes the following pseudo-code:</p> <pre data-language="python">`setup`

total_time = 0
while total_time &lt; min_run_time
    start = timer()
    for _ in range(block_size):
        `stmt`
    total_time += (timer() - start)
</pre> <p>Note the variable <code>block_size</code> in the inner loop. The choice of block size is important to measurement quality, and must balance two competing objectives:</p>  <ol class="arabic simple"> <li>A small block size results in more replicates and generally better statistics.</li> <li>A large block size better amortizes the cost of <code>timer</code> invocation, and results in a less biased measurement. This is important because CUDA synchronization time is non-trivial (order single to low double digit microseconds) and would otherwise bias the measurement.</li> </ol>  <p>blocked_autorange sets block_size by running a warmup period, increasing block size until timer overhead is less than 0.1% of the overall computation. This value is then used for the main measurement loop.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A <code>Measurement</code> object that contains measured runtimes and repetition counts, and can be used to compute statistics. (mean, median, etc.)</p> </dd> <dt class="field-even">Return type</dt> <dd class="field-even">
<p><a class="reference internal" href="#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.utils.common.Measurement">Measurement</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.Timer.collect_callgrind">
<code>collect_callgrind(number: int, *, repeats: None, collect_baseline: bool, retain_out_file: bool) → CallgrindStats</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/timer.html#Timer.collect_callgrind"><span class="viewcode-link">[source]</span></a>
</dt> <dt class="sig sig-object py"> <span class="sig-name descname">collect_callgrind</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">number</span><span class="p">:</span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a></span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">repeats</span><span class="p">:</span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a></span></em>, <em class="sig-param"><span class="n">collect_baseline</span><span class="p">:</span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a></span></em>, <em class="sig-param"><span class="n">retain_out_file</span><span class="p">:</span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)">Tuple</a><span class="p">[</span><a class="reference internal" href="#torch.utils.benchmark.CallgrindStats" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats">CallgrindStats</a><span class="p">,</span><span class="p">...</span><span class="p">]</span></span></span>
</dt> <dd>
<p>Collect instruction counts using Callgrind.</p> <p>Unlike wall times, instruction counts are deterministic (modulo non-determinism in the program itself and small amounts of jitter from the Python interpreter.) This makes them ideal for detailed performance analysis. This method runs <code>stmt</code> in a separate process so that Valgrind can instrument the program. Performance is severely degraded due to the instrumentation, however this is ameliorated by the fact that a small number of iterations is generally sufficient to obtain good measurements.</p> <p>In order to to use this method <code>valgrind</code>, <code>callgrind_control</code>, and <code>callgrind_annotate</code> must be installed.</p> <p>Because there is a process boundary between the caller (this process) and the <code>stmt</code> execution, <code>globals</code> cannot contain arbitrary in-memory data structures. (Unlike timing methods) Instead, globals are restricted to builtins, <code>nn.Modules</code>’s, and TorchScripted functions/modules to reduce the surprise factor from serialization and subsequent deserialization. The <code>GlobalsBridge</code> class provides more detail on this subject. Take particular care with nn.Modules: they rely on pickle and you may need to add an import to <code>setup</code> for them to transfer properly.</p> <p>By default, a profile for an empty statement will be collected and cached to indicate how many instructions are from the Python loop which drives <code>stmt</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A <code>CallgrindStats</code> object which provides instruction counts and some basic facilities for analyzing and manipulating results.</p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.Timer.timeit">
<code>timeit(number=1000000)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/timer.html#Timer.timeit"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Mirrors the semantics of timeit.Timer.timeit().</p> <p>Execute the main statement (<code>stmt</code>) <code>number</code> times. <a class="reference external" href="https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit">https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit</a></p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.utils.common.Measurement">Measurement</a></p> </dd> </dl> </dd>
</dl> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="torch.utils.benchmark.Measurement">
<code>class torch.utils.benchmark.Measurement(number_per_run, raw_times, task_spec, metadata=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/common.html#Measurement"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>The result of a Timer measurement.</p> <p>This class stores one or more measurements of a given statement. It is serializable and provides several convenience methods (including a detailed __repr__) for downstream consumers.</p>  <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.Measurement.merge">
<code>static merge(measurements)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/common.html#Measurement.merge"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Convenience method for merging replicates.</p> <p>Merge will extrapolate times to <code>number_per_run=1</code> and will not transfer any metadata. (Since it might differ between replicates)</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)">List</a>[<a class="reference internal" href="#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.utils.common.Measurement">Measurement</a>]</p> </dd> </dl> </dd>
</dl> <dl class="py property"> <dt class="sig sig-object py" id="torch.utils.benchmark.Measurement.significant_figures">
<code>property significant_figures: int</code> </dt> <dd>
<p>Approximate significant figure estimate.</p> <p>This property is intended to give a convenient way to estimate the precision of a measurement. It only uses the interquartile region to estimate statistics to try to mitigate skew from the tails, and uses a static z value of 1.645 since it is not expected to be used for small values of <code>n</code>, so z can approximate <code>t</code>.</p> <p>The significant figure estimation used in conjunction with the <code>trim_sigfig</code> method to provide a more human interpretable data summary. __repr__ does not use this method; it simply displays raw values. Significant figure estimation is intended for <code>Compare</code>.</p> </dd>
</dl> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="torch.utils.benchmark.CallgrindStats">
<code>class torch.utils.benchmark.CallgrindStats(task_spec, number_per_run, built_with_debug_symbols, baseline_inclusive_stats, baseline_exclusive_stats, stmt_inclusive_stats, stmt_exclusive_stats, stmt_callgrind_out)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Top level container for Callgrind results collected by Timer.</p> <p>Manipulation is generally done using the FunctionCounts class, which is obtained by calling <code>CallgrindStats.stats(…)</code>. Several convenience methods are provided as well; the most significant is <code>CallgrindStats.as_standardized()</code>.</p>  <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.CallgrindStats.as_standardized">
<code>as_standardized()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.as_standardized"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Strip library names and some prefixes from function strings.</p> <p>When comparing two different sets of instruction counts, on stumbling block can be path prefixes. Callgrind includes the full filepath when reporting a function (as it should). However, this can cause issues when diffing profiles. If a key component such as Python or PyTorch was built in separate locations in the two profiles, which can result in something resembling:</p> <pre data-language="python">23234231 /tmp/first_build_dir/thing.c:foo(...)
 9823794 /tmp/first_build_dir/thing.c:bar(...)
  ...
   53453 .../aten/src/Aten/...:function_that_actually_changed(...)
  ...
 -9823794 /tmp/second_build_dir/thing.c:bar(...)
-23234231 /tmp/second_build_dir/thing.c:foo(...)
</pre> <p>Stripping prefixes can ameliorate this issue by regularizing the strings and causing better cancellation of equivalent call sites when diffing.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.CallgrindStats" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats">CallgrindStats</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.CallgrindStats.counts">
<code>counts(*, denoise=False)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.counts"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the total number of instructions executed.</p> <p>See <code>FunctionCounts.denoise()</code> for an explanation of the <code>denoise</code> arg.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.CallgrindStats.delta">
<code>delta(other, inclusive=False)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.delta"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Diff two sets of counts.</p> <p>One common reason to collect instruction counts is to determine the the effect that a particular change will have on the number of instructions needed to perform some unit of work. If a change increases that number, the next logical question is “why”. This generally involves looking at what part if the code increased in instruction count. This function automates that process so that one can easily diff counts on both an inclusive and exclusive basis.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.FunctionCounts" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts">FunctionCounts</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.CallgrindStats.stats">
<code>stats(inclusive=False)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.stats"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns detailed function counts.</p> <p>Conceptually, the FunctionCounts returned can be thought of as a tuple of (count, path_and_function_name) tuples.</p> <p><code>inclusive</code> matches the semantics of callgrind. If True, the counts include instructions executed by children. <code>inclusive=True</code> is useful for identifying hot spots in code; <code>inclusive=False</code> is useful for reducing noise when diffing counts from two different runs. (See CallgrindStats.delta(…) for more details)</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.FunctionCounts" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts">FunctionCounts</a></p> </dd> </dl> </dd>
</dl> </dd>
</dl> <dl class="py class" id="module-torch.utils.benchmark.utils.valgrind_wrapper"> <dt class="sig sig-object py" id="torch.utils.benchmark.FunctionCounts">
<code>class torch.utils.benchmark.FunctionCounts(_data, inclusive, truncate_rows=True, _linewidth=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Container for manipulating Callgrind results.</p> <dl class="simple"> <dt>It supports:</dt>
<dd>
<ol class="arabic simple"> <li>Addition and subtraction to combine or diff results.</li> <li>Tuple-like indexing.</li> <li>A <code>denoise</code> function which strips CPython calls which are known to be non-deterministic and quite noisy.</li> <li>Two higher order methods (<code>filter</code> and <code>transform</code>) for custom manipulation.</li> </ol> </dd> </dl>  <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.FunctionCounts.denoise">
<code>denoise()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts.denoise"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Remove known noisy instructions.</p> <p>Several instructions in the CPython interpreter are rather noisy. These instructions involve unicode to dictionary lookups which Python uses to map variable names. FunctionCounts is generally a content agnostic container, however this is sufficiently important for obtaining reliable results to warrant an exception.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.FunctionCounts" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts">FunctionCounts</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.FunctionCounts.filter">
<code>filter(filter_fn)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts.filter"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Keep only the elements where <code>filter_fn</code> applied to function name returns True.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.FunctionCounts" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts">FunctionCounts</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.utils.benchmark.FunctionCounts.transform">
<code>transform(map_fn)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts.transform"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply <code>map_fn</code> to all of the function names.</p> <p>This can be used to regularize function names (e.g. stripping irrelevant parts of the file path), coalesce entries by mapping multiple functions to the same name (in which case the counts are added together), etc.</p> <dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="#torch.utils.benchmark.FunctionCounts" title="torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts">FunctionCounts</a></p> </dd> </dl> </dd>
</dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/benchmark_utils.html" class="_attribution-link">https://pytorch.org/docs/2.1/benchmark_utils.html</a>
  </p>
</div>
