<h1 id="lppool1d">LPPool1d</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.nn.LPPool1d">
<code>class torch.nn.LPPool1d(norm_type, kernel_size, stride=None, ceil_mode=False)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/modules/pooling.html#LPPool1d"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Applies a 1D power-average pooling over an input signal composed of several input planes.</p> <p>On each window, the function computed is:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mroot><mrow><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><msup><mi>x</mi><mi>p</mi></msup></mrow><mi>p</mi></mroot></mrow><annotation encoding="application/x-tex">f(X) = \sqrt[p]{\sum_{x \in X} x^{p}} </annotation></semantics></math></span></span></span>
</div>
<ul class="simple"> <li>At p = <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span></span></span>, one gets Max Pooling</li> <li>At p = 1, one gets Sum Pooling (which is proportional to Average Pooling)</li> </ul> <div class="admonition note"> <p class="admonition-title">Note</p> <p>If the sum to the power of <code>p</code> is zero, the gradient of this function is not defined. This implementation will set the gradient to zero in this case.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)">Union</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)">Tuple</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>]</em><em>]</em>) – a single int, the size of the window</li> <li>
<strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)">Union</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)">Tuple</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>]</em><em>]</em>) – a single int, the stride of the window. Default value is <code>kernel_size</code>
</li> <li>
<strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a>) – when True, will use <code>ceil</code> instead of <code>floor</code> to compute the output shape</li> </ul> </dd> </dl> <dl> <dt>Shape:</dt>
<dd>
<ul> <li>Input: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C, L_{in})</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C, L_{in})</annotation></semantics></math></span></span></span>.</li> <li>
<p>Output: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>L</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C, L_{out})</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>L</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C, L_{out})</annotation></semantics></math></span></span></span>, where</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">⌊</mo><mfrac><mrow><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>−</mo><mtext>kernel_size</mtext></mrow><mtext>stride</mtext></mfrac><mo>+</mo><mn>1</mn><mo fence="true">⌋</mo></mrow></mrow><annotation encoding="application/x-tex">L_{out} = \left\lfloor\frac{L_{in} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor </annotation></semantics></math></span></span></span>
</div>
</li> </ul> </dd> <dt>Examples::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; # power-2 pool of window of length 3, with stride 2.
&gt;&gt;&gt; m = nn.LPPool1d(2, 3, stride=2)
&gt;&gt;&gt; input = torch.randn(20, 16, 50)
&gt;&gt;&gt; output = m(input)
</pre> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.LPPool1d.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.LPPool1d.html</a>
  </p>
</div>
