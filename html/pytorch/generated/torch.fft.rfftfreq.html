<h1 id="torch-fft-rfftfreq">torch.fft.rfftfreq</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.fft.rfftfreq">
<code>torch.fft.rfftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</code> </dt> <dd>
<p>Computes the sample frequencies for <a class="reference internal" href="torch.fft.rfft.html#torch.fft.rfft" title="torch.fft.rfft"><code>rfft()</code></a> with a signal of size <code>n</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="torch.fft.rfft.html#torch.fft.rfft" title="torch.fft.rfft"><code>rfft()</code></a> returns Hermitian one-sided output, so only the positive frequency terms are returned. For a real FFT of length <code>n</code> and with inputs spaced in length unit <code>d</code>, the frequencies are:</p> <pre data-language="python">f = torch.arange((n + 1) // 2) / (d * n)
</pre> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For even lengths, the Nyquist frequency at <code>f[n/2]</code> can be thought of as either negative or positive. Unlike <a class="reference internal" href="torch.fft.fftfreq.html#torch.fft.fftfreq" title="torch.fft.fftfreq"><code>fftfreq()</code></a>, <a class="reference internal" href="#torch.fft.rfftfreq" title="torch.fft.rfftfreq"><code>rfftfreq()</code></a> always returns it as positive.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – the real FFT length</li> <li>
<strong>d</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – The sampling length scale. The spacing between individual samples of the FFT input. The default assumes unit spacing, dividing that result by the actual spacing gives the result in physical frequency units.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>out</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</li> <li>
<strong>dtype</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, optional) – the desired data type of returned tensor. Default: if <code>None</code>, uses a global default (see <a class="reference internal" href="torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code>torch.set_default_tensor_type()</code></a>).</li> <li>
<strong>layout</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.layout" title="torch.layout"><code>torch.layout</code></a>, optional) – the desired layout of returned Tensor. Default: <code>torch.strided</code>.</li> <li>
<strong>device</strong> (<a class="reference internal" href="../tensor_attributes.html#torch.device" title="torch.device"><code>torch.device</code></a>, optional) – the desired device of returned tensor. Default: if <code>None</code>, uses the current device for the default tensor type (see <a class="reference internal" href="torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code>torch.set_default_tensor_type()</code></a>). <code>device</code> will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.</li> <li>
<strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – If autograd should record operations on the returned tensor. Default: <code>False</code>.</li> </ul> </dd> </dl> <h4 class="rubric">Example</h4> <pre data-language="python">&gt;&gt;&gt; torch.fft.rfftfreq(5)
tensor([0.0000, 0.2000, 0.4000])
</pre> <pre data-language="python">&gt;&gt;&gt; torch.fft.rfftfreq(4)
tensor([0.0000, 0.2500, 0.5000])
</pre> <p>Compared to the output from <a class="reference internal" href="torch.fft.fftfreq.html#torch.fft.fftfreq" title="torch.fft.fftfreq"><code>fftfreq()</code></a>, we see that the Nyquist frequency at <code>f[2]</code> has changed sign: &gt;&gt;&gt; torch.fft.fftfreq(4) tensor([ 0.0000, 0.2500, -0.5000, -0.2500])</p> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.fft.rfftfreq.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.fft.rfftfreq.html</a>
  </p>
</div>
