<h1 id="python-builtin">python.builtin</h1>  <h2 id="dynamic-shape-round">dynamic_shape_round</h2> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Tags: <a class="reference internal" href="torch.dynamic-shape.html"><span class="doc">torch.dynamic-shape</span></a>, <a class="reference internal" href="#"><span class="doc">python.builtin</span></a></p> <p>Support Level: NOT_SUPPORTED_YET</p> </div> <p>Original source code:</p> <pre data-language="python">import torch

from torch._export import dynamic_dim

x = torch.ones(3, 2)
dynamic_constraint = dynamic_dim(x, 0)

def dynamic_shape_round(x):
    """
    Calling round on dynamic shapes is not supported.
    """
    return x[: round(x.shape[0] / 2)]
</pre> <p>Result:</p> <pre data-language="python">Unsupported: Calling round() on symbolic value is not supported. You can use floor() to implement this functionality
</pre>   <h2 id="tensor-setattr">tensor_setattr</h2> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Tags: <a class="reference internal" href="#"><span class="doc">python.builtin</span></a></p> <p>Support Level: SUPPORTED</p> </div> <p>Original source code:</p> <pre data-language="python">import torch



def tensor_setattr(x, attr):
    """
    setattr() call onto tensors is not supported.
    """
    setattr(x, attr, torch.randn(3, 2))
    return x + 4
</pre> <p>Result:</p> <pre data-language="python">ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, arg0_1: f32[3, 2], arg1_1):
            #
            add: f32[3, 2] = torch.ops.aten.add.Tensor(arg0_1, 4);  arg0_1 = None
            return (add,)

Graph Signature: ExportGraphSignature(parameters=[], buffers=[], user_inputs=['arg0_1', 'arg1_1'], user_outputs=['add'], inputs_to_parameters={}, inputs_to_buffers={}, buffers_to_mutate={}, backward_signature=None, assertion_dep_token=None)
Symbol to range: {}
</pre>   <h2 id="type-reflection-method">type_reflection_method</h2> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Tags: <a class="reference internal" href="#"><span class="doc">python.builtin</span></a></p> <p>Support Level: NOT_SUPPORTED_YET</p> </div> <p>Original source code:</p> <pre data-language="python">import torch



class A:
    @classmethod
    def func(cls, x):
        return 1 + x


def type_reflection_method(x):
    """
    type() calls on custom objects followed by method calls are not allowed
    due to its overly dynamic nature.
    """
    a = A()
    return type(a).func(x)
</pre> <p>Result:</p> <pre data-language="python">Unsupported: Can't call type() on generated custom object. Please use __class__ instead
</pre> <p>You can rewrite the example above to something like the following:</p> <pre data-language="python">def type_reflection_method_rewrite(x):
    """
    Custom object class methods will be inlined.
    """
    return A.func(x)
</pre><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/exportdb/python.builtin.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/exportdb/python.builtin.html</a>
  </p>
</div>
