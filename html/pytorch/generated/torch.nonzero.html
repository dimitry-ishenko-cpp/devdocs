<h1 id="torch-nonzero">torch.nonzero</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nonzero">
<code>torch.nonzero(input, *, out=None, as_tuple=False) → LongTensor or tuple of LongTensors</code> </dt> <dd>
<div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="#torch.nonzero" title="torch.nonzero"><code>torch.nonzero(..., as_tuple=False)</code></a> (default) returns a 2-D tensor where each row is the index for a nonzero value.</p> <p><a class="reference internal" href="#torch.nonzero" title="torch.nonzero"><code>torch.nonzero(..., as_tuple=True)</code></a> returns a tuple of 1-D index tensors, allowing for advanced indexing, so <code>x[x.nonzero(as_tuple=True)]</code> gives all nonzero values of tensor <code>x</code>. Of the returned tuple, each index tensor contains nonzero indices for a certain dimension.</p> <p>See below for more details on the two behaviors.</p> <p>When <code>input</code> is on CUDA, <a class="reference internal" href="#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a> causes host-device synchronization.</p> </div> <p><strong>When</strong> <code>as_tuple</code> <strong>is</strong> <code>False</code> <strong>(default)</strong>:</p> <p>Returns a tensor containing the indices of all non-zero elements of <code>input</code>. Each row in the result contains the indices of a non-zero element in <code>input</code>. The result is sorted lexicographically, with the last index changing the fastest (C-style).</p> <p>If <code>input</code> has <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> dimensions, then the resulting indices tensor <code>out</code> is of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>z</mi><mo>×</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(z \times n)</annotation></semantics></math></span></span></span>, where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span></span></span> is the total number of non-zero elements in the <code>input</code> tensor.</p> <p><strong>When</strong> <code>as_tuple</code> <strong>is</strong> <code>True</code>:</p> <p>Returns a tuple of 1-D tensors, one for each dimension in <code>input</code>, each containing the indices (in that dimension) of all non-zero elements of <code>input</code> .</p> <p>If <code>input</code> has <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> dimensions, then the resulting tuple contains <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> tensors of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span></span></span>, where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span></span></span> is the total number of non-zero elements in the <code>input</code> tensor.</p> <p>As a special case, when <code>input</code> has zero dimensions and a nonzero scalar value, it is treated as a one-dimensional tensor with one element.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – the output tensor containing indices</p> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>If <code>as_tuple</code> is <code>False</code>, the output tensor containing indices. If <code>as_tuple</code> is <code>True</code>, one 1-D tensor for each dimension, containing the indices of each nonzero element along that dimension.</p> </dd> <dt class="field-even">Return type</dt> <dd class="field-even">
<p>LongTensor or <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a> of LongTensor</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.nonzero(torch.tensor([1, 1, 1, 0, 1]))
tensor([[ 0],
        [ 1],
        [ 2],
        [ 4]])
&gt;&gt;&gt; torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],
...                             [0.0, 0.4, 0.0, 0.0],
...                             [0.0, 0.0, 1.2, 0.0],
...                             [0.0, 0.0, 0.0,-0.4]]))
tensor([[ 0,  0],
        [ 1,  1],
        [ 2,  2],
        [ 3,  3]])
&gt;&gt;&gt; torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True)
(tensor([0, 1, 2, 4]),)
&gt;&gt;&gt; torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],
...                             [0.0, 0.4, 0.0, 0.0],
...                             [0.0, 0.0, 1.2, 0.0],
...                             [0.0, 0.0, 0.0,-0.4]]), as_tuple=True)
(tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))
&gt;&gt;&gt; torch.nonzero(torch.tensor(5), as_tuple=True)
(tensor([0]),)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nonzero.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nonzero.html</a>
  </p>
</div>
