<h1 id="torch-cuda-ipc-collect">torch.cuda.ipc_collect</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.cuda.ipc_collect">
<code>torch.cuda.ipc_collect()</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda.html#ipc_collect"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Force collects GPU memory after it has been released by CUDA IPC.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Checks if any sent CUDA tensors could be cleaned from the memory. Force closes shared memory file used for reference counting if there is no active counters. Useful when the producer process stopped actively sending tensors and want to release unused memory.</p> </div> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.cuda.ipc_collect.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.cuda.ipc_collect.html</a>
  </p>
</div>
