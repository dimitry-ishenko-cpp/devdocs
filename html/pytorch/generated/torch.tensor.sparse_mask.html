<h1 id="torch-tensor-sparse-mask">torch.Tensor.sparse_mask</h1> <dl class="py method"> <dt class="sig sig-object py" id="torch.Tensor.sparse_mask">
<code>Tensor.sparse_mask(mask) → Tensor</code> </dt> <dd>
<p>Returns a new <a class="reference internal" href="../sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> with values from a strided tensor <code>self</code> filtered by the indices of the sparse tensor <code>mask</code>. The values of <code>mask</code> sparse tensor are ignored. <code>self</code> and <code>mask</code> tensors must have the same shape.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The returned sparse tensor might contain duplicate values if <code>mask</code> is not coalesced. It is therefore advisable to pass <code>mask.coalesce()</code> if such behavior is not desired.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The returned sparse tensor has the same indices as the sparse tensor <code>mask</code>, even when the corresponding values in <code>self</code> are zeros.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>mask</strong> (<a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) – a sparse tensor whose indices are used as a filter</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; nse = 5
&gt;&gt;&gt; dims = (5, 5, 2, 2)
&gt;&gt;&gt; I = torch.cat([torch.randint(0, dims[0], size=(nse,)),
...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)
&gt;&gt;&gt; V = torch.randn(nse, dims[2], dims[3])
&gt;&gt;&gt; S = torch.sparse_coo_tensor(I, V, dims).coalesce()
&gt;&gt;&gt; D = torch.randn(dims)
&gt;&gt;&gt; D.sparse_mask(S)
tensor(indices=tensor([[0, 0, 0, 2],
                       [0, 1, 4, 3]]),
       values=tensor([[[ 1.6550,  0.2397],
                       [-0.1611, -0.0779]],

                      [[ 0.2326, -1.0558],
                       [ 1.4711,  1.9678]],

                      [[-0.5138, -0.0411],
                       [ 1.9417,  0.5158]],

                      [[ 0.0793,  0.0036],
                       [-0.2569, -0.1055]]]),
       size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.Tensor.sparse_mask.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.Tensor.sparse_mask.html</a>
  </p>
</div>
