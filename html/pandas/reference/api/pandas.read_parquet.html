<h1>pandas.read_parquet</h1> <dl class="py function"> <dt class="sig sig-object py" id="pandas.read_parquet"> <span class="sig-prename descclassname"><span class="pre">pandas.</span></span><span class="sig-name descname"><span class="pre">read_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_nullable_dtypes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_NoDefault.no_default</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype_backend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_NoDefault.no_default</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filesystem</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pandas-dev/pandas/blob/v2.2.2/pandas/io/parquet.py#L498-L676"><span class="viewcode-link"><span class="pre">[source]</span></span></a>
</dt> <dd>
<p>Load a parquet object from the file path, returning a DataFrame.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>path</strong><span class="classifier">:str, path object or file-like object</span>
</dt>
<dd>
<p>String, path object (implementing <code class="docutils literal notranslate"><span class="pre">os.PathLike[str]</span></code>), or file-like object implementing a binary <code class="docutils literal notranslate"><span class="pre">read()</span></code> function. The string could be a URL. Valid URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is expected. A local file could be: <code class="docutils literal notranslate"><span class="pre">file://localhost/path/to/table.parquet</span></code>. A file URL can also be a path to a directory that contains multiple partitioned parquet files. Both pyarrow and fastparquet support paths to directories as well as file URLs. A directory path could be: <code class="docutils literal notranslate"><span class="pre">file://localhost/path/to/tables</span></code> or <code class="docutils literal notranslate"><span class="pre">s3://bucket/partition_dir</span></code>.</p> </dd> <dt>
<strong>engine</strong><span class="classifier">:{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’</span>
</dt>
<dd>
<p>Parquet library to use. If ‘auto’, then the option <code class="docutils literal notranslate"><span class="pre">io.parquet.engine</span></code> is used. The default <code class="docutils literal notranslate"><span class="pre">io.parquet.engine</span></code> behavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if ‘pyarrow’ is unavailable.</p> <p>When using the <code class="docutils literal notranslate"><span class="pre">'pyarrow'</span></code> engine and no storage options are provided and a filesystem is implemented by both <code class="docutils literal notranslate"><span class="pre">pyarrow.fs</span></code> and <code class="docutils literal notranslate"><span class="pre">fsspec</span></code> (e.g. “s3://”), then the <code class="docutils literal notranslate"><span class="pre">pyarrow.fs</span></code> filesystem is attempted first. Use the filesystem keyword with an instantiated fsspec filesystem if you wish to use its implementation.</p> </dd> <dt>
<strong>columns</strong><span class="classifier">:list, default=None</span>
</dt>
<dd>
<p>If not None, only these columns will be read from the file.</p> </dd> <dt>
<strong>storage_options</strong><span class="classifier">:dict, optional</span>
</dt>
<dd>
<p>Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded to <code class="docutils literal notranslate"><span class="pre">urllib.request.Request</span></code> as header options. For other URLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are forwarded to <code class="docutils literal notranslate"><span class="pre">fsspec.open</span></code>. Please see <code class="docutils literal notranslate"><span class="pre">fsspec</span></code> and <code class="docutils literal notranslate"><span class="pre">urllib</span></code> for more details, and for more examples on storage options refer <a class="reference external" href="https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files">here</a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.3.0.</span></p> </div> </dd> <dt>
<strong>use_nullable_dtypes</strong><span class="classifier">:bool, default False</span>
</dt>
<dd>
<p>If True, use dtypes that use <code class="docutils literal notranslate"><span class="pre">pd.NA</span></code> as missing value indicator for the resulting DataFrame. (only applicable for the <code class="docutils literal notranslate"><span class="pre">pyarrow</span></code> engine) As new dtypes are added that support <code class="docutils literal notranslate"><span class="pre">pd.NA</span></code> in the future, the output with this option will change to use those dtypes. Note: this is an experimental option, and behaviour (e.g. additional support dtypes) may change without notice.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 2.0.</span></p> </div> </dd> <dt>
<strong>dtype_backend</strong><span class="classifier">:{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’</span>
</dt>
<dd>
<p>Back-end data type applied to the resultant <a class="reference internal" href="pandas.dataframe.html#pandas.DataFrame" title="pandas.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a> (still experimental). Behaviour is as follows:</p> <ul class="simple"> <li><p><code class="docutils literal notranslate"><span class="pre">"numpy_nullable"</span></code>: returns nullable-dtype-backed <a class="reference internal" href="pandas.dataframe.html#pandas.DataFrame" title="pandas.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a> (default).</p></li> <li><p><code class="docutils literal notranslate"><span class="pre">"pyarrow"</span></code>: returns pyarrow-backed nullable <a class="reference internal" href="pandas.arrowdtype.html#pandas.ArrowDtype" title="pandas.ArrowDtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">ArrowDtype</span></code></a> DataFrame.</p></li> </ul> <div class="versionadded"> <p><span class="versionmodified added">New in version 2.0.</span></p> </div> </dd> <dt>
<strong>filesystem</strong><span class="classifier">:fsspec or pyarrow filesystem, default None</span>
</dt>
<dd>
<p>Filesystem object to use when reading the parquet file. Only implemented for <code class="docutils literal notranslate"><span class="pre">engine="pyarrow"</span></code>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 2.1.0.</span></p> </div> </dd> <dt>
<strong>filters</strong><span class="classifier">:List[Tuple] or List[List[Tuple]], default None</span>
</dt>
<dd>
<p>To filter out data. Filter syntax: [[(column, op, val), …],…] where op is [==, =, &gt;, &gt;=, &lt;, &lt;=, !=, in, not in] The innermost tuples are transposed into a set of filters applied through an <cite>AND</cite> operation. The outer list combines these sets of filters through an <cite>OR</cite> operation. A single list of tuples can also be used, meaning that no <cite>OR</cite> operation between set of filters is to be conducted.</p> <p>Using this argument will NOT result in row-wise filtering of the final partitions unless <code class="docutils literal notranslate"><span class="pre">engine="pyarrow"</span></code> is also specified. For other engines, filtering is only performed at the partition level, that is, to prevent the loading of some row-groups and/or files.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 2.1.0.</span></p> </div> </dd> <dt><strong>**kwargs</strong></dt>
<dd>
<p>Any additional kwargs are passed to the engine.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>DataFrame</dt>
 </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="pandas.dataframe.to_parquet.html#pandas.DataFrame.to_parquet" title="pandas.DataFrame.to_parquet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_parquet</span></code></a></dt>
<dd>
<p>Create a parquet object that serializes a DataFrame.</p> </dd> </dl> </div> <p class="rubric">Examples</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; original_df = pd.DataFrame(
...     {"foo": range(5), "bar": range(5, 10)}
...    )
&gt;&gt;&gt; original_df
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
&gt;&gt;&gt; df_parquet_bytes = original_df.to_parquet()
&gt;&gt;&gt; from io import BytesIO
&gt;&gt;&gt; restored_df = pd.read_parquet(BytesIO(df_parquet_bytes))
&gt;&gt;&gt; restored_df
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
&gt;&gt;&gt; restored_df.equals(original_df)
True
&gt;&gt;&gt; restored_bar = pd.read_parquet(BytesIO(df_parquet_bytes), columns=["bar"])
&gt;&gt;&gt; restored_bar
    bar
0    5
1    6
2    7
3    8
4    9
&gt;&gt;&gt; restored_bar.equals(original_df[['bar']])
True
</pre></div> </div> <p>The function uses <cite>kwargs</cite> that are passed directly to the engine. In the following example, we use the <cite>filters</cite> argument of the pyarrow engine to filter the rows of the DataFrame.</p> <p>Since <cite>pyarrow</cite> is the default engine, we can omit the <cite>engine</cite> argument. Note that the <cite>filters</cite> argument is implemented by the <cite>pyarrow</cite> engine, which can benefit from multithreading and also potentially be more economical in terms of memory.</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; sel = [("foo", "&gt;", 2)]
&gt;&gt;&gt; restored_part = pd.read_parquet(BytesIO(df_parquet_bytes), filters=sel)
&gt;&gt;&gt; restored_part
    foo  bar
0    3    8
1    4    9
</pre></div> </div> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2008&ndash;2022, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pandas.pydata.org/pandas-docs/version/2.2.2/reference/api/pandas.read_parquet.html" class="_attribution-link">https://pandas.pydata.org/pandas-docs/version/2.2.2/reference/api/pandas.read_parquet.html</a>
  </p>
</div>
