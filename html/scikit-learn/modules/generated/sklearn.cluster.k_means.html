<section id="sklearn-cluster-k-means"> <h1>sklearn.cluster.k_means</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.cluster.k_means"> <span class="sig-prename descclassname">sklearn.cluster.</span><span class="sig-name descname">k_means</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">n_clusters</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">init</span><span class="o">=</span><span class="default_value">'k-means++'</span></em>, <em class="sig-param"><span class="n">n_init</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">300</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">copy_x</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">algorithm</span><span class="o">=</span><span class="default_value">'lloyd'</span></em>, <em class="sig-param"><span class="n">return_n_iter</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/cluster/_kmeans.py#L263"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform K-means clustering algorithm.</p> <p>Read more in the <a class="reference internal" href="../clustering.html#k-means"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>The observations to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</p> </dd> <dt>
<strong>n_clusters</strong><span class="classifier">int</span>
</dt>
<dd>
<p>The number of clusters to form as well as the number of centroids to generate.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>The weights for each observation in <code>X</code>. If <code>None</code>, all observations are assigned equal weight.</p> </dd> <dt>
<strong>init</strong><span class="classifier">{‘k-means++’, ‘random’}, callable or array-like of shape (n_clusters, n_features), default=’k-means++’</span>
</dt>
<dd>
<p>Method for initialization:</p> <ul class="simple"> <li>
<code>'k-means++'</code> : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. See section Notes in k_init for more details.</li> <li>
<code>'random'</code>: choose <code>n_clusters</code> observations (rows) at random from data for the initial centroids.</li> <li>If an array is passed, it should be of shape <code>(n_clusters, n_features)</code> and gives the initial centers.</li> <li>If a callable is passed, it should take arguments <code>X</code>, <code>n_clusters</code> and a random state and return an initialization.</li> </ul> </dd> <dt>
<strong>n_init</strong><span class="classifier">int, default=10</span>
</dt>
<dd>
<p>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of <code>n_init</code> consecutive runs in terms of inertia.</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=300</span>
</dt>
<dd>
<p>Maximum number of iterations of the k-means algorithm to run.</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Verbosity mode.</p> </dd> <dt>
<strong>tol</strong><span class="classifier">float, default=1e-4</span>
</dt>
<dd>
<p>Relative tolerance with regards to Frobenius norm of the difference in the cluster centers of two consecutive iterations to declare convergence.</p> </dd> <dt>
<strong>random_state</strong><span class="classifier">int, RandomState instance or None, default=None</span>
</dt>
<dd>
<p>Determines random number generation for centroid initialization. Use an int to make the randomness deterministic. See <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p> </dd> <dt>
<strong>copy_x</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>When pre-computing distances it is more numerically accurate to center the data first. If <code>copy_x</code> is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if <code>copy_x</code> is False. If the original data is sparse, but not in CSR format, a copy will be made even if <code>copy_x</code> is False.</p> </dd> <dt>
<strong>algorithm</strong><span class="classifier">{“lloyd”, “elkan”, “auto”, “full”}, default=”lloyd”</span>
</dt>
<dd>
<p>K-means algorithm to use. The classical EM-style algorithm is <code>"lloyd"</code>. The <code>"elkan"</code> variation can be more efficient on some datasets with well-defined clusters, by using the triangle inequality. However it’s more memory intensive due to the allocation of an extra array of shape <code>(n_samples, n_clusters)</code>.</p> <p><code>"auto"</code> and <code>"full"</code> are deprecated and they will be removed in Scikit-Learn 1.3. They are both aliases for <code>"lloyd"</code>.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.18: </span>Added Elkan algorithm</p> </div> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 1.1: </span>Renamed “full” to “lloyd”, and deprecated “auto” and “full”. Changed “auto” to use “lloyd” instead of “elkan”.</p> </div> </dd> <dt>
<strong>return_n_iter</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Whether or not to return the number of iterations.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>centroid</strong><span class="classifier">ndarray of shape (n_clusters, n_features)</span>
</dt>
<dd>
<p>Centroids found at the last iteration of k-means.</p> </dd> <dt>
<strong>label</strong><span class="classifier">ndarray of shape (n_samples,)</span>
</dt>
<dd>
<p>The <code>label[i]</code> is the code or index of the centroid the i’th observation is closest to.</p> </dd> <dt>
<strong>inertia</strong><span class="classifier">float</span>
</dt>
<dd>
<p>The final value of the inertia criterion (sum of squared distances to the closest centroid for all observations in the training set).</p> </dd> <dt>
<strong>best_n_iter</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of iterations corresponding to the best results. Returned only if <code>return_n_iter</code> is set to True.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.cluster.k_means.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.cluster.k_means.html</a>
  </p>
</div>
