<section id="export-text"> <h1>export_text</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.tree.export_text"> <span class="sig-prename descclassname">sklearn.tree.</span><span class="sig-name descname">export_text</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">decision_tree</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">feature_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_depth</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">spacing</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">decimals</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">show_weights</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/99bf3d8e4/sklearn/tree/_export.py#L972"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Build a text report showing the rules of a decision tree.</p> <p>Note that backwards compatibility may not be supported.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>decision_tree</strong><span class="classifier">object</span>
</dt>
<dd>
<p>The decision tree estimator to be exported. It can be an instance of DecisionTreeClassifier or DecisionTreeRegressor.</p> </dd> <dt>
<strong>feature_names</strong><span class="classifier">array-like of shape (n_features,), default=None</span>
</dt>
<dd>
<p>An array containing the feature names. If None generic names will be used (“feature_0”, “feature_1”, …).</p> </dd> <dt>
<strong>class_names</strong><span class="classifier">array-like of shape (n_classes,), default=None</span>
</dt>
<dd>
<p>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output.</p> <ul class="simple"> <li>if <code>None</code>, the class names are delegated to <code>decision_tree.classes_</code>;</li> <li>otherwise, <code>class_names</code> will be used as class names instead of <code>decision_tree.classes_</code>. The length of <code>class_names</code> must match the length of <code>decision_tree.classes_</code>.</li> </ul> <div class="versionadded"> <p><span class="versionmodified added">Added in version 1.3.</span></p> </div> </dd> <dt>
<strong>max_depth</strong><span class="classifier">int, default=10</span>
</dt>
<dd>
<p>Only the first max_depth levels of the tree are exported. Truncated branches will be marked with “…”.</p> </dd> <dt>
<strong>spacing</strong><span class="classifier">int, default=3</span>
</dt>
<dd>
<p>Number of spaces between edges. The higher it is, the wider the result.</p> </dd> <dt>
<strong>decimals</strong><span class="classifier">int, default=2</span>
</dt>
<dd>
<p>Number of decimal digits to display.</p> </dd> <dt>
<strong>show_weights</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>If true the classification weights will be exported on each leaf. The classification weights are the number of samples each class.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>report</strong><span class="classifier">str</span>
</dt>
<dd>
<p>Text summary of all the rules in the decision tree.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier
&gt;&gt;&gt; from sklearn.tree import export_text
&gt;&gt;&gt; iris = load_iris()
&gt;&gt;&gt; X = iris['data']
&gt;&gt;&gt; y = iris['target']
&gt;&gt;&gt; decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)
&gt;&gt;&gt; decision_tree = decision_tree.fit(X, y)
&gt;&gt;&gt; r = export_text(decision_tree, feature_names=iris['feature_names'])
&gt;&gt;&gt; print(r)
|--- petal width (cm) &lt;= 0.80
|   |--- class: 0
|--- petal width (cm) &gt;  0.80
|   |--- petal width (cm) &lt;= 1.75
|   |   |--- class: 1
|   |--- petal width (cm) &gt;  1.75
|   |   |--- class: 2
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2025 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.6/modules/generated/sklearn.tree.export_text.html" class="_attribution-link">https://scikit-learn.org/1.6/modules/generated/sklearn.tree.export_text.html</a>
  </p>
</div>
