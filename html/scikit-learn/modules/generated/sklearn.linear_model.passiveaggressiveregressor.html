<section id="sklearn-linear-model-passiveaggressiveregressor"> <h1>sklearn.linear_model.PassiveAggressiveRegressor</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.linear_model.PassiveAggressiveRegressor"> <span class="sig-prename descclassname">sklearn.linear_model.</span><span class="sig-name descname">PassiveAggressiveRegressor</span><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">C</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">fit_intercept</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">early_stopping</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">validation_fraction</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">n_iter_no_change</span><span class="o">=</span><span class="default_value">5</span></em>, <em class="sig-param"><span class="n">shuffle</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">loss</span><span class="o">=</span><span class="default_value">'epsilon_insensitive'</span></em>, <em class="sig-param"><span class="n">epsilon</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">warm_start</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">average</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_passive_aggressive.py#L303"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Passive Aggressive Regressor.</p> <p>Read more in the <a class="reference internal" href="../linear_model.html#passive-aggressive"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>C</strong><span class="classifier">float, default=1.0</span>
</dt>
<dd>
<p>Maximum step size (regularization). Defaults to 1.0.</p> </dd> <dt>
<strong>fit_intercept</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=1000</span>
</dt>
<dd>
<p>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the <code>fit</code> method, and not the <code>partial_fit</code> method.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.19.</span></p> </div> </dd> <dt>
<strong>tol</strong><span class="classifier">float or None, default=1e-3</span>
</dt>
<dd>
<p>The stopping criterion. If it is not None, the iterations will stop when (loss &gt; previous_loss - tol).</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.19.</span></p> </div> </dd> <dt>
<strong>early_stopping</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.20.</span></p> </div> </dd> <dt>
<strong>validation_fraction</strong><span class="classifier">float, default=0.1</span>
</dt>
<dd>
<p>The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.20.</span></p> </div> </dd> <dt>
<strong>n_iter_no_change</strong><span class="classifier">int, default=5</span>
</dt>
<dd>
<p>Number of iterations with no improvement to wait before early stopping.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.20.</span></p> </div> </dd> <dt>
<strong>shuffle</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether or not the training data should be shuffled after each epoch.</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">int, default=0</span>
</dt>
<dd>
<p>The verbosity level.</p> </dd> <dt>
<strong>loss</strong><span class="classifier">str, default=”epsilon_insensitive”</span>
</dt>
<dd>
<p>The loss function to be used: epsilon_insensitive: equivalent to PA-I in the reference paper. squared_epsilon_insensitive: equivalent to PA-II in the reference paper.</p> </dd> <dt>
<strong>epsilon</strong><span class="classifier">float, default=0.1</span>
</dt>
<dd>
<p>If the difference between the current prediction and the correct label is below this threshold, the model is not updated.</p> </dd> <dt>
<strong>random_state</strong><span class="classifier">int, RandomState instance, default=None</span>
</dt>
<dd>
<p>Used to shuffle the training data, when <code>shuffle</code> is set to <code>True</code>. Pass an int for reproducible output across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p> </dd> <dt>
<strong>warm_start</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-warm_start"><span class="xref std std-term">the Glossary</span></a>.</p> <p>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.</p> </dd> <dt>
<strong>average</strong><span class="classifier">bool or int, default=False</span>
</dt>
<dd>
<p>When set to True, computes the averaged SGD weights and stores the result in the <code>coef_</code> attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.19: </span>parameter <em>average</em> to use weights averaging in SGD.</p> </div> </dd> </dl> </dd> <dt class="field-even">Attributes<span class="colon">:</span>
</dt> <dd class="field-even">
<dl> <dt>
<strong>coef_</strong><span class="classifier">array, shape = [1, n_features] if n_classes == 2 else [n_classes, n_features]</span>
</dt>
<dd>
<p>Weights assigned to the features.</p> </dd> <dt>
<strong>intercept_</strong><span class="classifier">array, shape = [1] if n_classes == 2 else [n_classes]</span>
</dt>
<dd>
<p>Constants in decision function.</p> </dd> <dt>
<strong>n_features_in_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> <dt>
<strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code>n_features_in_</code>,)</span>
</dt>
<dd>
<p>Names of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code>X</code> has feature names that are all strings.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.0.</span></p> </div> </dd> <dt>
<strong>n_iter_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>The actual number of iterations to reach the stopping criterion.</p> </dd> <dt>
<strong>t_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of weight updates performed during training. Same as <code>(n_iter_ * n_samples)</code>.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.linear_model.sgdregressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code>SGDRegressor</code></a></dt>
<dd>
<p>Linear model fitted by minimizing a regularized empirical loss with SGD.</p> </dd> </dl> </div> <h4 class="rubric">References</h4> <p>Online Passive-Aggressive Algorithms &lt;<a class="reference external" href="http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf">http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf</a>&gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006).</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.linear_model import PassiveAggressiveRegressor
&gt;&gt;&gt; from sklearn.datasets import make_regression
</pre> <pre data-language="python">&gt;&gt;&gt; X, y = make_regression(n_features=4, random_state=0)
&gt;&gt;&gt; regr = PassiveAggressiveRegressor(max_iter=100, random_state=0,
... tol=1e-3)
&gt;&gt;&gt; regr.fit(X, y)
PassiveAggressiveRegressor(max_iter=100, random_state=0)
&gt;&gt;&gt; print(regr.coef_)
[20.48736655 34.18818427 67.59122734 87.94731329]
&gt;&gt;&gt; print(regr.intercept_)
[-0.02306214]
&gt;&gt;&gt; print(regr.predict([[0, 0, 0, 0]]))
[-0.02306214]
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html</a>
  </p>
</div>
