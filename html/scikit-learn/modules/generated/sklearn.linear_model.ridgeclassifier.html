<section id="sklearn-linear-model-ridgeclassifier"> <h1>sklearn.linear_model.RidgeClassifier</h1> <dl class="py class"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier"> <em class="property">class</em><span class="sig-prename descclassname">sklearn.linear_model.</span><span class="sig-name descname">RidgeClassifier</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">fit_intercept</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">'deprecated'</span></em>, <em class="sig-param"><span class="n">copy_X</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">class_weight</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">solver</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">positive</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_ridge.py#L1219"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Classifier using Ridge regression.</p> <p>This classifier first converts the target values into <code>{-1, 1}</code> and then treats the problem as a regression task (multi-output regression in the multiclass case).</p> <p>Read more in the <a class="reference internal" href="../linear_model.html#ridge-regression"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>alpha</strong><span class="classifier">float, default=1.0</span>
</dt>
<dd>
<p>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to <code>1 / (2C)</code> in other linear models such as <a class="reference internal" href="sklearn.linear_model.logisticregression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code>LogisticRegression</code></a> or <a class="reference internal" href="sklearn.svm.linearsvc.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code>LinearSVC</code></a>.</p> </dd> <dt>
<strong>fit_intercept</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</p> </dd> <dt>
<strong>normalize</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>This parameter is ignored when <code>fit_intercept</code> is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use <a class="reference internal" href="sklearn.preprocessing.standardscaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.0: </span><code>normalize</code> was deprecated in version 1.0 and will be removed in 1.2.</p> </div> </dd> <dt>
<strong>copy_X</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True, X will be copied; else, it may be overwritten.</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=None</span>
</dt>
<dd>
<p>Maximum number of iterations for conjugate gradient solver. The default value is determined by scipy.sparse.linalg.</p> </dd> <dt>
<strong>tol</strong><span class="classifier">float, default=1e-3</span>
</dt>
<dd>
<p>Precision of the solution.</p> </dd> <dt>
<strong>class_weight</strong><span class="classifier">dict or ‘balanced’, default=None</span>
</dt>
<dd>
<p>Weights associated with classes in the form <code>{class_label: weight}</code>. If not given, all classes are supposed to have weight one.</p> <p>The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as <code>n_samples / (n_classes * np.bincount(y))</code>.</p> </dd> <dt>
<strong>solver</strong><span class="classifier">{‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’, ‘lbfgs’}, default=’auto’</span>
</dt>
<dd>
<p>Solver to use in the computational routines:</p> <ul> <li>‘auto’ chooses the solver automatically based on the type of data.</li> <li>‘svd’ uses a Singular Value Decomposition of X to compute the Ridge coefficients. It is the most stable solver, in particular more stable for singular matrices than ‘cholesky’ at the cost of being slower.</li> <li>‘cholesky’ uses the standard scipy.linalg.solve function to obtain a closed-form solution.</li> <li>‘sparse_cg’ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than ‘cholesky’ for large-scale data (possibility to set <code>tol</code> and <code>max_iter</code>).</li> <li>‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure.</li> <li>
<p>‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its unbiased and more flexible version named SAGA. Both methods use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.17: </span>Stochastic Average Gradient descent solver.</p> </div> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.19: </span>SAGA solver.</p> </div> </li> <li>‘lbfgs’ uses L-BFGS-B algorithm implemented in <code>scipy.optimize.minimize</code>. It can be used only when <code>positive</code> is True.</li> </ul> </dd> <dt>
<strong>positive</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>When set to <code>True</code>, forces the coefficients to be positive. Only ‘lbfgs’ solver is supported in this case.</p> </dd> <dt>
<strong>random_state</strong><span class="classifier">int, RandomState instance, default=None</span>
</dt>
<dd>
<p>Used when <code>solver</code> == ‘sag’ or ‘saga’ to shuffle the data. See <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a> for details.</p> </dd> </dl> </dd> <dt class="field-even">Attributes<span class="colon">:</span>
</dt> <dd class="field-even">
<dl> <dt>
<strong>coef_</strong><span class="classifier">ndarray of shape (1, n_features) or (n_classes, n_features)</span>
</dt>
<dd>
<p>Coefficient of the features in the decision function.</p> <p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.</p> </dd> <dt>
<strong>intercept_</strong><span class="classifier">float or ndarray of shape (n_targets,)</span>
</dt>
<dd>
<p>Independent term in decision function. Set to 0.0 if <code>fit_intercept = False</code>.</p> </dd> <dt>
<strong>n_iter_</strong><span class="classifier">None or ndarray of shape (n_targets,)</span>
</dt>
<dd>
<p>Actual number of iterations for each target. Available only for sag and lsqr solvers. Other solvers will return None.</p> </dd> <dt>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.classes_" title="sklearn.linear_model.RidgeClassifier.classes_"><code>classes_</code></a><span class="classifier">ndarray of shape (n_classes,)</span>
</dt>
<dd>
<p>Classes labels.</p> </dd> <dt>
<strong>n_features_in_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> <dt>
<strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code>n_features_in_</code>,)</span>
</dt>
<dd>
<p>Names of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code>X</code> has feature names that are all strings.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.0.</span></p> </div> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.linear_model.ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code>Ridge</code></a></dt>
<dd>
<p>Ridge regression.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.ridgeclassifiercv.html#sklearn.linear_model.RidgeClassifierCV" title="sklearn.linear_model.RidgeClassifierCV"><code>RidgeClassifierCV</code></a></dt>
<dd>
<p>Ridge classifier with built-in cross validation.</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import load_breast_cancer
&gt;&gt;&gt; from sklearn.linear_model import RidgeClassifier
&gt;&gt;&gt; X, y = load_breast_cancer(return_X_y=True)
&gt;&gt;&gt; clf = RidgeClassifier().fit(X, y)
&gt;&gt;&gt; clf.score(X, y)
0.9595...
</pre> <h4 class="rubric">Methods</h4> <table class="autosummary longtable docutils align-default">  <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.decision_function" title="sklearn.linear_model.RidgeClassifier.decision_function"><code>decision_function</code></a>(X)</p></td> <td><p>Predict confidence scores for samples.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.fit" title="sklearn.linear_model.RidgeClassifier.fit"><code>fit</code></a>(X, y[, sample_weight])</p></td> <td><p>Fit Ridge classifier model.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.get_params" title="sklearn.linear_model.RidgeClassifier.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.predict" title="sklearn.linear_model.RidgeClassifier.predict"><code>predict</code></a>(X)</p></td> <td><p>Predict class labels for samples in <code>X</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.score" title="sklearn.linear_model.RidgeClassifier.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the mean accuracy on the given test data and labels.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.set_params" title="sklearn.linear_model.RidgeClassifier.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py property"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.classes_"> <em class="property">property</em><span class="sig-name descname">classes_</span>
</dt> <dd>
<p>Classes labels.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.decision_function"> <span class="sig-name descname">decision_function</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_base.py#L408"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict confidence scores for samples.</p> <p>The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>The data matrix for which we want to get the confidence scores.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>scores</strong><span class="classifier">ndarray of shape (n_samples,) or (n_samples, n_classes)</span>
</dt>
<dd>
<p>Confidence scores per <code>(n_samples, n_classes)</code> combination. In the binary case, confidence score for <code>self.classes_[1]</code> where &gt;0 means this class would be predicted.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.fit"> <span class="sig-name descname">fit</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_ridge.py#L1397"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit Ridge classifier model.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>X</strong><span class="classifier">{ndarray, sparse matrix} of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Training data.</p> </dd> <dt>
<strong>y</strong><span class="classifier">ndarray of shape (n_samples,)</span>
</dt>
<dd>
<p>Target values.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">float or ndarray of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Individual weights for each sample. If given a float, every sample will have the same weight.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.17: </span><em>sample_weight</em> support to RidgeClassifier.</p> </div> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Instance of the estimator.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.get_params"> <span class="sig-name descname">get_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">deep</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L194"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>deep</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.predict"> <span class="sig-name descname">predict</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_ridge.py#L1185"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class labels for samples in <code>X</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">{array-like, spare matrix} of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>The data matrix for which we want to predict the targets.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>y_pred</strong><span class="classifier">ndarray of shape (n_samples,) or (n_samples, n_outputs)</span>
</dt>
<dd>
<p>Vector or matrix containing the predictions. In binary and multiclass problems, this is a vector containing <code>n_samples</code>. In a multilabel problem, it returns a matrix of shape <code>(n_samples, n_outputs)</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.score"> <span class="sig-name descname">score</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L640"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Test samples.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span>
</dt>
<dd>
<p>True labels for <code>X</code>.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>score</strong><span class="classifier">float</span>
</dt>
<dd>
<p>Mean accuracy of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.RidgeClassifier.set_params"> <span class="sig-name descname">set_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">params</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L218"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>**params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">estimator instance</span>
</dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <section id="examples-using-sklearn-linear-model-ridgeclassifier"> <h2>Examples using <code>sklearn.linear_model.RidgeClassifier</code>
</h2> <div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used to classify documents by topics using a...">
<img alt="Classification of text documents using sparse features" src="data:image/png;base64,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"> <p><a class="reference internal" href="../../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a></p>  </div></div>
</section> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.RidgeClassifier.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.RidgeClassifier.html</a>
  </p>
</div>
