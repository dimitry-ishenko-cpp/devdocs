<section id="zero-one-loss"> <h1>zero_one_loss</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.metrics.zero_one_loss"> <span class="sig-prename descclassname">sklearn.metrics.</span><span class="sig-name descname">zero_one_loss</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_pred</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/99bf3d8e4/sklearn/metrics/_classification.py#L1059"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Zero-one classification loss.</p> <p>If normalize is <code>True</code>, return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0.</p> <p>Read more in the <a class="reference internal" href="../model_evaluation.html#zero-one-loss"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>y_true</strong><span class="classifier">1d array-like, or label indicator array / sparse matrix</span>
</dt>
<dd>
<p>Ground truth (correct) labels.</p> </dd> <dt>
<strong>y_pred</strong><span class="classifier">1d array-like, or label indicator array / sparse matrix</span>
</dt>
<dd>
<p>Predicted labels, as returned by a classifier.</p> </dd> <dt>
<strong>normalize</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>False</code>, return the number of misclassifications. Otherwise, return the fraction of misclassifications.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>loss</strong><span class="classifier">float or int,</span>
</dt>
<dd>
<p>If <code>normalize == True</code>, return the fraction of misclassifications (float), else it returns the number of misclassifications (int).</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code>accuracy_score</code></a></dt>
<dd>
<p>Compute the accuracy score. By default, the function will return the fraction of correct predictions divided by the total number of predictions.</p> </dd> <dt><a class="reference internal" href="sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss"><code>hamming_loss</code></a></dt>
<dd>
<p>Compute the average Hamming loss or Hamming distance between two sets of samples.</p> </dd> <dt><a class="reference internal" href="sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score" title="sklearn.metrics.jaccard_score"><code>jaccard_score</code></a></dt>
<dd>
<p>Compute the Jaccard similarity coefficient score.</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>In multilabel classification, the zero_one_loss function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.metrics import zero_one_loss
&gt;&gt;&gt; y_pred = [1, 2, 3, 4]
&gt;&gt;&gt; y_true = [2, 2, 3, 4]
&gt;&gt;&gt; zero_one_loss(y_true, y_pred)
0.25
&gt;&gt;&gt; zero_one_loss(y_true, y_pred, normalize=False)
1.0
</pre> <p>In the multilabel case with binary label indicators:</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))
0.5
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2025 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.6/modules/generated/sklearn.metrics.zero_one_loss.html" class="_attribution-link">https://scikit-learn.org/1.6/modules/generated/sklearn.metrics.zero_one_loss.html</a>
  </p>
</div>
