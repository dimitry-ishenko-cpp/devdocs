<section id="mutual-info-classif"> <h1>mutual_info_classif</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.feature_selection.mutual_info_classif"> <span class="sig-prename descclassname">sklearn.feature_selection.</span><span class="sig-name descname">mutual_info_classif</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">discrete_features</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">n_neighbors</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">copy</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/99bf3d8e4/sklearn/feature_selection/_mutual_info.py#L453"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate mutual information for a discrete target variable.</p> <p>Mutual information (MI) <a class="reference internal" href="#r50b872b699c4-1" id="id1">[1]</a> between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</p> <p>The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances as described in <a class="reference internal" href="#r50b872b699c4-2" id="id2">[2]</a> and <a class="reference internal" href="#r50b872b699c4-3" id="id3">[3]</a>. Both methods are based on the idea originally proposed in <a class="reference internal" href="#r50b872b699c4-4" id="id4">[4]</a>.</p> <p>It can be used for univariate features selection, read more in the <a class="reference internal" href="../feature_selection.html#univariate-feature-selection"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Feature matrix.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>Target vector.</p> </dd> <dt>
<strong>discrete_features</strong><span class="classifier">‘auto’, bool or array-like, default=’auto’</span>
</dt>
<dd>
<p>If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If ‘auto’, it is assigned to False for dense <code>X</code> and to True for sparse <code>X</code>.</p> </dd> <dt>
<strong>n_neighbors</strong><span class="classifier">int, default=3</span>
</dt>
<dd>
<p>Number of neighbors to use for MI estimation for continuous variables, see <a class="reference internal" href="#r50b872b699c4-2" id="id5">[2]</a> and <a class="reference internal" href="#r50b872b699c4-3" id="id6">[3]</a>. Higher values reduce variance of the estimation, but could introduce a bias.</p> </dd> <dt>
<strong>copy</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether to make a copy of the given data. If set to False, the initial data will be overwritten.</p> </dd> <dt>
<strong>random_state</strong><span class="classifier">int, RandomState instance or None, default=None</span>
</dt>
<dd>
<p>Determines random number generation for adding small noise to continuous variables in order to remove repeated values. Pass an int for reproducible results across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/1.6/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p> </dd> <dt>
<strong>n_jobs</strong><span class="classifier">int, default=None</span>
</dt>
<dd>
<p>The number of jobs to use for computing the mutual information. The parallelization is done on the columns of <code>X</code>. <code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.parallel_backend.html#joblib.parallel_backend" title="(in joblib v1.5.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="https://scikit-learn.org/1.6/glossary.html#term-n_jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> <div class="versionadded"> <p><span class="versionmodified added">Added in version 1.5.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>mi</strong><span class="classifier">ndarray, shape (n_features,)</span>
</dt>
<dd>
<p>Estimated mutual information between each feature and the target in nat units.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <ol class="arabic simple"> <li>The term “discrete features” is used instead of naming them “categorical”, because it describes the essence more accurately. For example, pixel intensities of an image are discrete features (but hardly categorical) and you will get better results if mark them as such. Also note, that treating a continuous variable as discrete and vice versa will usually give incorrect results, so be attentive about that.</li> <li>True mutual information can’t be negative. If its estimate turns out to be negative, it is replaced by zero.</li> </ol> <h4 class="rubric">References</h4> <div role="list" class="citation-list"> <div class="citation" id="r50b872b699c4-1" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span> <p><a class="reference external" href="https://en.wikipedia.org/wiki/Mutual_information">Mutual Information</a> on Wikipedia.</p> </div> <div class="citation" id="r50b872b699c4-2" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span> <span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id5">2</a>)</span> <p>A. Kraskov, H. Stogbauer and P. Grassberger, “Estimating mutual information”. Phys. Rev. E 69, 2004.</p> </div> <div class="citation" id="r50b872b699c4-3" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span> <span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span> <p>B. C. Ross “Mutual Information between Discrete and Continuous Data Sets”. PLoS ONE 9(2), 2014.</p> </div> <div class="citation" id="r50b872b699c4-4" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span> <p>L. F. Kozachenko, N. N. Leonenko, “Sample Estimate of the Entropy of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16</p> </div> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import make_classification
&gt;&gt;&gt; from sklearn.feature_selection import mutual_info_classif
&gt;&gt;&gt; X, y = make_classification(
...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,
...     shuffle=False, random_state=42
... )
&gt;&gt;&gt; mutual_info_classif(X, y)
array([0.58..., 0.10..., 0.19..., 0.09... , 0.        ,
       0.     , 0.     , 0.     , 0.      , 0.        ])
</pre> </dd>
</dl> <section id="gallery-examples"> <h2>Gallery examples</h2> <div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of GridSearchCV and Pipeline to optimize over different classes of estimators in a single CV run -- unsupervised PCA and NMF dimensionality reductions are compared to univariate feature selection during the grid search.">
<img alt="" src="data:image/png;base64,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"> <p><a class="reference internal" href="../../auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py"><span class="std std-ref">Selecting dimensionality reduction with Pipeline and GridSearchCV</span></a></p>  </div></div></section> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2025 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.mutual_info_classif.html" class="_attribution-link">https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.mutual_info_classif.html</a>
  </p>
</div>
