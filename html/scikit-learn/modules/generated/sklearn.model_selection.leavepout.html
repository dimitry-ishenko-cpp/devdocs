<section id="sklearn-model-selection-leavepout"> <h1>sklearn.model_selection.LeavePOut</h1> <dl class="py class"> <dt class="sig sig-object py" id="sklearn.model_selection.LeavePOut"> <em class="property">class</em><span class="sig-prename descclassname">sklearn.model_selection.</span><span class="sig-name descname">LeavePOut</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/model_selection/_split.py#L193"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Leave-P-Out cross-validator</p> <p>Provides train/test indices to split data in train/test sets. This results in testing on all distinct samples of size p, while the remaining n - p samples form the training set in each iteration.</p> <p>Note: <code>LeavePOut(p)</code> is NOT equivalent to <code>KFold(n_splits=n_samples // p)</code> which creates non-overlapping test sets.</p> <p>Due to the high number of iterations which grows combinatorically with the number of samples this cross-validation method can be very costly. For large datasets one should favor <a class="reference internal" href="sklearn.model_selection.kfold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a>, <a class="reference internal" href="sklearn.model_selection.stratifiedkfold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code>StratifiedKFold</code></a> or <a class="reference internal" href="sklearn.model_selection.shufflesplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code>ShuffleSplit</code></a>.</p> <p>Read more in the <a class="reference internal" href="../cross_validation.html#leave-p-out"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>p</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Size of the test sets. Must be strictly less than the number of samples.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import LeavePOut
&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
&gt;&gt;&gt; y = np.array([1, 2, 3, 4])
&gt;&gt;&gt; lpo = LeavePOut(2)
&gt;&gt;&gt; lpo.get_n_splits(X)
6
&gt;&gt;&gt; print(lpo)
LeavePOut(p=2)
&gt;&gt;&gt; for train_index, test_index in lpo.split(X):
...     print("TRAIN:", train_index, "TEST:", test_index)
...     X_train, X_test = X[train_index], X[test_index]
...     y_train, y_test = y[train_index], y[test_index]
TRAIN: [2 3] TEST: [0 1]
TRAIN: [1 3] TEST: [0 2]
TRAIN: [1 2] TEST: [0 3]
TRAIN: [0 3] TEST: [1 2]
TRAIN: [0 2] TEST: [1 3]
TRAIN: [0 1] TEST: [2 3]
</pre> <h4 class="rubric">Methods</h4> <table class="autosummary longtable docutils align-default">  <tr>
<td><p><a class="reference internal" href="#sklearn.model_selection.LeavePOut.get_n_splits" title="sklearn.model_selection.LeavePOut.get_n_splits"><code>get_n_splits</code></a>(X[, y, groups])</p></td> <td><p>Returns the number of splitting iterations in the cross-validator</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.model_selection.LeavePOut.split" title="sklearn.model_selection.LeavePOut.split"><code>split</code></a>(X[, y, groups])</p></td> <td><p>Generate indices to split data into training and test set.</p></td> </tr>  </table> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.model_selection.LeavePOut.get_n_splits"> <span class="sig-name descname">get_n_splits</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/model_selection/_split.py#L253"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the number of splitting iterations in the cross-validator</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Training data, where <code>n_samples</code> is the number of samples and <code>n_features</code> is the number of features.</p> </dd> <dt>
<strong>y</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Always ignored, exists for compatibility.</p> </dd> <dt>
<strong>groups</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Always ignored, exists for compatibility.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.model_selection.LeavePOut.split"> <span class="sig-name descname">split</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/model_selection/_split.py#L60"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Generate indices to split data into training and test set.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Training data, where <code>n_samples</code> is the number of samples and <code>n_features</code> is the number of features.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>The target variable for supervised learning problems.</p> </dd> <dt>
<strong>groups</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Group labels for the samples used while splitting the dataset into train/test set.</p> </dd> </dl> </dd> <dt class="field-even">Yields<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>train</strong><span class="classifier">ndarray</span>
</dt>
<dd>
<p>The training set indices for that split.</p> </dd> <dt>
<strong>test</strong><span class="classifier">ndarray</span>
</dt>
<dd>
<p>The testing set indices for that split.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.model_selection.LeavePOut.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.model_selection.LeavePOut.html</a>
  </p>
</div>
