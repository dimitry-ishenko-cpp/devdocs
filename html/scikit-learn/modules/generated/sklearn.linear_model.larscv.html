<section id="sklearn-linear-model-larscv"> <h1>sklearn.linear_model.LarsCV</h1> <dl class="py class"> <dt class="sig sig-object py" id="sklearn.linear_model.LarsCV"> <em class="property">class</em><span class="sig-prename descclassname">sklearn.linear_model.</span><span class="sig-name descname">LarsCV</span><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">fit_intercept</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">'deprecated'</span></em>, <em class="sig-param"><span class="n">precompute</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">cv</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_n_alphas</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">2.220446049250313e-16</span></em>, <em class="sig-param"><span class="n">copy_X</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_least_angle.py#L1472"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Cross-validated Least Angle Regression model.</p> <p>See glossary entry for <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-cross-validation-estimator"><span class="xref std std-term">cross-validation estimator</span></a>.</p> <p>Read more in the <a class="reference internal" href="../linear_model.html#least-angle-regression"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>fit_intercept</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">bool or int, default=False</span>
</dt>
<dd>
<p>Sets the verbosity amount.</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=500</span>
</dt>
<dd>
<p>Maximum number of iterations to perform.</p> </dd> <dt>
<strong>normalize</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>This parameter is ignored when <code>fit_intercept</code> is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use <a class="reference internal" href="sklearn.preprocessing.standardscaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.0: </span><code>normalize</code> was deprecated in version 1.0. It will default to False in 1.2 and be removed in 1.4.</p> </div> </dd> <dt>
<strong>precompute</strong><span class="classifier">bool, ‘auto’ or array-like , default=’auto’</span>
</dt>
<dd>
<p>Whether to use a precomputed Gram matrix to speed up calculations. If set to <code>'auto'</code> let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</p> </dd> <dt>
<strong>cv</strong><span class="classifier">int, cross-validation generator or an iterable, default=None</span>
</dt>
<dd>
<p>Determines the cross-validation splitting strategy. Possible inputs for cv are:</p> <ul class="simple"> <li>None, to use the default 5-fold cross-validation,</li> <li>integer, to specify the number of folds.</li> <li>
<a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-CV-splitter"><span class="xref std std-term">CV splitter</span></a>,</li> <li>An iterable yielding (train, test) splits as arrays of indices.</li> </ul> <p>For integer/None inputs, <code>KFold</code> is used.</p> <p>Refer <a class="reference internal" href="../cross_validation.html#cross-validation"><span class="std std-ref">User Guide</span></a> for the various cross-validation strategies that can be used here.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.22: </span><code>cv</code> default value if None changed from 3-fold to 5-fold.</p> </div> </dd> <dt>
<strong>max_n_alphas</strong><span class="classifier">int, default=1000</span>
</dt>
<dd>
<p>The maximum number of points on the path used to compute the residuals in the cross-validation.</p> </dd> <dt>
<strong>n_jobs</strong><span class="classifier">int or None, default=None</span>
</dt>
<dd>
<p>Number of CPUs to use during the cross validation. <code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v1.3.0.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-n_jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> </dd> <dt>
<strong>eps</strong><span class="classifier">float, default=np.finfo(float).eps</span>
</dt>
<dd>
<p>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the <code>tol</code> parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</p> </dd> <dt>
<strong>copy_X</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>True</code>, X will be copied; else, it may be overwritten.</p> </dd> </dl> </dd> <dt class="field-even">Attributes<span class="colon">:</span>
</dt> <dd class="field-even">
<dl> <dt>
<strong>active_</strong><span class="classifier">list of length n_alphas or list of such lists</span>
</dt>
<dd>
<p>Indices of active variables at the end of the path. If this is a list of lists, the outer list length is <code>n_targets</code>.</p> </dd> <dt>
<strong>coef_</strong><span class="classifier">array-like of shape (n_features,)</span>
</dt>
<dd>
<p>parameter vector (w in the formulation formula)</p> </dd> <dt>
<strong>intercept_</strong><span class="classifier">float</span>
</dt>
<dd>
<p>independent term in decision function</p> </dd> <dt>
<strong>coef_path_</strong><span class="classifier">array-like of shape (n_features, n_alphas)</span>
</dt>
<dd>
<p>the varying values of the coefficients along the path</p> </dd> <dt>
<strong>alpha_</strong><span class="classifier">float</span>
</dt>
<dd>
<p>the estimated regularization parameter alpha</p> </dd> <dt>
<strong>alphas_</strong><span class="classifier">array-like of shape (n_alphas,)</span>
</dt>
<dd>
<p>the different values of alpha along the path</p> </dd> <dt>
<strong>cv_alphas_</strong><span class="classifier">array-like of shape (n_cv_alphas,)</span>
</dt>
<dd>
<p>all the values of alpha along the path for the different folds</p> </dd> <dt>
<strong>mse_path_</strong><span class="classifier">array-like of shape (n_folds, n_cv_alphas)</span>
</dt>
<dd>
<p>the mean square error on left-out for each fold along the path (alpha values given by <code>cv_alphas</code>)</p> </dd> <dt>
<strong>n_iter_</strong><span class="classifier">array-like or int</span>
</dt>
<dd>
<p>the number of iterations run by Lars with the optimal alpha.</p> </dd> <dt>
<strong>n_features_in_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> <dt>
<strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code>n_features_in_</code>,)</span>
</dt>
<dd>
<p>Names of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code>X</code> has feature names that are all strings.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.0.</span></p> </div> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.linear_model.lars_path.html#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code>lars_path</code></a></dt>
<dd>
<p>Compute Least Angle Regression or Lasso path using LARS algorithm.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path" title="sklearn.linear_model.lasso_path"><code>lasso_path</code></a></dt>
<dd>
<p>Compute Lasso path with coordinate descent.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code>Lasso</code></a></dt>
<dd>
<p>Linear Model trained with L1 prior as regularizer (aka the Lasso).</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassocv.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code>LassoCV</code></a></dt>
<dd>
<p>Lasso linear model with iterative fitting along a regularization path.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassolars.html#sklearn.linear_model.LassoLars" title="sklearn.linear_model.LassoLars"><code>LassoLars</code></a></dt>
<dd>
<p>Lasso model fit with Least Angle Regression a.k.a. Lars.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassolarsic.html#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><code>LassoLarsIC</code></a></dt>
<dd>
<p>Lasso model fit with Lars using BIC or AIC for model selection.</p> </dd> <dt><a class="reference internal" href="sklearn.decomposition.sparse_encode.html#sklearn.decomposition.sparse_encode" title="sklearn.decomposition.sparse_encode"><code>sklearn.decomposition.sparse_encode</code></a></dt>
<dd>
<p>Sparse coding.</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>In <code>fit</code>, once the best parameter <code>alpha</code> is found through cross-validation, the model is fit again using the entire training set.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.linear_model import LarsCV
&gt;&gt;&gt; from sklearn.datasets import make_regression
&gt;&gt;&gt; X, y = make_regression(n_samples=200, noise=4.0, random_state=0)
&gt;&gt;&gt; reg = LarsCV(cv=5, normalize=False).fit(X, y)
&gt;&gt;&gt; reg.score(X, y)
0.9996...
&gt;&gt;&gt; reg.alpha_
0.2961...
&gt;&gt;&gt; reg.predict(X[:1,])
array([154.3996...])
</pre> <h4 class="rubric">Methods</h4> <table class="autosummary longtable docutils align-default">  <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.fit" title="sklearn.linear_model.LarsCV.fit"><code>fit</code></a>(X, y)</p></td> <td><p>Fit the model using X, y as training data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.get_params" title="sklearn.linear_model.LarsCV.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.predict" title="sklearn.linear_model.LarsCV.predict"><code>predict</code></a>(X)</p></td> <td><p>Predict using the linear model.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.score" title="sklearn.linear_model.LarsCV.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the coefficient of determination of the prediction.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.set_params" title="sklearn.linear_model.LarsCV.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LarsCV.fit"> <span class="sig-name descname">fit</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_least_angle.py#L1655"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the model using X, y as training data.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Training data.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>Target values.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Returns an instance of self.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LarsCV.get_params"> <span class="sig-name descname">get_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">deep</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L194"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>deep</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LarsCV.predict"> <span class="sig-name descname">predict</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_base.py#L372"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the linear model.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like or sparse matrix, shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Samples.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>C</strong><span class="classifier">array, shape (n_samples,)</span>
</dt>
<dd>
<p>Returns predicted values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LarsCV.score"> <span class="sig-name descname">score</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L677"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the coefficient of determination of the prediction.</p> <p>The coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> is defined as <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, where <span class="math notranslate nohighlight">\(u\)</span> is the residual sum of squares <code>((y_true - y_pred)** 2).sum()</code> and <span class="math notranslate nohighlight">\(v\)</span> is the total sum of squares <code>((y_true - y_true.mean()) ** 2).sum()</code>. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of <code>y</code>, disregarding the input features, would get a <span class="math notranslate nohighlight">\(R^2\)</span> score of 0.0.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape <code>(n_samples, n_samples_fitted)</code>, where <code>n_samples_fitted</code> is the number of samples used in the fitting for the estimator.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span>
</dt>
<dd>
<p>True values for <code>X</code>.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>score</strong><span class="classifier">float</span>
</dt>
<dd>
<p><span class="math notranslate nohighlight">\(R^2\)</span> of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The <span class="math notranslate nohighlight">\(R^2\)</span> score used when calling <code>score</code> on a regressor uses <code>multioutput='uniform_average'</code> from version 0.23 to keep consistent with default value of <a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code>r2_score</code></a>. This influences the <code>score</code> method of all the multioutput regressors (except for <a class="reference internal" href="sklearn.multioutput.multioutputregressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code>MultiOutputRegressor</code></a>).</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LarsCV.set_params"> <span class="sig-name descname">set_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">params</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L218"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>**params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">estimator instance</span>
</dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.LarsCV.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.LarsCV.html</a>
  </p>
</div>
