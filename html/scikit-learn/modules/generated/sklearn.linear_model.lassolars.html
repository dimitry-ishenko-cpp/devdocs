<section id="sklearn-linear-model-lassolars"> <h1>sklearn.linear_model.LassoLars</h1> <dl class="py class"> <dt class="sig sig-object py" id="sklearn.linear_model.LassoLars"> <em class="property">class</em><span class="sig-prename descclassname">sklearn.linear_model.</span><span class="sig-name descname">LassoLars</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">fit_intercept</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">'deprecated'</span></em>, <em class="sig-param"><span class="n">precompute</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">2.220446049250313e-16</span></em>, <em class="sig-param"><span class="n">copy_X</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">fit_path</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">positive</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">jitter</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_least_angle.py#L1141"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Lasso model fit with Least Angle Regression a.k.a. Lars.</p> <p>It is a Linear Model trained with an L1 prior as regularizer.</p> <p>The optimization objective for Lasso is:</p> <pre data-language="python">(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
</pre> <p>Read more in the <a class="reference internal" href="../linear_model.html#least-angle-regression"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>alpha</strong><span class="classifier">float, default=1.0</span>
</dt>
<dd>
<p>Constant that multiplies the penalty term. Defaults to 1.0. <code>alpha = 0</code> is equivalent to an ordinary least square, solved by <a class="reference internal" href="sklearn.linear_model.linearregression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code>LinearRegression</code></a>. For numerical reasons, using <code>alpha = 0</code> with the LassoLars object is not advised and you should prefer the LinearRegression object.</p> </dd> <dt>
<strong>fit_intercept</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">bool or int, default=False</span>
</dt>
<dd>
<p>Sets the verbosity amount.</p> </dd> <dt>
<strong>normalize</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>This parameter is ignored when <code>fit_intercept</code> is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use <a class="reference internal" href="sklearn.preprocessing.standardscaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.0: </span><code>normalize</code> was deprecated in version 1.0. It will default to False in 1.2 and be removed in 1.4.</p> </div> </dd> <dt>
<strong>precompute</strong><span class="classifier">bool, ‘auto’ or array-like, default=’auto’</span>
</dt>
<dd>
<p>Whether to use a precomputed Gram matrix to speed up calculations. If set to <code>'auto'</code> let us decide. The Gram matrix can also be passed as argument.</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=500</span>
</dt>
<dd>
<p>Maximum number of iterations to perform.</p> </dd> <dt>
<strong>eps</strong><span class="classifier">float, default=np.finfo(float).eps</span>
</dt>
<dd>
<p>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the <code>tol</code> parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</p> </dd> <dt>
<strong>copy_X</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True, X will be copied; else, it may be overwritten.</p> </dd> <dt>
<strong>fit_path</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>True</code> the full path is stored in the <code>coef_path_</code> attribute. If you compute the solution for a large problem or many targets, setting <code>fit_path</code> to <code>False</code> will lead to a speedup, especially with a small alpha.</p> </dd> <dt>
<strong>positive</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Restrict coefficients to be &gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.</p> </dd> <dt>
<strong>jitter</strong><span class="classifier">float, default=None</span>
</dt>
<dd>
<p>Upper bound on a uniform noise parameter to be added to the <code>y</code> values, to satisfy the model’s assumption of one-at-a-time computations. Might help with stability.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.23.</span></p> </div> </dd> <dt>
<strong>random_state</strong><span class="classifier">int, RandomState instance or None, default=None</span>
</dt>
<dd>
<p>Determines random number generation for jittering. Pass an int for reproducible output across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>. Ignored if <code>jitter</code> is None.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.23.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Attributes<span class="colon">:</span>
</dt> <dd class="field-even">
<dl> <dt>
<strong>alphas_</strong><span class="classifier">array-like of shape (n_alphas + 1,) or list of such arrays</span>
</dt>
<dd>
<p>Maximum of covariances (in absolute value) at each iteration. <code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever is smaller. If this is a list of array-like, the length of the outer list is <code>n_targets</code>.</p> </dd> <dt>
<strong>active_</strong><span class="classifier">list of length n_alphas or list of such lists</span>
</dt>
<dd>
<p>Indices of active variables at the end of the path. If this is a list of list, the length of the outer list is <code>n_targets</code>.</p> </dd> <dt>
<strong>coef_path_</strong><span class="classifier">array-like of shape (n_features, n_alphas + 1) or list of such arrays</span>
</dt>
<dd>
<p>If a list is passed it’s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the <code>fit_path</code> parameter is <code>False</code>. If this is a list of array-like, the length of the outer list is <code>n_targets</code>.</p> </dd> <dt>
<strong>coef_</strong><span class="classifier">array-like of shape (n_features,) or (n_targets, n_features)</span>
</dt>
<dd>
<p>Parameter vector (w in the formulation formula).</p> </dd> <dt>
<strong>intercept_</strong><span class="classifier">float or array-like of shape (n_targets,)</span>
</dt>
<dd>
<p>Independent term in decision function.</p> </dd> <dt>
<strong>n_iter_</strong><span class="classifier">array-like or int</span>
</dt>
<dd>
<p>The number of iterations taken by lars_path to find the grid of alphas for each target.</p> </dd> <dt>
<strong>n_features_in_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> <dt>
<strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code>n_features_in_</code>,)</span>
</dt>
<dd>
<p>Names of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code>X</code> has feature names that are all strings.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.0.</span></p> </div> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.linear_model.lars_path.html#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code>lars_path</code></a></dt>
<dd>
<p>Compute Least Angle Regression or Lasso path using LARS algorithm.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path" title="sklearn.linear_model.lasso_path"><code>lasso_path</code></a></dt>
<dd>
<p>Compute Lasso path with coordinate descent.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code>Lasso</code></a></dt>
<dd>
<p>Linear Model trained with L1 prior as regularizer (aka the Lasso).</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassocv.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code>LassoCV</code></a></dt>
<dd>
<p>Lasso linear model with iterative fitting along a regularization path.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassolarscv.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code>LassoLarsCV</code></a></dt>
<dd>
<p>Cross-validated Lasso, using the LARS algorithm.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassolarsic.html#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><code>LassoLarsIC</code></a></dt>
<dd>
<p>Lasso model fit with Lars using BIC or AIC for model selection.</p> </dd> <dt><a class="reference internal" href="sklearn.decomposition.sparse_encode.html#sklearn.decomposition.sparse_encode" title="sklearn.decomposition.sparse_encode"><code>sklearn.decomposition.sparse_encode</code></a></dt>
<dd>
<p>Sparse coding.</p> </dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn import linear_model
&gt;&gt;&gt; reg = linear_model.LassoLars(alpha=0.01, normalize=False)
&gt;&gt;&gt; reg.fit([[-1, 1], [0, 0], [1, 1]], [-1, 0, -1])
LassoLars(alpha=0.01, normalize=False)
&gt;&gt;&gt; print(reg.coef_)
[ 0.         -0.955...]
</pre> <h4 class="rubric">Methods</h4> <table class="autosummary longtable docutils align-default">  <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.fit" title="sklearn.linear_model.LassoLars.fit"><code>fit</code></a>(X, y[, Xy])</p></td> <td><p>Fit the model using X, y as training data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.get_params" title="sklearn.linear_model.LassoLars.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.predict" title="sklearn.linear_model.LassoLars.predict"><code>predict</code></a>(X)</p></td> <td><p>Predict using the linear model.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.score" title="sklearn.linear_model.LassoLars.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the coefficient of determination of the prediction.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.set_params" title="sklearn.linear_model.LassoLars.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LassoLars.fit"> <span class="sig-name descname">fit</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">Xy</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_least_angle.py#L1088"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the model using X, y as training data.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Training data.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_targets)</span>
</dt>
<dd>
<p>Target values.</p> </dd> <dt>
<strong>Xy</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_targets), default=None</span>
</dt>
<dd>
<p>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Returns an instance of self.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LassoLars.get_params"> <span class="sig-name descname">get_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">deep</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L194"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>deep</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LassoLars.predict"> <span class="sig-name descname">predict</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/linear_model/_base.py#L372"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the linear model.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like or sparse matrix, shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Samples.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>C</strong><span class="classifier">array, shape (n_samples,)</span>
</dt>
<dd>
<p>Returns predicted values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LassoLars.score"> <span class="sig-name descname">score</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L677"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the coefficient of determination of the prediction.</p> <p>The coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> is defined as <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, where <span class="math notranslate nohighlight">\(u\)</span> is the residual sum of squares <code>((y_true - y_pred)** 2).sum()</code> and <span class="math notranslate nohighlight">\(v\)</span> is the total sum of squares <code>((y_true - y_true.mean()) ** 2).sum()</code>. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of <code>y</code>, disregarding the input features, would get a <span class="math notranslate nohighlight">\(R^2\)</span> score of 0.0.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape <code>(n_samples, n_samples_fitted)</code>, where <code>n_samples_fitted</code> is the number of samples used in the fitting for the estimator.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span>
</dt>
<dd>
<p>True values for <code>X</code>.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>score</strong><span class="classifier">float</span>
</dt>
<dd>
<p><span class="math notranslate nohighlight">\(R^2\)</span> of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The <span class="math notranslate nohighlight">\(R^2\)</span> score used when calling <code>score</code> on a regressor uses <code>multioutput='uniform_average'</code> from version 0.23 to keep consistent with default value of <a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code>r2_score</code></a>. This influences the <code>score</code> method of all the multioutput regressors (except for <a class="reference internal" href="sklearn.multioutput.multioutputregressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code>MultiOutputRegressor</code></a>).</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.linear_model.LassoLars.set_params"> <span class="sig-name descname">set_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">params</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L218"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>**params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">estimator instance</span>
</dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.LassoLars.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.linear_model.LassoLars.html</a>
  </p>
</div>
