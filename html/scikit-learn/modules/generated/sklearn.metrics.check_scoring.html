<section id="check-scoring"> <h1>check_scoring</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.metrics.check_scoring"> <span class="sig-prename descclassname">sklearn.metrics.</span><span class="sig-name descname">check_scoring</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scoring</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">allow_none</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">raise_exc</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/99bf3d8e4/sklearn/metrics/_scorer.py#L904"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Determine scorer from user options.</p> <p>A TypeError will be thrown if the estimator cannot be scored.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>estimator</strong><span class="classifier">estimator object implementing ‘fit’ or None, default=None</span>
</dt>
<dd>
<p>The object to use to fit the data. If <code>None</code>, then this function may error depending on <code>allow_none</code>.</p> </dd> <dt>
<strong>scoring</strong><span class="classifier">str, callable, list, tuple, set, or dict, default=None</span>
</dt>
<dd>
<p>Scorer to use. If <code>scoring</code> represents a single score, one can use:</p> <ul class="simple"> <li>a single string (see <a class="reference internal" href="../model_evaluation.html#scoring-parameter"><span class="std std-ref">The scoring parameter: defining model evaluation rules</span></a>);</li> <li>a callable (see <a class="reference internal" href="../model_evaluation.html#scoring-callable"><span class="std std-ref">Callable scorers</span></a>) that returns a single value.</li> </ul> <p>If <code>scoring</code> represents multiple scores, one can use:</p> <ul class="simple"> <li>a list, tuple or set of unique strings;</li> <li>a callable returning a dictionary where the keys are the metric names and the values are the metric scorers;</li> <li>a dictionary with metric names as keys and callables a values. The callables need to have the signature <code>callable(estimator, X, y)</code>.</li> </ul> <p>If None, the provided estimator object’s <code>score</code> method is used.</p> </dd> <dt>
<strong>allow_none</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Whether to return None or raise an error if no <code>scoring</code> is specified and the estimator has no <code>score</code> method.</p> </dd> <dt>
<strong>raise_exc</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether to raise an exception (if a subset of the scorers in multimetric scoring fails) or to return an error code.</p> <ul class="simple"> <li>If set to <code>True</code>, raises the failing scorer’s exception.</li> <li>If set to <code>False</code>, a formatted string of the exception details is passed as result of the failing scorer(s).</li> </ul> <p>This applies if <code>scoring</code> is list, tuple, set, or dict. Ignored if <code>scoring</code> is a str or a callable.</p> <div class="versionadded"> <p><span class="versionmodified added">Added in version 1.6.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>scoring</strong><span class="classifier">callable</span>
</dt>
<dd>
<p>A scorer callable object / function with signature <code>scorer(estimator, X, y)</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.metrics import check_scoring
&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier
&gt;&gt;&gt; X, y = load_iris(return_X_y=True)
&gt;&gt;&gt; classifier = DecisionTreeClassifier(max_depth=2).fit(X, y)
&gt;&gt;&gt; scorer = check_scoring(classifier, scoring='accuracy')
&gt;&gt;&gt; scorer(classifier, X, y)
0.96...
</pre> <pre data-language="python">&gt;&gt;&gt; from sklearn.metrics import make_scorer, accuracy_score, mean_squared_log_error
&gt;&gt;&gt; X, y = load_iris(return_X_y=True)
&gt;&gt;&gt; y *= -1
&gt;&gt;&gt; clf = DecisionTreeClassifier().fit(X, y)
&gt;&gt;&gt; scoring = {
...     "accuracy": make_scorer(accuracy_score),
...     "mean_squared_log_error": make_scorer(mean_squared_log_error),
... }
&gt;&gt;&gt; scoring_call = check_scoring(estimator=clf, scoring=scoring, raise_exc=False)
&gt;&gt;&gt; scores = scoring_call(clf, X, y)
&gt;&gt;&gt; scores
{'accuracy': 1.0, 'mean_squared_log_error': 'Traceback ...'}
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2025 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.6/modules/generated/sklearn.metrics.check_scoring.html" class="_attribution-link">https://scikit-learn.org/1.6/modules/generated/sklearn.metrics.check_scoring.html</a>
  </p>
</div>
