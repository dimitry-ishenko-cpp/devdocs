<section id="lars-path-gram"> <h1>lars_path_gram</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.linear_model.lars_path_gram"> <span class="sig-prename descclassname">sklearn.linear_model.</span><span class="sig-name descname">lars_path_gram</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xy</span></em>, <em class="sig-param"><span class="n">Gram</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">n_samples</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">alpha_min</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'lar'</span></em>, <em class="sig-param"><span class="n">copy_X</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">np.float64(2.220446049250313e-16)</span></em>, <em class="sig-param"><span class="n">copy_Gram</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">return_path</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">return_n_iter</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">positive</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/99bf3d8e4/sklearn/linear_model/_least_angle.py#L235"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>The lars_path in the sufficient stats mode.</p> <p>The optimization objective for the case method=’lasso’ is:</p> <pre data-language="python">(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
</pre> <p>in the case of method=’lar’, the objective function is only known in the form of an implicit equation (see discussion in <a class="reference internal" href="#r34229eeff553-1" id="id1">[1]</a>).</p> <p>Read more in the <a class="reference internal" href="../linear_model.html#least-angle-regression"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>Xy</strong><span class="classifier">ndarray of shape (n_features,)</span>
</dt>
<dd>
<p><code>Xy = X.T @ y</code>.</p> </dd> <dt>
<strong>Gram</strong><span class="classifier">ndarray of shape (n_features, n_features)</span>
</dt>
<dd>
<p><code>Gram = X.T @ X</code>.</p> </dd> <dt>
<strong>n_samples</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Equivalent size of sample.</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=500</span>
</dt>
<dd>
<p>Maximum number of iterations to perform, set to infinity for no limit.</p> </dd> <dt>
<strong>alpha_min</strong><span class="classifier">float, default=0</span>
</dt>
<dd>
<p>Minimum correlation along the path. It corresponds to the regularization parameter alpha parameter in the Lasso.</p> </dd> <dt>
<strong>method</strong><span class="classifier">{‘lar’, ‘lasso’}, default=’lar’</span>
</dt>
<dd>
<p>Specifies the returned model. Select <code>'lar'</code> for Least Angle Regression, <code>'lasso'</code> for the Lasso.</p> </dd> <dt>
<strong>copy_X</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>False</code>, <code>X</code> is overwritten.</p> </dd> <dt>
<strong>eps</strong><span class="classifier">float, default=np.finfo(float).eps</span>
</dt>
<dd>
<p>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the <code>tol</code> parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</p> </dd> <dt>
<strong>copy_Gram</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>False</code>, <code>Gram</code> is overwritten.</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">int, default=0</span>
</dt>
<dd>
<p>Controls output verbosity.</p> </dd> <dt>
<strong>return_path</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>return_path==True</code> returns the entire path, else returns only the last point of the path.</p> </dd> <dt>
<strong>return_n_iter</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Whether to return the number of iterations.</p> </dd> <dt>
<strong>positive</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>Restrict coefficients to be &gt;= 0. This option is only allowed with method ‘lasso’. Note that the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt; 0.].min()</code> when <code>fit_path=True</code>) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent lasso_path function.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>alphas</strong><span class="classifier">ndarray of shape (n_alphas + 1,)</span>
</dt>
<dd>
<p>Maximum of covariances (in absolute value) at each iteration. <code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever is smaller.</p> </dd> <dt>
<strong>active</strong><span class="classifier">ndarray of shape (n_alphas,)</span>
</dt>
<dd>
<p>Indices of active variables at the end of the path.</p> </dd> <dt>
<strong>coefs</strong><span class="classifier">ndarray of shape (n_features, n_alphas + 1)</span>
</dt>
<dd>
<p>Coefficients along the path.</p> </dd> <dt>
<strong>n_iter</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of iterations run. Returned only if <code>return_n_iter</code> is set to True.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="#sklearn.linear_model.lars_path_gram" title="sklearn.linear_model.lars_path_gram"><code>lars_path_gram</code></a></dt>
<dd>
<p>Compute LARS path.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path" title="sklearn.linear_model.lasso_path"><code>lasso_path</code></a></dt>
<dd>
<p>Compute Lasso path with coordinate descent.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassolars.html#sklearn.linear_model.LassoLars" title="sklearn.linear_model.LassoLars"><code>LassoLars</code></a></dt>
<dd>
<p>Lasso model fit with Least Angle Regression a.k.a. Lars.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lars.html#sklearn.linear_model.Lars" title="sklearn.linear_model.Lars"><code>Lars</code></a></dt>
<dd>
<p>Least Angle Regression model a.k.a. LAR.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.lassolarscv.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code>LassoLarsCV</code></a></dt>
<dd>
<p>Cross-validated Lasso, using the LARS algorithm.</p> </dd> <dt><a class="reference internal" href="sklearn.linear_model.larscv.html#sklearn.linear_model.LarsCV" title="sklearn.linear_model.LarsCV"><code>LarsCV</code></a></dt>
<dd>
<p>Cross-validated Least Angle Regression model.</p> </dd> <dt><a class="reference internal" href="sklearn.decomposition.sparse_encode.html#sklearn.decomposition.sparse_encode" title="sklearn.decomposition.sparse_encode"><code>sklearn.decomposition.sparse_encode</code></a></dt>
<dd>
<p>Sparse coding.</p> </dd> </dl> </div> <h4 class="rubric">References</h4> <div role="list" class="citation-list"> <div class="citation" id="r34229eeff553-1" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span> <p>“Least Angle Regression”, Efron et al. <a class="reference external" href="http://statweb.stanford.edu/~tibs/ftp/lars.pdf">http://statweb.stanford.edu/~tibs/ftp/lars.pdf</a></p> </div> <div class="citation" id="r34229eeff553-2" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span> <p><a class="reference external" href="https://en.wikipedia.org/wiki/Least-angle_regression">Wikipedia entry on the Least-angle regression</a></p> </div> <div class="citation" id="r34229eeff553-3" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span> <p><a class="reference external" href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Wikipedia entry on the Lasso</a></p> </div> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.linear_model import lars_path_gram
&gt;&gt;&gt; from sklearn.datasets import make_regression
&gt;&gt;&gt; X, y, true_coef = make_regression(
...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0
... )
&gt;&gt;&gt; true_coef
array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])
&gt;&gt;&gt; alphas, _, estimated_coef = lars_path_gram(X.T @ y, X.T @ X, n_samples=100)
&gt;&gt;&gt; alphas.shape
(3,)
&gt;&gt;&gt; estimated_coef
array([[ 0.     ,  0.     ,  0.     ],
       [ 0.     ,  0.     ,  0.     ],
       [ 0.     ,  0.     ,  0.     ],
       [ 0.     , 46.96..., 97.99...],
       [ 0.     ,  0.     , 45.70...]])
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2025 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.lars_path_gram.html" class="_attribution-link">https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.lars_path_gram.html</a>
  </p>
</div>
