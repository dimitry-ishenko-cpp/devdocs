<section id="sklearn-metrics-top-k-accuracy-score"> <h1>sklearn.metrics.top_k_accuracy_score</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.metrics.top_k_accuracy_score"> <span class="sig-prename descclassname">sklearn.metrics.</span><span class="sig-name descname">top_k_accuracy_score</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_score</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">k</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">labels</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/metrics/_ranking.py#L1644"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Top-k Accuracy classification score.</p> <p>This metric computes the number of times where the correct label is among the top <code>k</code> labels predicted (ranked by predicted scores). Note that the multilabel case isnâ€™t covered here.</p> <p>Read more in the <a class="reference internal" href="../model_evaluation.html#top-k-accuracy-score"><span class="std std-ref">User Guide</span></a></p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>y_true</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>True labels.</p> </dd> <dt>
<strong>y_score</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_classes)</span>
</dt>
<dd>
<p>Target scores. These can be either probability estimates or non-thresholded decision values (as returned by <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-decision_function"><span class="xref std std-term">decision_function</span></a> on some classifiers). The binary case expects scores with shape (n_samples,) while the multiclass case expects scores with shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of <code>labels</code>, if provided, or else to the numerical or lexicographical order of the labels in <code>y_true</code>. If <code>y_true</code> does not contain all the labels, <code>labels</code> must be provided.</p> </dd> <dt>
<strong>k</strong><span class="classifier">int, default=2</span>
</dt>
<dd>
<p>Number of most likely outcomes considered to find the correct label.</p> </dd> <dt>
<strong>normalize</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If <code>True</code>, return the fraction of correctly classified samples. Otherwise, return the number of correctly classified samples.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Sample weights. If <code>None</code>, all samples are given the same weight.</p> </dd> <dt>
<strong>labels</strong><span class="classifier">array-like of shape (n_classes,), default=None</span>
</dt>
<dd>
<p>Multiclass only. List of labels that index the classes in <code>y_score</code>. If <code>None</code>, the numerical or lexicographical order of the labels in <code>y_true</code> is used. If <code>y_true</code> does not contain all the labels, <code>labels</code> must be provided.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>score</strong><span class="classifier">float</span>
</dt>
<dd>
<p>The top-k accuracy score. The best performance is 1 with <code>normalize == True</code> and the number of samples with <code>normalize == False</code>.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code>accuracy_score</code></a></dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <p>In cases where two or more labels are assigned equal predicted scores, the labels with the highest indices will be chosen first. This might impact the result if the correct label falls after the threshold because of that.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import top_k_accuracy_score
&gt;&gt;&gt; y_true = np.array([0, 1, 2, 2])
&gt;&gt;&gt; y_score = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2
...                     [0.3, 0.4, 0.2],  # 1 is in top 2
...                     [0.2, 0.4, 0.3],  # 2 is in top 2
...                     [0.7, 0.2, 0.1]]) # 2 isn't in top 2
&gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2)
0.75
&gt;&gt;&gt; # Not normalizing gives the number of "correctly" classified samples
&gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2, normalize=False)
3
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.metrics.top_k_accuracy_score.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.metrics.top_k_accuracy_score.html</a>
  </p>
</div>
