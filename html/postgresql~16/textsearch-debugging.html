<h1>12.8. Testing and Debugging Text Search </h1>    <div class="toc"> <dl class="toc"> <dt><a href="textsearch-debugging.html#TEXTSEARCH-CONFIGURATION-TESTING">12.8.1. Configuration Testing</a></dt> <dt><a href="textsearch-debugging.html#TEXTSEARCH-PARSER-TESTING">12.8.2. Parser Testing</a></dt> <dt><a href="textsearch-debugging.html#TEXTSEARCH-DICTIONARY-TESTING">12.8.3. Dictionary Testing</a></dt> </dl> </div> <p>The behavior of a custom text search configuration can easily become confusing. The functions described in this section are useful for testing text search objects. You can test a complete configuration, or test parsers and dictionaries separately.</p> <div class="sect2" id="id-1.5.11.11.3.3">    <h2 class="title">12.8.1. Configuration Testing </h2>    <p>The function <code class="function">ts_debug</code> allows easy testing of a text search configuration.</p> <pre data-language="sql">
ts_debug([ config regconfig, ] document text,
         OUT alias text,
         OUT description text,
         OUT token text,
         OUT dictionaries regdictionary[],
         OUT dictionary regdictionary,
         OUT lexemes text[])
         returns setof record
</pre> <p><code class="function">ts_debug</code> displays information about every token of <code>document</code> as produced by the parser and processed by the configured dictionaries. It uses the configuration specified by <code>config</code>, or <code class="varname">default_text_search_config</code> if that argument is omitted.</p> <p><code class="function">ts_debug</code> returns one row for each token identified in the text by the parser. The columns returned are</p>  <ul> <li> <p><code>alias</code> <code class="type">text</code> — short name of the token type</p> </li> <li> <p><code>description</code> <code class="type">text</code> — description of the token type</p> </li> <li> <p><code>token</code> <code class="type">text</code> — text of the token</p> </li> <li> <p><code>dictionaries</code> <code class="type">regdictionary[]</code> — the dictionaries selected by the configuration for this token type</p> </li> <li> <p><code>dictionary</code> <code class="type">regdictionary</code> — the dictionary that recognized the token, or <code class="literal">NULL</code> if none did</p> </li> <li> <p><code>lexemes</code> <code class="type">text[]</code> — the lexeme(s) produced by the dictionary that recognized the token, or <code class="literal">NULL</code> if none did; an empty array (<code class="literal">{}</code>) means it was recognized as a stop word</p> </li> </ul>  <p>Here is a simple example:</p> <pre>
SELECT * FROM ts_debug('english', 'a fat  cat sat on a mat - it ate a fat rats');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}
 blank     | Space symbols   |       | {}             |              |
 blank     | Space symbols   | -     | {}             |              |
 asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}
</pre> <p>For a more extensive demonstration, we first create a <code class="literal">public.english</code> configuration and Ispell dictionary for the English language:</p> <pre data-language="sql">
CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );

CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);

ALTER TEXT SEARCH CONFIGURATION public.english
   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;
</pre> <pre>
SELECT * FROM ts_debug('public.english', 'The Brightest supernovaes');
   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes
-----------+-----------------+-------------+-------------------------------+----------------+-------------
 asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}
 blank     | Space symbols   |             | {}                            |                |
 asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}
 blank     | Space symbols   |             | {}                            |                |
 asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}
</pre> <p>In this example, the word <code class="literal">Brightest</code> was recognized by the parser as an <code class="literal">ASCII word</code> (alias <code class="literal">asciiword</code>). For this token type the dictionary list is <code class="literal">english_ispell</code> and <code class="literal">english_stem</code>. The word was recognized by <code class="literal">english_ispell</code>, which reduced it to the noun <code class="literal">bright</code>. The word <code class="literal">supernovaes</code> is unknown to the <code class="literal">english_ispell</code> dictionary so it was passed to the next dictionary, and, fortunately, was recognized (in fact, <code class="literal">english_stem</code> is a Snowball dictionary which recognizes everything; that is why it was placed at the end of the dictionary list).</p> <p>The word <code class="literal">The</code> was recognized by the <code class="literal">english_ispell</code> dictionary as a stop word (<a class="xref" href="textsearch-dictionaries.html#TEXTSEARCH-STOPWORDS" title="12.6.1. Stop Words">Section 12.6.1</a>) and will not be indexed. The spaces are discarded too, since the configuration provides no dictionaries at all for them.</p> <p>You can reduce the width of the output by explicitly specifying which columns you want to see:</p> <pre>
SELECT alias, token, dictionary, lexemes
FROM ts_debug('public.english', 'The Brightest supernovaes');
   alias   |    token    |   dictionary   |   lexemes
-----------+-------------+----------------+-------------
 asciiword | The         | english_ispell | {}
 blank     |             |                |
 asciiword | Brightest   | english_ispell | {bright}
 blank     |             |                |
 asciiword | supernovaes | english_stem   | {supernova}
</pre> </div> <div class="sect2" id="id-1.5.11.11.4.6">    <h2 class="title">12.8.2. Parser Testing </h2>    <p>The following functions allow direct testing of a text search parser.</p> <pre data-language="sql">
ts_parse(parser_name text, document text,
         OUT tokid integer, OUT token text) returns setof record
ts_parse(parser_oid oid, document text,
         OUT tokid integer, OUT token text) returns setof record
</pre> <p><code class="function">ts_parse</code> parses the given <code>document</code> and returns a series of records, one for each token produced by parsing. Each record includes a <code class="varname">tokid</code> showing the assigned token type and a <code class="varname">token</code> which is the text of the token. For example:</p> <pre>
SELECT * FROM ts_parse('default', '123 - a number');
 tokid | token
-------+--------
    22 | 123
    12 |
    12 | -
     1 | a
    12 |
     1 | number
</pre> <pre data-language="sql">
ts_token_type(parser_name text, OUT tokid integer,
              OUT alias text, OUT description text) returns setof record
ts_token_type(parser_oid oid, OUT tokid integer,
              OUT alias text, OUT description text) returns setof record
</pre> <p><code class="function">ts_token_type</code> returns a table which describes each type of token the specified parser can recognize. For each token type, the table gives the integer <code class="varname">tokid</code> that the parser uses to label a token of that type, the <code class="varname">alias</code> that names the token type in configuration commands, and a short <code class="varname">description</code>. For example:</p> <pre>
SELECT * FROM ts_token_type('default');
 tokid |      alias      |               description
-------+-----------------+------------------------------------------
     1 | asciiword       | Word, all ASCII
     2 | word            | Word, all letters
     3 | numword         | Word, letters and digits
     4 | email           | Email address
     5 | url             | URL
     6 | host            | Host
     7 | sfloat          | Scientific notation
     8 | version         | Version number
     9 | hword_numpart   | Hyphenated word part, letters and digits
    10 | hword_part      | Hyphenated word part, all letters
    11 | hword_asciipart | Hyphenated word part, all ASCII
    12 | blank           | Space symbols
    13 | tag             | XML tag
    14 | protocol        | Protocol head
    15 | numhword        | Hyphenated word, letters and digits
    16 | asciihword      | Hyphenated word, all ASCII
    17 | hword           | Hyphenated word, all letters
    18 | url_path        | URL path
    19 | file            | File or path name
    20 | float           | Decimal notation
    21 | int             | Signed integer
    22 | uint            | Unsigned integer
    23 | entity          | XML entity
</pre> </div> <div class="sect2" id="id-1.5.11.11.5.3">    <h2 class="title">12.8.3. Dictionary Testing </h2>    <p>The <code class="function">ts_lexize</code> function facilitates dictionary testing.</p> <pre data-language="sql">
ts_lexize(dict regdictionary, token text) returns text[]
</pre> <p><code class="function">ts_lexize</code> returns an array of lexemes if the input <code>token</code> is known to the dictionary, or an empty array if the token is known to the dictionary but it is a stop word, or <code class="literal">NULL</code> if it is an unknown word.</p> <p>Examples:</p> <pre>
SELECT ts_lexize('english_stem', 'stars');
 ts_lexize
-----------
 {star}

SELECT ts_lexize('english_stem', 'a');
 ts_lexize
-----------
 {}
</pre> <blockquote class="note"> <h3 class="title">Note</h3> <p>The <code class="function">ts_lexize</code> function expects a single <span class="emphasis"><em>token</em></span>, not text. Here is a case where this can be confusing:</p> <pre>
SELECT ts_lexize('thesaurus_astro', 'supernovae stars') is null;
 ?column?
----------
 t
</pre> <p>The thesaurus dictionary <code class="literal">thesaurus_astro</code> does know the phrase <code class="literal">supernovae stars</code>, but <code class="function">ts_lexize</code> fails since it does not parse the input text but treats it as a single token. Use <code class="function">plainto_tsquery</code> or <code class="function">to_tsvector</code> to test thesaurus dictionaries, for example:</p> <pre>
SELECT plainto_tsquery('supernovae stars');
 plainto_tsquery
-----------------
 'sn'
</pre> </blockquote> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 1996&ndash;2023 The PostgreSQL Global Development Group<br>Licensed under the PostgreSQL License.<br>
    <a href="https://www.postgresql.org/docs/16/textsearch-debugging.html" class="_attribution-link">https://www.postgresql.org/docs/16/textsearch-debugging.html</a>
  </p>
</div>
