<h1>Test Support (numpy.testing)</h1> <p>Common test support for all numpy test scripts.</p> <p>This single module should provide all the common functionality for numpy tests in a single location, so that <a class="reference internal" href="../dev/development_environment.html#development-environment"><span class="std std-ref">test scripts</span></a> can just import it and work right away. For background, see the <a class="reference internal" href="testing.html#testing-guidelines"><span class="std std-ref">Testing Guidelines</span></a></p> <section id="asserts"> <h2>Asserts</h2> <table class="autosummary longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose"><code>assert_allclose</code></a>(actual, desired[, rtol, ...])</p></td> <td><p>Raises an AssertionError if two objects are not equal up to desired tolerance.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_array_almost_equal_nulp.html#numpy.testing.assert_array_almost_equal_nulp" title="numpy.testing.assert_array_almost_equal_nulp"><code>assert_array_almost_equal_nulp</code></a>(x, y[, nulp])</p></td> <td><p>Compare two arrays relatively to their spacing.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_array_max_ulp.html#numpy.testing.assert_array_max_ulp" title="numpy.testing.assert_array_max_ulp"><code>assert_array_max_ulp</code></a>(a, b[, maxulp, dtype])</p></td> <td><p>Check that all items of arrays differ in at most N Units in the Last Place.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_array_equal.html#numpy.testing.assert_array_equal" title="numpy.testing.assert_array_equal"><code>assert_array_equal</code></a>(x, y[, err_msg, verbose])</p></td> <td><p>Raises an AssertionError if two array_like objects are not equal.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_array_less.html#numpy.testing.assert_array_less" title="numpy.testing.assert_array_less"><code>assert_array_less</code></a>(x, y[, err_msg, verbose])</p></td> <td><p>Raises an AssertionError if two array_like objects are not ordered by less than.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="numpy.testing.assert_equal"><code>assert_equal</code></a>(actual, desired[, err_msg, verbose])</p></td> <td><p>Raises an AssertionError if two objects are not equal.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_raises.html#numpy.testing.assert_raises" title="numpy.testing.assert_raises"><code>assert_raises</code></a>(assert_raises)</p></td> <td><p>Fail unless an exception of class exception_class is thrown by callable when invoked with arguments args and keyword arguments kwargs.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_raises_regex.html#numpy.testing.assert_raises_regex" title="numpy.testing.assert_raises_regex"><code>assert_raises_regex</code></a>(exception_class, ...)</p></td> <td><p>Fail unless an exception of class exception_class and with message that matches expected_regexp is thrown by callable when invoked with arguments args and keyword arguments kwargs.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_warns.html#numpy.testing.assert_warns" title="numpy.testing.assert_warns"><code>assert_warns</code></a>(warning_class, *args, **kwargs)</p></td> <td><p>Fail unless the given callable throws the specified warning.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_no_warnings.html#numpy.testing.assert_no_warnings" title="numpy.testing.assert_no_warnings"><code>assert_no_warnings</code></a>(*args, **kwargs)</p></td> <td><p>Fail if the given callable produces any warnings.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_no_gc_cycles.html#numpy.testing.assert_no_gc_cycles" title="numpy.testing.assert_no_gc_cycles"><code>assert_no_gc_cycles</code></a>(*args, **kwargs)</p></td> <td><p>Fail if the given callable produces any reference cycles.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_string_equal.html#numpy.testing.assert_string_equal" title="numpy.testing.assert_string_equal"><code>assert_string_equal</code></a>(actual, desired)</p></td> <td><p>Test if two strings are equal.</p></td> </tr>  </table> </section> <section id="asserts-not-recommended"> <h2>Asserts (not recommended)</h2> <p>It is recommended to use one of <a class="reference internal" href="generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose"><code>assert_allclose</code></a>, <a class="reference internal" href="generated/numpy.testing.assert_array_almost_equal_nulp.html#numpy.testing.assert_array_almost_equal_nulp" title="numpy.testing.assert_array_almost_equal_nulp"><code>assert_array_almost_equal_nulp</code></a> or <a class="reference internal" href="generated/numpy.testing.assert_array_max_ulp.html#numpy.testing.assert_array_max_ulp" title="numpy.testing.assert_array_max_ulp"><code>assert_array_max_ulp</code></a> instead of these functions for more consistent floating point comparisons.</p> <table class="autosummary longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_.html#numpy.testing.assert_" title="numpy.testing.assert_"><code>assert_</code></a>(val[, msg])</p></td> <td><p>Assert that works in release mode.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_almost_equal.html#numpy.testing.assert_almost_equal" title="numpy.testing.assert_almost_equal"><code>assert_almost_equal</code></a>(actual, desired[, ...])</p></td> <td><p>Raises an AssertionError if two items are not equal up to desired precision.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_approx_equal.html#numpy.testing.assert_approx_equal" title="numpy.testing.assert_approx_equal"><code>assert_approx_equal</code></a>(actual, desired[, ...])</p></td> <td><p>Raises an AssertionError if two items are not equal up to significant digits.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.assert_array_almost_equal.html#numpy.testing.assert_array_almost_equal" title="numpy.testing.assert_array_almost_equal"><code>assert_array_almost_equal</code></a>(x, y[, decimal, ...])</p></td> <td><p>Raises an AssertionError if two objects are not equal up to desired precision.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.print_assert_equal.html#numpy.testing.print_assert_equal" title="numpy.testing.print_assert_equal"><code>print_assert_equal</code></a>(test_string, actual, desired)</p></td> <td><p>Test if two objects are equal, and print an error message if test fails.</p></td> </tr>  </table> </section> <section id="decorators"> <h2>Decorators</h2> <table class="autosummary longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.dec.deprecated.html#numpy.testing.dec.deprecated" title="numpy.testing.dec.deprecated"><code>dec.deprecated</code></a>([conditional])</p></td> <td>

<div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.21.</span></p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.dec.knownfailureif.html#numpy.testing.dec.knownfailureif" title="numpy.testing.dec.knownfailureif"><code>dec.knownfailureif</code></a>(fail_condition[, msg])</p></td> <td>

<div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.21.</span></p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.dec.setastest.html#numpy.testing.dec.setastest" title="numpy.testing.dec.setastest"><code>dec.setastest</code></a>([tf])</p></td> <td>

<div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.21.</span></p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.dec.skipif.html#numpy.testing.dec.skipif" title="numpy.testing.dec.skipif"><code>dec.skipif</code></a>(skip_condition[, msg])</p></td> <td>

<div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.21.</span></p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.dec.slow.html#numpy.testing.dec.slow" title="numpy.testing.dec.slow"><code>dec.slow</code></a>(t)</p></td> <td>

<div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.21.</span></p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.decorate_methods.html#numpy.testing.decorate_methods" title="numpy.testing.decorate_methods"><code>decorate_methods</code></a>(cls, decorator[, testmatch])</p></td> <td><p>Apply a decorator to all methods in a class matching a regular expression.</p></td> </tr>  </table> </section> <section id="test-running"> <h2>Test Running</h2> <table class="autosummary longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.tester.html#numpy.testing.Tester" title="numpy.testing.Tester"><code>Tester</code></a></p></td> <td><p>alias of <code>numpy.testing._private.nosetester.NoseTester</code></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.clear_and_catch_warnings.html#numpy.testing.clear_and_catch_warnings" title="numpy.testing.clear_and_catch_warnings"><code>clear_and_catch_warnings</code></a>([record, modules])</p></td> <td><p>Context manager that resets warning registry for catching warnings</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.measure.html#numpy.testing.measure" title="numpy.testing.measure"><code>measure</code></a>(code_str[, times, label])</p></td> <td><p>Return elapsed time for executing code in the namespace of the caller.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.run_module_suite.html#numpy.testing.run_module_suite" title="numpy.testing.run_module_suite"><code>run_module_suite</code></a>([file_to_run, argv])</p></td> <td><p>Run a test module.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.rundocs.html#numpy.testing.rundocs" title="numpy.testing.rundocs"><code>rundocs</code></a>([filename, raise_on_error])</p></td> <td><p>Run doctests found in the given file.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.testing.suppress_warnings.html#numpy.testing.suppress_warnings" title="numpy.testing.suppress_warnings"><code>suppress_warnings</code></a>([forwarding_rule])</p></td> <td><p>Context manager and decorator doing much the same as <code>warnings.catch_warnings</code>.</p></td> </tr>  </table> </section> <section id="guidelines"> <h2>Guidelines</h2>  <ul> <li class="toctree-l1">
<a class="reference internal" href="testing.html">Testing Guidelines</a><ul> <li class="toctree-l2"><a class="reference internal" href="testing.html#introduction">Introduction</a></li> <li class="toctree-l2">
<a class="reference internal" href="testing.html#testing-numpy">Testing NumPy</a><ul> <li class="toctree-l3"><a class="reference internal" href="testing.html#running-tests-from-inside-python">Running tests from inside Python</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#running-tests-from-the-command-line">Running tests from the command line</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#other-methods-of-running-tests">Other methods of running tests</a></li> </ul> </li> <li class="toctree-l2">
<a class="reference internal" href="testing.html#writing-your-own-tests">Writing your own tests</a><ul> <li class="toctree-l3"><a class="reference internal" href="testing.html#using-c-code-in-tests">Using C code in tests</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#labeling-tests">Labeling tests</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#easier-setup-and-teardown-functions-methods">Easier setup and teardown functions / methods</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#parametric-tests">Parametric tests</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#doctests">Doctests</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#tests"><code>tests/</code></a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#init-py-and-setup-py"><code>__init__.py</code> and <code>setup.py</code></a></li> </ul> </li> <li class="toctree-l2">
<a class="reference internal" href="testing.html#tips-tricks">Tips &amp; Tricks</a><ul> <li class="toctree-l3"><a class="reference internal" href="testing.html#creating-many-similar-tests">Creating many similar tests</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#known-failures-skipping-tests">Known failures &amp; skipping tests</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#tests-on-random-data">Tests on random data</a></li> <li class="toctree-l3"><a class="reference internal" href="testing.html#documentation-for-numpy-test">Documentation for <code>numpy.test</code></a></li> </ul> </li> </ul> </li> </ul>  </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2022 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/1.23/reference/routines.testing.html" class="_attribution-link">https://numpy.org/doc/1.23/reference/routines.testing.html</a>
  </p>
</div>
