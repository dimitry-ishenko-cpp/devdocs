<section id="sklearn-calibration-calibration-curve"> <h1>sklearn.calibration.calibration_curve</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.calibration.calibration_curve"> <span class="sig-prename descclassname">sklearn.calibration.</span><span class="sig-name descname">calibration_curve</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_prob</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">pos_label</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">'deprecated'</span></em>, <em class="sig-param"><span class="n">n_bins</span><span class="o">=</span><span class="default_value">5</span></em>, <em class="sig-param"><span class="n">strategy</span><span class="o">=</span><span class="default_value">'uniform'</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/calibration.py#L873"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute true and predicted probabilities for a calibration curve.</p> <p>The method assumes the inputs come from a binary classifier, and discretize the [0, 1] interval into bins.</p> <p>Calibration curves may also be referred to as reliability diagrams.</p> <p>Read more in the <a class="reference internal" href="../calibration.html#calibration"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>y_true</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>True targets.</p> </dd> <dt>
<strong>y_prob</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>Probabilities of the positive class.</p> </dd> <dt>
<strong>pos_label</strong><span class="classifier">int or str, default=None</span>
</dt>
<dd>
<p>The label of the positive class.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.1.</span></p> </div> </dd> <dt>
<strong>normalize</strong><span class="classifier">bool, default=”deprecated”</span>
</dt>
<dd>
<p>Whether y_prob needs to be normalized into the [0, 1] interval, i.e. is not a proper probability. If True, the smallest value in y_prob is linearly mapped onto 0 and the largest one onto 1.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.1: </span>The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing <code>y_prob</code> will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier’s <code>predict_proba</code> positive class).</p> </div> </dd> <dt>
<strong>n_bins</strong><span class="classifier">int, default=5</span>
</dt>
<dd>
<p>Number of bins to discretize the [0, 1] interval. A bigger number requires more data. Bins with no samples (i.e. without corresponding values in <code>y_prob</code>) will not be returned, thus the returned arrays may have less than <code>n_bins</code> values.</p> </dd> <dt>
<strong>strategy</strong><span class="classifier">{‘uniform’, ‘quantile’}, default=’uniform’</span>
</dt>
<dd>
<p>Strategy used to define the widths of the bins.</p> <dl class="simple"> <dt>uniform</dt>
<dd>
<p>The bins have identical widths.</p> </dd> <dt>quantile</dt>
<dd>
<p>The bins have the same number of samples and depend on <code>y_prob</code>.</p> </dd> </dl> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>prob_true</strong><span class="classifier">ndarray of shape (n_bins,) or smaller</span>
</dt>
<dd>
<p>The proportion of samples whose class is the positive class, in each bin (fraction of positives).</p> </dd> <dt>
<strong>prob_pred</strong><span class="classifier">ndarray of shape (n_bins,) or smaller</span>
</dt>
<dd>
<p>The mean predicted probability in each bin.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <p>Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good Probabilities With Supervised Learning, in Proceedings of the 22nd International Conference on Machine Learning (ICML). See section 4 (Qualitative Analysis of Predictions).</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.calibration import calibration_curve
&gt;&gt;&gt; y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])
&gt;&gt;&gt; y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.65, 0.7, 0.8, 0.9,  1.])
&gt;&gt;&gt; prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=3)
&gt;&gt;&gt; prob_true
array([0. , 0.5, 1. ])
&gt;&gt;&gt; prob_pred
array([0.2  , 0.525, 0.85 ])
</pre> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.calibration.calibration_curve.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.calibration.calibration_curve.html</a>
  </p>
</div>
