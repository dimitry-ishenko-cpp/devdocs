<section id="sklearn-model-selection-leavepgroupsout"> <h1>sklearn.model_selection.LeavePGroupsOut</h1> <dl class="py class"> <dt class="sig sig-object py" id="sklearn.model_selection.LeavePGroupsOut"> <em class="property">class</em><span class="sig-prename descclassname">sklearn.model_selection.</span><span class="sig-name descname">LeavePGroupsOut</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_groups</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/model_selection/_split.py#L1231"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Leave P Group(s) Out cross-validator</p> <p>Provides train/test indices to split data according to a third-party provided group. This group information can be used to encode arbitrary domain specific stratifications of the samples as integers.</p> <p>For instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits.</p> <p>The difference between LeavePGroupsOut and LeaveOneGroupOut is that the former builds the test sets with all the samples assigned to <code>p</code> different values of the groups while the latter uses samples all assigned the same groups.</p> <p>Read more in the <a class="reference internal" href="../cross_validation.html#leave-p-groups-out"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>n_groups</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of groups (<code>p</code>) to leave out in the test split.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.model_selection.groupkfold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code>GroupKFold</code></a></dt>
<dd>
<p>K-fold iterator variant with non-overlapping groups.</p> </dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import LeavePGroupsOut
&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])
&gt;&gt;&gt; y = np.array([1, 2, 1])
&gt;&gt;&gt; groups = np.array([1, 2, 3])
&gt;&gt;&gt; lpgo = LeavePGroupsOut(n_groups=2)
&gt;&gt;&gt; lpgo.get_n_splits(X, y, groups)
3
&gt;&gt;&gt; lpgo.get_n_splits(groups=groups)  # 'groups' is always required
3
&gt;&gt;&gt; print(lpgo)
LeavePGroupsOut(n_groups=2)
&gt;&gt;&gt; for train_index, test_index in lpgo.split(X, y, groups):
...     print("TRAIN:", train_index, "TEST:", test_index)
...     X_train, X_test = X[train_index], X[test_index]
...     y_train, y_test = y[train_index], y[test_index]
...     print(X_train, X_test, y_train, y_test)
TRAIN: [2] TEST: [0 1]
[[5 6]] [[1 2]
 [3 4]] [1] [1 2]
TRAIN: [1] TEST: [0 2]
[[3 4]] [[1 2]
 [5 6]] [2] [1 1]
TRAIN: [0] TEST: [1 2]
[[1 2]] [[3 4]
 [5 6]] [1] [2 1]
</pre> <h4 class="rubric">Methods</h4> <table class="autosummary longtable docutils align-default">  <tr>
<td><p><a class="reference internal" href="#sklearn.model_selection.LeavePGroupsOut.get_n_splits" title="sklearn.model_selection.LeavePGroupsOut.get_n_splits"><code>get_n_splits</code></a>([X, y, groups])</p></td> <td><p>Returns the number of splitting iterations in the cross-validator</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.model_selection.LeavePGroupsOut.split" title="sklearn.model_selection.LeavePGroupsOut.split"><code>split</code></a>(X[, y, groups])</p></td> <td><p>Generate indices to split data into training and test set.</p></td> </tr>  </table> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.model_selection.LeavePGroupsOut.get_n_splits"> <span class="sig-name descname">get_n_splits</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/model_selection/_split.py#L1311"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the number of splitting iterations in the cross-validator</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Always ignored, exists for compatibility.</p> </dd> <dt>
<strong>y</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Always ignored, exists for compatibility.</p> </dd> <dt>
<strong>groups</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>Group labels for the samples used while splitting the dataset into train/test set. This ‘groups’ parameter must always be specified to calculate the number of splits, though the other parameters can be omitted.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>n_splits</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Returns the number of splitting iterations in the cross-validator.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.model_selection.LeavePGroupsOut.split"> <span class="sig-name descname">split</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/model_selection/_split.py#L1338"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Generate indices to split data into training and test set.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Training data, where <code>n_samples</code> is the number of samples and <code>n_features</code> is the number of features.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>The target variable for supervised learning problems.</p> </dd> <dt>
<strong>groups</strong><span class="classifier">array-like of shape (n_samples,)</span>
</dt>
<dd>
<p>Group labels for the samples used while splitting the dataset into train/test set.</p> </dd> </dl> </dd> <dt class="field-even">Yields<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>train</strong><span class="classifier">ndarray</span>
</dt>
<dd>
<p>The training set indices for that split.</p> </dd> <dt>
<strong>test</strong><span class="classifier">ndarray</span>
</dt>
<dd>
<p>The testing set indices for that split.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.model_selection.LeavePGroupsOut.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.model_selection.LeavePGroupsOut.html</a>
  </p>
</div>
