<section id="sklearn-covariance-graphicallasso"> <h1>sklearn.covariance.GraphicalLasso</h1> <dl class="py class"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso"> <em class="property">class</em><span class="sig-prename descclassname">sklearn.covariance.</span><span class="sig-name descname">GraphicalLasso</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">'cd'</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">enet_tol</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">assume_centered</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/covariance/_graph_lasso.py#L337"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Sparse inverse covariance estimation with an l1-penalized estimator.</p> <p>Read more in the <a class="reference internal" href="../covariance.html#sparse-inverse-covariance"><span class="std std-ref">User Guide</span></a>.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version v0.20: </span>GraphLasso has been renamed to GraphicalLasso</p> </div> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>alpha</strong><span class="classifier">float, default=0.01</span>
</dt>
<dd>
<p>The regularization parameter: the higher alpha, the more regularization, the sparser the inverse covariance. Range is (0, inf].</p> </dd> <dt>
<strong>mode</strong><span class="classifier">{‘cd’, ‘lars’}, default=’cd’</span>
</dt>
<dd>
<p>The Lasso solver to use: coordinate descent or LARS. Use LARS for very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd which is more numerically stable.</p> </dd> <dt>
<strong>tol</strong><span class="classifier">float, default=1e-4</span>
</dt>
<dd>
<p>The tolerance to declare convergence: if the dual gap goes below this value, iterations are stopped. Range is (0, inf].</p> </dd> <dt>
<strong>enet_tol</strong><span class="classifier">float, default=1e-4</span>
</dt>
<dd>
<p>The tolerance for the elastic net solver used to calculate the descent direction. This parameter controls the accuracy of the search direction for a given column update, not of the overall parameter estimate. Only used for mode=’cd’. Range is (0, inf].</p> </dd> <dt>
<strong>max_iter</strong><span class="classifier">int, default=100</span>
</dt>
<dd>
<p>The maximum number of iterations.</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>If verbose is True, the objective function and dual gap are plotted at each iteration.</p> </dd> <dt>
<strong>assume_centered</strong><span class="classifier">bool, default=False</span>
</dt>
<dd>
<p>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.</p> </dd> </dl> </dd> <dt class="field-even">Attributes<span class="colon">:</span>
</dt> <dd class="field-even">
<dl> <dt>
<strong>location_</strong><span class="classifier">ndarray of shape (n_features,)</span>
</dt>
<dd>
<p>Estimated location, i.e. the estimated mean.</p> </dd> <dt>
<strong>covariance_</strong><span class="classifier">ndarray of shape (n_features, n_features)</span>
</dt>
<dd>
<p>Estimated covariance matrix</p> </dd> <dt>
<strong>precision_</strong><span class="classifier">ndarray of shape (n_features, n_features)</span>
</dt>
<dd>
<p>Estimated pseudo inverse matrix.</p> </dd> <dt>
<strong>n_iter_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of iterations run.</p> </dd> <dt>
<strong>n_features_in_</strong><span class="classifier">int</span>
</dt>
<dd>
<p>Number of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> <dt>
<strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code>n_features_in_</code>,)</span>
</dt>
<dd>
<p>Names of features seen during <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code>X</code> has feature names that are all strings.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.0.</span></p> </div> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.covariance.graphical_lasso.html#sklearn.covariance.graphical_lasso" title="sklearn.covariance.graphical_lasso"><code>graphical_lasso</code></a></dt>
<dd>
<p>L1-penalized covariance estimator.</p> </dd> <dt><a class="reference internal" href="sklearn.covariance.graphicallassocv.html#sklearn.covariance.GraphicalLassoCV" title="sklearn.covariance.GraphicalLassoCV"><code>GraphicalLassoCV</code></a></dt>
<dd>
<p>Sparse inverse covariance with cross-validated choice of the l1 penalty.</p> </dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.covariance import GraphicalLasso
&gt;&gt;&gt; true_cov = np.array([[0.8, 0.0, 0.2, 0.0],
...                      [0.0, 0.4, 0.0, 0.0],
...                      [0.2, 0.0, 0.3, 0.1],
...                      [0.0, 0.0, 0.1, 0.7]])
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; X = np.random.multivariate_normal(mean=[0, 0, 0, 0],
...                                   cov=true_cov,
...                                   size=200)
&gt;&gt;&gt; cov = GraphicalLasso().fit(X)
&gt;&gt;&gt; np.around(cov.covariance_, decimals=3)
array([[0.816, 0.049, 0.218, 0.019],
       [0.049, 0.364, 0.017, 0.034],
       [0.218, 0.017, 0.322, 0.093],
       [0.019, 0.034, 0.093, 0.69 ]])
&gt;&gt;&gt; np.around(cov.location_, decimals=3)
array([0.073, 0.04 , 0.038, 0.143])
</pre> <h4 class="rubric">Methods</h4> <table class="autosummary longtable docutils align-default">  <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.error_norm" title="sklearn.covariance.GraphicalLasso.error_norm"><code>error_norm</code></a>(comp_cov[, norm, scaling, squared])</p></td> <td><p>Compute the Mean Squared Error between two covariance estimators.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.fit" title="sklearn.covariance.GraphicalLasso.fit"><code>fit</code></a>(X[, y])</p></td> <td><p>Fit the GraphicalLasso model to X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.get_params" title="sklearn.covariance.GraphicalLasso.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.get_precision" title="sklearn.covariance.GraphicalLasso.get_precision"><code>get_precision</code></a>()</p></td> <td><p>Getter for the precision matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.mahalanobis" title="sklearn.covariance.GraphicalLasso.mahalanobis"><code>mahalanobis</code></a>(X)</p></td> <td><p>Compute the squared Mahalanobis distances of given observations.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.score" title="sklearn.covariance.GraphicalLasso.score"><code>score</code></a>(X_test[, y])</p></td> <td><p>Compute the log-likelihood of <code>X_test</code> under the estimated Gaussian model.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.covariance.GraphicalLasso.set_params" title="sklearn.covariance.GraphicalLasso.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.error_norm"> <span class="sig-name descname">error_norm</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">comp_cov</span></em>, <em class="sig-param"><span class="n">norm</span><span class="o">=</span><span class="default_value">'frobenius'</span></em>, <em class="sig-param"><span class="n">scaling</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">squared</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/covariance/_empirical_covariance.py#L267"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the Mean Squared Error between two covariance estimators.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>comp_cov</strong><span class="classifier">array-like of shape (n_features, n_features)</span>
</dt>
<dd>
<p>The covariance to compare with.</p> </dd> <dt>
<strong>norm</strong><span class="classifier">{“frobenius”, “spectral”}, default=”frobenius”</span>
</dt>
<dd>
<p>The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error <code>(comp_cov - self.covariance_)</code>.</p> </dd> <dt>
<strong>scaling</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</p> </dd> <dt>
<strong>squared</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>result</strong><span class="classifier">float</span>
</dt>
<dd>
<p>The Mean Squared Error (in the sense of the Frobenius norm) between <code>self</code> and <code>comp_cov</code> covariance estimators.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.fit"> <span class="sig-name descname">fit</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/covariance/_graph_lasso.py#L452"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the GraphicalLasso model to X.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Data from which to compute the covariance estimate.</p> </dd> <dt>
<strong>y</strong><span class="classifier">Ignored</span>
</dt>
<dd>
<p>Not used, present for API consistency by convention.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">object</span>
</dt>
<dd>
<p>Returns the instance itself.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.get_params"> <span class="sig-name descname">get_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">deep</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L194"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>deep</strong><span class="classifier">bool, default=True</span>
</dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.get_precision"> <span class="sig-name descname">get_precision</span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/covariance/_empirical_covariance.py#L195"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Getter for the precision matrix.</p> <dl class="field-list simple"> <dt class="field-odd">Returns<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>precision_</strong><span class="classifier">array-like of shape (n_features, n_features)</span>
</dt>
<dd>
<p>The precision matrix associated to the current covariance object.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.mahalanobis"> <span class="sig-name descname">mahalanobis</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/covariance/_empirical_covariance.py#L318"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the squared Mahalanobis distances of given observations.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>dist</strong><span class="classifier">ndarray of shape (n_samples,)</span>
</dt>
<dd>
<p>Squared Mahalanobis distances of the observations.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.score"> <span class="sig-name descname">score</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">X_test</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/covariance/_empirical_covariance.py#L236"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the log-likelihood of <code>X_test</code> under the estimated Gaussian model.</p> <p>The Gaussian model is defined by its mean and covariance matrix which are represented respectively by <code>self.location_</code> and <code>self.covariance_</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>X_test</strong><span class="classifier">array-like of shape (n_samples, n_features)</span>
</dt>
<dd>
<p>Test data of which we compute the likelihood, where <code>n_samples</code> is the number of samples and <code>n_features</code> is the number of features. <code>X_test</code> is assumed to be drawn from the same distribution than the data used in fit (including centering).</p> </dd> <dt>
<strong>y</strong><span class="classifier">Ignored</span>
</dt>
<dd>
<p>Not used, present for API consistency by convention.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>res</strong><span class="classifier">float</span>
</dt>
<dd>
<p>The log-likelihood of <code>X_test</code> with <code>self.location_</code> and <code>self.covariance_</code> as estimators of the Gaussian model mean and covariance matrix respectively.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="sklearn.covariance.GraphicalLasso.set_params"> <span class="sig-name descname">set_params</span><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">params</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/base.py#L218"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>**params</strong><span class="classifier">dict</span>
</dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>self</strong><span class="classifier">estimator instance</span>
</dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.covariance.GraphicalLasso.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.covariance.GraphicalLasso.html</a>
  </p>
</div>
