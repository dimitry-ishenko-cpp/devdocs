<section id="sklearn-metrics-average-precision-score"> <h1>sklearn.metrics.average_precision_score</h1> <dl class="py function"> <dt class="sig sig-object py" id="sklearn.metrics.average_precision_score"> <span class="sig-prename descclassname">sklearn.metrics.</span><span class="sig-name descname">average_precision_score</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_score</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">average</span><span class="o">=</span><span class="default_value">'macro'</span></em>, <em class="sig-param"><span class="n">pos_label</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/metrics/_ranking.py#L112"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute average precision (AP) from prediction scores.</p> <p>AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:</p> <div class="math notranslate nohighlight"> \[\text{AP} = \sum_n (R_n - R_{n-1}) P_n\]</div> <p>where <span class="math notranslate nohighlight">\(P_n\)</span> and <span class="math notranslate nohighlight">\(R_n\)</span> are the precision and recall at the nth threshold <a class="reference internal" href="#rcdf8f32d7f9d-1" id="id1">[1]</a>. This implementation is not interpolated and is different from computing the area under the precision-recall curve with the trapezoidal rule, which uses linear interpolation and can be too optimistic.</p> <p>Note: this implementation is restricted to the binary classification task or multilabel classification task.</p> <p>Read more in the <a class="reference internal" href="../model_evaluation.html#precision-recall-f-measure-metrics"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>y_true</strong><span class="classifier">ndarray of shape (n_samples,) or (n_samples, n_classes)</span>
</dt>
<dd>
<p>True binary labels or binary label indicators.</p> </dd> <dt>
<strong>y_score</strong><span class="classifier">ndarray of shape (n_samples,) or (n_samples, n_classes)</span>
</dt>
<dd>
<p>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by <a class="reference internal" href="https://scikit-learn.org/1.1/glossary.html#term-decision_function"><span class="xref std std-term">decision_function</span></a> on some classifiers).</p> </dd> <dt>
<strong>average</strong><span class="classifier">{‘micro’, ‘samples’, ‘weighted’, ‘macro’} or None, default=’macro’</span>
</dt>
<dd>
<p>If <code>None</code>, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</p> <dl class="simple"> <dt>
<code>'micro'</code>:</dt>
<dd>
<p>Calculate metrics globally by considering each element of the label indicator matrix as a label.</p> </dd> <dt>
<code>'macro'</code>:</dt>
<dd>
<p>Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.</p> </dd> <dt>
<code>'weighted'</code>:</dt>
<dd>
<p>Calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label).</p> </dd> <dt>
<code>'samples'</code>:</dt>
<dd>
<p>Calculate metrics for each instance, and find their average.</p> </dd> </dl> <p>Will be ignored when <code>y_true</code> is binary.</p> </dd> <dt>
<strong>pos_label</strong><span class="classifier">int or str, default=1</span>
</dt>
<dd>
<p>The label of the positive class. Only applied to binary <code>y_true</code>. For multilabel-indicator <code>y_true</code>, <code>pos_label</code> is fixed to 1.</p> </dd> <dt>
<strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span>
</dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>average_precision</strong><span class="classifier">float</span>
</dt>
<dd>
<p>Average precision score.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code>roc_auc_score</code></a></dt>
<dd>
<p>Compute the area under the ROC curve.</p> </dd> <dt><a class="reference internal" href="sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code>precision_recall_curve</code></a></dt>
<dd>
<p>Compute precision-recall pairs for different probability thresholds.</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.19: </span>Instead of linearly interpolating between operating points, precisions are weighted by the change in recall since the last operating point.</p> </div> <h4 class="rubric">References</h4> <div role="list" class="citation-list"> <div class="citation" id="rcdf8f32d7f9d-1" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span> <p><a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;oldid=793358396#Average_precision">Wikipedia entry for the Average precision</a></p> </div> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import average_precision_score
&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])
&gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])
&gt;&gt;&gt; average_precision_score(y_true, y_scores)
0.83...
</pre> </dd>
</dl> <section id="examples-using-sklearn-metrics-average-precision-score"> <h2>Examples using <code>sklearn.metrics.average_precision_score</code>
</h2> <div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Example of Precision-Recall metric to evaluate classifier output quality.">
<img alt="Precision-Recall" src="data:image/png;base64,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"> <p><a class="reference internal" href="../../auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"><span class="std std-ref">Precision-Recall</span></a></p>  </div></div>
</section> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2022 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/1.1/modules/generated/sklearn.metrics.average_precision_score.html" class="_attribution-link">https://scikit-learn.org/1.1/modules/generated/sklearn.metrics.average_precision_score.html</a>
  </p>
</div>
