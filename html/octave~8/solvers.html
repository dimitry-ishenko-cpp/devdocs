<div class="section" id="Solvers">   <h1 class="section">20.1 Solvers</h1> <p>Octave can solve sets of nonlinear equations of the form </p> <pre class="example" data-language="matlab">F (x) = 0</pre> <p>using the function <code>fsolve</code>, which is based on the <small>MINPACK</small> subroutine <code>hybrd</code>. This is an iterative technique so a starting point must be provided. This also has the consequence that convergence is not guaranteed even if a solution exists. </p> <dl class="def"> <dt id="index-fsolve">
<span class="category">: </span><span><em><var>x</var> =</em> <strong>fsolve</strong> <em>(<var>fcn</var>, <var>x0</var>)</em><a href="#index-fsolve" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fsolve-1">
<span class="category">: </span><span><em><var>x</var> =</em> <strong>fsolve</strong> <em>(<var>fcn</var>, <var>x0</var>, <var>options</var>)</em><a href="#index-fsolve-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fsolve-2">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>] =</em> <strong>fsolve</strong> <em>(…)</em><a href="#index-fsolve-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fsolve-3">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>, <var>info</var>] =</em> <strong>fsolve</strong> <em>(…)</em><a href="#index-fsolve-3" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fsolve-4">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>, <var>info</var>, <var>output</var>] =</em> <strong>fsolve</strong> <em>(…)</em><a href="#index-fsolve-4" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fsolve-5">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>, <var>info</var>, <var>output</var>, <var>fjac</var>] =</em> <strong>fsolve</strong> <em>(…)</em><a href="#index-fsolve-5" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Solve a system of nonlinear equations defined by the function <var>fcn</var>. </p> <p><var>fcn</var> is a function handle, inline function, or string containing the name of the function to evaluate. <var>fcn</var> should accept a vector (array) defining the unknown variables, and return a vector of left-hand sides of the equations. Right-hand sides are defined to be zeros. In other words, this function attempts to determine a vector <var>x</var> such that <code><var>fcn</var> (<var>x</var>)</code> gives (approximately) all zeros. </p> <p><var>x0</var> is an initial guess for the solution. The shape of <var>x0</var> is preserved in all calls to <var>fcn</var>, but otherwise is treated as a column vector. </p> <p><var>options</var> is a structure specifying additional parameters which control the algorithm. Currently, <code>fsolve</code> recognizes these options: <code>"AutoScaling"</code>, <code>"ComplexEqn"</code>, <code>"FinDiffType"</code>, <code>"FunValCheck"</code>, <code>"Jacobian"</code>, <code>"MaxFunEvals"</code>, <code>"MaxIter"</code>, <code>"OutputFcn"</code>, <code>"TolFun"</code>, <code>"TolX"</code>, <code>"TypicalX"</code>, and <code>"Updating"</code>. </p> <p>If <code>"AutoScaling"</code> is <code>"on"</code>, the variables will be automatically scaled according to the column norms of the (estimated) Jacobian. As a result, <code>"TolFun"</code> becomes scaling-independent. By default, this option is <code>"off"</code> because it may sometimes deliver unexpected (though mathematically correct) results. </p> <p>If <code>"ComplexEqn"</code> is <code>"on"</code>, <code>fsolve</code> will attempt to solve complex equations in complex variables, assuming that the equations possess a complex derivative (i.e., are holomorphic). If this is not what you want, you should unpack the real and imaginary parts of the system to get a real system. </p> <p>If <code>"Jacobian"</code> is <code>"on"</code>, it specifies that <var>fcn</var>—when called with 2 output arguments—also returns the Jacobian matrix of right-hand sides at the requested point. </p> <p><code>"MaxFunEvals"</code> proscribes the maximum number of function evaluations before optimization is halted. The default value is <code>100 * number_of_variables</code>, i.e., <code>100 * length (<var>x0</var>)</code>. The value must be a positive integer. </p> <p>If <code>"Updating"</code> is <code>"on"</code>, the function will attempt to use Broyden updates to update the Jacobian, in order to reduce the number of Jacobian calculations. If your user function always calculates the Jacobian (regardless of number of output arguments) then this option provides no advantage and should be disabled. </p> <p><code>"TolX"</code> specifies the termination tolerance in the unknown variables, while <code>"TolFun"</code> is a tolerance for equations. Default is <code>1e-6</code> for both <code>"TolX"</code> and <code>"TolFun"</code>. </p> <p>For a description of the other options, see <a href="linear-least-squares.html#XREFoptimset"><code>optimset</code></a>. To initialize an options structure with default values for <code>fsolve</code> use <code>options = optimset ("fsolve")</code>. </p> <p>The first output <var>x</var> is the solution while the second output <var>fval</var> contains the value of the function <var>fcn</var> evaluated at <var>x</var> (ideally a vector of all zeros). </p> <p>The third output <var>info</var> reports whether the algorithm succeeded and may take one of the following values: </p> <dl compact> <dt><span>1</span></dt> <dd>
<p>Converged to a solution point. Relative residual error is less than specified by <code>TolFun</code>. </p> </dd> <dt><span>2</span></dt> <dd>
<p>Last relative step size was less than <code>TolX</code>. </p> </dd> <dt><span>3</span></dt> <dd>
<p>Last relative decrease in residual was less than <code>TolFun</code>. </p> </dd> <dt><span>0</span></dt> <dd>
<p>Iteration limit (either <code>MaxIter</code> or <code>MaxFunEvals</code>) exceeded. </p> </dd> <dt><span>-1</span></dt> <dd>
<p>Stopped by <code>OutputFcn</code>. </p> </dd> <dt><span>-2</span></dt> <dd>
<p>The Jacobian became excessively small and the search stalled. </p> </dd> <dt><span>-3</span></dt> <dd><p>The trust region radius became excessively small. </p></dd> </dl> <p><var>output</var> is a structure containing runtime information about the <code>fsolve</code> algorithm. Fields in the structure are: </p> <dl compact> <dt><span><code>iterations</code></span></dt> <dd>
<p>Number of iterations through loop. </p> </dd> <dt><span><code>successful</code></span></dt> <dd>
<p>Number of successful iterations. </p> </dd> <dt><span><code>funcCount</code></span></dt> <dd>
<p>Number of function evaluations. </p> </dd> </dl> <p>The final output <var>fjac</var> contains the value of the Jacobian evaluated at <var>x</var>. </p> <p>Note: If you only have a single nonlinear equation of one variable, using <code>fzero</code> is usually a much better idea. </p> <p>Note about user-supplied Jacobians: As an inherent property of the algorithm, a Jacobian is always requested for a solution vector whose residual vector is already known, and it is the last accepted successful step. Often this will be one of the last two calls, but not always. If the savings by reusing intermediate results from residual calculation in Jacobian calculation are significant, the best strategy is to employ <code>OutputFcn</code>: After a vector is evaluated for residuals, if <code>OutputFcn</code> is called with that vector, then the intermediate results should be saved for future Jacobian evaluation, and should be kept until a Jacobian evaluation is requested or until <code>OutputFcn</code> is called with a different vector, in which case they should be dropped in favor of this most recent vector. A short example how this can be achieved follows: </p> <pre class="example" data-language="matlab">function [fval, fjac] = user_fcn (x, optimvalues, state)
persistent sav = [], sav0 = [];
if (nargin == 1)
  ## evaluation call
  if (nargout == 1)
    sav0.x = x; # mark saved vector
    ## calculate fval, save results to sav0.
  elseif (nargout == 2)
    ## calculate fjac using sav.
  endif
else
  ## outputfcn call.
  if (all (x == sav0.x))
    sav = sav0;
  endif
  ## maybe output iteration status, etc.
endif
endfunction

## …

fsolve (@user_fcn, x0, optimset ("OutputFcn", @user_fcn, …))</pre> <p><strong>See also:</strong> <a href="#XREFfzero">fzero</a>, <a href="linear-least-squares.html#XREFoptimset">optimset</a>. </p>
</dd>
</dl> <p>The following is a complete example. To solve the set of equations </p> <pre class="example" data-language="matlab">-2x^2 + 3xy   + 4 sin(y) = 6
 3x^2 - 2xy^2 + 3 cos(x) = -4</pre> <p>you first need to write a function to compute the value of the given function. For example: </p> <pre class="example" data-language="matlab">function y = f (x)
  y = zeros (2, 1);
  y(1) = -2*x(1)^2 + 3*x(1)*x(2)   + 4*sin(x(2)) - 6;
  y(2) =  3*x(1)^2 - 2*x(1)*x(2)^2 + 3*cos(x(1)) + 4;
endfunction</pre> <p>Then, call <code>fsolve</code> with a specified initial condition to find the roots of the system of equations. For example, given the function <code>f</code> defined above, </p> <pre class="example" data-language="matlab">[x, fval, info] = fsolve (@f, [1; 2])</pre> <p>results in the solution </p> <pre class="example" data-language="matlab">x =

  0.57983
  2.54621

fval =

  -5.7184e-10
   5.5460e-10

info = 1</pre> <p>A value of <code>info = 1</code> indicates that the solution has converged. </p> <p>When no Jacobian is supplied (as in the example above) it is approximated numerically. This requires more function evaluations, and hence is less efficient. In the example above we could compute the Jacobian analytically as </p> <pre class="example" data-language="matlab">function [y, jac] = f (x)
  y = zeros (2, 1);
  y(1) = -2*x(1)^2 + 3*x(1)*x(2)   + 4*sin(x(2)) - 6;
  y(2) =  3*x(1)^2 - 2*x(1)*x(2)^2 + 3*cos(x(1)) + 4;
  if (nargout == 2)
    jac = zeros (2, 2);
    jac(1,1) =  3*x(2) - 4*x(1);
    jac(1,2) =  4*cos(x(2)) + 3*x(1);
    jac(2,1) = -2*x(2)^2 - 3*sin(x(1)) + 6*x(1);
    jac(2,2) = -4*x(1)*x(2);
  endif
endfunction</pre> <p>The Jacobian can then be used with the following call to <code>fsolve</code>: </p> <pre class="example" data-language="matlab">[x, fval, info] = fsolve (@f, [1; 2], optimset ("jacobian", "on"));</pre> <p>which gives the same solution as before. </p> <dl class="def"> <dt id="index-fzero">
<span class="category">: </span><span><em><var>x</var> =</em> <strong>fzero</strong> <em>(<var>fcn</var>, <var>x0</var>)</em><a href="#index-fzero" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fzero-1">
<span class="category">: </span><span><em><var>x</var> =</em> <strong>fzero</strong> <em>(<var>fcn</var>, <var>x0</var>, <var>options</var>)</em><a href="#index-fzero-1" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fzero-2">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>] =</em> <strong>fzero</strong> <em>(…)</em><a href="#index-fzero-2" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fzero-3">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>, <var>info</var>] =</em> <strong>fzero</strong> <em>(…)</em><a href="#index-fzero-3" class="copiable-anchor"> ¶</a></span>
</dt> <dt id="index-fzero-4">
<span class="category">: </span><span><em>[<var>x</var>, <var>fval</var>, <var>info</var>, <var>output</var>] =</em> <strong>fzero</strong> <em>(…)</em><a href="#index-fzero-4" class="copiable-anchor"> ¶</a></span>
</dt> <dd>
<p>Find a zero of a univariate function. </p> <p><var>fcn</var> is a function handle, inline function, or string containing the name of the function to evaluate. </p> <p><var>x0</var> should be a two-element vector specifying two points which bracket a zero. In other words, there must be a change in sign of the function between <var>x0</var>(1) and <var>x0</var>(2). More mathematically, the following must hold </p> <pre class="example" data-language="matlab">sign (fcn(x0(1))) * sign (fcn(x0(2))) &lt;= 0</pre> <p>If <var>x0</var> is a single scalar then several nearby and distant values are probed in an attempt to obtain a valid bracketing. If this is not successful, the function fails. </p> <p><var>options</var> is a structure specifying additional options. Currently, <code>fzero</code> recognizes these options: <code>"Display"</code>, <code>"FunValCheck"</code>, <code>"MaxFunEvals"</code>, <code>"MaxIter"</code>, <code>"OutputFcn"</code>, and <code>"TolX"</code>. </p> <p><code>"MaxFunEvals"</code> proscribes the maximum number of function evaluations before the search is halted. The default value is <code>Inf</code>. The value must be a positive integer. </p> <p><code>"MaxIter"</code> proscribes the maximum number of algorithm iterations before the search is halted. The default value is <code>Inf</code>. The value must be a positive integer. </p> <p><code>"TolX"</code> specifies the termination tolerance for the solution <var>x</var>. The default value is <code>eps</code>. </p> <p>For a description of the other options, see <a href="linear-least-squares.html#XREFoptimset"><code>optimset</code></a>. To initialize an options structure with default values for <code>fzero</code> use <code>options = optimset ("fzero")</code>. </p> <p>On exit, the function returns <var>x</var>, the approximate zero point, and <var>fval</var>, the function evaluated at <var>x</var>. </p> <p>The third output <var>info</var> reports whether the algorithm succeeded and may take one of the following values: </p> <ul> <li> 1 The algorithm converged to a solution. </li>
<li> 0 Maximum number of iterations or function evaluations has been reached. </li>
<li> -1 The algorithm has been terminated by a user <code>OutputFcn</code>. </li>
<li> -5 The algorithm may have converged to a singular point. </li>
</ul> <p><var>output</var> is a structure containing runtime information about the <code>fzero</code> algorithm. Fields in the structure are: </p> <ul> <li> iterations Number of iterations through loop. </li>
<li> funcCount Number of function evaluations. </li>
<li> algorithm The string <code>"bisection, interpolation"</code>. </li>
<li> bracketx A two-element vector with the final bracketing of the zero along the x-axis. </li>
<li> brackety A two-element vector with the final bracketing of the zero along the y-axis. </li>
</ul> <p><strong>See also:</strong> <a href="linear-least-squares.html#XREFoptimset">optimset</a>, <a href="#XREFfsolve">fsolve</a>. </p>
</dd>
</dl> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 1996–2023 The Octave Project Developers<br>Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.<br/>Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.</br>Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions.<br>
    <a href="https://docs.octave.org/v8.1.0/Solvers.html" class="_attribution-link">https://docs.octave.org/v8.1.0/Solvers.html</a>
  </p>
</div>
