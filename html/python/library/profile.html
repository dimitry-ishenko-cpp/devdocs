 <span id="profile"></span><h1>The Python Profilers</h1> <p><strong>Source code:</strong> <a class="reference external" href="https://github.com/python/cpython/tree/3.12/Lib/profile.py">Lib/profile.py</a> and <a class="reference external" href="https://github.com/python/cpython/tree/3.12/Lib/pstats.py">Lib/pstats.py</a></p>  <section id="introduction-to-the-profilers"> <span id="profiler-introduction"></span><h2>Introduction to the profilers</h2> <p id="index-0"><a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a> and <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> provide <em class="dfn">deterministic profiling</em> of Python programs. A <em class="dfn">profile</em> is a set of statistics that describes how often and for how long various parts of the program executed. These statistics can be formatted into reports via the <a class="reference internal" href="#module-pstats" title="pstats: Statistics object for use with the profiler."><code>pstats</code></a> module.</p> <p>The Python standard library provides two different implementations of the same profiling interface:</p> <ol class="arabic simple"> <li>
<a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a> is recommended for most users; it’s a C extension with reasonable overhead that makes it suitable for profiling long-running programs. Based on <code>lsprof</code>, contributed by Brett Rosen and Ted Czotter.</li> <li>
<a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a>, a pure Python module whose interface is imitated by <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>, but which adds significant overhead to profiled programs. If you’re trying to extend the profiler in some way, the task might be easier with this module. Originally designed and written by Jim Roskind.</li> </ol> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The profiler modules are designed to provide an execution profile for a given program, not for benchmarking purposes (for that, there is <a class="reference internal" href="timeit.html#module-timeit" title="timeit: Measure the execution time of small code snippets."><code>timeit</code></a> for reasonably accurate results). This particularly applies to benchmarking Python code against C code: the profilers introduce overhead for Python code, but not for C-level functions, and so the C code would seem faster than any Python one.</p> </div> </section> <section id="instant-user-s-manual"> <span id="profile-instant"></span><h2>Instant User’s Manual</h2> <p>This section is provided for users that “don’t want to read the manual.” It provides a very brief overview, and allows a user to rapidly perform profiling on an existing application.</p> <p>To profile a function that takes a single argument, you can do:</p> <pre data-language="python">import cProfile
import re
cProfile.run('re.compile("foo|bar")')
</pre> <p>(Use <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> instead of <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a> if the latter is not available on your system.)</p> <p>The above action would run <a class="reference internal" href="re.html#re.compile" title="re.compile"><code>re.compile()</code></a> and print profile results like the following:</p> <pre data-language="python">      214 function calls (207 primitive calls) in 0.002 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.002    0.002 {built-in method builtins.exec}
     1    0.000    0.000    0.001    0.001 &lt;string&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.001    0.001 __init__.py:250(compile)
     1    0.000    0.000    0.001    0.001 __init__.py:289(_compile)
     1    0.000    0.000    0.000    0.000 _compiler.py:759(compile)
     1    0.000    0.000    0.000    0.000 _parser.py:937(parse)
     1    0.000    0.000    0.000    0.000 _compiler.py:598(_code)
     1    0.000    0.000    0.000    0.000 _parser.py:435(_parse_sub)
</pre> <p>The first line indicates that 214 calls were monitored. Of those calls, 207 were <em class="dfn">primitive</em>, meaning that the call was not induced via recursion. The next line: <code>Ordered by: cumulative time</code> indicates the output is sorted by the <code>cumtime</code> values. The column headings include:</p> <dl class="simple"> <dt>ncalls</dt>
<dd>
<p>for the number of calls.</p> </dd> <dt>tottime</dt>
<dd>
<p>for the total time spent in the given function (and excluding time made in calls to sub-functions)</p> </dd> <dt>percall</dt>
<dd>
<p>is the quotient of <code>tottime</code> divided by <code>ncalls</code></p> </dd> <dt>cumtime</dt>
<dd>
<p>is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate <em>even</em> for recursive functions.</p> </dd> <dt>percall</dt>
<dd>
<p>is the quotient of <code>cumtime</code> divided by primitive calls</p> </dd> <dt>filename:lineno(function)</dt>
<dd>
<p>provides the respective data of each function</p> </dd> </dl> <p>When there are two numbers in the first column (for example <code>3/1</code>), it means that the function recursed. The second value is the number of primitive calls and the former is the total number of calls. Note that when the function does not recurse, these two values are the same, and only the single figure is printed.</p> <p>Instead of printing the output at the end of the profile run, you can save the results to a file by specifying a filename to the <code>run()</code> function:</p> <pre data-language="python">import cProfile
import re
cProfile.run('re.compile("foo|bar")', 'restats')
</pre> <p>The <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>pstats.Stats</code></a> class reads profile results from a file and formats them in various ways.</p> <p id="profile-cli">The files <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a> and <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> can also be invoked as a script to profile another script. For example:</p> <pre data-language="python">python -m cProfile [-o output_file] [-s sort_order] (-m module | myscript.py)
</pre> <p><code>-o</code> writes the profile results to a file instead of to stdout</p> <p><code>-s</code> specifies one of the <a class="reference internal" href="#pstats.Stats.sort_stats" title="pstats.Stats.sort_stats"><code>sort_stats()</code></a> sort values to sort the output by. This only applies when <code>-o</code> is not supplied.</p> <p><code>-m</code> specifies that a module is being profiled instead of a script.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.7: </span>Added the <code>-m</code> option to <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>.</p> </div> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.8: </span>Added the <code>-m</code> option to <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a>.</p> </div> <p>The <a class="reference internal" href="#module-pstats" title="pstats: Statistics object for use with the profiler."><code>pstats</code></a> module’s <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class has a variety of methods for manipulating and printing the data saved into a profile results file:</p> <pre data-language="python">import pstats
from pstats import SortKey
p = pstats.Stats('restats')
p.strip_dirs().sort_stats(-1).print_stats()
</pre> <p>The <a class="reference internal" href="#pstats.Stats.strip_dirs" title="pstats.Stats.strip_dirs"><code>strip_dirs()</code></a> method removed the extraneous path from all the module names. The <a class="reference internal" href="#pstats.Stats.sort_stats" title="pstats.Stats.sort_stats"><code>sort_stats()</code></a> method sorted all the entries according to the standard module/line/name string that is printed. The <a class="reference internal" href="#pstats.Stats.print_stats" title="pstats.Stats.print_stats"><code>print_stats()</code></a> method printed out all the statistics. You might try the following sort calls:</p> <pre data-language="python">p.sort_stats(SortKey.NAME)
p.print_stats()
</pre> <p>The first call will actually sort the list by function name, and the second call will print out the statistics. The following are some interesting calls to experiment with:</p> <pre data-language="python">p.sort_stats(SortKey.CUMULATIVE).print_stats(10)
</pre> <p>This sorts the profile by cumulative time in a function, and then only prints the ten most significant lines. If you want to understand what algorithms are taking time, the above line is what you would use.</p> <p>If you were looking to see what functions were looping a lot, and taking a lot of time, you would do:</p> <pre data-language="python">p.sort_stats(SortKey.TIME).print_stats(10)
</pre> <p>to sort according to time spent within each function, and then print the statistics for the top ten functions.</p> <p>You might also try:</p> <pre data-language="python">p.sort_stats(SortKey.FILENAME).print_stats('__init__')
</pre> <p>This will sort all the statistics by file name, and then print out statistics for only the class init methods (since they are spelled with <code>__init__</code> in them). As one final example, you could try:</p> <pre data-language="python">p.sort_stats(SortKey.TIME, SortKey.CUMULATIVE).print_stats(.5, 'init')
</pre> <p>This line sorts statistics with a primary key of time, and a secondary key of cumulative time, and then prints out some of the statistics. To be specific, the list is first culled down to 50% (re: <code>.5</code>) of its original size, then only lines containing <code>init</code> are maintained, and that sub-sub-list is printed.</p> <p>If you wondered what functions called the above functions, you could now (<code>p</code> is still sorted according to the last criteria) do:</p> <pre data-language="python">p.print_callers(.5, 'init')
</pre> <p>and you would get a list of callers for each of the listed functions.</p> <p>If you want more functionality, you’re going to have to read the manual, or guess what the following functions do:</p> <pre data-language="python">p.print_callees()
p.add('restats')
</pre> <p>Invoked as a script, the <a class="reference internal" href="#module-pstats" title="pstats: Statistics object for use with the profiler."><code>pstats</code></a> module is a statistics browser for reading and examining profile dumps. It has a simple line-oriented interface (implemented using <a class="reference internal" href="cmd.html#module-cmd" title="cmd: Build line-oriented command interpreters."><code>cmd</code></a>) and interactive help.</p> </section> <section id="module-cProfile"> <span id="profile-and-cprofile-module-reference"></span><h2>profile and cProfile Module Reference</h2> <span class="target" id="module-profile"></span><p>Both the <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> and <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a> modules provide the following functions:</p> <dl class="py function"> <dt class="sig sig-object py" id="profile.run">
<code>profile.run(command, filename=None, sort=- 1)</code> </dt> <dd>
<p>This function takes a single argument that can be passed to the <a class="reference internal" href="functions.html#exec" title="exec"><code>exec()</code></a> function, and an optional file name. In all cases this routine executes:</p> <pre data-language="python">exec(command, __main__.__dict__, __main__.__dict__)
</pre> <p>and gathers profiling statistics from the execution. If no file name is present, then this function automatically creates a <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> instance and prints a simple profiling report. If the sort value is specified, it is passed to this <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> instance to control how the results are sorted.</p> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="profile.runctx">
<code>profile.runctx(command, globals, locals, filename=None, sort=- 1)</code> </dt> <dd>
<p>This function is similar to <a class="reference internal" href="#profile.run" title="profile.run"><code>run()</code></a>, with added arguments to supply the globals and locals dictionaries for the <em>command</em> string. This routine executes:</p> <pre data-language="python">exec(command, globals, locals)
</pre> <p>and gathers profiling statistics as in the <a class="reference internal" href="#profile.run" title="profile.run"><code>run()</code></a> function above.</p> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="profile.Profile">
<code>class profile.Profile(timer=None, timeunit=0.0, subcalls=True, builtins=True)</code> </dt> <dd>
<p>This class is normally only used if more precise control over profiling is needed than what the <code>cProfile.run()</code> function provides.</p> <p>A custom timer can be supplied for measuring how long code takes to run via the <em>timer</em> argument. This must be a function that returns a single number representing the current time. If the number is an integer, the <em>timeunit</em> specifies a multiplier that specifies the duration of each unit of time. For example, if the timer returns times measured in thousands of seconds, the time unit would be <code>.001</code>.</p> <p>Directly using the <a class="reference internal" href="#profile.Profile" title="profile.Profile"><code>Profile</code></a> class allows formatting profile results without writing the profile data to a file:</p> <pre data-language="python">import cProfile, pstats, io
from pstats import SortKey
pr = cProfile.Profile()
pr.enable()
# ... do something ...
pr.disable()
s = io.StringIO()
sortby = SortKey.CUMULATIVE
ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
ps.print_stats()
print(s.getvalue())
</pre> <p>The <a class="reference internal" href="#profile.Profile" title="profile.Profile"><code>Profile</code></a> class can also be used as a context manager (supported only in <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a> module. see <a class="reference internal" href="stdtypes.html#typecontextmanager"><span class="std std-ref">Context Manager Types</span></a>):</p> <pre data-language="python">import cProfile

with cProfile.Profile() as pr:
    # ... do something ...

    pr.print_stats()
</pre> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 3.8: </span>Added context manager support.</p> </div> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.enable">
<code>enable()</code> </dt> <dd>
<p>Start collecting profiling data. Only in <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.disable">
<code>disable()</code> </dt> <dd>
<p>Stop collecting profiling data. Only in <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.create_stats">
<code>create_stats()</code> </dt> <dd>
<p>Stop collecting profiling data and record the results internally as the current profile.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.print_stats">
<code>print_stats(sort=- 1)</code> </dt> <dd>
<p>Create a <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> object based on the current profile and print the results to stdout.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.dump_stats">
<code>dump_stats(filename)</code> </dt> <dd>
<p>Write the results of the current profile to <em>filename</em>.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.run">
<code>run(cmd)</code> </dt> <dd>
<p>Profile the cmd via <a class="reference internal" href="functions.html#exec" title="exec"><code>exec()</code></a>.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.runctx">
<code>runctx(cmd, globals, locals)</code> </dt> <dd>
<p>Profile the cmd via <a class="reference internal" href="functions.html#exec" title="exec"><code>exec()</code></a> with the specified global and local environment.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="profile.Profile.runcall">
<code>runcall(func, /, *args, **kwargs)</code> </dt> <dd>
<p>Profile <code>func(*args, **kwargs)</code></p> </dd>
</dl> </dd>
</dl> <p>Note that profiling will only work if the called command/function actually returns. If the interpreter is terminated (e.g. via a <a class="reference internal" href="sys.html#sys.exit" title="sys.exit"><code>sys.exit()</code></a> call during the called command/function execution) no profiling results will be printed.</p> </section> <section id="the-stats-class"> <span id="profile-stats"></span><h2>The <code>Stats</code> Class</h2> <p>Analysis of the profiler data is done using the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class.</p> <span class="target" id="module-pstats"></span><dl class="py class"> <dt class="sig sig-object py" id="pstats.Stats">
<code>class pstats.Stats(*filenames or profile, stream=sys.stdout)</code> </dt> <dd>
<p>This class constructor creates an instance of a “statistics object” from a <em>filename</em> (or list of filenames) or from a <code>Profile</code> instance. Output will be printed to the stream specified by <em>stream</em>.</p> <p>The file selected by the above constructor must have been created by the corresponding version of <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> or <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>. To be specific, there is <em>no</em> file compatibility guaranteed with future versions of this profiler, and there is no compatibility with files produced by other profilers, or the same profiler run on a different operating system. If several files are provided, all the statistics for identical functions will be coalesced, so that an overall view of several processes can be considered in a single report. If additional files need to be combined with data in an existing <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> object, the <a class="reference internal" href="#pstats.Stats.add" title="pstats.Stats.add"><code>add()</code></a> method can be used.</p> <p>Instead of reading the profile data from a file, a <code>cProfile.Profile</code> or <a class="reference internal" href="#profile.Profile" title="profile.Profile"><code>profile.Profile</code></a> object can be used as the profile data source.</p> <p><a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> objects have the following methods:</p> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.strip_dirs">
<code>strip_dirs()</code> </dt> <dd>
<p>This method for the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class removes all leading path information from file names. It is very useful in reducing the size of the printout to fit within (close to) 80 columns. This method modifies the object, and the stripped information is lost. After performing a strip operation, the object is considered to have its entries in a “random” order, as it was just after object initialization and loading. If <a class="reference internal" href="#pstats.Stats.strip_dirs" title="pstats.Stats.strip_dirs"><code>strip_dirs()</code></a> causes two function names to be indistinguishable (they are on the same line of the same filename, and have the same function name), then the statistics for these two entries are accumulated into a single entry.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.add">
<code>add(*filenames)</code> </dt> <dd>
<p>This method of the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class accumulates additional profiling information into the current profiling object. Its arguments should refer to filenames created by the corresponding version of <a class="reference internal" href="#profile.run" title="profile.run"><code>profile.run()</code></a> or <code>cProfile.run()</code>. Statistics for identically named (re: file, line, name) functions are automatically accumulated into single function statistics.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.dump_stats">
<code>dump_stats(filename)</code> </dt> <dd>
<p>Save the data loaded into the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> object to a file named <em>filename</em>. The file is created if it does not exist, and is overwritten if it already exists. This is equivalent to the method of the same name on the <a class="reference internal" href="#profile.Profile" title="profile.Profile"><code>profile.Profile</code></a> and <code>cProfile.Profile</code> classes.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.sort_stats">
<code>sort_stats(*keys)</code> </dt> <dd>
<p>This method modifies the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> object by sorting it according to the supplied criteria. The argument can be either a string or a SortKey enum identifying the basis of a sort (example: <code>'time'</code>, <code>'name'</code>, <code>SortKey.TIME</code> or <code>SortKey.NAME</code>). The SortKey enums argument have advantage over the string argument in that it is more robust and less error prone.</p> <p>When more than one key is provided, then additional keys are used as secondary criteria when there is equality in all keys selected before them. For example, <code>sort_stats(SortKey.NAME, SortKey.FILE)</code> will sort all the entries according to their function name, and resolve all ties (identical function names) by sorting by file name.</p> <p>For the string argument, abbreviations can be used for any key names, as long as the abbreviation is unambiguous.</p> <p>The following are the valid string and SortKey:</p> <table class="docutils align-default">  <thead> <tr>
<th class="head"><p>Valid String Arg</p></th> <th class="head"><p>Valid enum Arg</p></th> <th class="head"><p>Meaning</p></th> </tr> </thead>  <tr>
<td><p><code>'calls'</code></p></td> <td><p>SortKey.CALLS</p></td> <td><p>call count</p></td> </tr> <tr>
<td><p><code>'cumulative'</code></p></td> <td><p>SortKey.CUMULATIVE</p></td> <td><p>cumulative time</p></td> </tr> <tr>
<td><p><code>'cumtime'</code></p></td> <td><p>N/A</p></td> <td><p>cumulative time</p></td> </tr> <tr>
<td><p><code>'file'</code></p></td> <td><p>N/A</p></td> <td><p>file name</p></td> </tr> <tr>
<td><p><code>'filename'</code></p></td> <td><p>SortKey.FILENAME</p></td> <td><p>file name</p></td> </tr> <tr>
<td><p><code>'module'</code></p></td> <td><p>N/A</p></td> <td><p>file name</p></td> </tr> <tr>
<td><p><code>'ncalls'</code></p></td> <td><p>N/A</p></td> <td><p>call count</p></td> </tr> <tr>
<td><p><code>'pcalls'</code></p></td> <td><p>SortKey.PCALLS</p></td> <td><p>primitive call count</p></td> </tr> <tr>
<td><p><code>'line'</code></p></td> <td><p>SortKey.LINE</p></td> <td><p>line number</p></td> </tr> <tr>
<td><p><code>'name'</code></p></td> <td><p>SortKey.NAME</p></td> <td><p>function name</p></td> </tr> <tr>
<td><p><code>'nfl'</code></p></td> <td><p>SortKey.NFL</p></td> <td><p>name/file/line</p></td> </tr> <tr>
<td><p><code>'stdname'</code></p></td> <td><p>SortKey.STDNAME</p></td> <td><p>standard name</p></td> </tr> <tr>
<td><p><code>'time'</code></p></td> <td><p>SortKey.TIME</p></td> <td><p>internal time</p></td> </tr> <tr>
<td><p><code>'tottime'</code></p></td> <td><p>N/A</p></td> <td><p>internal time</p></td> </tr>  </table> <p>Note that all sorts on statistics are in descending order (placing most time consuming items first), where as name, file, and line number searches are in ascending order (alphabetical). The subtle distinction between <code>SortKey.NFL</code> and <code>SortKey.STDNAME</code> is that the standard name is a sort of the name as printed, which means that the embedded line numbers get compared in an odd way. For example, lines 3, 20, and 40 would (if the file names were the same) appear in the string order 20, 3 and 40. In contrast, <code>SortKey.NFL</code> does a numeric compare of the line numbers. In fact, <code>sort_stats(SortKey.NFL)</code> is the same as <code>sort_stats(SortKey.NAME, SortKey.FILENAME, SortKey.LINE)</code>.</p> <p>For backward-compatibility reasons, the numeric arguments <code>-1</code>, <code>0</code>, <code>1</code>, and <code>2</code> are permitted. They are interpreted as <code>'stdname'</code>, <code>'calls'</code>, <code>'time'</code>, and <code>'cumulative'</code> respectively. If this old style format (numeric) is used, only one sort key (the numeric key) will be used, and additional arguments will be silently ignored.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.7: </span>Added the SortKey enum.</p> </div> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.reverse_order">
<code>reverse_order()</code> </dt> <dd>
<p>This method for the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class reverses the ordering of the basic list within the object. Note that by default ascending vs descending order is properly selected based on the sort key of choice.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.print_stats">
<code>print_stats(*restrictions)</code> </dt> <dd>
<p>This method for the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class prints out a report as described in the <a class="reference internal" href="#profile.run" title="profile.run"><code>profile.run()</code></a> definition.</p> <p>The order of the printing is based on the last <a class="reference internal" href="#pstats.Stats.sort_stats" title="pstats.Stats.sort_stats"><code>sort_stats()</code></a> operation done on the object (subject to caveats in <a class="reference internal" href="#pstats.Stats.add" title="pstats.Stats.add"><code>add()</code></a> and <a class="reference internal" href="#pstats.Stats.strip_dirs" title="pstats.Stats.strip_dirs"><code>strip_dirs()</code></a>).</p> <p>The arguments provided (if any) can be used to limit the list down to the significant entries. Initially, the list is taken to be the complete set of profiled functions. Each restriction is either an integer (to select a count of lines), or a decimal fraction between 0.0 and 1.0 inclusive (to select a percentage of lines), or a string that will interpreted as a regular expression (to pattern match the standard name that is printed). If several restrictions are provided, then they are applied sequentially. For example:</p> <pre data-language="python">print_stats(.1, 'foo:')
</pre> <p>would first limit the printing to first 10% of list, and then only print functions that were part of filename <code>.*foo:</code>. In contrast, the command:</p> <pre data-language="python">print_stats('foo:', .1)
</pre> <p>would limit the list to all functions having file names <code>.*foo:</code>, and then proceed to only print the first 10% of them.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.print_callers">
<code>print_callers(*restrictions)</code> </dt> <dd>
<p>This method for the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class prints a list of all functions that called each function in the profiled database. The ordering is identical to that provided by <a class="reference internal" href="#pstats.Stats.print_stats" title="pstats.Stats.print_stats"><code>print_stats()</code></a>, and the definition of the restricting argument is also identical. Each caller is reported on its own line. The format differs slightly depending on the profiler that produced the stats:</p> <ul class="simple"> <li>With <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a>, a number is shown in parentheses after each caller to show how many times this specific call was made. For convenience, a second non-parenthesized number repeats the cumulative time spent in the function at the right.</li> <li>With <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>, each caller is preceded by three numbers: the number of times this specific call was made, and the total and cumulative times spent in the current function while it was invoked by this specific caller.</li> </ul> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.print_callees">
<code>print_callees(*restrictions)</code> </dt> <dd>
<p>This method for the <a class="reference internal" href="#pstats.Stats" title="pstats.Stats"><code>Stats</code></a> class prints a list of all function that were called by the indicated function. Aside from this reversal of direction of calls (re: called vs was called by), the arguments and ordering are identical to the <a class="reference internal" href="#pstats.Stats.print_callers" title="pstats.Stats.print_callers"><code>print_callers()</code></a> method.</p> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="pstats.Stats.get_stats_profile">
<code>get_stats_profile()</code> </dt> <dd>
<p>This method returns an instance of StatsProfile, which contains a mapping of function names to instances of FunctionProfile. Each FunctionProfile instance holds information related to the function’s profile such as how long the function took to run, how many times it was called, etc…</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.9: </span>Added the following dataclasses: StatsProfile, FunctionProfile. Added the following function: get_stats_profile.</p> </div> </dd>
</dl> </dd>
</dl> </section> <section id="what-is-deterministic-profiling"> <span id="deterministic-profiling"></span><h2>What Is Deterministic Profiling?</h2> <p><em class="dfn">Deterministic profiling</em> is meant to reflect the fact that all <em>function call</em>, <em>function return</em>, and <em>exception</em> events are monitored, and precise timings are made for the intervals between these events (during which time the user’s code is executing). In contrast, <em class="dfn">statistical profiling</em> (which is not done by this module) randomly samples the effective instruction pointer, and deduces where time is being spent. The latter technique traditionally involves less overhead (as the code does not need to be instrumented), but provides only relative indications of where time is being spent.</p> <p>In Python, since there is an interpreter active during execution, the presence of instrumented code is not required in order to do deterministic profiling. Python automatically provides a <em class="dfn">hook</em> (optional callback) for each event. In addition, the interpreted nature of Python tends to add so much overhead to execution, that deterministic profiling tends to only add small processing overhead in typical applications. The result is that deterministic profiling is not that expensive, yet provides extensive run time statistics about the execution of a Python program.</p> <p>Call count statistics can be used to identify bugs in code (surprising counts), and to identify possible inline-expansion points (high call counts). Internal time statistics can be used to identify “hot loops” that should be carefully optimized. Cumulative time statistics should be used to identify high level errors in the selection of algorithms. Note that the unusual handling of cumulative times in this profiler allows statistics for recursive implementations of algorithms to be directly compared to iterative implementations.</p> </section> <section id="limitations"> <span id="profile-limitations"></span><h2>Limitations</h2> <p>One limitation has to do with accuracy of timing information. There is a fundamental problem with deterministic profilers involving accuracy. The most obvious restriction is that the underlying “clock” is only ticking at a rate (typically) of about .001 seconds. Hence no measurements will be more accurate than the underlying clock. If enough measurements are taken, then the “error” will tend to average out. Unfortunately, removing this first error induces a second source of error.</p> <p>The second problem is that it “takes a while” from when an event is dispatched until the profiler’s call to get the time actually <em>gets</em> the state of the clock. Similarly, there is a certain lag when exiting the profiler event handler from the time that the clock’s value was obtained (and then squirreled away), until the user’s code is once again executing. As a result, functions that are called many times, or call many functions, will typically accumulate this error. The error that accumulates in this fashion is typically less than the accuracy of the clock (less than one clock tick), but it <em>can</em> accumulate and become very significant.</p> <p>The problem is more important with <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> than with the lower-overhead <a class="reference internal" href="#module-cProfile" title="cProfile"><code>cProfile</code></a>. For this reason, <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> provides a means of calibrating itself for a given platform so that this error can be probabilistically (on the average) removed. After the profiler is calibrated, it will be more accurate (in a least square sense), but it will sometimes produce negative numbers (when call counts are exceptionally low, and the gods of probability work against you :-). ) Do <em>not</em> be alarmed by negative numbers in the profile. They should <em>only</em> appear if you have calibrated your profiler, and the results are actually better than without calibration.</p> </section> <section id="calibration"> <span id="profile-calibration"></span><h2>Calibration</h2> <p>The profiler of the <a class="reference internal" href="#module-profile" title="profile: Python source profiler."><code>profile</code></a> module subtracts a constant from each event handling time to compensate for the overhead of calling the time function, and socking away the results. By default, the constant is 0. The following procedure can be used to obtain a better constant for a given platform (see <a class="reference internal" href="#profile-limitations"><span class="std std-ref">Limitations</span></a>).</p> <pre data-language="python">import profile
pr = profile.Profile()
for i in range(5):
    print(pr.calibrate(10000))
</pre> <p>The method executes the number of Python calls given by the argument, directly and again under the profiler, measuring the time for both. It then computes the hidden overhead per profiler event, and returns that as a float. For example, on a 1.8Ghz Intel Core i5 running macOS, and using Python’s time.process_time() as the timer, the magical number is about 4.04e-6.</p> <p>The object of this exercise is to get a fairly consistent result. If your computer is <em>very</em> fast, or your timer function has poor resolution, you might have to pass 100000, or even 1000000, to get consistent results.</p> <p>When you have a consistent answer, there are three ways you can use it:</p> <pre data-language="python">import profile

# 1. Apply computed bias to all Profile instances created hereafter.
profile.Profile.bias = your_computed_bias

# 2. Apply computed bias to a specific Profile instance.
pr = profile.Profile()
pr.bias = your_computed_bias

# 3. Specify computed bias in instance constructor.
pr = profile.Profile(bias=your_computed_bias)
</pre> <p>If you have a choice, you are better off choosing a smaller constant, and then your results will “less often” show up as negative in profile statistics.</p> </section> <section id="using-a-custom-timer"> <span id="profile-timers"></span><h2>Using a custom timer</h2> <p>If you want to change how current time is determined (for example, to force use of wall-clock time or elapsed process time), pass the timing function you want to the <code>Profile</code> class constructor:</p> <pre data-language="python">pr = profile.Profile(your_time_func)
</pre> <p>The resulting profiler will then call <code>your_time_func</code>. Depending on whether you are using <a class="reference internal" href="#profile.Profile" title="profile.Profile"><code>profile.Profile</code></a> or <code>cProfile.Profile</code>, <code>your_time_func</code>’s return value will be interpreted differently:</p> <dl> <dt>
<code></code> <a class="reference internal" href="#profile.Profile" title="profile.Profile"><code>profile.Profile</code></a>
</dt>
<dd>
<p><code>your_time_func</code> should return a single number, or a list of numbers whose sum is the current time (like what <a class="reference internal" href="os.html#os.times" title="os.times"><code>os.times()</code></a> returns). If the function returns a single time number, or the list of returned numbers has length 2, then you will get an especially fast version of the dispatch routine.</p> <p>Be warned that you should calibrate the profiler class for the timer function that you choose (see <a class="reference internal" href="#profile-calibration"><span class="std std-ref">Calibration</span></a>). For most machines, a timer that returns a lone integer value will provide the best results in terms of low overhead during profiling. (<a class="reference internal" href="os.html#os.times" title="os.times"><code>os.times()</code></a> is <em>pretty</em> bad, as it returns a tuple of floating point values). If you want to substitute a better timer in the cleanest fashion, derive a class and hardwire a replacement dispatch method that best handles your timer call, along with the appropriate calibration constant.</p> </dd> <dt>
<code>cProfile.Profile</code> </dt>
<dd>
<p><code>your_time_func</code> should return a single number. If it returns integers, you can also invoke the class constructor with a second argument specifying the real duration of one unit of time. For example, if <code>your_integer_time_func</code> returns times measured in thousands of seconds, you would construct the <code>Profile</code> instance as follows:</p> <pre data-language="python">pr = cProfile.Profile(your_integer_time_func, 0.001)
</pre> <p>As the <code>cProfile.Profile</code> class cannot be calibrated, custom timer functions should be used with care and should be as fast as possible. For the best results with a custom timer, it might be necessary to hard-code it in the C source of the internal <code>_lsprof</code> module.</p> </dd> </dl> <p>Python 3.3 adds several new functions in <a class="reference internal" href="time.html#module-time" title="time: Time access and conversions."><code>time</code></a> that can be used to make precise measurements of process or wall-clock time. For example, see <a class="reference internal" href="time.html#time.perf_counter" title="time.perf_counter"><code>time.perf_counter()</code></a>.</p> </section> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2001&ndash;2023 Python Software Foundation<br>Licensed under the PSF License.<br>
    <a href="https://docs.python.org/3.12/library/profile.html" class="_attribution-link">https://docs.python.org/3.12/library/profile.html</a>
  </p>
</div>
