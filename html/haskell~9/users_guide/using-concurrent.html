<h1 id="using-concurrent">5.4. Using Concurrent Haskell</h1>
<div class="_sphinx"> <div itemprop="articleBody">   <p id="using-concurrent-haskell">GHC supports Concurrent Haskell by default, without requiring a special option or libraries compiled in a certain way. To get access to the support libraries for Concurrent Haskell, just import <a class="reference external" href="../libraries/base-4.17.0.0/control-concurrent.html">Control.Concurrent</a>. More information on Concurrent Haskell is provided in the documentation for that module.</p> <p>Optionally, the program may be linked with the <a class="reference internal" href="phases.html#ghc-flag--threaded"><code>-threaded</code></a> option (see <a class="reference internal" href="phases.html#options-linker"><span class="std std-ref">Options affecting linking</span></a>. This provides two benefits:</p> <ul class="simple"> <li>It enables the <a class="reference internal" href="#rts-flag--N%20%E2%9F%A8x%E2%9F%A9"><code>-N ⟨x⟩</code></a> to be used, which allows threads to run in parallel on a multi-processor or multi-core machine. See <a class="reference internal" href="#using-smp"><span class="std std-ref">Using SMP parallelism</span></a>.</li> <li>If a thread makes a foreign call (and the call is not marked <code>unsafe</code>), then other Haskell threads in the program will continue to run while the foreign call is in progress. Additionally, <code>foreign export</code>ed Haskell functions may be called from multiple OS threads simultaneously. See <a class="reference internal" href="exts/ffi.html#ffi-threads"><span class="std std-ref">Multi-threading and the FFI</span></a>.</li> </ul> <p>The following RTS option(s) affect the behaviour of Concurrent Haskell programs:</p> <dl class="rts-flag" id="index-1"> <dt id="rts-flag--C ⟨s⟩">
<code>-C ⟨s⟩</code> </dt> <dd>
<table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Default:</th>
<td class="field-body">20 milliseconds</td> </tr>  </table> <p>Sets the context switch interval to ⟨s⟩ seconds. A context switch will occur at the next heap block allocation after the timer expires (a heap block allocation occurs every 4k of allocation). With <code>-C0</code> or <code>-C</code>, context switches will occur as often as possible (at every heap block allocation).</p> </dd>
</dl>   <h1 id="using-smp">5.5. Using SMP parallelism</h1> <p id="using-smp-parallelism">GHC supports running Haskell programs in parallel on an SMP (symmetric multiprocessor).</p> <p>There’s a fine distinction between <em>concurrency</em> and <em>parallelism</em>: parallelism is all about making your program run <em>faster</em> by making use of multiple processors simultaneously. Concurrency, on the other hand, is a means of abstraction: it is a convenient way to structure a program that must respond to multiple asynchronous events.</p> <p>However, the two terms are certainly related. By making use of multiple CPUs it is possible to run concurrent threads in parallel, and this is exactly what GHC’s SMP parallelism support does. But it is also possible to obtain performance improvements with parallelism on programs that do not use concurrency. This section describes how to use GHC to compile and run parallel programs, in <a class="reference internal" href="exts/parallel.html#lang-parallel"><span class="std std-ref">Parallel and Concurrent</span></a> we describe the language features that affect parallelism.</p>  <h2 id="parallel-compile-options">5.5.1. Compile-time options for SMP parallelism</h2> <p id="compile-time-options-for-smp-parallelism">In order to make use of multiple CPUs, your program must be linked with the <a class="reference internal" href="phases.html#ghc-flag--threaded"><code>-threaded</code></a> option (see <a class="reference internal" href="phases.html#options-linker"><span class="std std-ref">Options affecting linking</span></a>). Additionally, the following compiler options affect parallelism:</p> <dl class="ghc-flag"> <dt>
<code>-feager-blackholing</code> </dt> <dd>
<p>Blackholing is the act of marking a thunk (lazy computation) as being under evaluation. It is useful for three reasons: firstly it lets us detect certain kinds of infinite loop (the <code>NonTermination</code> exception), secondly it avoids certain kinds of space leak, and thirdly it avoids repeating a computation in a parallel program, because we can tell when a computation is already in progress.</p> <p>The option <a class="reference internal" href="using-optimisation.html#ghc-flag--feager-blackholing"><code>-feager-blackholing</code></a> causes each thunk to be blackholed as soon as evaluation begins. The default is “lazy blackholing”, whereby thunks are only marked as being under evaluation when a thread is paused for some reason. Lazy blackholing is typically more efficient (by 1-2% or so), because most thunks don’t need to be blackholed. However, eager blackholing can avoid more repeated computation in a parallel program, and this often turns out to be important for parallelism.</p> <p>We recommend compiling any code that is intended to be run in parallel with the <a class="reference internal" href="using-optimisation.html#ghc-flag--feager-blackholing"><code>-feager-blackholing</code></a> flag.</p> </dd>
</dl>   <h2 id="parallel-options">5.5.2. RTS options for SMP parallelism</h2> <p id="rts-options-for-smp-parallelism">There are two ways to run a program on multiple processors: call <a class="reference external" href="../libraries/base-4.17.0.0/control-concurrent.html#v:setNumCapabilities">Control.Concurrent.setNumCapabilities</a> from your program, or use the RTS <a class="reference internal" href="#rts-flag--N%20%E2%9F%A8x%E2%9F%A9"><code>-N ⟨x⟩</code></a> options.</p> <dl class="rts-flag"> <dt id="rts-flag--N ⟨x⟩">
<code>-N ⟨x⟩</code> </dt> <dt id="rts-flag--N">
<code>-N</code> </dt> <dt id="rts-flag--maxN ⟨x⟩">
<code>-maxN ⟨x⟩</code> </dt> <dd>
<p>Use ⟨x⟩ simultaneous threads when running the program.</p> <p>The runtime manages a set of virtual processors, which we call <em>capabilities</em>, the number of which is determined by the <code>-N</code> option. Each capability can run one Haskell thread at a time, so the number of capabilities is equal to the number of Haskell threads that can run physically in parallel. A capability is animated by one or more OS threads; the runtime manages a pool of OS threads for each capability, so that if a Haskell thread makes a foreign call (see <a class="reference internal" href="exts/ffi.html#ffi-threads"><span class="std std-ref">Multi-threading and the FFI</span></a>) another OS thread can take over that capability.</p> <p>Normally ⟨x⟩ should be chosen to match the number of CPU cores on the machine <a class="footnote-reference" href="#id2" id="id1">[1]</a>. For example, on a dual-core machine we would probably use <code>+RTS -N2 -RTS</code>.</p> <p>Omitting ⟨x⟩, i.e. <code>+RTS -N -RTS</code>, lets the runtime choose the value of ⟨x⟩ itself based on how many processors are in your machine.</p> <p>Omitting <code>-N⟨x⟩</code> entirely means <code>-N1</code>.</p> <p>With <code>-maxN⟨x⟩</code>, i.e. <code>+RTS -maxN3 -RTS</code>, the runtime will choose at most (x), also limited by the number of processors on the system. Omitting (x) is an error, if you need a default use option <code>-N</code>.</p> <p>Be careful when using all the processors in your machine: if some of your processors are in use by other programs, this can actually harm performance rather than improve it. Asking GHC to create more capabilities than you have physical threads is almost always a bad idea.</p> <p>Setting <code>-N</code> also has the effect of enabling the parallel garbage collector (see <a class="reference internal" href="runtime_control.html#rts-options-gc"><span class="std std-ref">RTS options to control the garbage collector</span></a>).</p> <p>The current value of the <code>-N</code> option is available to the Haskell program via <code>Control.Concurrent.getNumCapabilities</code>, and it may be changed while the program is running by calling <code>Control.Concurrent.setNumCapabilities</code>.</p> </dd>
</dl> <p>The following options affect the way the runtime schedules threads on CPUs:</p> <dl class="rts-flag"> <dt id="rts-flag--qa">
<code>-qa</code> </dt> <dd>
<p>Use the OS’s affinity facilities to try to pin OS threads to CPU cores.</p> <p>When this option is enabled, the OS threads for a capability <span class="math notranslate nohighlight">\(i\)</span> are bound to the CPU core <span class="math notranslate nohighlight">\(i\)</span> using the API provided by the OS for setting thread affinity. e.g. on Linux GHC uses <code>sched_setaffinity()</code>.</p> <p>Depending on your workload and the other activity on the machine, this may or may not result in a performance improvement. We recommend trying it out and measuring the difference.</p> </dd>
</dl> <dl class="rts-flag"> <dt id="rts-flag--qm">
<code>-qm</code> </dt> <dd>
<p>Disable automatic migration for load balancing. Normally the runtime will automatically try to schedule threads across the available CPUs to make use of idle CPUs; this option disables that behaviour. Note that migration only applies to threads; sparks created by <code>par</code> are load-balanced separately by work-stealing.</p> <p>This option is probably only of use for concurrent programs that explicitly schedule threads onto CPUs with <a class="reference external" href="../libraries/base-4.17.0.0/control-concurrent.html#v:forkOn">Control.Concurrent.forkOn</a>.</p> </dd>
</dl>   <h2 id="hints-for-using-smp-parallelism">5.5.3. Hints for using SMP parallelism</h2> <p>Add the <a class="reference internal" href="#"><code>-s [⟨file⟩]</code></a> RTS option when running the program to see timing stats, which will help to tell you whether your program got faster by using more CPUs or not. If the user time is greater than the elapsed time, then the program used more than one CPU. You should also run the program without <a class="reference internal" href="#rts-flag--N%20%E2%9F%A8x%E2%9F%A9"><code>-N ⟨x⟩</code></a> for comparison.</p> <p>The output of <code>+RTS -s</code> tells you how many “sparks” were created and executed during the run of the program (see <a class="reference internal" href="runtime_control.html#rts-options-gc"><span class="std std-ref">RTS options to control the garbage collector</span></a>), which will give you an idea how well your <code>par</code> annotations are working.</p> <p>GHC’s parallelism support has improved in 6.12.1 as a result of much experimentation and tuning in the runtime system. We’d still be interested to hear how well it works for you, and we’re also interested in collecting parallel programs to add to our benchmarking suite.</p> <table class="docutils footnote" frame="void" id="id2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id1">[1]</a></td>
<td>Whether hyperthreading cores should be counted or not is an open question; please feel free to experiment and let us know what results you find.</td>
</tr>  </table>   </div> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2002&ndash;2007 The University Court of the University of Glasgow. All rights reserved.<br>Licensed under the Glasgow Haskell Compiler License.<br>
    <a href="https://downloads.haskell.org/~ghc/9.4.2/docs/users_guide/using-concurrent.html" class="_attribution-link">https://downloads.haskell.org/~ghc/9.4.2/docs/users_guide/using-concurrent.html</a>
  </p>
</div>
