<h1 class="devsite-page-title">tf.quantization.fake_quant_with_min_max_vars</h1> <devsite-bookmark></devsite-bookmark>       <p>Fake-quantize the 'inputs' tensor of type float via global float scalars</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/quantization/fake_quant_with_min_max_vars"><code translate="no" dir="ltr">tf.compat.v1.fake_quant_with_min_max_vars</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/quantization/fake_quant_with_min_max_vars"><code translate="no" dir="ltr">tf.compat.v1.quantization.fake_quant_with_min_max_vars</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.quantization.fake_quant_with_min_max_vars(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
</pre>  <p>Fake-quantize the <code translate="no" dir="ltr">inputs</code> tensor of type float via global float scalars <code translate="no" dir="ltr">min</code> and <code translate="no" dir="ltr">max</code> to <code translate="no" dir="ltr">outputs</code> tensor of same shape as <code translate="no" dir="ltr">inputs</code>.</p> <p>Attributes</p> <ul> <li>
<code translate="no" dir="ltr">[min; max]</code> define the clamping range for the <code translate="no" dir="ltr">inputs</code> data.</li> <li>
<code translate="no" dir="ltr">inputs</code> values are quantized into the quantization range ( <code translate="no" dir="ltr">[0; 2^num_bits - 1]</code> when <code translate="no" dir="ltr">narrow_range</code> is false and <code translate="no" dir="ltr">[1; 2^num_bits - 1]</code> when it is true) and then de-quantized and output as floats in <code translate="no" dir="ltr">[min; max]</code> interval.</li> <li>
<code translate="no" dir="ltr">num_bits</code> is the bitwidth of the quantization; between 2 and 16, inclusive.</li> </ul> <p>Before quantization, <code translate="no" dir="ltr">min</code> and <code translate="no" dir="ltr">max</code> values are adjusted with the following logic. It is suggested to have <code translate="no" dir="ltr">min &lt;= 0 &lt;= max</code>. If <code translate="no" dir="ltr">0</code> is not in the range of values, the behavior can be unexpected:</p> <ul> <li>If <code translate="no" dir="ltr">0 &lt; min &lt; max</code>: <code translate="no" dir="ltr">min_adj = 0</code> and <code translate="no" dir="ltr">max_adj = max - min</code>.</li> <li>If <code translate="no" dir="ltr">min &lt; max &lt; 0</code>: <code translate="no" dir="ltr">min_adj = min - max</code> and <code translate="no" dir="ltr">max_adj = 0</code>.</li> <li>If <code translate="no" dir="ltr">min &lt;= 0 &lt;= max</code>: <code translate="no" dir="ltr">scale = (max - min) / (2^num_bits - 1)</code>, <code translate="no" dir="ltr">min_adj = scale * round(min / scale)</code> and <code translate="no" dir="ltr">max_adj = max + min_adj - min</code>.</li> </ul> <p>This operation has a gradient and thus allows for training <code translate="no" dir="ltr">min</code> and <code translate="no" dir="ltr">max</code> values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">min</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_bits</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">8</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">narrow_range</code> </td> <td> An optional <code translate="no" dir="ltr">bool</code>. Defaults to <code translate="no" dir="ltr">False</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/quantization/fake_quant_with_min_max_vars" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/quantization/fake_quant_with_min_max_vars</a>
  </p>
</div>
