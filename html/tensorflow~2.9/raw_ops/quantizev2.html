<h1 class="devsite-page-title">tf.raw_ops.QuantizeV2</h1> <devsite-bookmark></devsite-bookmark>       <p>Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/QuantizeV2"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.QuantizeV2</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.QuantizeV2(
    input,
    min_range,
    max_range,
    T,
    mode='MIN_COMBINED',
    round_mode='HALF_AWAY_FROM_ZERO',
    narrow_range=False,
    axis=-1,
    ensure_minimum_range=0.01,
    name=None
)
</pre>  <p>[min_range, max_range] are scalar floats that specify the range for the 'input' data. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents. The 'round_mode' attribute controls which rounding tie-breaking algorithm is used when rounding float values to their quantized equivalents.</p> <p>In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)
if T == qint8: out[i] -= (range(T) + 1) / 2.0
</pre> <p>here <code translate="no" dir="ltr">range(T) = numeric_limits&lt;T&gt;::max() - numeric_limits&lt;T&gt;::min()</code></p> <p><em>MIN_COMBINED Mode Example</em></p> <p>Assume the input is type float and has a possible range of [0.0, 6.0] and the output type is quint8 ([0, 255]). The min_range and max_range values should be specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each value of the input by 255/6 and cast to quint8.</p> <p>If the output type was qint8 ([-128, 127]), the operation will additionally subtract each value by 128 prior to casting, so that the range of values aligns with the range of qint8.</p> <p>If the mode is 'MIN_FIRST', then this approach is used:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">num_discrete_values = 1 &lt;&lt; (# of bits in T)
range_adjust = num_discrete_values / (num_discrete_values - 1)
range = (range_max - range_min) * range_adjust
range_scale = num_discrete_values / range
quantized = round(input * range_scale) - round(range_min * range_scale) +
  numeric_limits&lt;T&gt;::min()
quantized = max(quantized, numeric_limits&lt;T&gt;::min())
quantized = min(quantized, numeric_limits&lt;T&gt;::max())
</pre> <p>The biggest difference between this and MIN_COMBINED is that the minimum range is rounded first, before it's subtracted from the rounded value. With MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing and dequantizing will introduce a larger and larger error.</p> <p><em>SCALED mode Example</em></p> <p><code translate="no" dir="ltr">SCALED</code> mode matches the quantization approach used in <code translate="no" dir="ltr">QuantizeAndDequantize{V2|V3}</code>.</p> <p>If the mode is <code translate="no" dir="ltr">SCALED</code>, the quantization is performed by multiplying each input value by a scaling_factor. The scaling_factor is determined from <code translate="no" dir="ltr">min_range</code> and <code translate="no" dir="ltr">max_range</code> to be as large as possible such that the range from <code translate="no" dir="ltr">min_range</code> to <code translate="no" dir="ltr">max_range</code> is representable within values of type T.</p> <pre class="prettyprint lang-c++" translate="no" dir="ltr" data-language="cpp">
const int min_T = std::numeric_limits&lt;T&gt;::min();
const int max_T = std::numeric_limits&lt;T&gt;::max();
const float max_float = std::numeric_limits&lt;float&gt;::max();

const float scale_factor_from_min_side =
    (min_T * min_range &gt; 0) ? min_T / min_range : max_float;
const float scale_factor_from_max_side =
    (max_T * max_range &gt; 0) ? max_T / max_range : max_float;

const float scale_factor = std::min(scale_factor_from_min_side,
                                    scale_factor_from_max_side);
</pre> <p>We next use the scale_factor to adjust min_range and max_range as follows:</p> <pre class="prettyprint lang-c++" translate="no" dir="ltr" data-language="cpp">min_range = min_T / scale_factor;
max_range = max_T / scale_factor;
</pre> <p>e.g. if T = qint8, and initially min_range = -10, and max_range = 9, we would compare -128/-10.0 = 12.8 to 127/9.0 = 14.11, and set scaling_factor = 12.8 In this case, min_range would remain -10, but max_range would be adjusted to 127 / 12.8 = 9.921875</p> <p>So we will quantize input values in the range (-10, 9.921875) to (-128, 127).</p> <p>The input tensor can now be quantized by clipping values to the range <code translate="no" dir="ltr">min_range</code> to <code translate="no" dir="ltr">max_range</code>, then multiplying by scale_factor as follows:</p> <pre class="prettyprint lang-c++" translate="no" dir="ltr" data-language="cpp">result = round(min(max_range, max(min_range, input)) * scale_factor)
</pre> <p>The adjusted <code translate="no" dir="ltr">min_range</code> and <code translate="no" dir="ltr">max_range</code> are returned as outputs 2 and 3 of this operation. These outputs should be used as the range for any further calculations.</p> <p><em>narrow_range (bool) attribute</em></p> <p>If true, we do not use the minimum quantized value. i.e. for int8 the quantized output, it would be restricted to the range -127..127 instead of the full -128..127 range. This is provided for compatibility with certain inference backends. (Only applies to SCALED mode)</p> <p><em>axis (int) attribute</em></p> <p>An optional <code translate="no" dir="ltr">axis</code> attribute can specify a dimension index of the input tensor, such that quantization ranges will be calculated and applied separately for each slice of the tensor along that dimension. This is useful for per-channel quantization.</p> <p>If axis is specified, min_range and max_range</p> <p>if <code translate="no" dir="ltr">axis</code>=None, per-tensor quantization is performed as normal.</p> <p><em>ensure_minimum_range (float) attribute</em></p> <p>Ensures the minimum quantization range is at least this value. The legacy default value for this is 0.01, but it is strongly suggested to set it to 0 for new uses.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">min_range</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. The minimum value of the quantization range. This value may be adjusted by the op depending on other parameters. The adjusted value is written to <code translate="no" dir="ltr">output_min</code>. If the <code translate="no" dir="ltr">axis</code> attribute is specified, this must be a 1-D tensor whose size matches the <code translate="no" dir="ltr">axis</code> dimension of the input and output tensors. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_range</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. The maximum value of the quantization range. This value may be adjusted by the op depending on other parameters. The adjusted value is written to <code translate="no" dir="ltr">output_max</code>. If the <code translate="no" dir="ltr">axis</code> attribute is specified, this must be a 1-D tensor whose size matches the <code translate="no" dir="ltr">axis</code> dimension of the input and output tensors. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">T</code> </td> <td> A <a href="../dtypes/dtype.html"><code translate="no" dir="ltr">tf.DType</code></a> from: <code translate="no" dir="ltr">tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mode</code> </td> <td> An optional <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"MIN_COMBINED", "MIN_FIRST", "SCALED"</code>. Defaults to <code translate="no" dir="ltr">"MIN_COMBINED"</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">round_mode</code> </td> <td> An optional <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"HALF_AWAY_FROM_ZERO", "HALF_TO_EVEN"</code>. Defaults to <code translate="no" dir="ltr">"HALF_AWAY_FROM_ZERO"</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">narrow_range</code> </td> <td> An optional <code translate="no" dir="ltr">bool</code>. Defaults to <code translate="no" dir="ltr">False</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">axis</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">-1</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ensure_minimum_range</code> </td> <td> An optional <code translate="no" dir="ltr">float</code>. Defaults to <code translate="no" dir="ltr">0.01</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A tuple of <code translate="no" dir="ltr">Tensor</code> objects (output, output_min, output_max). </td> </tr> <tr> <td> <code translate="no" dir="ltr">output</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">T</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_min</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_max</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/QuantizeV2" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/QuantizeV2</a>
  </p>
</div>
