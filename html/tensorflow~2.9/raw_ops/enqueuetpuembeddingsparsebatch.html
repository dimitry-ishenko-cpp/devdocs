<h1 class="devsite-page-title">tf.raw_ops.EnqueueTPUEmbeddingSparseBatch</h1> <devsite-bookmark></devsite-bookmark>       <p>An op that enqueues TPUEmbedding input indices from a SparseTensor.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/EnqueueTPUEmbeddingSparseBatch"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.EnqueueTPUEmbeddingSparseBatch</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.EnqueueTPUEmbeddingSparseBatch(
    sample_indices,
    embedding_indices,
    aggregation_weights,
    mode_override,
    device_ordinal=-1,
    combiners=[],
    name=None
)
</pre>  <p>This Op eases the porting of code that uses embedding_lookup_sparse(), although some Python preprocessing of the SparseTensor arguments to embedding_lookup_sparse() is required to produce the arguments to this Op, since only a single EnqueueTPUEmbeddingSparseBatch Op is allowed per training step.</p> <p>The tensors at corresponding positions in the three input lists must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding table_id.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">sample_indices</code> </td> <td> A list of at least 1 <code translate="no" dir="ltr">Tensor</code> objects with the same type in: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>. A list of rank 1 Tensors specifying the training example and feature to which the corresponding embedding_indices and aggregation_weights values belong. sample_indices[i] must equal b * nf + f, where nf is the number of features from the corresponding table, f is in [0, nf), and b is in [0, batch size). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">embedding_indices</code> </td> <td> A list with the same length as <code translate="no" dir="ltr">sample_indices</code> of <code translate="no" dir="ltr">Tensor</code> objects with the same type in: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>. A list of rank 1 Tensors, indices into the embedding tables. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">aggregation_weights</code> </td> <td> A list with the same length as <code translate="no" dir="ltr">sample_indices</code> of <code translate="no" dir="ltr">Tensor</code> objects with the same type in: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. A list of rank 1 Tensors containing per sample -- i.e. per (training example, feature) -- aggregation weights. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mode_override</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">string</code>. A string input that overrides the mode specified in the TPUEmbeddingConfiguration. Supported values are {'unspecified', 'inference', 'training', 'backward_pass_only'}. When set to 'unspecified', the mode set in TPUEmbeddingConfiguration is used, otherwise mode_override is used. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">device_ordinal</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">-1</code>. The TPU device to use. Should be &gt;= 0 and less than the number of TPU cores in the task on which the node is placed. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">combiners</code> </td> <td> An optional list of <code translate="no" dir="ltr">strings</code>. Defaults to <code translate="no" dir="ltr">[]</code>. A list of string scalars, one for each embedding table that specify how to normalize the embedding activations after weighted summation. Supported combiners are 'mean', 'sum', or 'sqrtn'. It is invalid to have the sum of the weights be 0 for 'mean' or the sum of the squared weights be 0 for 'sqrtn'. If combiners isn't passed, the default is to use 'sum' for all tables. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The created Operation. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/EnqueueTPUEmbeddingSparseBatch" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/EnqueueTPUEmbeddingSparseBatch</a>
  </p>
</div>
