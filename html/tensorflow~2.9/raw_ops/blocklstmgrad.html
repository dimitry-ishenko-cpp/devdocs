<h1 class="devsite-page-title">tf.raw_ops.BlockLSTMGrad</h1> <devsite-bookmark></devsite-bookmark>       <p>Computes the LSTM cell backward propagation for the entire time sequence.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/BlockLSTMGrad"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.BlockLSTMGrad</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.BlockLSTMGrad(
    seq_len_max,
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    i,
    cs,
    f,
    o,
    ci,
    co,
    h,
    cs_grad,
    h_grad,
    use_peephole,
    name=None
)
</pre>  <p>This implementation is to be used in conjunction of LSTMBlock.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">seq_len_max</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">int64</code>. Maximum time length actually used by this input. Outputs are padded with zeros beyond this length. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>. The sequence input to the LSTM, shape (timelen, batch_size, num_inputs). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cs_prev</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. Value of the initial cell state. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">h_prev</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. Initial output of cell (to be used for peephole). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">w</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The weight matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wci</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The weight matrix for input gate peephole connection. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wcf</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The weight matrix for forget gate peephole connection. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wco</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The weight matrix for output gate peephole connection. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">i</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The input gate over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cs</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The cell state before the tanh over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">f</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The forget gate over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">o</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The output gate over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ci</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The cell input over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">co</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The cell after the tanh over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">h</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The output h vector over the whole time sequence. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cs_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The current gradient of cs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">h_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. The gradient of h vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_peephole</code> </td> <td> A <code translate="no" dir="ltr">bool</code>. Whether to use peephole weights. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A tuple of <code translate="no" dir="ltr">Tensor</code> objects (x_grad, cs_prev_grad, h_prev_grad, w_grad, wci_grad, wcf_grad, wco_grad, b_grad). </td> </tr> <tr> <td> <code translate="no" dir="ltr">x_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cs_prev_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">h_prev_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">w_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wci_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wcf_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">wco_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_grad</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/BlockLSTMGrad" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/BlockLSTMGrad</a>
  </p>
</div>
