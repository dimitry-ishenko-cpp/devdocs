<h1 class="devsite-page-title">tf.raw_ops.MatrixSolveLs</h1> <devsite-bookmark></devsite-bookmark>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>    <p>Solves one or more linear least-squares problems.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/MatrixSolveLs"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.MatrixSolveLs</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.MatrixSolveLs(
    matrix, rhs, l2_regularizer, fast=True, name=None
)
</pre>  <p><code translate="no" dir="ltr">matrix</code> is a tensor of shape <code translate="no" dir="ltr">[..., M, N]</code> whose inner-most 2 dimensions form real or complex matrices of size <code translate="no" dir="ltr">[M, N]</code>. <code translate="no" dir="ltr">Rhs</code> is a tensor of the same type as <code translate="no" dir="ltr">matrix</code> and shape <code translate="no" dir="ltr">[..., M, K]</code>. The output is a tensor shape <code translate="no" dir="ltr">[..., N, K]</code> where each output matrix solves each of the equations <code translate="no" dir="ltr">matrix[..., :, :]</code> * <code translate="no" dir="ltr">output[..., :, :]</code> = <code translate="no" dir="ltr">rhs[..., :, :]</code> in the least squares sense.</p> <p>We use the following notation for (complex) matrix and right-hand sides in the batch:</p> <p><code translate="no" dir="ltr">matrix</code>=\(A \in \mathbb{C}^{m \times n}\), <code translate="no" dir="ltr">rhs</code>=\(B \in \mathbb{C}^{m \times k}\), <code translate="no" dir="ltr">output</code>=\(X \in \mathbb{C}^{n \times k}\), <code translate="no" dir="ltr">l2_regularizer</code>=\(\lambda \in \mathbb{R}\).</p> <p>If <code translate="no" dir="ltr">fast</code> is <code translate="no" dir="ltr">True</code>, then the solution is computed by solving the normal equations using Cholesky decomposition. Specifically, if \(m \ge n\) then \(X = (A^H A + \lambda I)^{-1} A^H B\), which solves the least-squares problem \(X = \mathrm{argmin}_{Z \in \Re^{n \times k} } ||A Z - B||_F^2 + \lambda ||Z||_F^2\). If \(m \lt n\) then <code translate="no" dir="ltr">output</code> is computed as \(X = A^H (A A^H + \lambda I)^{-1} B\), which (for \(\lambda = 0\)) is the minimum-norm solution to the under-determined linear system, i.e. \(X = \mathrm{argmin}_{Z \in \mathbb{C}^{n \times k} } ||Z||_F^2 \), subject to \(A Z = B\). Notice that the fast path is only numerically stable when \(A\) is numerically full rank and has a condition number \(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach} } }\) or \(\lambda\) is sufficiently large.</p> <p>If <code translate="no" dir="ltr">fast</code> is <code translate="no" dir="ltr">False</code> an algorithm based on the numerically robust complete orthogonal decomposition is used. This computes the minimum-norm least-squares solution, even when \(A\) is rank deficient. This path is typically 6-7 times slower than the fast path. If <code translate="no" dir="ltr">fast</code> is <code translate="no" dir="ltr">False</code> then <code translate="no" dir="ltr">l2_regularizer</code> is ignored.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">matrix</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. Shape is <code translate="no" dir="ltr">[..., M, N]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">rhs</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">matrix</code>. Shape is <code translate="no" dir="ltr">[..., M, K]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">l2_regularizer</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float64</code>. Scalar tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">fast</code> </td> <td> An optional <code translate="no" dir="ltr">bool</code>. Defaults to <code translate="no" dir="ltr">True</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">matrix</code>. </td> </tr> 
</table> <p><section><devsite-expandable expanded> <h2 class="showalways" id="numpy-compatibility" data-text="numpy compatibility">numpy compatibility</h2></devsite-expandable></section></p> <p>Equivalent to np.linalg.lstsq</p>   <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/MatrixSolveLs" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/MatrixSolveLs</a>
  </p>
</div>
