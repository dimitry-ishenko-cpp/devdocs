<h1 class="devsite-page-title">tf.raw_ops.Einsum</h1> <devsite-bookmark></devsite-bookmark>       <p>Tensor contraction according to Einstein summation convention.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/Einsum"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.Einsum</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.Einsum(
    inputs, equation, name=None
)
</pre>  <p>Implements generalized Tensor contraction and reduction. Each input Tensor must have a corresponding input subscript appearing in the comma-separated left-hand side of the equation. The right-hand side of the equation consists of the output subscript. The input subscripts and the output subscript should consist of zero or more named axis labels and at most one ellipsis (<code translate="no" dir="ltr">...</code>).</p> <p>The named axis labels may be any single character other than those having special meaning, namely <code translate="no" dir="ltr">,.-&gt;</code>. The behavior of this Op is undefined if it receives an ill-formatted equation; since the validation is done at graph-building time, we omit format validation checks at runtime.</p> <blockquote class="note">
<strong>Note:</strong><span> This Op is <em>not</em> intended to be called by the user; instead users should call <a href="../einsum.html"><code translate="no" dir="ltr">tf.einsum</code></a> directly. It is a hidden Op used by <a href="../einsum.html"><code translate="no" dir="ltr">tf.einsum</code></a>.</span>
</blockquote> <p>Operations are applied to the input(s) according to the following rules:</p> <p>(a) Generalized Diagonals: For input dimensions corresponding to axis labels appearing more than once in the same input subscript, we take the generalized (<code translate="no" dir="ltr">k</code>-dimensional) diagonal. For example, in the equation <code translate="no" dir="ltr">iii-&gt;i</code> with input shape <code translate="no" dir="ltr">[3, 3, 3]</code>, the generalized diagonal would consist of <code translate="no" dir="ltr">3</code> elements at indices <code translate="no" dir="ltr">(0, 0, 0)</code>, <code translate="no" dir="ltr">(1, 1, 1)</code> and <code translate="no" dir="ltr">(2, 2, 2)</code> to create a Tensor of shape <code translate="no" dir="ltr">[3]</code>.</p> <p>(b) Reduction: Axes corresponding to labels appearing only in one input subscript but not in the output subscript are summed over prior to Tensor contraction. For example, in the equation <code translate="no" dir="ltr">ab,bc-&gt;b</code>, the axis labels <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">c</code> are the reduction axis labels.</p> <p>(c) Batch Dimensions: Axes corresponding to labels appearing in each of the input subscripts and also in the output subscript make up the batch dimensions in Tensor contraction. Unnamed axis labels corresponding to ellipsis (<code translate="no" dir="ltr">...</code>) also correspond to batch dimensions. For example, for the equation denoting batch matrix multiplication, <code translate="no" dir="ltr">bij,bjk-&gt;bik</code>, the axis label <code translate="no" dir="ltr">b</code> corresponds to a batch dimension.</p> <p>(d) Contraction: In case of binary einsum, axes corresponding to labels appearing in two different inputs (and not in the output) are contracted against each other. Considering the batch matrix multiplication equation again (<code translate="no" dir="ltr">bij,bjk-&gt;bik</code>), the contracted axis label is <code translate="no" dir="ltr">j</code>.</p> <p>(e) Expand Diagonal: If the output subscripts contain repeated (explicit) axis labels, the opposite operation of (a) is applied. For example, in the equation <code translate="no" dir="ltr">i-&gt;iii</code>, and input shape <code translate="no" dir="ltr">[3]</code>, the output of shape <code translate="no" dir="ltr">[3, 3, 3]</code> are all zeros, except for the (generalized) diagonal which is populated with values from the input. Note: This operation is not supported by <code translate="no" dir="ltr">np.einsum</code> or <a href="../einsum.html"><code translate="no" dir="ltr">tf.einsum</code></a>; it is provided to enable computing the symbolic gradient of <a href="../einsum.html"><code translate="no" dir="ltr">tf.einsum</code></a>.</p> <p>The output subscripts must contain only labels appearing in at least one of the input subscripts. Furthermore, all dimensions mapping to the same axis label must be equal.</p> <p>Any of the input and output subscripts may contain at most a single ellipsis (<code translate="no" dir="ltr">...</code>). These ellipsis are mapped against dimensions not corresponding to any named axis label. If two inputs contain ellipsis, then they are broadcasted according to standard NumPy broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">rules</a>.</p> <p>The broadcasted dimensions are placed in the corresponding location of the ellipsis in the output subscript. If the broadcasted dimensions are non-empty and the output subscripts do not contain ellipsis, then an InvalidArgument error is raised.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> A list of at least 1 <code translate="no" dir="ltr">Tensor</code> objects with the same type. List of 1 or 2 Tensors. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">equation</code> </td> <td> A <code translate="no" dir="ltr">string</code>. String describing the Einstein Summation operation; in the format of np.einsum. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">inputs</code>. </td> </tr> 
</table> <p><section><devsite-expandable expanded> <h2 class="showalways" id="numpy-compatibility" data-text="numpy compatibility">numpy compatibility</h2></devsite-expandable></section></p> <p>Similar to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html"><code translate="no" dir="ltr">numpy.einsum</code></a>.</p> <p>Comparison with <code translate="no" dir="ltr">numpy.einsum</code>:</p> <ul> <li>This Op only supports unary and binary forms of <code translate="no" dir="ltr">numpy.einsum</code>.</li> <li>This Op does not support implicit form. (i.e. equations without <code translate="no" dir="ltr">-&gt;</code>).</li> <li>
<p>This Op also supports repeated indices in the output subscript, which is not supported by <code translate="no" dir="ltr">numpy.einsum</code>.</p> 
</li> </ul>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/Einsum" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/raw_ops/Einsum</a>
  </p>
</div>
