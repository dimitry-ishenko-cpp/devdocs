<h1 class="devsite-page-title">tf.clip_by_norm</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/clip_ops.py#L151-L233">  View source on GitHub </a> </td> </table> <p>Clips tensor values to a maximum L2-norm.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/clip_by_norm"><code translate="no" dir="ltr">tf.compat.v1.clip_by_norm</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.clip_by_norm(
    t, clip_norm, axes=None, name=None
)
</pre>  <p>Given a tensor <code translate="no" dir="ltr">t</code>, and a maximum clip value <code translate="no" dir="ltr">clip_norm</code>, this operation normalizes <code translate="no" dir="ltr">t</code> so that its L2-norm is less than or equal to <code translate="no" dir="ltr">clip_norm</code>, along the dimensions given in <code translate="no" dir="ltr">axes</code>. Specifically, in the default case where all dimensions are used for calculation, if the L2-norm of <code translate="no" dir="ltr">t</code> is already less than or equal to <code translate="no" dir="ltr">clip_norm</code>, then <code translate="no" dir="ltr">t</code> is not modified. If the L2-norm is greater than <code translate="no" dir="ltr">clip_norm</code>, then this operation returns a tensor of the same type and shape as <code translate="no" dir="ltr">t</code> with its values set to:</p> <p><code translate="no" dir="ltr">t * clip_norm / l2norm(t)</code></p> <p>In this case, the L2-norm of the output tensor is <code translate="no" dir="ltr">clip_norm</code>.</p> <p>As another example, if <code translate="no" dir="ltr">t</code> is a matrix and <code translate="no" dir="ltr">axes == [1]</code>, then each row of the output will have L2-norm less than or equal to <code translate="no" dir="ltr">clip_norm</code>. If <code translate="no" dir="ltr">axes == [0]</code> instead, each column of the output will be clipped.</p> <h4 id="code_example" data-text="Code example:">Code example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
some_nums = tf.constant([[1, 2, 3, 4, 5]], dtype=tf.float32)
tf.clip_by_norm(some_nums, 2.0).numpy()
array([[0.26967996, 0.5393599 , 0.80903983, 1.0787199 , 1.3483998 ]],
      dtype=float32)
</pre> <p>This operation is typically used to clip gradients before applying them with an optimizer. Most gradient data is a collection of different shaped tensors for different parts of the model. Thus, this is a common usage:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp"># Get your gradients after training
loss_value, grads = grad(model, features, labels)

# Apply some clipping
grads = [tf.clip_by_norm(g, norm)
             for g in grads]

# Continue on with training
optimizer.apply_gradients(grads)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">t</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">IndexedSlices</code>. This must be a floating point type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">clip_norm</code> </td> <td> A 0-D (scalar) <code translate="no" dir="ltr">Tensor</code> &gt; 0. A maximum clipping value, also floating point </td> </tr>
<tr> <td> <code translate="no" dir="ltr">axes</code> </td> <td> A 1-D (vector) <code translate="no" dir="ltr">Tensor</code> of type int32 containing the dimensions to use for computing the L2-norm. If <code translate="no" dir="ltr">None</code> (the default), uses all dimensions. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A clipped <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">IndexedSlices</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the clip_norm tensor is not a 0-D scalar tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If dtype of the input is not a floating point or complex type. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/clip_by_norm" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/clip_by_norm</a>
  </p>
</div>
