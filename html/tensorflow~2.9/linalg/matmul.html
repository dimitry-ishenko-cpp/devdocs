<h1 class="devsite-page-title">tf.linalg.matmul</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/math_ops.py#L3488-L3714">  View source on GitHub </a> </td> </table> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul"><code translate="no" dir="ltr">tf.matmul</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul"><code translate="no" dir="ltr">tf.compat.v1.linalg.matmul</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul"><code translate="no" dir="ltr">tf.compat.v1.matmul</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    output_type=None,
    name=None
)
</pre>  <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <p>A simple 2-D tensor matrix multiplication:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])
a  # 2-D tensor
&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)&gt;
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])
b  # 2-D tensor
&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[ 7,  8],
       [ 9, 10],
       [11, 12]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=
array([[ 58,  64],
       [139, 154]], dtype=int32)&gt;
</pre> <p>A batch matrix multiplication with batch shape [2]:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])
a  # 3-D tensor
&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]], dtype=int32)&gt;
b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])
b  # 3-D tensor
&lt;tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=
array([[[13, 14],
        [15, 16],
        [17, 18]],
       [[19, 20],
        [21, 22],
        [23, 24]]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=
array([[[ 94, 100],
        [229, 244]],
       [[508, 532],
        [697, 730]]], dtype=int32)&gt;
</pre> <p>Since python &gt;= 3.5 the @ operator is supported (see <a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>). In TensorFlow, it simply calls the <a href="matmul.html"><code translate="no" dir="ltr">tf.matmul()</code></a> function, so the following lines are equivalent:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d = a @ b @ [[10], [11]]
d = tf.matmul(tf.matmul(a, b), [[10], [11]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <a href="../tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <a href="../tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="../sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="../sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="../sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="../sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="../sparse/sparse_dense_matmul.html"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="../sparse/sparsetensor.html"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">output_type</code> </td> <td> The output datatype if needed. Defaults to None in which case the output_type is the same as input type. Currently only works when input tensors are type (u)int8 and output_type can be int32. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="../tensor.html"><code translate="no" dir="ltr">tf.Tensor</code></a> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])</code>, for all indices <code translate="no" dir="ltr">i</code>, <code translate="no" dir="ltr">j</code>. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">transpose_a</code> and <code translate="no" dir="ltr">adjoint_a</code>, or <code translate="no" dir="ltr">transpose_b</code> and <code translate="no" dir="ltr">adjoint_b</code> are both set to <code translate="no" dir="ltr">True</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If output_type is specified but the types of <code translate="no" dir="ltr">a</code>, <code translate="no" dir="ltr">b</code> and <code translate="no" dir="ltr">output_type</code> is not (u)int8, (u)int8 and int32. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/linalg/matmul" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/linalg/matmul</a>
  </p>
</div>
