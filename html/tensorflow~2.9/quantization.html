<h1 class="devsite-page-title">Module: tf.quantization</h1> <devsite-bookmark></devsite-bookmark>       <p>Public API for tf.quantization namespace.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="quantization/dequantize.html"><code translate="no" dir="ltr">dequantize(...)</code></a>: Dequantize the 'input' tensor into a float or bfloat16 Tensor.</p> <p><a href="quantization/fake_quant_with_min_max_args.html"><code translate="no" dir="ltr">fake_quant_with_min_max_args(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.</p> <p><a href="quantization/fake_quant_with_min_max_args_gradient.html"><code translate="no" dir="ltr">fake_quant_with_min_max_args_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p> <p><a href="quantization/fake_quant_with_min_max_vars.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars</p> <p><a href="quantization/fake_quant_with_min_max_vars_gradient.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p> <p><a href="quantization/fake_quant_with_min_max_vars_per_channel.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_per_channel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via per-channel floats</p> <p><a href="quantization/fake_quant_with_min_max_vars_per_channel_gradient.html"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_per_channel_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p> <p><a href="quantization/quantize.html"><code translate="no" dir="ltr">quantize(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <p><a href="quantization/quantize_and_dequantize.html"><code translate="no" dir="ltr">quantize_and_dequantize(...)</code></a>: Quantizes then dequantizes a tensor. (deprecated)</p> <p><a href="quantization/quantize_and_dequantize_v2.html"><code translate="no" dir="ltr">quantize_and_dequantize_v2(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="quantization/quantized_concat.html"><code translate="no" dir="ltr">quantized_concat(...)</code></a>: Concatenates quantized tensors along one dimension.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/quantization" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/quantization</a>
  </p>
</div>
