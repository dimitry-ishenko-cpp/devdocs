<h1 class="devsite-page-title">tf.keras.callbacks.EarlyStopping</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/callbacks.py#L1745-L1893">  View source on GitHub </a> </td> </table> <p>Stop training when a monitored metric has stopped improving.</p> <p>Inherits From: <a href="callback.html"><code translate="no" dir="ltr">Callback</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping"><code translate="no" dir="ltr">tf.compat.v1.keras.callbacks.EarlyStopping</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    min_delta=0,
    patience=0,
    verbose=0,
    mode='auto',
    baseline=None,
    restore_best_weights=False
)
</pre>  <p>Assuming the goal of a training is to minimize the loss. With this, the metric to be monitored would be <code translate="no" dir="ltr">'loss'</code>, and mode would be <code translate="no" dir="ltr">'min'</code>. A <code translate="no" dir="ltr">model.fit()</code> training loop will check at end of every epoch whether the loss is no longer decreasing, considering the <code translate="no" dir="ltr">min_delta</code> and <code translate="no" dir="ltr">patience</code> if applicable. Once it's found no longer decreasing, <code translate="no" dir="ltr">model.stop_training</code> is marked True and the training terminates.</p> <p>The quantity to be monitored needs to be available in <code translate="no" dir="ltr">logs</code> dict. To make it so, pass the loss or metrics at <code translate="no" dir="ltr">model.compile()</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">monitor</code> </td> <td> Quantity to be monitored. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">min_delta</code> </td> <td> Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">patience</code> </td> <td> Number of epochs with no improvement after which training will be stopped. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays messages when the callback takes an action. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mode</code> </td> <td> One of <code translate="no" dir="ltr">{"auto", "min", "max"}</code>. In <code translate="no" dir="ltr">min</code> mode, training will stop when the quantity monitored has stopped decreasing; in <code translate="no" dir="ltr">"max"</code> mode it will stop when the quantity monitored has stopped increasing; in <code translate="no" dir="ltr">"auto"</code> mode, the direction is automatically inferred from the name of the monitored quantity. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">baseline</code> </td> <td> Baseline value for the monitored quantity. Training will stop if the model doesn't show improvement over the baseline. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">restore_best_weights</code> </td> <td> Whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used. An epoch will be restored regardless of the performance relative to the <code translate="no" dir="ltr">baseline</code>. If no epoch improves on <code translate="no" dir="ltr">baseline</code>, training will run for <code translate="no" dir="ltr">patience</code> epochs and restore weights from the best epoch in that set. </td> </tr> </table> <h4 id="example" data-text="Example:">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
# This callback will stop the training when there is no improvement in
# the loss for three consecutive epochs.
model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])
model.compile(tf.keras.optimizers.SGD(), loss='mse')
history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),
                    epochs=10, batch_size=1, callbacks=[callback],
                    verbose=0)
len(history.history['loss'])  # Only 4 epochs are run.
4
</pre> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="get_monitor_value" data-text="get_monitor_value"><code translate="no" dir="ltr">get_monitor_value</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/callbacks.py#L1883-L1890">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_monitor_value(
    logs
)
</pre> <h3 id="set_model" data-text="set_model"><code translate="no" dir="ltr">set_model</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/callbacks.py#L647-L648">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_model(
    model
)
</pre> <h3 id="set_params" data-text="set_params"><code translate="no" dir="ltr">set_params</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/callbacks.py#L644-L645">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_params(
    params
)
</pre>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/callbacks/EarlyStopping" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/callbacks/EarlyStopping</a>
  </p>
</div>
