<h1 class="devsite-page-title">tf.keras.utils.experimental.DatasetCreator</h1> <devsite-bookmark></devsite-bookmark>       <p>Object that returns a <a href="../../../data/dataset.html"><code translate="no" dir="ltr">tf.data.Dataset</code></a> upon invoking.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.utils.experimental.DatasetCreator(
    dataset_fn, input_options=None
)
</pre>  <p><a href="datasetcreator.html"><code translate="no" dir="ltr">tf.keras.utils.experimental.DatasetCreator</code></a> is designated as a supported type for <code translate="no" dir="ltr">x</code>, or the input, in <a href="../../model.html#fit"><code translate="no" dir="ltr">tf.keras.Model.fit</code></a>. Pass an instance of this class to <code translate="no" dir="ltr">fit</code> when using a callable (with a <code translate="no" dir="ltr">input_context</code> argument) that returns a <a href="../../../data/dataset.html"><code translate="no" dir="ltr">tf.data.Dataset</code></a>.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">model = tf.keras.Sequential([tf.keras.layers.Dense(10)])
model.compile(tf.keras.optimizers.SGD(), loss="mse")

def dataset_fn(input_context):
  global_batch_size = 64
  batch_size = input_context.get_per_replica_batch_size(global_batch_size)
  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat()
  dataset = dataset.shard(
      input_context.num_input_pipelines, input_context.input_pipeline_id)
  dataset = dataset.batch(batch_size)
  dataset = dataset.prefetch(2)
  return dataset

input_options = tf.distribute.InputOptions(
    experimental_fetch_to_device=True,
    experimental_per_replica_buffer_size=2)
model.fit(tf.keras.utils.experimental.DatasetCreator(
    dataset_fn, input_options=input_options), epochs=10, steps_per_epoch=10)
</pre> <p><a href="../../model.html#fit"><code translate="no" dir="ltr">Model.fit</code></a> usage with <code translate="no" dir="ltr">DatasetCreator</code> is intended to work across all <a href="../../../distribute/strategy.html"><code translate="no" dir="ltr">tf.distribute.Strategy</code></a>s, as long as <a href="../../../distribute/mirroredstrategy.html#scope"><code translate="no" dir="ltr">Strategy.scope</code></a> is used at model creation:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">strategy = tf.distribute.experimental.ParameterServerStrategy(
    cluster_resolver)
with strategy.scope():
  model = tf.keras.Sequential([tf.keras.layers.Dense(10)])
model.compile(tf.keras.optimizers.SGD(), loss="mse")

def dataset_fn(input_context):
  ...

input_options = ...
model.fit(tf.keras.utils.experimental.DatasetCreator(
    dataset_fn, input_options=input_options), epochs=10, steps_per_epoch=10)
</pre>
<blockquote class="note">
<strong>Note:</strong><span> When using <code translate="no" dir="ltr">DatasetCreator</code>, <code translate="no" dir="ltr">steps_per_epoch</code> argument in <a href="../../model.html#fit"><code translate="no" dir="ltr">Model.fit</code></a> must be provided as the cardinality of such input cannot be inferred.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">dataset_fn</code> </td> <td> A callable that takes a single argument of type <a href="../../../distribute/inputcontext.html"><code translate="no" dir="ltr">tf.distribute.InputContext</code></a>, which is used for batch size calculation and cross-worker input pipeline sharding (if neither is needed, the <code translate="no" dir="ltr">InputContext</code> parameter can be ignored in the <code translate="no" dir="ltr">dataset_fn</code>), and returns a <a href="../../../data/dataset.html"><code translate="no" dir="ltr">tf.data.Dataset</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_options</code> </td> <td> Optional <a href="../../../distribute/inputoptions.html"><code translate="no" dir="ltr">tf.distribute.InputOptions</code></a>, used for specific options when used with distribution, for example, whether to prefetch dataset elements to accelerator device memory or host device memory, and prefetch buffer size in the replica device memory. No effect if not used with distributed training. See <a href="../../../distribute/inputoptions.html"><code translate="no" dir="ltr">tf.distribute.InputOptions</code></a> for more information. </td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="__call__" data-text="__call__"><code translate="no" dir="ltr">__call__</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/utils/dataset_creator.py#L102-L110">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__call__(
    *args, **kwargs
)
</pre> <p>Call self as a function.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/utils/experimental/DatasetCreator" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/utils/experimental/DatasetCreator</a>
  </p>
</div>
