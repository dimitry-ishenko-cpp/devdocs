<h1 class="devsite-page-title">tf.keras.utils.unpack_x_y_sample_weight</h1> <devsite-bookmark></devsite-bookmark>       <p>Unpacks user-provided data tuple.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.utils.unpack_x_y_sample_weight(
    data
)
</pre>  <p>This is a convenience utility to be used when overriding <a href="../model.html#train_step"><code translate="no" dir="ltr">Model.train_step</code></a>, <a href="../model.html#test_step"><code translate="no" dir="ltr">Model.test_step</code></a>, or <a href="../model.html#predict_step"><code translate="no" dir="ltr">Model.predict_step</code></a>. This utility makes it easy to support data of the form <code translate="no" dir="ltr">(x,)</code>, <code translate="no" dir="ltr">(x, y)</code>, or <code translate="no" dir="ltr">(x, y, sample_weight)</code>.</p> <h4 id="standalone_usage" data-text="Standalone usage:">Standalone usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
features_batch = tf.ones((10, 5))
labels_batch = tf.zeros((10, 5))
data = (features_batch, labels_batch)
# `y` and `sample_weight` will default to `None` if not provided.
x, y, sample_weight = tf.keras.utils.unpack_x_y_sample_weight(data)
sample_weight is None
True
</pre> <p>Example in overridden <a href="../model.html#train_step"><code translate="no" dir="ltr">Model.train_step</code></a>:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">class MyModel(tf.keras.Model):

  def train_step(self, data):
    # If `sample_weight` is not provided, all samples will be weighted
    # equally.
    x, y, sample_weight = tf.keras.utils.unpack_x_y_sample_weight(data)

    with tf.GradientTape() as tape:
      y_pred = self(x, training=True)
      loss = self.compiled_loss(
        y, y_pred, sample_weight, regularization_losses=self.losses)
      trainable_variables = self.trainable_variables
      gradients = tape.gradient(loss, trainable_variables)
      self.optimizer.apply_gradients(zip(gradients, trainable_variables))

    self.compiled_metrics.update_state(y, y_pred, sample_weight)
    return {m.name: m.result() for m in self.metrics}
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">data</code> </td> <td> A tuple of the form <code translate="no" dir="ltr">(x,)</code>, <code translate="no" dir="ltr">(x, y)</code>, or <code translate="no" dir="ltr">(x, y, sample_weight)</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The unpacked tuple, with <code translate="no" dir="ltr">None</code>s for <code translate="no" dir="ltr">y</code> and <code translate="no" dir="ltr">sample_weight</code> if they are not provided. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/utils/unpack_x_y_sample_weight" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/utils/unpack_x_y_sample_weight</a>
  </p>
</div>
