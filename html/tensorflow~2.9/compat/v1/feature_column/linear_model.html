<h1 class="devsite-page-title">tf.compat.v1.feature_column.linear_model</h1> <devsite-bookmark></devsite-bookmark>       <p>Returns a linear prediction <code translate="no" dir="ltr">Tensor</code> based on given <code translate="no" dir="ltr">feature_columns</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.feature_column.linear_model(
    features,
    feature_columns,
    units=1,
    sparse_combiner='sum',
    weight_collections=None,
    trainable=True,
    cols_to_vars=None
)
</pre>  <p>This function generates a weighted sum based on output dimension <code translate="no" dir="ltr">units</code>. Weighted sum refers to logits in classification problems. It refers to the prediction itself for linear regression problems.</p> <p>Note on supported columns: <code translate="no" dir="ltr">linear_model</code> treats categorical columns as <code translate="no" dir="ltr">indicator_column</code>s. To be specific, assume the input as <code translate="no" dir="ltr">SparseTensor</code> looks like:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">shape = [2, 2]
{
    [0, 0]: "a"
    [1, 0]: "b"
    [1, 1]: "c"
}
</pre> <p><code translate="no" dir="ltr">linear_model</code> assigns weights for the presence of "a", "b", "c' implicitly, just like <code translate="no" dir="ltr">indicator_column</code>, while <code translate="no" dir="ltr">input_layer</code> explicitly requires wrapping each of categorical columns with an <code translate="no" dir="ltr">embedding_column</code> or an <code translate="no" dir="ltr">indicator_column</code>.</p> <h4 id="example_of_usage" data-text="Example of usage:">Example of usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">price = numeric_column('price')
price_buckets = bucketized_column(price, boundaries=[0., 10., 100., 1000.])
keywords = categorical_column_with_hash_bucket("keywords", 10K)
keywords_price = crossed_column('keywords', price_buckets, ...)
columns = [price_buckets, keywords, keywords_price ...]
features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
prediction = linear_model(features, columns)
</pre> <p>The <code translate="no" dir="ltr">sparse_combiner</code> argument works as follows For example, for two features represented as the categorical columns:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Feature 1

shape = [2, 2]
{
    [0, 0]: "a"
    [0, 1]: "b"
    [1, 0]: "c"
}

# Feature 2

shape = [2, 3]
{
    [0, 0]: "d"
    [1, 0]: "e"
    [1, 1]: "f"
    [1, 2]: "f"
}
</pre> <p>with <code translate="no" dir="ltr">sparse_combiner</code> as "mean", the linear model outputs consequently are:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">y_0 = 1.0 / 2.0 * ( w_a + w_b ) + w_d + b
y_1 = w_c + 1.0 / 3.0 * ( w_e + 2.0 * w_f ) + b
</pre> <p>where <code translate="no" dir="ltr">y_i</code> is the output, <code translate="no" dir="ltr">b</code> is the bias, and <code translate="no" dir="ltr">w_x</code> is the weight assigned to the presence of <code translate="no" dir="ltr">x</code> in the input features.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">features</code> </td> <td> A mapping from key to tensors. <code translate="no" dir="ltr">_FeatureColumn</code>s look up via these keys. For example <code translate="no" dir="ltr">numeric_column('price')</code> will look at 'price' key in this dict. Values are <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> depending on corresponding <code translate="no" dir="ltr">_FeatureColumn</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">feature_columns</code> </td> <td> An iterable containing the FeatureColumns to use as inputs to your model. All items should be instances of classes derived from <code translate="no" dir="ltr">_FeatureColumn</code>s. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">units</code> </td> <td> An integer, dimensionality of the output space. Default value is 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sparse_combiner</code> </td> <td> A string specifying how to reduce if a categorical column is multivalent. Except <code translate="no" dir="ltr">numeric_column</code>, almost all columns passed to <code translate="no" dir="ltr">linear_model</code> are considered as categorical columns. It combines each categorical column independently. Currently "mean", "sqrtn" and "sum" are supported, with "sum" the default for linear model. "sqrtn" often achieves good accuracy, in particular with bag-of-words columns. <ul> <li>"sum": do not normalize features in the column</li> <li>"mean": do l1 normalization on features in the column</li> <li>"sqrtn": do l2 normalization on features in the column </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">weight_collections</code> </td> <td> A list of collection names to which the Variable will be added. Note that, variables will also be added to collections <code translate="no" dir="ltr">tf.GraphKeys.GLOBAL_VARIABLES</code> and <code translate="no" dir="ltr">ops.GraphKeys.MODEL_VARIABLES</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable</code> </td> <td> If <code translate="no" dir="ltr">True</code> also add the variable to the graph collection <code translate="no" dir="ltr">GraphKeys.TRAINABLE_VARIABLES</code> (see <a href="../../../variable.html"><code translate="no" dir="ltr">tf.Variable</code></a>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">cols_to_vars</code> </td> <td> If not <code translate="no" dir="ltr">None</code>, must be a dictionary that will be filled with a mapping from <code translate="no" dir="ltr">_FeatureColumn</code> to associated list of <code translate="no" dir="ltr">Variable</code>s. For example, after the call, we might have cols_to_vars = { _NumericColumn( key='numeric_feature1', shape=(1,): [<tf.variable shape="(1,">], 'bias': [<tf.variable shape="(1,)">], _NumericColumn( key='numeric_feature2', shape=(2,)): [<tf.variable shape="(2,">]} If a column creates no variables, its value will be an empty list. Note that cols_to_vars will also contain a string key 'bias' that maps to a list of Variables. </tf.variable></tf.variable></tf.variable>
</td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> which represents predictions/logits of a linear model. Its shape is (batch_size, units) and its dtype is <code translate="no" dir="ltr">float32</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if an item in <code translate="no" dir="ltr">feature_columns</code> is neither a <code translate="no" dir="ltr">_DenseColumn</code> nor <code translate="no" dir="ltr">_CategoricalColumn</code>. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/feature_column/linear_model" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/feature_column/linear_model</a>
  </p>
</div>
