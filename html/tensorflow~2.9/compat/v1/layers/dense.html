<h1 class="devsite-page-title">tf.compat.v1.layers.Dense</h1> <devsite-bookmark></devsite-bookmark>       <p>Densely-connected layer class.</p> <p>Inherits From: <a href="../../../keras/layers/dense.html"><code translate="no" dir="ltr">Dense</code></a>, <a href="layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../keras/layers/layer.html"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../module.html"><code translate="no" dir="ltr">Module</code></a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
</pre> <p><section><devsite-expandable expanded> <h2 class="showalways" id="migrate-to-tf2" data-text="Migrate to TF2">Migrate to TF2</h2></devsite-expandable></section></p> <aside class="caution"><strong>Caution:</strong><span> This API was designed for TensorFlow v1. Continue reading for details on how to migrate from this API to a native TensorFlow v2 equivalent. See the <a href="https://www.tensorflow.org/guide/migrate">TensorFlow v1 to TensorFlow v2 migration guide</a> for instructions on how to migrate the rest of your code.</span></aside> <p>This API is a legacy api that is only compatible with eager execution and <a href="../../../function.html"><code translate="no" dir="ltr">tf.function</code></a> if you combine it with <a href="../keras/utils/track_tf1_style_variables.html"><code translate="no" dir="ltr">tf.compat.v1.keras.utils.track_tf1_style_variables</code></a></p> <p>Please refer to <a href="https://www.tensorflow.org/guide/migrate/model_mapping">tf.layers model mapping section of the migration guide</a> to learn how to use your TensorFlow v1 model in TF2 with Keras.</p> <p>The corresponding TensorFlow v2 layer is <a href="../../../keras/layers/dense.html"><code translate="no" dir="ltr">tf.keras.layers.Dense</code></a>.</p> <h4 id="structural_mapping_to_native_tf2" data-text="Structural Mapping to Native TF2">Structural Mapping to Native TF2</h4> <p>None of the supported arguments have changed name.</p> <p>Before:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">dense = tf.compat.v1.layers.Dense(units=3)
</pre> <p>After:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">dense = tf.keras.layers.Dense(units=3)
</pre>  <h2 id="description" data-text="Description">Description</h2>  <p>This layer implements the operation: <code translate="no" dir="ltr">outputs = activation(inputs * kernel + bias)</code> Where <code translate="no" dir="ltr">activation</code> is the activation function passed as the <code translate="no" dir="ltr">activation</code> argument (if not <code translate="no" dir="ltr">None</code>), <code translate="no" dir="ltr">kernel</code> is a weights matrix created by the layer, and <code translate="no" dir="ltr">bias</code> is a bias vector created by the layer (only if <code translate="no" dir="ltr">use_bias</code> is <code translate="no" dir="ltr">True</code>).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">units</code> </td> <td> Integer or Long, dimensionality of the output space. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activation</code> </td> <td> Activation function (callable). Set it to None to maintain a linear activation. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_bias</code> </td> <td> Boolean, whether the layer uses a bias. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_initializer</code> </td> <td> Initializer function for the weight matrix. If <code translate="no" dir="ltr">None</code> (default), weights are initialized using the default initializer used by <a href="../get_variable.html"><code translate="no" dir="ltr">tf.compat.v1.get_variable</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_initializer</code> </td> <td> Initializer function for the bias. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_regularizer</code> </td> <td> Regularizer function for the weight matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_regularizer</code> </td> <td> Regularizer function for the bias. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activity_regularizer</code> </td> <td> Regularizer function for the output. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_constraint</code> </td> <td> An optional projection function to be applied to the kernel after being updated by an <code translate="no" dir="ltr">Optimizer</code> (e.g. used to implement norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_constraint</code> </td> <td> An optional projection function to be applied to the bias after being updated by an <code translate="no" dir="ltr">Optimizer</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable</code> </td> <td> Boolean, if <code translate="no" dir="ltr">True</code> also add variables to the graph collection <code translate="no" dir="ltr">GraphKeys.TRAINABLE_VARIABLES</code> (see <a href="../../../variable.html"><code translate="no" dir="ltr">tf.Variable</code></a>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> String, the name of the layer. Layers with the same name will share weights, but to avoid mistakes we require reuse=True in such cases. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">_reuse</code> </td> <td> Boolean, whether to reuse the weights of a previous layer by the same name. </td> </tr> </table> <h4 id="properties" data-text="Properties:">Properties:</h4> <ul> <li>
<b><code translate="no" dir="ltr">units</code></b>: Python integer, dimensionality of the output space.</li> <li>
<b><code translate="no" dir="ltr">activation</code></b>: Activation function (callable).</li> <li>
<b><code translate="no" dir="ltr">use_bias</code></b>: Boolean, whether the layer uses a bias.</li> <li>
<b><code translate="no" dir="ltr">kernel_initializer</code></b>: Initializer instance (or name) for the kernel matrix.</li> <li>
<b><code translate="no" dir="ltr">bias_initializer</code></b>: Initializer instance (or name) for the bias.</li> <li>
<b><code translate="no" dir="ltr">kernel_regularizer</code></b>: Regularizer instance for the kernel matrix (callable)</li> <li>
<b><code translate="no" dir="ltr">bias_regularizer</code></b>: Regularizer instance for the bias (callable).</li> <li>
<b><code translate="no" dir="ltr">activity_regularizer</code></b>: Regularizer instance for the output (callable)</li> <li>
<b><code translate="no" dir="ltr">kernel_constraint</code></b>: Constraint function for the kernel matrix.</li> <li>
<b><code translate="no" dir="ltr">bias_constraint</code></b>: Constraint function for the bias.</li> <li>
<b><code translate="no" dir="ltr">kernel</code></b>: Weight matrix (TensorFlow variable or tensor).</li> <li>
<b><code translate="no" dir="ltr">bias</code></b>: Bias vector, if applicable (TensorFlow variable or tensor).</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">graph</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">scope_name</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="apply" data-text="apply"><code translate="no" dir="ltr">apply</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/legacy_tf_layers/base.py#L239-L240">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
apply(
    *args, **kwargs
)
</pre> <h3 id="get_losses_for" data-text="get_losses_for"><code translate="no" dir="ltr">get_losses_for</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/engine/base_layer_v1.py#L1341-L1358">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_losses_for(
    inputs
)
</pre> <p>Retrieves losses relevant to a specific set of inputs.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> Input tensor or list/tuple of input tensors. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> List of loss tensors of the layer that depend on <code translate="no" dir="ltr">inputs</code>. </td> </tr> 
</table> <h3 id="get_updates_for" data-text="get_updates_for"><code translate="no" dir="ltr">get_updates_for</code></h3> <p><a target="_blank" class="external" href="https://github.com/keras-team/keras/tree/v2.9.0/keras/engine/base_layer_v1.py#L1322-L1339">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_updates_for(
    inputs
)
</pre> <p>Retrieves updates relevant to a specific set of inputs.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> Input tensor or list/tuple of input tensors. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> List of update ops of the layer that depend on <code translate="no" dir="ltr">inputs</code>. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/layers/Dense" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/layers/Dense</a>
  </p>
</div>
