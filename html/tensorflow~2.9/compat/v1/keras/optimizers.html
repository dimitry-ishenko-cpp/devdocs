<h1 class="devsite-page-title">Module: tf.compat.v1.keras.optimizers</h1> <devsite-bookmark></devsite-bookmark>       <p>Built-in optimizer classes.</p> <p>For more examples see the base class <a href="../../../keras/optimizers/optimizer.html"><code translate="no" dir="ltr">tf.keras.optimizers.Optimizer</code></a>.</p> <h2 id="modules" data-text="Modules">Modules</h2> <p><a href="optimizers/legacy.html"><code translate="no" dir="ltr">legacy</code></a> module: Public API for tf.keras.optimizers.legacy namespace.</p> <p><a href="optimizers/schedules.html"><code translate="no" dir="ltr">schedules</code></a> module: Public API for tf.keras.optimizers.schedules namespace.</p> <h2 id="classes" data-text="Classes">Classes</h2> <p><a href="../../../keras/optimizers/adadelta.html"><code translate="no" dir="ltr">class Adadelta</code></a>: Optimizer that implements the Adadelta algorithm.</p> <p><a href="../../../keras/optimizers/adagrad.html"><code translate="no" dir="ltr">class Adagrad</code></a>: Optimizer that implements the Adagrad algorithm.</p> <p><a href="../../../keras/optimizers/adam.html"><code translate="no" dir="ltr">class Adam</code></a>: Optimizer that implements the Adam algorithm.</p> <p><a href="../../../keras/optimizers/adamax.html"><code translate="no" dir="ltr">class Adamax</code></a>: Optimizer that implements the Adamax algorithm.</p> <p><a href="../../../keras/optimizers/ftrl.html"><code translate="no" dir="ltr">class Ftrl</code></a>: Optimizer that implements the FTRL algorithm.</p> <p><a href="../../../keras/optimizers/nadam.html"><code translate="no" dir="ltr">class Nadam</code></a>: Optimizer that implements the NAdam algorithm.</p> <p><a href="../../../keras/optimizers/optimizer.html"><code translate="no" dir="ltr">class Optimizer</code></a>: Base class for Keras optimizers.</p> <p><a href="../../../keras/optimizers/rmsprop.html"><code translate="no" dir="ltr">class RMSprop</code></a>: Optimizer that implements the RMSprop algorithm.</p> <p><a href="../../../keras/optimizers/sgd.html"><code translate="no" dir="ltr">class SGD</code></a>: Gradient descent (with momentum) optimizer.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="../../../keras/optimizers/deserialize.html"><code translate="no" dir="ltr">deserialize(...)</code></a>: Inverse of the <code translate="no" dir="ltr">serialize</code> function.</p> <p><a href="../../../keras/optimizers/get.html"><code translate="no" dir="ltr">get(...)</code></a>: Retrieves a Keras Optimizer instance.</p> <p><a href="../../../keras/optimizers/serialize.html"><code translate="no" dir="ltr">serialize(...)</code></a>: Serialize the optimizer configuration to JSON compatible python dict.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/keras/optimizers" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/keras/optimizers</a>
  </p>
</div>
