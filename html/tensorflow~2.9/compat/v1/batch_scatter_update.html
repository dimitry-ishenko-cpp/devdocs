<h1 class="devsite-page-title">tf.compat.v1.batch_scatter_update</h1> <devsite-bookmark></devsite-bookmark>       <p>Generalization of <a href="scatter_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> to axis different than 0. (deprecated)</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.batch_scatter_update(
    ref, indices, updates, use_locking=True, name=None
)
</pre>  <aside class="deprecated"><strong>Deprecated:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed after 2018-11-29. Instructions for updating: Use the batch_scatter_update method of Variable instead.</span></aside> <p>Analogous to <code translate="no" dir="ltr">batch_gather</code>. This assumes that <code translate="no" dir="ltr">ref</code>, <code translate="no" dir="ltr">indices</code> and <code translate="no" dir="ltr">updates</code> have a series of leading dimensions that are the same for all of them, and the updates are performed on the last dimension of indices. In other words, the dimensions should be the following:</p> <p><code translate="no" dir="ltr">num_prefix_dims = indices.ndims - 1</code> <code translate="no" dir="ltr">batch_dim = num_prefix_dims + 1</code> <code translate="no" dir="ltr">updates.shape = indices.shape + var.shape[batch_dim:]</code></p> <p>where</p> <p><code translate="no" dir="ltr">updates.shape[:num_prefix_dims]</code> <code translate="no" dir="ltr">== indices.shape[:num_prefix_dims]</code> <code translate="no" dir="ltr">== var.shape[:num_prefix_dims]</code></p> <p>And the operation performed can be expressed as:</p> <p><code translate="no" dir="ltr">var[i_1, ..., i_n, indices[i_1, ..., i_n, j]] = updates[i_1, ..., i_n, j]</code></p> <p>When indices is a 1D tensor, this operation is equivalent to <a href="scatter_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a>.</p> <p>To avoid this operation there would be 2 alternatives:</p> <p>1) Reshaping the variable by merging the first <code translate="no" dir="ltr">ndims</code> dimensions. However, this is not possible because <a href="../../reshape.html"><code translate="no" dir="ltr">tf.reshape</code></a> returns a Tensor, which we cannot use <a href="scatter_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> on. 2) Looping over the first <code translate="no" dir="ltr">ndims</code> of the variable and using <a href="scatter_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> on the subtensors that result of slicing the first dimension. This is a valid option for <code translate="no" dir="ltr">ndims = 1</code>, but less efficient than this implementation.</p> <p>See also <a href="scatter_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> and <a href="scatter_nd_update.html"><code translate="no" dir="ltr">tf.compat.v1.scatter_nd_update</code></a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ref</code> </td> <td> <code translate="no" dir="ltr">Variable</code> to scatter onto. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">indices</code> </td> <td> Tensor containing indices as described above. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">updates</code> </td> <td> Tensor of updates to apply to <code translate="no" dir="ltr">ref</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_locking</code> </td> <td> Boolean indicating whether to lock the writing operation. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Optional scope name string. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Ref to <code translate="no" dir="ltr">variable</code> after it has been modified. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the initial <code translate="no" dir="ltr">ndims</code> of <code translate="no" dir="ltr">ref</code>, <code translate="no" dir="ltr">indices</code>, and <code translate="no" dir="ltr">updates</code> are not the same. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/batch_scatter_update" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/batch_scatter_update</a>
  </p>
</div>
