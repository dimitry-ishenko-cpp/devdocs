<h1 class="devsite-page-title">tf.compat.v1.tpu.experimental.shared_embedding_columns</h1> <devsite-bookmark></devsite-bookmark>       <p>TPU version of <a href="../../feature_column/shared_embedding_columns.html"><code translate="no" dir="ltr">tf.compat.v1.feature_column.shared_embedding_columns</code></a>.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.tpu.experimental.shared_embedding_columns(
    categorical_columns,
    dimension,
    combiner='mean',
    initializer=None,
    shared_embedding_collection_name=None,
    max_sequence_lengths=None,
    learning_rate_fn=None,
    embedding_lookup_device=None,
    tensor_core_shape=None,
    use_safe_embedding_lookup=True
)
</pre>  <p>Note that the interface for <code translate="no" dir="ltr">tf.tpu.experimental.shared_embedding_columns</code> is different from that of <a href="../../feature_column/shared_embedding_columns.html"><code translate="no" dir="ltr">tf.compat.v1.feature_column.shared_embedding_columns</code></a>: The following arguments are NOT supported: <code translate="no" dir="ltr">ckpt_to_load_from</code>, <code translate="no" dir="ltr">tensor_name_in_ckpt</code>, <code translate="no" dir="ltr">max_norm</code> and <code translate="no" dir="ltr">trainable</code>.</p> <p>Use this function in place of tf.compat.v1.feature_column.shared_embedding_columns` when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">column_a = tf.feature_column.categorical_column_with_identity(...)
column_b = tf.feature_column.categorical_column_with_identity(...)
tpu_columns = tf.tpu.experimental.shared_embedding_columns(
    [column_a, column_b], 10)
...
def model_fn(features):
  dense_feature = tf.keras.layers.DenseFeature(tpu_columns)
  embedded_feature = dense_feature(features)
  ...

estimator = tf.estimator.tpu.TPUEstimator(
    model_fn=model_fn,
    ...
    embedding_config_spec=tf.estimator.tpu.experimental.EmbeddingConfigSpec(
        column=tpu_columns,
        ...))
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">categorical_columns</code> </td> <td> A list of categorical columns returned from <code translate="no" dir="ltr">categorical_column_with_identity</code>, <code translate="no" dir="ltr">weighted_categorical_column</code>, <code translate="no" dir="ltr">categorical_column_with_vocabulary_file</code>, <code translate="no" dir="ltr">categorical_column_with_vocabulary_list</code>, <code translate="no" dir="ltr">sequence_categorical_column_with_identity</code>, <code translate="no" dir="ltr">sequence_categorical_column_with_vocabulary_file</code>, <code translate="no" dir="ltr">sequence_categorical_column_with_vocabulary_list</code> </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dimension</code> </td> <td> An integer specifying dimension of the embedding, must be &gt; 0. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">combiner</code> </td> <td> A string specifying how to reduce if there are multiple entries in a single row for a non-sequence column. For more information, see <a href="../../../../feature_column/embedding_column.html"><code translate="no" dir="ltr">tf.feature_column.embedding_column</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">initializer</code> </td> <td> A variable initializer function to be used in embedding variable initialization. If not specified, defaults to <code translate="no" dir="ltr">tf.truncated_normal_initializer</code> with mean <code translate="no" dir="ltr">0.0</code> and standard deviation <code translate="no" dir="ltr">1/sqrt(dimension)</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shared_embedding_collection_name</code> </td> <td> Optional name of the collection where shared embedding weights are added. If not given, a reasonable name will be chosen based on the names of <code translate="no" dir="ltr">categorical_columns</code>. This is also used in <code translate="no" dir="ltr">variable_scope</code> when creating shared embedding weights. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_sequence_lengths</code> </td> <td> An list of non-negative integers, either None or empty or the same length as the argument categorical_columns. Entries corresponding to non-sequence columns must be 0 and entries corresponding to sequence columns specify the max sequence length for the column. Any sequence shorter then this will be padded with 0 embeddings and any sequence longer will be truncated. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">learning_rate_fn</code> </td> <td> A function that takes global step and returns learning rate for the embedding table. If you intend to use the same learning rate for multiple embedding tables, please ensure that you pass the exact same python function to all calls of shared_embedding_columns, otherwise performence may suffer. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">embedding_lookup_device</code> </td> <td> The device on which to run the embedding lookup. Valid options are "cpu", "tpu_tensor_core", and "tpu_embedding_core". If specifying "tpu_tensor_core", a tensor_core_shape must be supplied. Defaults to "cpu". If not specified, the default behavior is embedding lookup on "tpu_embedding_core" for training and "cpu" for inference. Valid options for training : ["tpu_embedding_core", "tpu_tensor_core"] Valid options for serving : ["cpu", "tpu_tensor_core"] For training, tpu_embedding_core is good for large embedding vocab (&gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">tensor_core_shape</code> </td> <td> If supplied, a list of integers which specifies the intended dense shape to run embedding lookup for this feature on TensorCore. The batch dimension can be left None or -1 to indicate a dynamic shape. Only rank 2 shapes currently supported. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_safe_embedding_lookup</code> </td> <td> If true, uses safe_embedding_lookup_sparse instead of embedding_lookup_sparse. safe_embedding_lookup_sparse ensures there are no empty rows and all weights and ids are positive at the expense of extra compute cost. This only applies to rank 2 (NxM) shaped input tensors. Defaults to true, consider turning off if the above checks are not needed. Note that having empty rows will not trigger any error though the output result might be 0 or omitted. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of <code translate="no" dir="ltr">_TPUSharedEmbeddingColumnV2</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">dimension</code> not &gt; 0. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">initializer</code> is specified but not callable. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">max_sequence_lengths</code> is specified and not the same length as <code translate="no" dir="ltr">categorical_columns</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">max_sequence_lengths</code> is positive for a non sequence column or 0 for a sequence column. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/tpu/experimental/shared_embedding_columns" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/tpu/experimental/shared_embedding_columns</a>
  </p>
</div>
