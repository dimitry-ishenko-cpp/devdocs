<h1 class="devsite-page-title">tf.compat.v1.nn.ctc_beam_search_decoder</h1> <devsite-bookmark></devsite-bookmark>       <p>Performs beam search decoding on the logits given in input.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.nn.ctc_beam_search_decoder(
    inputs, sequence_length, beam_width=100, top_paths=1, merge_repeated=True
)
</pre>  <blockquote class="note">
<strong>Note:</strong><span> Although in general greedy search is a special case of beam-search with <code translate="no" dir="ltr">top_paths=1</code> and <code translate="no" dir="ltr">beam_width=1</code>, <code translate="no" dir="ltr">ctc_beam_search_decoder</code> differs from <code translate="no" dir="ltr">ctc_greedy_decoder</code> in the treatment of blanks when computing the probability of a sequence:</span>
</blockquote> <ul> <li>
<code translate="no" dir="ltr">ctc_beam_search_decoder</code> treats blanks as sequence termination</li> <li>
<code translate="no" dir="ltr">ctc_greedy_decoder</code> treats blanks as regular elements</li> </ul> <p>If <code translate="no" dir="ltr">merge_repeated</code> is <code translate="no" dir="ltr">True</code>, merge repeated classes in the output beams. This means that if consecutive entries in a beam are the same, only the first of these is emitted. That is, when the sequence is <code translate="no" dir="ltr">A B B * B * B</code> (where '*' is the blank label), the return value is:</p> <ul> <li>
<code translate="no" dir="ltr">A B</code> if <code translate="no" dir="ltr">merge_repeated = True</code>.</li> <li>
<code translate="no" dir="ltr">A B B B</code> if <code translate="no" dir="ltr">merge_repeated = False</code>.</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">inputs</code> </td> <td> 3-D <code translate="no" dir="ltr">float</code> <code translate="no" dir="ltr">Tensor</code>, size <code translate="no" dir="ltr">[max_time x batch_size x num_classes]</code>. The logits. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sequence_length</code> </td> <td> 1-D <code translate="no" dir="ltr">int32</code> vector containing sequence lengths, having size <code translate="no" dir="ltr">[batch_size]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">beam_width</code> </td> <td> An int scalar &gt;= 0 (beam search beam width). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">top_paths</code> </td> <td> An int scalar &gt;= 0, &lt;= beam_width (controls output size). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">merge_repeated</code> </td> <td> Boolean. Default: True. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A tuple <code translate="no" dir="ltr">(decoded, log_probabilities)</code> where </td> </tr> <tr> <td> <code translate="no" dir="ltr">decoded</code> </td> <td> A list of length top_paths, where <code translate="no" dir="ltr">decoded[j]</code> is a <code translate="no" dir="ltr">SparseTensor</code> containing the decoded outputs: <p><code translate="no" dir="ltr">decoded[j].indices</code>: Indices matrix <code translate="no" dir="ltr">(total_decoded_outputs[j] x 2)</code> The rows store: [batch, time].</p> <p><code translate="no" dir="ltr">decoded[j].values</code>: Values vector, size <code translate="no" dir="ltr">(total_decoded_outputs[j])</code>. The vector stores the decoded classes for beam j.</p> <p><code translate="no" dir="ltr">decoded[j].dense_shape</code>: Shape vector, size <code translate="no" dir="ltr">(2)</code>. The shape values are: <code translate="no" dir="ltr">[batch_size, max_decoded_length[j]]</code>. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">log_probability</code> </td> <td> A <code translate="no" dir="ltr">float</code> matrix <code translate="no" dir="ltr">(batch_size x top_paths)</code> containing sequence log-probabilities. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/nn/ctc_beam_search_decoder" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/nn/ctc_beam_search_decoder</a>
  </p>
</div>
