<h1 class="devsite-page-title">tf.bitcast</h1> <devsite-bookmark></devsite-bookmark>       <p>Bitcasts a tensor from one type to another without copying data.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/bitcast"><code translate="no" dir="ltr">tf.compat.v1.bitcast</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.bitcast(
    input, type, name=None
)
</pre>  <p>Given a tensor <code translate="no" dir="ltr">input</code>, this operation returns a tensor that has the same buffer data as <code translate="no" dir="ltr">input</code> with datatype <code translate="no" dir="ltr">type</code>.</p> <p>If the input datatype <code translate="no" dir="ltr">T</code> is larger than the output datatype <code translate="no" dir="ltr">type</code> then the shape changes from [...] to [..., sizeof(<code translate="no" dir="ltr">T</code>)/sizeof(<code translate="no" dir="ltr">type</code>)].</p> <p>If <code translate="no" dir="ltr">T</code> is smaller than <code translate="no" dir="ltr">type</code>, the operator requires that the rightmost dimension be equal to sizeof(<code translate="no" dir="ltr">type</code>)/sizeof(<code translate="no" dir="ltr">T</code>). The shape then goes from [..., sizeof(<code translate="no" dir="ltr">type</code>)/sizeof(<code translate="no" dir="ltr">T</code>)] to [...].</p> <p>tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast() gives module error. For example,</p> <h4 id="example_1" data-text="Example 1:">Example 1:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = [1., 2., 3.]
equality_bitcast = tf.bitcast(a, tf.complex128)
Traceback (most recent call last):

InvalidArgumentError: Cannot bitcast from 1 to 18 [Op:Bitcast]
equality_cast = tf.cast(a, tf.complex128)
print(equality_cast)
tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)
</pre> <h4 id="example_2" data-text="Example 2:">Example 2:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)
&lt;tf.Tensor: shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)&gt;
</pre> <h4 id="example_3" data-text="Example 3:">Example 3:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = [1., 2., 3.]
y = [0., 2., 3.]
equality= tf.equal(x,y)
equality_cast = tf.cast(equality,tf.float32)
equality_bitcast = tf.bitcast(equality_cast,tf.uint8)
print(equality)
tf.Tensor([False True True], shape=(3,), dtype=bool)
print(equality_cast)
tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)
print(equality_bitcast)
tf.Tensor(
    [[  0   0   0   0]
     [  0   0 128  63]
     [  0   0 128  63]], shape=(3, 4), dtype=uint8)
</pre> <blockquote class="note">
<strong>Note:</strong><span> Bitcast is implemented as a low-level cast, so machines with different endian orderings will give different results.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">qint8</code>, <code translate="no" dir="ltr">quint8</code>, <code translate="no" dir="ltr">qint16</code>, <code translate="no" dir="ltr">quint16</code>, <code translate="no" dir="ltr">qint32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">type</code> </td> <td> A <a href="dtypes/dtype.html"><code translate="no" dir="ltr">tf.DType</code></a> from: <code translate="no" dir="ltr">tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">type</code>. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/bitcast" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/bitcast</a>
  </p>
</div>
