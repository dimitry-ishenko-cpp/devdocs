<h1 class="devsite-page-title">tf.nn.dropout</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/ops/nn_ops.py#L5388-L5480">  View source on GitHub </a> </td> </table> <p>Computes dropout: randomly sets elements to zero to prevent overfitting.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.nn.dropout(
    x, rate, noise_shape=None, seed=None, name=None
)
</pre>  <aside class="warning"><strong>Warning:</strong><span> You should consider using <a href="experimental/stateless_dropout.html"><code translate="no" dir="ltr">tf.nn.experimental.stateless_dropout</code></a> instead of this function. The difference between <a href="experimental/stateless_dropout.html"><code translate="no" dir="ltr">tf.nn.experimental.stateless_dropout</code></a> and this function is analogous to the difference between <a href="../random/stateless_uniform.html"><code translate="no" dir="ltr">tf.random.stateless_uniform</code></a> and <a href="../random/uniform.html"><code translate="no" dir="ltr">tf.random.uniform</code></a>. Please see <a href="https://www.tensorflow.org/guide/random_numbers">Random number generation</a> guide for a detailed description of the various RNG systems in TF. As the guide states, legacy stateful RNG ops like <a href="../random/uniform.html"><code translate="no" dir="ltr">tf.random.uniform</code></a> and <a href="dropout.html"><code translate="no" dir="ltr">tf.nn.dropout</code></a> are not deprecated yet but highly discouraged, because their states are hard to control.</span></aside><blockquote class="note">
<strong>Note:</strong><span> The behavior of dropout has changed between TensorFlow 1.x and 2.x. When converting 1.x code, please use named arguments to ensure behavior stays consistent.</span>
</blockquote> <p>See also: <a href="../keras/layers/dropout.html"><code translate="no" dir="ltr">tf.keras.layers.Dropout</code></a> for a dropout layer.</p> <p><a href="https://arxiv.org/abs/1207.0580">Dropout</a> is useful for regularizing DNN models. Inputs elements are randomly set to zero (and the other elements are rescaled). This encourages each node to be independently useful, as it cannot rely on the output of other nodes.</p> <p>More precisely: With probability <code translate="no" dir="ltr">rate</code> elements of <code translate="no" dir="ltr">x</code> are set to <code translate="no" dir="ltr">0</code>. The remaining elements are scaled up by <code translate="no" dir="ltr">1.0 / (1 - rate)</code>, so that the expected value is preserved.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.random.set_seed(0)
x = tf.ones([3,5])
tf.nn.dropout(x, rate = 0.5, seed = 1).numpy()
array([[2., 0., 0., 2., 2.],
     [2., 2., 2., 2., 2.],
     [2., 0., 2., 0., 2.]], dtype=float32)
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.random.set_seed(0)
x = tf.ones([3,5])
tf.nn.dropout(x, rate = 0.8, seed = 1).numpy()
array([[0., 0., 0., 5., 5.],
     [0., 5., 0., 5., 0.],
     [5., 0., 5., 0., 5.]], dtype=float32)
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.nn.dropout(x, rate = 0.0) == x
&lt;tf.Tensor: shape=(3, 5), dtype=bool, numpy=
  array([[ True,  True,  True,  True,  True],
         [ True,  True,  True,  True,  True],
         [ True,  True,  True,  True,  True]])&gt;
</pre> <p>By default, each element is kept or dropped independently. If <code translate="no" dir="ltr">noise_shape</code> is specified, it must be <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcastable</a> to the shape of <code translate="no" dir="ltr">x</code>, and only dimensions with <code translate="no" dir="ltr">noise_shape[i] == shape(x)[i]</code> will make independent decisions. This is useful for dropping whole channels from an image or sequence. For example:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.random.set_seed(0)
x = tf.ones([3,10])
tf.nn.dropout(x, rate = 2/3, noise_shape=[1,10], seed=1).numpy()
array([[0., 0., 0., 3., 3., 0., 3., 3., 3., 0.],
     [0., 0., 0., 3., 3., 0., 3., 3., 3., 0.],
     [0., 0., 0., 3., 3., 0., 3., 3., 3., 0.]], dtype=float32)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A floating point tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">rate</code> </td> <td> A scalar <code translate="no" dir="ltr">Tensor</code> with the same type as x. The probability that each element is dropped. For example, setting rate=0.1 would drop 10% of input elements. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">noise_shape</code> </td> <td> A 1-D integer <code translate="no" dir="ltr">Tensor</code>, representing the shape for randomly generated keep/drop flags. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">seed</code> </td> <td> A Python integer. Used to create random seeds. See <a href="../random/set_seed.html"><code translate="no" dir="ltr">tf.random.set_seed</code></a> for behavior. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for this operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A Tensor of the same shape of <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">rate</code> is not in <code translate="no" dir="ltr">[0, 1)</code> or if <code translate="no" dir="ltr">x</code> is not a floating point tensor. <code translate="no" dir="ltr">rate=1</code> is disallowed, because the output would be all zeros, which is likely not what was intended. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/dropout" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/nn/dropout</a>
  </p>
</div>
