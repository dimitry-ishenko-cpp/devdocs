<h1>Aggregators</h1> <p>OpenTSDB was designed to efficiently combine multiple, distinct time series during query execution. But how do you merge individual time series into a single series of data? Aggregation functions provide the means of mathematically merging the different data series into one, giving you a choice of various mathematical operations. Since OpenTSDB doesn't know whether or not a query will return multiple time series, an aggregation function is always required just in case.</p> <p>Aggregators have two methods of operation:</p>  <h2>Aggregation</h2> <p>Since OpenTSDB doesn't know whether a query will return multiple time series until it scans through all of the data, an aggregation function must be specified for every query just in case. When more than one series is found, the two series are <strong>aggregated</strong> together into a single time series. For each timestamp in the different time series, the aggregator will perform it's computation for each value in every time series at that timestamp. That is, the aggregator will work <em>across</em> all of the time series at each timestamp. The following table illustrates the <code class="docutils literal"><span class="pre">sum</span></code> aggregator as it works across time series <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code> to produce series <code class="docutils literal"><span class="pre">Output</span></code>.</p> <table class="docutils"> <colgroup> <col width="40%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">series</th> <th class="head">ts0</th> <th class="head">ts0+10s</th> <th class="head">ts0+20s</th> <th class="head">ts0+30s</th> <th class="head">ts0+40s</th> <th class="head">ts0+50s</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td>A</td> <td>5</td> <td>5</td> <td>10</td> <td>15</td> <td>20</td> <td>5</td> </tr> <tr class="row-odd">
<td>B</td> <td>10</td> <td>5</td> <td>20</td> <td>15</td> <td>10</td> <td>0</td> </tr> <tr class="row-even">
<td>Output</td> <td>15</td> <td>10</td> <td>30</td> <td>30</td> <td>30</td> <td>5</td> </tr> </tbody> </table> <p>For timestamp <code class="docutils literal"><span class="pre">ts0</span></code> the data points for <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code> are summed, i.e. <code class="docutils literal"><span class="pre">5</span> <span class="pre">+</span> <span class="pre">10</span> <span class="pre">==</span> <span class="pre">15</span></code>. Next, the two values for <code class="docutils literal"><span class="pre">ts1</span></code> are summed together to get <code class="docutils literal"><span class="pre">10</span></code> and so on. Each aggregation function will perform a different mathematical operation.</p> <div class="section" id="interpolation"> <h3>Interpolation</h3> <p>In the example above, both time series <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code> had data points at every time stamp, they lined up neatly. However what happens when two series do not line up? It can be difficult, and sometimes undesired, to synchronize all sources of data to write at the exact same time. For example, if we have 10,000 servers sending 100 system metrics every 5 minutes, that would be a burst of 10M data points in a single second. We would need a pretty beefy network and cluster to accommodate that traffic. Not to mention the system would be sitting idle for the rest of 5 minutes. Instead it makes much more sense to splay the writes over time so that we have an average of 3,333 writes per second to reduce our hardware and network requirements.</p> <div class="sidebar"> <p class="first sidebar-title">Missing Data</p> <p class="last">By "missing" we simply mean that a time series does not have a data point for the timestamp requested. Usually the data is simply time shifted before or after the requested timestamp, but it could actually be missing if the source or the TSD encountered an error and the data wasn't recorded.</p> </div> <p>How do you <em>sum</em> or find the <em>avg</em> of a number and something that doesn't exist? One option is to simply ignore the data points for all time series at the time stamp where any series is missing data. But if you have two time series and they are simply miss-aligned, your query would return an empty data set even though there is good data in storage, so that's not very useful.</p> <p>Another option is to define a scalar value (e.g. <code class="docutils literal"><span class="pre">0</span></code> or the maximum value for a Long) to use whenever a data point is missing. OpenTSDB 2.0 provides a few aggregation methods that substitute a scalar value for missing data points. These are useful when working with distinct value time series such as the number of sales in at a given time.</p> <p>However sometimes it doesn't make sense to define a scalar for missing data. Often you may be recording a monotonically increasing counter such as the number of bytes transmitted from a network interface. With a counter, we can use <strong>interpolation</strong> to make a guess as to what the value would be at that point in time. Interpolation takes two points and the time span between them to calculate a <em>best guess</em> value at the time stamp requested.</p> <p>Take a look at these two time series where the data is simply offset by 10 seconds:</p> <table class="docutils"> <colgroup> <col width="30%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">series</th> <th class="head">ts0</th> <th class="head">ts0+10s</th> <th class="head">ts0+20s</th> <th class="head">ts0+30s</th> <th class="head">ts0+40s</th> <th class="head">ts0+50s</th> <th class="head">ts0+60s</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td>A</td> <td>na</td> <td>5</td> <td>na</td> <td>15</td> <td>na</td> <td>5</td> <td>na</td> </tr> <tr class="row-odd">
<td>B</td> <td>10</td> <td>na</td> <td>20</td> <td>na</td> <td>10</td> <td>na</td> <td>20</td> </tr> </tbody> </table> <p>When OpenTSDB is calculating an aggregation it starts at the first data point found for any series, in this case it will be the data for <code class="docutils literal"><span class="pre">B</span></code> at <code class="docutils literal"><span class="pre">ts0</span></code>. We request a value for <code class="docutils literal"><span class="pre">A</span></code> at <code class="docutils literal"><span class="pre">ts0</span></code> but there isn't any data there. We know that there is data for <code class="docutils literal"><span class="pre">A</span></code> at <code class="docutils literal"><span class="pre">ts0+10s</span></code> but since we don't have any value before that, we can't make a guess as to what it would be. Thus we simply return the value for <code class="docutils literal"><span class="pre">B</span></code>.</p> <p>Next we run across a value for <code class="docutils literal"><span class="pre">A</span></code> at time <code class="docutils literal"><span class="pre">ts0+10s</span></code>. We request a value for <code class="docutils literal"><span class="pre">ts0+10s</span></code> from time series <code class="docutils literal"><span class="pre">B</span></code> but there isn't one. But <code class="docutils literal"><span class="pre">B</span></code> knows there is a value at <code class="docutils literal"><span class="pre">ts0+20s</span></code> and we had a value at <code class="docutils literal"><span class="pre">ts0</span></code> so we can now calculate a guess for <code class="docutils literal"><span class="pre">ts0+10s</span></code>. The formula for linear interpolation is <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">y0</span> <span class="pre">+</span> <span class="pre">(y1</span> <span class="pre">-</span> <span class="pre">y0)</span> <span class="pre">*</span> <span class="pre">((x</span> <span class="pre">-</span> <span class="pre">x0)</span> <span class="pre">/</span> <span class="pre">(x1</span> <span class="pre">-</span> <span class="pre">x0))</span></code> where, for series <code class="docutils literal"><span class="pre">B</span></code>, <code class="docutils literal"><span class="pre">y0</span> <span class="pre">=</span> <span class="pre">10</span></code>, <code class="docutils literal"><span class="pre">y1</span> <span class="pre">=</span> <span class="pre">20</span></code>, <code class="docutils literal"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">ts0+10s</span> <span class="pre">(or</span> <span class="pre">10)</span></code>, <code class="docutils literal"><span class="pre">x0</span> <span class="pre">=</span> <span class="pre">ts0</span> <span class="pre">(or</span> <span class="pre">0)</span></code> and <code class="docutils literal"><span class="pre">x1</span> <span class="pre">=</span> <span class="pre">ts0+20s</span> <span class="pre">(or</span> <span class="pre">20)</span></code>. Thus we have <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">10)</span> <span class="pre">*</span> <span class="pre">((10</span> <span class="pre">-</span> <span class="pre">0)</span> <span class="pre">/</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">0)</span></code> which will reduce to <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">10</span> <span class="pre">*</span> <span class="pre">(10</span> <span class="pre">/</span> <span class="pre">20)</span></code> further reducing to <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">10</span> <span class="pre">*</span> <span class="pre">.5</span></code> and <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">5</span></code>. Therefore <code class="docutils literal"><span class="pre">B</span></code> will give us a <em>guestimated</em> value of <code class="docutils literal"><span class="pre">15</span></code> at <code class="docutils literal"><span class="pre">ts0+10s</span></code>.</p> <p>Iteration continues over every timestamp for which a data point is found for every series returned as a part of the query. The resulting series, using the <strong>sum</strong> aggregator, will look like this:</p> <table class="docutils"> <colgroup> <col width="30%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">series</th> <th class="head">ts0</th> <th class="head">ts0+10s</th> <th class="head">ts0+20s</th> <th class="head">ts0+30s</th> <th class="head">ts0+40s</th> <th class="head">ts0+50s</th> <th class="head">ts0+60s</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td>A</td> <td>na</td> <td>5</td> <td>na</td> <td>15</td> <td>na</td> <td>5</td> <td>na</td> </tr> <tr class="row-odd">
<td>B</td> <td>10</td> <td>na</td> <td>20</td> <td>na</td> <td>10</td> <td>na</td> <td>20</td> </tr> <tr class="row-even">
<td>Interpolated A</td> <td>na</td> <td> </td> <td>10</td> <td> </td> <td>10</td> <td> </td> <td> </td> </tr> <tr class="row-odd">
<td>Interpolated B</td> <td> </td> <td>15</td> <td> </td> <td>15</td> <td> </td> <td>15</td> <td>na</td> </tr> <tr class="row-even">
<td>Summed Result</td> <td>10</td> <td>20</td> <td>30</td> <td>25</td> <td>20</td> <td>20</td> <td>20</td> </tr> </tbody> </table> <p><strong>More Examples:</strong> For the graphically inclined we have the following examples. An imaginary metric named <code class="docutils literal"><span class="pre">m</span></code> is recorded in OpenTSDB. The "sum of m" is the blue line at the top resulting from a query like <code class="docutils literal"><span class="pre">start=1h-ago&amp;m=sum:m</span></code>. It's made of the sum of the red line for <code class="docutils literal"><span class="pre">host=foo</span></code> and the green line for <code class="docutils literal"><span class="pre">host=bar</span></code>:</p> <img alt="../../_images/with-lerp.png" src="http://opentsdb.net/docs/build/html/_images/with-lerp.png"> <p>It seems intuitive from the image above that if you "stack up" the red line and the green line, you'd get the blue line. At any discrete point in time, the blue line has a value that is equal to the sum of the value of the red line and the value of the green line at that time. Without interpolation, you get something rather unintuitive that is harder to make sense of, and which is also a lot less meaningful and useful:</p> <img alt="../../_images/without-lerp.png" src="http://opentsdb.net/docs/build/html/_images/without-lerp.png"> <p>Notice how the blue line drops down to the green data point at 18:46:48. No need to be a mathematician or to have taken advanced maths classes to see that interpolation is needed to properly aggregate multiple time series together and get meaningful results.</p> <p>At the moment OpenTSDB primarily supports <a class="reference external" href="http://en.wikipedia.org/wiki/Linear_interpolation">linear interpolation</a> (sometimes shortened "lerp") along with some aggregators that will simply substitute zeros or the max or min value. Patches are welcome for those who would like to add other interpolation methods.</p> <p>Interpolation is only performed at query time when more than one time series are found to match a query. Many metrics collection systems interpolate on <em>write</em> so that you original value is never recorded. OpenTSDB stores your original value and lets you retrieve it at any time.</p> <p>Here is another slightly more complicated example that came from the mailing list, depicting how multiple time series are aggregated by average:</p> <a class="reference external image-reference" href="../../_images/aggregation_average.png.html"><img alt="Click the image to enlarge." src="http://opentsdb.net/docs/build/html/_images/aggregation-average_sm.png"></a> <p>The thick blue line with triangles is the an aggregation with the <code class="docutils literal"><span class="pre">avg</span></code> function of multiple time series as per the query <code class="docutils literal"><span class="pre">start=1h-ago&amp;m=avg:duration_seconds</span></code>. As we can see, the resulting time series has one data point at each timestamp of all the underlying time series it aggregates, and that data point is computed by taking the average of the values of all the time series at that timestamp. This is also true for the lonely data point of the squared-purple time series, that temporarily boosted the average until the next data point.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">Aggregation functions return integer or double values based on the input data points. If both source values are integers in storage, the resulting calculations will be integers. This means any fractional values resulting from the computation will be lopped off, no rounding will occur. If either data point is a floating point value, the result will be a floating point. However if downsampling or rates are enabled, the result will always be a float.</p> </div> </div>   <h2>Downsampling</h2> <p>The second method of operation for aggregation functions is <code class="docutils literal"><span class="pre">downsampling</span></code>. Since OpenTSDB stores data at the original resolution indefinitely, requesting data for a long time span can return millions of points. This can cause a burden on bandwidth or graphing libraries so it's common to request data at a lower resolution for longer spans. Downsampling breaks the long span of data into smaller spans and merges the data for the smaller span into a single data point. Aggregation functions will perform the same calculation as for an aggregation process but instead of working across data points for multiple time series at a single time stamp, downsampling works across multiple data points within a single time series over a given time span.</p> <p>For example, take series <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code> in the first table under <strong>Aggregation</strong>. The data points cover a 50 second time span. Let's say we want to downsample that to 30 seconds. This will give us two data points for each series:</p> <table class="docutils"> <colgroup> <col width="40%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">series</th> <th class="head">ts0</th> <th class="head">ts0+10s</th> <th class="head">ts0+20s</th> <th class="head">ts0+30s</th> <th class="head">ts0+40s</th> <th class="head">ts0+50s</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td>A</td> <td>5</td> <td>5</td> <td>10</td> <td>15</td> <td>20</td> <td>5</td> </tr> <tr class="row-odd">
<td>A Downsampled</td> <td> </td> <td> </td> <td> </td> <td>35</td> <td> </td> <td>25</td> </tr> <tr class="row-even">
<td>B</td> <td>10</td> <td>5</td> <td>20</td> <td>15</td> <td>10</td> <td>0</td> </tr> <tr class="row-odd">
<td>B Downsampled</td> <td> </td> <td> </td> <td> </td> <td>50</td> <td> </td> <td>10</td> </tr> <tr class="row-even">
<td>Aggregated Result</td> <td> </td> <td> </td> <td> </td> <td>85</td> <td> </td> <td>35</td> </tr> </tbody> </table> <p>For early versions of OpenTSDB, the actual time stamps for the new data points will be an average of the time stamps for each data point in the time span. As of 2.1 and later, the timestamp for each point is aligned to the start of a time bucket based on a modulo of the current time and the downsample interval.</p> <p>Note that when a query specifies a down sampling function and multiple time series are returned, downsampling occurs <strong>before</strong> aggregation. I.e. now that we have <code class="docutils literal"><span class="pre">A</span> <span class="pre">Downsampled</span></code> and <code class="docutils literal"><span class="pre">B</span> <span class="pre">Downsampled</span></code> we can aggregate the two series to come up with the aggregated result on the bottom line.</p>   <h2>Fill Policies</h2> <p>With version 2.2 you can specify a fill policy when downsampling to substitute values for use in cross-series aggregations when data points are "missing". Because OpenTSDB does not impose constraints on time alignment or when values are supposed to exist, such constraints must be specified at query time. At serialization time, if all series are missing values for an expected timestamp, nothing is emitted. For example, if a series is writing data every minute from T0 to T4, but for some reason the source fails to write data at T3, only 4 values will be serialized when the user may expect 5. With fill policies you can now choose what value is emitted for T3.</p> <p>When aggregating multiple series OpenTSDB generally performs linear interpolation when a series is missing a value at a timestamp present in one or more other series. Some aggregators substitute specific values such as zero, min or max values. With fill policies you can modify aggregation behavior by flagging a missing value as a NaN or a scalar such as zero. When a NaN is emitted for a series, it is skipped for all calculations. For example, if a query asks for the average of a metric and one or more series are missing values, substituting a 0 would drive down the average and lerping introduces non-extant values. However with NaNs we can flag the value as missing and skip it in the calculation.</p> <p>Available polices include:</p> <ul class="simple"> <li>None (<code class="docutils literal"><span class="pre">none</span></code>) - The default behavior that does not emit missing values during serialization and performs linear interpolation (or otherwise specified interpolation) when aggregating series.</li> <li>NaN (<code class="docutils literal"><span class="pre">nan</span></code>) - Emits a <code class="docutils literal"><span class="pre">NaN</span></code> in the serialization output when all values are missing in a series. Skips series in aggregations when the value is missing.</li> <li>Null (<code class="docutils literal"><span class="pre">null</span></code>) - Same behavior as NaN except that during serialization it emits a <code class="docutils literal"><span class="pre">null</span></code> instead of a <code class="docutils literal"><span class="pre">NaN</span></code>.</li> <li>Zero (<code class="docutils literal"><span class="pre">zero</span></code>) - Substitutes a zero when a timestamp is missing. The zero value will be incorporated in aggregated results.</li> </ul> <p>(The terms in parentheses can be used in downsampling specifications, e.g. <code class="docutils literal"><span class="pre">1h-sum-nan</span></code>)</p> <p>An example with the NaN fill policy and downsampling on 10 seconds:</p> <table class="docutils"> <colgroup> <col width="30%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> <col width="10%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">series</th> <th class="head">ts0</th> <th class="head">ts0+10s</th> <th class="head">ts0+20s</th> <th class="head">ts0+30s</th> <th class="head">ts0+40s</th> <th class="head">ts0+50s</th> <th class="head">ts0+60s</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td>A</td> <td>na</td> <td>na</td> <td>na</td> <td>15</td> <td>na</td> <td>5</td> <td>na</td> </tr> <tr class="row-odd">
<td>B</td> <td>10</td> <td>na</td> <td>20</td> <td>na</td> <td>na</td> <td>na</td> <td>20</td> </tr> <tr class="row-even">
<td>Interpolated A</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td> </td> <td>NaN</td> <td> </td> <td>NaN</td> </tr> <tr class="row-odd">
<td>Interpolated B</td> <td> </td> <td>NaN</td> <td> </td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td> </td> </tr> <tr class="row-even">
<td>Summed Result</td> <td>10</td> <td>NaN</td> <td>20</td> <td>15</td> <td>NaN</td> <td>5</td> <td>20</td> </tr> </tbody> </table>   <h2>Available Aggregators</h2> <p>The following is a description of the aggregation functions available in OpenTSDB.</p> <table class="docutils"> <colgroup> <col width="20%"> <col width="40%"> <col width="40%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">Aggregator</th> <th class="head">Description</th> <th class="head">Interpolation</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td>avg</td> <td>Averages the data points</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>count</td> <td>The number of raw data points in the set</td> <td>Zero if missing</td> </tr> <tr class="row-even">
<td>dev</td> <td>Calculates the standard deviation</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>ep50r3</td> <td>Calculates the estimated 50th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>ep50r7</td> <td>Calculates the estimated 50th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>ep75r3</td> <td>Calculates the estimated 75th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>ep75r7</td> <td>Calculates the estimated 75th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>ep90r3</td> <td>Calculates the estimated 90th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>ep90r7</td> <td>Calculates the estimated 90th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>ep95r3</td> <td>Calculates the estimated 95th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>ep95r7</td> <td>Calculates the estimated 95th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>ep99r3</td> <td>Calculates the estimated 99th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>ep99r7</td> <td>Calculates the estimated 99th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>ep999r3</td> <td>Calculates the estimated 999th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>ep999r7</td> <td>Calculates the estimated 999th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>first</td> <td>Returns the first data point in the set. Only useful for downsampling, not aggregation. (2.3)</td> <td>Indeterminate</td> </tr> <tr class="row-even">
<td>last</td> <td>Returns the last data point in the set. Only useful for downsampling, not aggregation. (2.3)</td> <td>Indeterminate</td> </tr> <tr class="row-odd">
<td>mimmin</td> <td>Selects the smallest data point</td> <td>Maximum if missing</td> </tr> <tr class="row-even">
<td>mimmax</td> <td>Selects the largest data point</td> <td>Minimum if missing</td> </tr> <tr class="row-odd">
<td>min</td> <td>Selects the smallest data point</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>max</td> <td>Selects the largest data point</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>none</td> <td>Skips group by aggregation of all time series. (2.3)</td> <td>Zero if missing</td> </tr> <tr class="row-even">
<td>p50</td> <td>Calculates the 50th percentile</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>p75</td> <td>Calculates the 75th percentile</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>p90</td> <td>Calculates the 90th percentile</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>p95</td> <td>Calculates the 95th percentile</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>p99</td> <td>Calculates the 99th percentile</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>p999</td> <td>Calculates the 999th percentile</td> <td>Linear Interpolation</td> </tr> <tr class="row-even">
<td>sum</td> <td>Adds the data points together</td> <td>Linear Interpolation</td> </tr> <tr class="row-odd">
<td>zimsum</td> <td>Adds the data points together</td> <td>Zero if missing</td> </tr> </tbody> </table> <p>* For percentile calculations, see the <a class="reference external" href="http://en.wikipedia.org/wiki/Quantile">Wikipedia</a> article. For high cardinality calculations, using the estimated percentiles may be more performant.</p> <div class="section" id="avg"> <h3>Avg</h3> <p>Calculates the average of all values across the time span or across multiple time series. This function will perform linear interpolation across time series. It's useful for looking at gauge metrics. Note that even though the calculation will usually result in a float, if the data points are recorded as integers, an integer will be returned losing some precision.</p> </div> <div class="section" id="count"> <h3>Count</h3> <p>Returns the number of data points stored in the series or range. When used to aggregate multiple series, zeros will be substituted. It's best to use this when downsampling.</p> </div> <div class="section" id="dev"> <h3>Dev</h3> <p>Calculates the <a class="reference external" href="http://en.wikipedia.org/wiki/Standard_deviation">standard deviation</a> across a span or time series. This function will perform linear interpolation across time series. It's useful for looking at gauge metrics. Note that even though the calculation will usually result in a float, if the data points are recorded as integers, an integer will be returned losing some precision.</p> </div> <div class="section" id="estimated-percentiles"> <h3>Estimated Percentiles</h3> <p>Calculates various percentiles using a choice of algorithms. These are useful for series with many data points as some data may be kicked out of the calculation. When used to aggregate multiple series, the function will perform linear interpolation. See <a class="reference external" href="http://en.wikipedia.org/wiki/Quantile">Wikipedia</a> for details. Implementation is through the <a class="reference external" href="http://commons.apache.org/proper/commons-math/">Apache Math library.</a></p> </div> <div class="section" id="first-last"> <h3>First &amp; Last</h3> <p>(2.3) These aggregators will return the first or the last data point in the downsampling interval. E.g. if a downsample bucket consists of the series <code class="docutils literal"><span class="pre">2,</span> <span class="pre">6,</span> <span class="pre">1,</span> <span class="pre">7</span></code> then the <code class="docutils literal"><span class="pre">first</span></code> aggregator will return <code class="docutils literal"><span class="pre">1</span></code> and <code class="docutils literal"><span class="pre">last</span></code> will return <code class="docutils literal"><span class="pre">7</span></code>. Note that this aggregator is only useful for downsamplers. When used as a group-by aggregator, the results are indeterminate as the ordering of time series retrieved from storage and held in memory is not consistent from TSD to TSD or execution to execution.</p> </div> <div class="section" id="max"> <h3>Max</h3> <p>The inverse of <code class="docutils literal"><span class="pre">min</span></code>, it returns the largest data point from all of the time series or within a time span. This function will perform linear interpolation across time series. It's useful for looking at the upper bounds of gauge metrics.</p> </div> <div class="section" id="mimmin"> <h3>MimMin</h3> <p>The "maximum if missing minimum" function returns only the smallest data point from all of the time series or within the time span. This function will <em>not</em> perform interpolation, instead it will return the maximum value for the type of data specified if the value is missing. This will return the Long.MaxValue for integer points or Double.MaxValue for floating point values. See <a class="reference external" href="http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">Primitive Data Types</a> for details. It's useful for looking at the lower bounds of gauge metrics.</p> </div> <div class="section" id="mimmax"> <h3>MimMax</h3> <p>The "minimum if missing maximum" function returns only the largest data point from all of the time series or within the time span. This function will <em>not</em> perform interpolation, instead it will return the minimum value for the type of data specified if the value is missing. This will return the Long.MinValue for integer points or Double.MinValue for floating point values. See <a class="reference external" href="http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">Primitive Data Types</a> for details. It's useful for looking at the upper bounds of gauge metrics.</p> </div> <div class="section" id="min"> <h3>Min</h3> <p>Returns only the smallest data point from all of the time series or within the time span. This function will perform linear interpolation across time series. It's useful for looking at the lower bounds of gauge metrics.</p> </div> <div class="section" id="none"> <h3>None</h3> <p>(2.3) Skips group by aggregation. This aggregator is useful for fetching the <em>raw</em> data from storage as it will return a result set for every time series matching the filters. Note that the query will throw an exception if used with a downsampler.</p> </div> <div class="section" id="percentiles"> <h3>Percentiles</h3> <p>Calculates various percentiles. When used to aggregate multiple series, the function will perform linear interpolation. Implementation is through the <a class="reference external" href="http://commons.apache.org/proper/commons-math/">Apache Math library.</a></p> </div> <div class="section" id="sum"> <h3>Sum</h3> <p>Calculates the sum of all data points from all of the time series or within the time span if down sampling. This is the default aggregation function for the GUI as it's often the most useful when combining multiple time series such as gauges or counters. It performs linear interpolation when data points fail to line up. If you have a distinct series of values that you want to sum and you do not need interpolation, look at <code class="docutils literal"><span class="pre">zimsum</span></code></p> </div> <div class="section" id="zimsum"> <h3>ZimSum</h3> <p>Calculates the sum of all data points at the specified timestamp from all of the time series or within the time span. This function does <em>not</em> perform interpolation, instead it substitutes a <code class="docutils literal"><span class="pre">0</span></code> for missing data points. This can be useful when working with discrete values.</p> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>
    <a href="http://opentsdb.net/docs/build/html/user_guide/query/aggregators.html" class="_attribution-link">http://opentsdb.net/docs/build/html/user_guide/query/aggregators.html</a>
  </p>
</div>
