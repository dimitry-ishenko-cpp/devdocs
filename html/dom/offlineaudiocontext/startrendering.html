<header><h1>OfflineAudioContext: startRendering() method</h1>
<details class="baseline-indicator high"><summary><div class="status-title">Baseline <span class="not-bold">Widely available</span>
</div>

</summary><div class="extra">
<p>This feature is well established and works across many devices and browser versions. It’s been available across browsers since April 2021.</p>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Glossary/Baseline/Compatibility" data-glean="baseline_link_learn_more" target="_blank" class="learn-more">Learn more</a></li>
<li><a href="#browser_compatibility" data-glean="baseline_link_bcd_table">See full compatibility</a></li>
<li><a href="https://survey.alchemer.com/s3/7634825/MDN-baseline-feedback?page=%2Fen-US%2Fdocs%2FWeb%2FAPI%2FOfflineAudioContext%2FstartRendering&amp;level=high" data-glean="baseline_link_feedback" class="feedback-link" target="_blank" rel="noreferrer">Report feedback</a></li>
</ul>
</div></details></header><div class="section-content">
<p>The <code>startRendering()</code> method of the <a href="../offlineaudiocontext.html"><code>OfflineAudioContext</code></a> Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes.</p> <p>The <a href="complete_event.html"><code>complete</code></a> event (of type <a href="../offlineaudiocompletionevent.html"><code>OfflineAudioCompletionEvent</code></a>) is raised when the rendering is finished, containing the resulting <a href="../audiobuffer.html"><code>AudioBuffer</code></a> in its <code>renderedBuffer</code> property.</p> <p>Browsers currently support two versions of the <code>startRendering()</code> method — an older event-based version and a newer promise-based version. The former will eventually be removed, but currently both mechanisms are provided for legacy reasons.</p>
</div>
<h2 id="syntax">Syntax</h2>
<div class="section-content"><div class="code-example"><pre data-language="js">startRendering()
</pre></div></div>
<h3 id="parameters">Parameters</h3>
<div class="section-content"><p>None.</p></div>
<h3 id="return_value">Return value</h3>
<div class="section-content"><p>A <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise"><code>Promise</code></a> that fulfills with an <a href="../audiobuffer.html"><code>AudioBuffer</code></a>.</p></div>
<h2 id="examples">Examples</h2>

<h3 id="playing_audio_with_an_offline_audio_context">Playing audio with an offline audio context</h3>
<div class="section-content">
<p>In this example, we declare both an <a href="../audiocontext.html"><code>AudioContext</code></a> and an <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an audio track <a href="../window/fetch.html"><code>fetch()</code></a>, then the <code>OfflineAudioContext</code> to render the audio into an <a href="../audiobuffersourcenode.html"><code>AudioBufferSourceNode</code></a> and play the track through. After the offline audio graph is set up, we render it to an <a href="../audiobuffer.html"><code>AudioBuffer</code></a> using <code>OfflineAudioContext.startRendering()</code>.</p> <p>When the <code>startRendering()</code> promise resolves, rendering has completed and the output <code>AudioBuffer</code> is returned out of the promise.</p> <p>At this point we create another audio context, create an <a href="../audiobuffersourcenode.html"><code>AudioBufferSourceNode</code></a> inside it, and set its buffer to be equal to the promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio graph.</p> <div class="notecard note"> <p><strong>Note:</strong> You can <a href="https://mdn.github.io/webaudio-examples/offline-audio-context-promise/" target="_blank">run the full example live</a>, or <a href="https://github.com/mdn/webaudio-examples/tree/main/offline-audio-context-promise" target="_blank">view the source</a>.</p> </div> <div class="code-example"><pre data-language="js">// Define both online and offline audio contexts
let audioCtx; // Must be initialized after a user interaction
const offlineCtx = new OfflineAudioContext(2, 44100 * 40, 44100);

// Define constants for dom nodes
const play = document.querySelector("#play");

function getData() {
  // Fetch an audio track, decode it and stick it in a buffer.
  // Then we put the buffer into the source and can play it.
  fetch("viper.ogg")
    .then((response) =&gt; response.arrayBuffer())
    .then((downloadedBuffer) =&gt; audioCtx.decodeAudioData(downloadedBuffer))
    .then((decodedBuffer) =&gt; {
      console.log("File downloaded successfully.");
      const source = new AudioBufferSourceNode(offlineCtx, {
        buffer: decodedBuffer,
      });
      source.connect(offlineCtx.destination);
      return source.start();
    })
    .then(() =&gt; offlineCtx.startRendering())
    .then((renderedBuffer) =&gt; {
      console.log("Rendering completed successfully.");
      play.disabled = false;
      const song = new AudioBufferSourceNode(audioCtx, {
        buffer: renderedBuffer,
      });
      song.connect(audioCtx.destination);

      // Start the song
      song.start();
    })
    .catch((err) =&gt; {
      console.error(`Error encountered: ${err}`);
    });
}

// Activate the play button
play.onclick = () =&gt; {
  play.disabled = true;
  // We can initialize the context as the user clicked.
  audioCtx = new AudioContext();

  // Fetch the data and start the song
  getData();
};
</pre></div>
</div>
<h2 id="specifications">Specifications</h2>
<div class="_table"><table class="standard-table">
<thead><tr><th scope="col">Specification</th></tr></thead>
<tbody><tr><td><a href="https://webaudio.github.io/web-audio-api/#dom-offlineaudiocontext-startrendering">Web Audio API <br><small># dom-offlineaudiocontext-startrendering</small></a></td></tr></tbody>
</table></div>
<h2 id="browser_compatibility">Browser compatibility</h2>
<div class="_table"><table>
<thead>
<tr id="bct-browser-type">
<th></th>
<th colspan="5">Desktop</th>
<th colspan="6">Mobile</th>
</tr>
<tr id="bct-browsers">
<th></th>
<th>Chrome</th>
<th>Edge</th>
<th>Firefox</th>
<th>Opera</th>
<th>Safari</th>
<th>Chrome Android</th>
<th>Firefox for Android</th>
<th>Opera Android</th>
<th>Safari on IOS</th>
<th>Samsung Internet</th>
<th>WebView Android</th>
</tr>
</thead>
<tbody>
<tr>
<th><code>startRendering</code></th>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">12</td>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">15</td>
<td class="bc-supports-yes">7</td>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">14</td>
<td class="bc-supports-yes">7</td>
<td class="bc-supports-yes">1.5</td>
<td class="bc-supports-yes">4.4</td>
</tr>
<tr>
<th><code>returns_promise</code></th>
<td class="bc-supports-yes">42</td>
<td class="bc-supports-yes">≤18</td>
<td class="bc-supports-yes">37</td>
<td class="bc-supports-yes">29</td>
<td class="bc-supports-yes">14.1</td>
<td class="bc-supports-yes">42</td>
<td class="bc-supports-yes">37</td>
<td class="bc-supports-yes">29</td>
<td class="bc-supports-yes">14.5</td>
<td class="bc-supports-yes">4.0</td>
<td class="bc-supports-yes">42</td>
</tr>
</tbody>
</table></div>
<h2 id="see_also">See also</h2>
<div class="section-content"><ul> <li><a href="../web_audio_api/using_web_audio_api.html">Using the Web Audio API</a></li> </ul></div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2024 MDN contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/startRendering" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/startRendering</a>
  </p>
</div>
