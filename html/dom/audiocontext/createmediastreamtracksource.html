<header><h1>AudioContext: createMediaStreamTrackSource() method</h1></header><div class="section-content">
<p>The <code>createMediaStreamTrackSource()</code> method of the <a href="../audiocontext.html"><code>AudioContext</code></a> interface creates and returns a <a href="../mediastreamtrackaudiosourcenode.html"><code>MediaStreamTrackAudioSourceNode</code></a> which represents an audio source whose data comes from the specified <a href="../mediastreamtrack.html"><code>MediaStreamTrack</code></a>.</p> <p>This differs from <a href="createmediastreamsource.html"><code>createMediaStreamSource()</code></a>, which creates a <a href="../mediastreamaudiosourcenode.html"><code>MediaStreamAudioSourceNode</code></a> whose audio comes from the audio track in a specified <a href="../mediastream.html"><code>MediaStream</code></a> whose <a href="../mediastreamtrack/id.html"><code>id</code></a> is first, lexicographically (alphabetically).</p>
</div>
<h2 id="syntax">Syntax</h2>
<div class="section-content"><div class="code-example"><pre data-language="js">createMediaStreamTrackSource(track)
</pre></div></div>
<h3 id="parameters">Parameters</h3>
<div class="section-content"><dl> <dt id="track"><a href="#track"><code>track</code></a></dt> <dd> <p>The <a href="../mediastreamtrack.html"><code>MediaStreamTrack</code></a> to use as the source of all audio data for the new node.</p> </dd> </dl></div>
<h3 id="return_value">Return value</h3>
<div class="section-content"><p>A <a href="../mediastreamtrackaudiosourcenode.html"><code>MediaStreamTrackAudioSourceNode</code></a> object which acts as a source for audio data found in the specified audio track.</p></div>
<h2 id="examples">Examples</h2>
<div class="section-content">
<p>In this example, <a href="../mediadevices/getusermedia.html"><code>getUserMedia()</code></a> is used to request access to the user's microphone. Once that access is attained, an audio context is established and a <a href="../mediastreamtrackaudiosourcenode.html"><code>MediaStreamTrackAudioSourceNode</code></a> is created using <code>createMediaStreamTrackSource()</code>, taking its audio from the first audio track in the stream returned by <code>getUserMedia()</code>.</p> <p>Then a <a href="../biquadfilternode.html"><code>BiquadFilterNode</code></a> is created using <a href="../baseaudiocontext/createbiquadfilter.html"><code>createBiquadFilter()</code></a>, and it's configured as desired to perform a lowshelf filter on the audio coming from the source. The output from the microphone is then routed into the new biquad filter, and the filter's output is in turn routed to the audio context's <a href="../baseaudiocontext/destination.html"><code>destination</code></a>.</p> <div class="code-example"><pre data-language="js">navigator.mediaDevices
  .getUserMedia({ audio: true, video: false })
  .then((stream) =&gt; {
    audio.srcObject = stream;
    audio.onloadedmetadata = (e) =&gt; {
      audio.play();
      audio.muted = true;
    };

    const audioCtx = new AudioContext();
    const audioTracks = stream.getAudioTracks();
    const source = audioCtx.createMediaStreamTrackSource(audioTracks[0]);

    const biquadFilter = audioCtx.createBiquadFilter();
    biquadFilter.type = "lowshelf";
    biquadFilter.frequency.value = 3000;
    biquadFilter.gain.value = 20;

    source.connect(biquadFilter);
    biquadFilter.connect(audioCtx.destination);
  })
  .catch((err) =&gt; {
    // Handle getUserMedia() error
  });
</pre></div>
</div>
<h2 id="specifications">Specifications</h2>
<div class="_table"><table class="standard-table">
<thead><tr><th scope="col">Specification</th></tr></thead>
<tbody><tr><td><a href="https://webaudio.github.io/web-audio-api/#dom-audiocontext-createmediastreamtracksource">Web Audio API <br><small># dom-audiocontext-createmediastreamtracksource</small></a></td></tr></tbody>
</table></div>
<h2 id="browser_compatibility">Browser compatibility</h2>
<div class="_table"><table>
<thead>
<tr id="bct-browser-type">
<th></th>
<th colspan="5">Desktop</th>
<th colspan="6">Mobile</th>
</tr>
<tr id="bct-browsers">
<th></th>
<th>Chrome</th>
<th>Edge</th>
<th>Firefox</th>
<th>Opera</th>
<th>Safari</th>
<th>Chrome Android</th>
<th>Firefox for Android</th>
<th>Opera Android</th>
<th>Safari on IOS</th>
<th>Samsung Internet</th>
<th>WebView Android</th>
</tr>
</thead>
<tbody><tr>
<th><code>createMediaStreamTrackSource</code></th>
<td class="bc-supports-no">No</td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-yes"><details><summary>68</summary>Firefox 68 implements the updated standard's definition of the "first" audio track; now the first track is the one whose ID comes first lexicographically.</details></td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-yes"><details><summary>68</summary>Firefox for Android 68 implements the updated standard's definition of the "first" audio track; now the first track is the one whose ID comes first lexicographically.</details></td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-no">No</td>
<td class="bc-supports-no">No</td>
</tr></tbody>
</table></div>
<h2 id="see_also">See also</h2>
<div class="section-content"><ul> <li>Web Audio API</li> <li><a href="../web_audio_api/using_web_audio_api.html">Using the Web Audio API</a></li> <li><a href="../mediastreamtrackaudiosourcenode.html"><code>MediaStreamTrackAudioSourceNode</code></a></li> </ul></div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2024 MDN contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource</a>
  </p>
</div>
