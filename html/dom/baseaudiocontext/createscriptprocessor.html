<header><h1>BaseAudioContext: createScriptProcessor() method</h1></header><div class="section-content">
<div class="notecard deprecated"><p><strong>Deprecated:</strong> This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the <a href="#browser_compatibility">compatibility table</a> at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.</p></div> <p>The <code>createScriptProcessor()</code> method of the <a href="../baseaudiocontext.html"><code>BaseAudioContext</code></a> interface creates a <a href="../scriptprocessornode.html"><code>ScriptProcessorNode</code></a> used for direct audio processing.</p> <div class="notecard note"> <p><strong>Note:</strong> This feature was replaced by <a href="../audioworklet.html">AudioWorklets</a> and the <a href="../audioworkletnode.html"><code>AudioWorkletNode</code></a> interface.</p> </div>
</div>
<h2 id="syntax">Syntax</h2>
<div class="section-content"><div class="code-example"><pre data-language="js">createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels)
</pre></div></div>
<h3 id="parameters">Parameters</h3>
<div class="section-content">
<dl> <dt id="buffersize"><a href="#buffersize"><code>bufferSize</code></a></dt> <dd> <p>The buffer size in units of sample-frames. If specified, the bufferSize must be one of the following values: 256, 512, 1024, 2048, 4096, 8192, 16384. If it's not passed in, or if the value is 0, then the implementation will choose the best buffer size for the given environment, which will be a constant power of 2 throughout the lifetime of the node.</p> <p>This value controls how frequently the <code>audioprocess</code> event is dispatched and how many sample-frames need to be processed each call. Lower values for <code>bufferSize</code> will result in a lower (better) latency. Higher values will be necessary to avoid audio breakup and glitches. It is recommended for authors to not specify this buffer size and allow the implementation to pick a good buffer size to balance between latency and audio quality.</p> </dd> <dt id="numberofinputchannels"><a href="#numberofinputchannels"><code>numberOfInputChannels</code></a></dt> <dd> <p>Integer specifying the number of channels for this node's input, defaults to 2. Values of up to 32 are supported.</p> </dd> <dt id="numberofoutputchannels"><a href="#numberofoutputchannels"><code>numberOfOutputChannels</code></a></dt> <dd> <p>Integer specifying the number of channels for this node's output, defaults to 2. Values of up to 32 are supported.</p> </dd> </dl> <div class="notecard warning"> <p><strong>Warning:</strong> WebKit currently (version 31) requires that a valid <code>bufferSize</code> be passed when calling this method.</p> </div> <div class="notecard note"> <p><strong>Note:</strong> It is invalid for both <code>numberOfInputChannels</code> and <code>numberOfOutputChannels</code> to be zero.</p> </div>
</div>
<h3 id="return_value">Return value</h3>
<div class="section-content"><p>A <a href="../scriptprocessornode.html"><code>ScriptProcessorNode</code></a>.</p></div>
<h2 id="examples">Examples</h2>

<h3 id="adding_white_noise_using_a_script_processor">Adding white noise using a script processor</h3>
<div class="section-content">
<p>The following example shows how to use a <code>ScriptProcessorNode</code> to take a track loaded via <a href="decodeaudiodata.html"><code>AudioContext.decodeAudioData()</code></a>, process it, adding a bit of white noise to each audio sample of the input track, and play it through the <a href="../audiodestinationnode.html"><code>AudioDestinationNode</code></a>.</p> <p>For each channel and each sample frame, the script node's <a href="../scriptprocessornode/audioprocess_event.html"><code>audioprocess</code></a> event handler uses the associated <code>audioProcessingEvent</code> to loop through each channel of the input buffer, and each sample in each channel, and add a small amount of white noise, before setting that result to be the output sample in each case.</p> <div class="notecard note"> <p><strong>Note:</strong> You can <a href="https://mdn.github.io/webaudio-examples/script-processor-node/" target="_blank">run the full example live</a>, or <a href="https://github.com/mdn/webaudio-examples/tree/main/script-processor-node" target="_blank">view the source</a>.</p> </div> <div class="code-example"><pre data-language="js">const myScript = document.querySelector("script");
const myPre = document.querySelector("pre");
const playButton = document.querySelector("button");

// Create AudioContext and buffer source
let audioCtx;

async function init() {
  audioCtx = new AudioContext();
  const source = audioCtx.createBufferSource();

  // Create a ScriptProcessorNode with a bufferSize of 4096 and
  // a single input and output channel
  const scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);

  // Load in an audio track using fetch() and decodeAudioData()
  try {
    const response = await fetch("viper.ogg");
    const arrayBuffer = await response.arrayBuffer();
    source.buffer = await audioCtx.decodeAudioData(arrayBuffer);
  } catch (err) {
    console.error(
      `Unable to fetch the audio file: ${name} Error: ${err.message}`,
    );
  }

  // Give the node a function to process audio events
  scriptNode.addEventListener("audioprocess", (audioProcessingEvent) =&gt; {
    // The input buffer is the song we loaded earlier
    let inputBuffer = audioProcessingEvent.inputBuffer;

    // The output buffer contains the samples that will be modified and played
    let outputBuffer = audioProcessingEvent.outputBuffer;

    // Loop through the output channels (in this case there is only one)
    for (let channel = 0; channel &lt; outputBuffer.numberOfChannels; channel++) {
      let inputData = inputBuffer.getChannelData(channel);
      let outputData = outputBuffer.getChannelData(channel);

      // Loop through the 4096 samples
      for (let sample = 0; sample &lt; inputBuffer.length; sample++) {
        // make output equal to the same as the input
        outputData[sample] = inputData[sample];

        // add noise to each output sample
        outputData[sample] += (Math.random() * 2 - 1) * 0.1;
      }
    }
  });

  source.connect(scriptNode);
  scriptNode.connect(audioCtx.destination);
  source.start();

  // When the buffer source stops playing, disconnect everything
  source.addEventListener("ended", () =&gt; {
    source.disconnect(scriptNode);
    scriptNode.disconnect(audioCtx.destination);
  });
}

// wire up play button
playButton.addEventListener("click", () =&gt; {
  if (!audioCtx) {
    init();
  }
});
</pre></div>
</div>
<h2 id="specifications">Specifications</h2>
<div class="_table"><table class="standard-table">
<thead><tr><th scope="col">Specification</th></tr></thead>
<tbody><tr><td><a href="https://webaudio.github.io/web-audio-api/#dom-baseaudiocontext-createscriptprocessor">Web Audio API <br><small># dom-baseaudiocontext-createscriptprocessor</small></a></td></tr></tbody>
</table></div>
<h2 id="browser_compatibility">Browser compatibility</h2>
<div class="_table"><table>
<thead>
<tr id="bct-browser-type">
<th></th>
<th colspan="5">Desktop</th>
<th colspan="6">Mobile</th>
</tr>
<tr id="bct-browsers">
<th></th>
<th>Chrome</th>
<th>Edge</th>
<th>Firefox</th>
<th>Opera</th>
<th>Safari</th>
<th>Chrome Android</th>
<th>Firefox for Android</th>
<th>Opera Android</th>
<th>Safari on IOS</th>
<th>Samsung Internet</th>
<th>WebView Android</th>
</tr>
</thead>
<tbody><tr>
<th><code>createScriptProcessor</code></th>
<td class="bc-supports-yes">24</td>
<td class="bc-supports-yes">12</td>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">15</td>
<td class="bc-supports-yes">7</td>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">25</td>
<td class="bc-supports-yes">14</td>
<td class="bc-supports-yes">7</td>
<td class="bc-supports-yes">1.5</td>
<td class="bc-supports-yes">â‰¤37</td>
</tr></tbody>
</table></div>
<h2 id="see_also">See also</h2>
<div class="section-content"><ul> <li><a href="../web_audio_api/using_web_audio_api.html">Using the Web Audio API</a></li> </ul></div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2024 MDN contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor</a>
  </p>
</div>
