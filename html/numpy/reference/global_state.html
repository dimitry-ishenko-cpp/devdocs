<section id="global-state"> <h1 id="id1">Global state</h1> <p>NumPy has a few import-time, compile-time, or runtime options which change the global behaviour. Most of these are related to performance or for debugging purposes and will not be interesting to the vast majority of users.</p> <section id="performance-related-options"> <h2>Performance-related options</h2> <section id="number-of-threads-used-for-linear-algebra"> <h3>Number of threads used for linear algebra</h3> <p>NumPy itself is normally intentionally limited to a single thread during function calls, however it does support multiple Python threads running at the same time. Note that for performant linear algebra NumPy uses a BLAS backend such as OpenBLAS or MKL, which may use multiple threads that may be controlled by environment variables such as <code>OMP_NUM_THREADS</code> depending on what is used. One way to control the number of threads is the package <a class="reference external" href="https://pypi.org/project/threadpoolctl/">threadpoolctl</a></p> </section> <section id="madvise-hugepage-on-linux"> <h3>madvise hugepage on Linux</h3> <p>When working with very large arrays on modern Linux kernels, you can experience a significant speedup when <a class="reference external" href="https://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html">transparent hugepage</a> is used. The current system policy for transparent hugepages can be seen by:</p> <pre data-language="python">cat /sys/kernel/mm/transparent_hugepage/enabled
</pre> <p>When set to <code>madvise</code> NumPy will typically use hugepages for a performance boost. This behaviour can be modified by setting the environment variable:</p> <pre data-language="python">NUMPY_MADVISE_HUGEPAGE=0
</pre> <p>or setting it to <code>1</code> to always enable it. When not set, the default is to use madvise on Kernels 4.6 and newer. These kernels presumably experience a large speedup with hugepage support. This flag is checked at import time.</p> </section> <section id="simd-feature-selection"> <h3>SIMD feature selection</h3> <p>Setting <code>NPY_DISABLE_CPU_FEATURES</code> will exclude simd features at runtime. See <a class="reference internal" href="simd/build-options.html#runtime-simd-dispatch"><span class="std std-ref">Runtime dispatch</span></a>.</p> </section> </section> <section id="debugging-related-options"> <h2>Debugging-related options</h2> <section id="warn-if-no-memory-allocation-policy-when-deallocating-data"> <h3>Warn if no memory allocation policy when deallocating data</h3> <p>Some users might pass ownership of the data pointer to the <code>ndarray</code> by setting the <code>OWNDATA</code> flag. If they do this without setting (manually) a memory allocation policy, the default will be to call <code>free</code>. If <code>NUMPY_WARN_IF_NO_MEM_POLICY</code> is set to <code>"1"</code>, a <code>RuntimeWarning</code> will be emitted. A better alternative is to use a <code>PyCapsule</code> with a deallocator and set the <code>ndarray.base</code>.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 1.25.2: </span>This variable is only checked on the first import.</p> </div> </section> </section> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2024 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/2.0/reference/global_state.html" class="_attribution-link">https://numpy.org/doc/2.0/reference/global_state.html</a>
  </p>
</div>
