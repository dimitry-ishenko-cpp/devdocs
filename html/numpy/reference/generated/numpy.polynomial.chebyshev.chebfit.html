<h1>numpy.polynomial.chebyshev.chebfit</h1> <dl class="py function"> <dt class="sig sig-object py" id="numpy.polynomial.chebyshev.chebfit"> <span class="sig-prename descclassname">polynomial.chebyshev.</span><span class="sig-name descname">chebfit</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">deg</span></em>, <em class="sig-param"><span class="n">rcond</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">full</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">w</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/numpy/numpy/blob/v1.23.0/numpy/polynomial/chebyshev.py#L1547-L1671"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Least squares fit of Chebyshev series to data.</p> <p>Return the coefficients of a Chebyshev series of degree <code>deg</code> that is the least squares fit to the data values <code>y</code> given at points <code>x</code>. If <code>y</code> is 1-D the returned coefficients will also be 1-D. If <code>y</code> is 2-D multiple fits are done, one for each column of <code>y</code>, and the resulting coefficients are stored in the corresponding columns of a 2-D return. The fitted polynomial(s) are in the form</p> <div class="math notranslate nohighlight"> \[p(x) = c_0 + c_1 * T_1(x) + ... + c_n * T_n(x),\]</div> <p>where <code>n</code> is <code>deg</code>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<strong>x</strong><span class="classifier">array_like, shape (M,)</span>
</dt>
<dd>
<p>x-coordinates of the M sample points <code>(x[i], y[i])</code>.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array_like, shape (M,) or (M, K)</span>
</dt>
<dd>
<p>y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.</p> </dd> <dt>
<strong>deg</strong><span class="classifier">int or 1-D array_like</span>
</dt>
<dd>
<p>Degree(s) of the fitting polynomials. If <code>deg</code> is a single integer, all terms up to and including the <code>deg</code>’th term are included in the fit. For NumPy versions &gt;= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.</p> </dd> <dt>
<strong>rcond</strong><span class="classifier">float, optional</span>
</dt>
<dd>
<p>Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.</p> </dd> <dt>
<strong>full</strong><span class="classifier">bool, optional</span>
</dt>
<dd>
<p>Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.</p> </dd> <dt>
<strong>w</strong><span class="classifier">array_like, shape (<code>M</code>,), optional</span>
</dt>
<dd>
<p>Weights. If not None, the weight <code>w[i]</code> applies to the unsquared residual <code>y[i] - y_hat[i]</code> at <code>x[i]</code>. Ideally the weights are chosen so that the errors of the products <code>w[i]*y[i]</code> all have the same variance. When using inverse-variance weighting, use <code>w[i] = 1/sigma(y[i])</code>. The default value is None.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.5.0.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl> <dt>
<strong>coef</strong><span class="classifier">ndarray, shape (M,) or (M, K)</span>
</dt>
<dd>
<p>Chebyshev coefficients ordered from low to high. If <code>y</code> was 2-D, the coefficients for the data in column k of <code>y</code> are in column <code>k</code>.</p> </dd> <dt>
<strong>[residuals, rank, singular_values, rcond]</strong><span class="classifier">list</span>
</dt>
<dd>
<p>These values are only returned if <code>full == True</code></p> <ul class="simple"> <li>residuals – sum of squared residuals of the least squares fit</li> <li>rank – the numerical rank of the scaled Vandermonde matrix</li> <li>singular_values – singular values of the scaled Vandermonde matrix</li> <li>rcond – value of <code>rcond</code>.</li> </ul> <p>For more details, see <a class="reference internal" href="numpy.linalg.lstsq.html#numpy.linalg.lstsq" title="numpy.linalg.lstsq"><code>numpy.linalg.lstsq</code></a>.</p> </dd> </dl> </dd> <dt class="field-odd">Warns</dt> <dd class="field-odd">
<dl> <dt>RankWarning</dt>
<dd>
<p>The rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if <code>full == False</code>. The warnings can be turned off by</p> <pre data-language="python">&gt;&gt;&gt; import warnings
&gt;&gt;&gt; warnings.simplefilter('ignore', np.RankWarning)
</pre> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="numpy.polynomial.polynomial.polyfit.html#numpy.polynomial.polynomial.polyfit" title="numpy.polynomial.polynomial.polyfit"><code>numpy.polynomial.polynomial.polyfit</code></a></dt>
 <dt><a class="reference internal" href="numpy.polynomial.legendre.legfit.html#numpy.polynomial.legendre.legfit" title="numpy.polynomial.legendre.legfit"><code>numpy.polynomial.legendre.legfit</code></a></dt>
 <dt><a class="reference internal" href="numpy.polynomial.laguerre.lagfit.html#numpy.polynomial.laguerre.lagfit" title="numpy.polynomial.laguerre.lagfit"><code>numpy.polynomial.laguerre.lagfit</code></a></dt>
 <dt><a class="reference internal" href="numpy.polynomial.hermite.hermfit.html#numpy.polynomial.hermite.hermfit" title="numpy.polynomial.hermite.hermfit"><code>numpy.polynomial.hermite.hermfit</code></a></dt>
 <dt><a class="reference internal" href="numpy.polynomial.hermite_e.hermefit.html#numpy.polynomial.hermite_e.hermefit" title="numpy.polynomial.hermite_e.hermefit"><code>numpy.polynomial.hermite_e.hermefit</code></a></dt>
 <dt><a class="reference internal" href="numpy.polynomial.chebyshev.chebval.html#numpy.polynomial.chebyshev.chebval" title="numpy.polynomial.chebyshev.chebval"><code>chebval</code></a></dt>
<dd>
<p>Evaluates a Chebyshev series.</p> </dd> <dt><a class="reference internal" href="numpy.polynomial.chebyshev.chebvander.html#numpy.polynomial.chebyshev.chebvander" title="numpy.polynomial.chebyshev.chebvander"><code>chebvander</code></a></dt>
<dd>
<p>Vandermonde matrix of Chebyshev series.</p> </dd> <dt><a class="reference internal" href="numpy.polynomial.chebyshev.chebweight.html#numpy.polynomial.chebyshev.chebweight" title="numpy.polynomial.chebyshev.chebweight"><code>chebweight</code></a></dt>
<dd>
<p>Chebyshev weight function.</p> </dd> <dt><a class="reference internal" href="numpy.linalg.lstsq.html#numpy.linalg.lstsq" title="numpy.linalg.lstsq"><code>numpy.linalg.lstsq</code></a></dt>
<dd>
<p>Computes a least-squares fit from the matrix.</p> </dd> <dt><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.UnivariateSpline.html#scipy.interpolate.UnivariateSpline" title="(in SciPy v1.8.1)"><code>scipy.interpolate.UnivariateSpline</code></a></dt>
<dd>
<p>Computes spline fits.</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>The solution is the coefficients of the Chebyshev series <code>p</code> that minimizes the sum of the weighted squared errors</p> <div class="math notranslate nohighlight"> \[E = \sum_j w_j^2 * |y_j - p(x_j)|^2,\]</div> <p>where <span class="math notranslate nohighlight">\(w_j\)</span> are the weights. This problem is solved by setting up as the (typically) overdetermined matrix equation</p> <div class="math notranslate nohighlight"> \[V(x) * c = w * y,\]</div> <p>where <code>V</code> is the weighted pseudo Vandermonde matrix of <code>x</code>, <code>c</code> are the coefficients to be solved for, <code>w</code> are the weights, and <code>y</code> are the observed values. This equation is then solved using the singular value decomposition of <code>V</code>.</p> <p>If some of the singular values of <code>V</code> are so small that they are neglected, then a <a class="reference internal" href="numpy.rankwarning.html#numpy.RankWarning" title="numpy.RankWarning"><code>RankWarning</code></a> will be issued. This means that the coefficient values may be poorly determined. Using a lower order fit will usually get rid of the warning. The <code>rcond</code> parameter can also be set to a value smaller than its default, but the resulting fit may be spurious and have large contributions from roundoff error.</p> <p>Fits using Chebyshev series are usually better conditioned than fits using power series, but much can depend on the distribution of the sample points and the smoothness of the data. If the quality of the fit is inadequate splines may be a good alternative.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r0f3b6a011c4f-1"><span class="brackets">1</span></dt> <dd>
<p>Wikipedia, “Curve fitting”, <a class="reference external" href="https://en.wikipedia.org/wiki/Curve_fitting">https://en.wikipedia.org/wiki/Curve_fitting</a></p> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2022 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/1.23/reference/generated/numpy.polynomial.chebyshev.chebfit.html" class="_attribution-link">https://numpy.org/doc/1.23/reference/generated/numpy.polynomial.chebyshev.chebfit.html</a>
  </p>
</div>
