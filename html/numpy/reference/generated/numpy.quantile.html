<section id="numpy-quantile"> <h1>numpy.quantile</h1> <dl class="py function"> <dt class="sig sig-object py" id="numpy.quantile"> <span class="sig-prename descclassname">numpy.</span><span class="sig-name descname">quantile</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">out</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">overwrite_input</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">interpolation</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/numpy/numpy/blob/v2.0.0/numpy/lib/_function_base_impl.py#L4297-L4605"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the q-th quantile of the data along the specified axis.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.15.0.</span></p> </div> <dl class="field-list"> <dt class="field-odd">Parameters<span class="colon">:</span>
</dt> <dd class="field-odd">
<dl> <dt>
<strong>a</strong><span class="classifier">array_like of real numbers</span>
</dt>
<dd>
<p>Input array or object that can be converted to an array.</p> </dd> <dt>
<strong>q</strong><span class="classifier">array_like of float</span>
</dt>
<dd>
<p>Probability or sequence of probabilities for the quantiles to compute. Values must be between 0 and 1 inclusive.</p> </dd> <dt>
<strong>axis</strong><span class="classifier">{int, tuple of int, None}, optional</span>
</dt>
<dd>
<p>Axis or axes along which the quantiles are computed. The default is to compute the quantile(s) along a flattened version of the array.</p> </dd> <dt>
<strong>out</strong><span class="classifier">ndarray, optional</span>
</dt>
<dd>
<p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output, but the type (of the output) will be cast if necessary.</p> </dd> <dt>
<strong>overwrite_input</strong><span class="classifier">bool, optional</span>
</dt>
<dd>
<p>If True, then allow the input array <code>a</code> to be modified by intermediate calculations, to save memory. In this case, the contents of the input <code>a</code> after this function completes is undefined.</p> </dd> <dt>
<strong>method</strong><span class="classifier">str, optional</span>
</dt>
<dd>
<p>This parameter specifies the method to use for estimating the quantile. There are many different methods, some unique to NumPy. See the notes for explanation. The options sorted by their R type as summarized in the H&amp;F paper <a class="reference internal" href="#re01cd3f3acfe-1" id="id1">[1]</a> are:</p> <ol class="arabic simple"> <li>‘inverted_cdf’</li> <li>‘averaged_inverted_cdf’</li> <li>‘closest_observation’</li> <li>‘interpolated_inverted_cdf’</li> <li>‘hazen’</li> <li>‘weibull’</li> <li>‘linear’ (default)</li> <li>‘median_unbiased’</li> <li>‘normal_unbiased’</li> </ol> <p>The first three methods are discontinuous. NumPy further defines the following discontinuous variations of the default ‘linear’ (7.) option:</p> <ul class="simple"> <li>‘lower’</li> <li>‘higher’,</li> <li>‘midpoint’</li> <li>‘nearest’</li> </ul> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 1.22.0: </span>This argument was previously called “interpolation” and only offered the “linear” default and last four options.</p> </div> </dd> <dt>
<strong>keepdims</strong><span class="classifier">bool, optional</span>
</dt>
<dd>
<p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array <code>a</code>.</p> </dd> <dt>
<strong>weights</strong><span class="classifier">array_like, optional</span>
</dt>
<dd>
<p>An array of weights associated with the values in <code>a</code>. Each value in <code>a</code> contributes to the quantile according to its associated weight. The weights array can either be 1-D (in which case its length must be the size of <code>a</code> along the given axis) or of the same shape as <code>a</code>. If <code>weights=None</code>, then all data in <code>a</code> are assumed to have a weight equal to one. Only <code>method=”inverted_cdf”</code> supports weights. See the notes for more details.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 2.0.0.</span></p> </div> </dd> <dt>
<strong>interpolation</strong><span class="classifier">str, optional</span>
</dt>
<dd>
<p>Deprecated name for the method keyword argument.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 1.22.0.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Returns<span class="colon">:</span>
</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>quantile</strong><span class="classifier">scalar or ndarray</span>
</dt>
<dd>
<p>If <code>q</code> is a single probability and <code>axis=None</code>, then the result is a scalar. If multiple probability levels are given, first axis of the result corresponds to the quantiles. The other axes are the axes that remain after the reduction of <code>a</code>. If the input contains integers or floats smaller than <code>float64</code>, the output data-type is <code>float64</code>. Otherwise, the output data-type is the same as that of the input. If <code>out</code> is specified, that array is returned instead.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="numpy.mean.html#numpy.mean" title="numpy.mean"><code>mean</code></a></dt>
 <dt><a class="reference internal" href="numpy.percentile.html#numpy.percentile" title="numpy.percentile"><code>percentile</code></a></dt>
<dd>
<p>equivalent to quantile, but with q in the range [0, 100].</p> </dd> <dt><a class="reference internal" href="numpy.median.html#numpy.median" title="numpy.median"><code>median</code></a></dt>
<dd>
<p>equivalent to <code>quantile(..., 0.5)</code></p> </dd> <dt><a class="reference internal" href="numpy.nanquantile.html#numpy.nanquantile" title="numpy.nanquantile"><code>nanquantile</code></a></dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <p>In general, the quantile at probability level <span class="math notranslate nohighlight">\(q\)</span> of a cumulative distribution function <span class="math notranslate nohighlight">\(F(y)=P(Y \leq y)\)</span> with probability measure <span class="math notranslate nohighlight">\(P\)</span> is defined as any number <span class="math notranslate nohighlight">\(x\)</span> that fulfills the <em>coverage conditions</em></p> <div class="math notranslate nohighlight"> \[P(Y &lt; x) \leq q \quad\text{and}\quad P(Y \leq x) \geq q\]</div> <p>with random variable <span class="math notranslate nohighlight">\(Y\sim P\)</span>. Sample quantiles, the result of <code>quantile</code>, provide nonparametric estimation of the underlying population counterparts, represented by the unknown <span class="math notranslate nohighlight">\(F\)</span>, given a data vector <code>a</code> of length <code>n</code>.</p> <p>One type of estimators arises when one considers <span class="math notranslate nohighlight">\(F\)</span> as the empirical distribution function of the data, i.e. <span class="math notranslate nohighlight">\(F(y) = \frac{1}{n} \sum_i 1_{a_i \leq y}\)</span>. Then, different methods correspond to different choices of <span class="math notranslate nohighlight">\(x\)</span> that fulfill the above inequalities. Methods that follow this approach are <code>inverted_cdf</code> and <code>averaged_inverted_cdf</code>.</p> <p>A more general way to define sample quantile estimators is as follows. The empirical q-quantile of <code>a</code> is the <code>n * q</code>-th value of the way from the minimum to the maximum in a sorted copy of <code>a</code>. The values and distances of the two nearest neighbors as well as the <code>method</code> parameter will determine the quantile if the normalized ranking does not match the location of <code>n * q</code> exactly. This function is the same as the median if <code>q=0.5</code>, the same as the minimum if <code>q=0.0</code> and the same as the maximum if <code>q=1.0</code>.</p> <p>The optional <code>method</code> parameter specifies the method to use when the desired quantile lies between two indexes <code>i</code> and <code>j = i + 1</code>. In that case, we first determine <code>i + g</code>, a virtual index that lies between <code>i</code> and <code>j</code>, where <code>i</code> is the floor and <code>g</code> is the fractional part of the index. The final result is, then, an interpolation of <code>a[i]</code> and <code>a[j]</code> based on <code>g</code>. During the computation of <code>g</code>, <code>i</code> and <code>j</code> are modified using correction constants <code>alpha</code> and <code>beta</code> whose choices depend on the <code>method</code> used. Finally, note that since Python uses 0-based indexing, the code subtracts another 1 from the index internally.</p> <p>The following formula determines the virtual index <code>i + g</code>, the location of the quantile in the sorted sample:</p> <div class="math notranslate nohighlight"> \[i + g = q * ( n - alpha - beta + 1 ) + alpha\]</div> <p>The different methods then work as follows</p> <dl class="simple"> <dt>inverted_cdf:</dt>
<dd>
<p>method 1 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id2">[1]</a>. This method gives discontinuous results:</p> <ul class="simple"> <li>if g &gt; 0 ; then take j</li> <li>if g = 0 ; then take i</li> </ul> </dd> <dt>averaged_inverted_cdf:</dt>
<dd>
<p>method 2 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id3">[1]</a>. This method gives discontinuous results:</p> <ul class="simple"> <li>if g &gt; 0 ; then take j</li> <li>if g = 0 ; then average between bounds</li> </ul> </dd> <dt>closest_observation:</dt>
<dd>
<p>method 3 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id4">[1]</a>. This method gives discontinuous results:</p> <ul class="simple"> <li>if g &gt; 0 ; then take j</li> <li>if g = 0 and index is odd ; then take j</li> <li>if g = 0 and index is even ; then take i</li> </ul> </dd> <dt>interpolated_inverted_cdf:</dt>
<dd>
<p>method 4 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id5">[1]</a>. This method gives continuous results using:</p> <ul class="simple"> <li>alpha = 0</li> <li>beta = 1</li> </ul> </dd> <dt>hazen:</dt>
<dd>
<p>method 5 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id6">[1]</a>. This method gives continuous results using:</p> <ul class="simple"> <li>alpha = 1/2</li> <li>beta = 1/2</li> </ul> </dd> <dt>weibull:</dt>
<dd>
<p>method 6 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id7">[1]</a>. This method gives continuous results using:</p> <ul class="simple"> <li>alpha = 0</li> <li>beta = 0</li> </ul> </dd> <dt>linear:</dt>
<dd>
<p>method 7 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id8">[1]</a>. This method gives continuous results using:</p> <ul class="simple"> <li>alpha = 1</li> <li>beta = 1</li> </ul> </dd> <dt>median_unbiased:</dt>
<dd>
<p>method 8 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id9">[1]</a>. This method is probably the best method if the sample distribution function is unknown (see reference). This method gives continuous results using:</p> <ul class="simple"> <li>alpha = 1/3</li> <li>beta = 1/3</li> </ul> </dd> <dt>normal_unbiased:</dt>
<dd>
<p>method 9 of H&amp;F <a class="reference internal" href="#re01cd3f3acfe-1" id="id10">[1]</a>. This method is probably the best method if the sample distribution function is known to be normal. This method gives continuous results using:</p> <ul class="simple"> <li>alpha = 3/8</li> <li>beta = 3/8</li> </ul> </dd> <dt>lower:</dt>
<dd>
<p>NumPy method kept for backwards compatibility. Takes <code>i</code> as the interpolation point.</p> </dd> <dt>higher:</dt>
<dd>
<p>NumPy method kept for backwards compatibility. Takes <code>j</code> as the interpolation point.</p> </dd> <dt>nearest:</dt>
<dd>
<p>NumPy method kept for backwards compatibility. Takes <code>i</code> or <code>j</code>, whichever is nearest.</p> </dd> <dt>midpoint:</dt>
<dd>
<p>NumPy method kept for backwards compatibility. Uses <code>(i + j) / 2</code>.</p> </dd> </dl> <p><strong>Weighted quantiles:</strong> For weighted quantiles, the above coverage conditions still hold. The empirical cumulative distribution is simply replaced by its weighted version, i.e. <span class="math notranslate nohighlight">\(P(Y \leq t) = \frac{1}{\sum_i w_i} \sum_i w_i 1_{x_i \leq t}\)</span>. Only <code>method="inverted_cdf"</code> supports weights.</p> <h4 class="rubric">References</h4> <div role="list" class="citation-list"> <div class="citation" id="re01cd3f3acfe-1" role="doc-biblioentry"> <span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span> <span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>,<a role="doc-backlink" href="#id3">3</a>,<a role="doc-backlink" href="#id4">4</a>,<a role="doc-backlink" href="#id5">5</a>,<a role="doc-backlink" href="#id6">6</a>,<a role="doc-backlink" href="#id7">7</a>,<a role="doc-backlink" href="#id8">8</a>,<a role="doc-backlink" href="#id9">9</a>,<a role="doc-backlink" href="#id10">10</a>)</span> <p>R. J. Hyndman and Y. Fan, “Sample quantiles in statistical packages,” The American Statistician, 50(4), pp. 361-365, 1996</p> </div> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; a = np.array([[10, 7, 4], [3, 2, 1]])
&gt;&gt;&gt; a
array([[10,  7,  4],
       [ 3,  2,  1]])
&gt;&gt;&gt; np.quantile(a, 0.5)
3.5
&gt;&gt;&gt; np.quantile(a, 0.5, axis=0)
array([6.5, 4.5, 2.5])
&gt;&gt;&gt; np.quantile(a, 0.5, axis=1)
array([7.,  2.])
&gt;&gt;&gt; np.quantile(a, 0.5, axis=1, keepdims=True)
array([[7.],
       [2.]])
&gt;&gt;&gt; m = np.quantile(a, 0.5, axis=0)
&gt;&gt;&gt; out = np.zeros_like(m)
&gt;&gt;&gt; np.quantile(a, 0.5, axis=0, out=out)
array([6.5, 4.5, 2.5])
&gt;&gt;&gt; m
array([6.5, 4.5, 2.5])
&gt;&gt;&gt; b = a.copy()
&gt;&gt;&gt; np.quantile(b, 0.5, axis=1, overwrite_input=True)
array([7.,  2.])
&gt;&gt;&gt; assert not np.all(a == b)
</pre> <p>See also <a class="reference internal" href="numpy.percentile.html#numpy.percentile" title="numpy.percentile"><code>numpy.percentile</code></a> for a visualization of most methods.</p> </dd>
</dl> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2024 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/2.0/reference/generated/numpy.quantile.html" class="_attribution-link">https://numpy.org/doc/2.0/reference/generated/numpy.quantile.html</a>
  </p>
</div>
