<h1 id="module-feature">Module: feature</h1> <table class="longtable docutils align-default" id="module-skimage.feature">   <tr>
<td><p><a class="reference internal" href="#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code>skimage.feature.blob_dog</code></a>(image[, min_sigma, …])</p></td> <td><p>Finds blobs in the given grayscale image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.blob_doh" title="skimage.feature.blob_doh"><code>skimage.feature.blob_doh</code></a>(image[, min_sigma, …])</p></td> <td><p>Finds blobs in the given grayscale image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.blob_log" title="skimage.feature.blob_log"><code>skimage.feature.blob_log</code></a>(image[, min_sigma, …])</p></td> <td><p>Finds blobs in the given grayscale image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.canny" title="skimage.feature.canny"><code>skimage.feature.canny</code></a>(image[, sigma, …])</p></td> <td><p>Edge filter an image using the Canny algorithm.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_fast" title="skimage.feature.corner_fast"><code>skimage.feature.corner_fast</code></a>(image[, n, …])</p></td> <td><p>Extract FAST corners for a given image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_foerstner" title="skimage.feature.corner_foerstner"><code>skimage.feature.corner_foerstner</code></a>(image[, sigma])</p></td> <td><p>Compute Foerstner corner measure response image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_harris" title="skimage.feature.corner_harris"><code>skimage.feature.corner_harris</code></a>(image[, …])</p></td> <td><p>Compute Harris corner measure response image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_kitchen_rosenfeld" title="skimage.feature.corner_kitchen_rosenfeld"><code>skimage.feature.corner_kitchen_rosenfeld</code></a>(image)</p></td> <td><p>Compute Kitchen and Rosenfeld corner measure response image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_moravec" title="skimage.feature.corner_moravec"><code>skimage.feature.corner_moravec</code></a>(image[, …])</p></td> <td><p>Compute Moravec corner measure response image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_orientations" title="skimage.feature.corner_orientations"><code>skimage.feature.corner_orientations</code></a>(image, …)</p></td> <td><p>Compute the orientation of corners.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_peaks" title="skimage.feature.corner_peaks"><code>skimage.feature.corner_peaks</code></a>(image[, …])</p></td> <td><p>Find peaks in corner measure response image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_shi_tomasi" title="skimage.feature.corner_shi_tomasi"><code>skimage.feature.corner_shi_tomasi</code></a>(image[, sigma])</p></td> <td><p>Compute Shi-Tomasi (Kanade-Tomasi) corner measure response image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.corner_subpix" title="skimage.feature.corner_subpix"><code>skimage.feature.corner_subpix</code></a>(image, corners)</p></td> <td><p>Determine subpixel position of corners.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.daisy" title="skimage.feature.daisy"><code>skimage.feature.daisy</code></a>(image[, step, radius, …])</p></td> <td><p>Extract DAISY feature descriptors densely for the given image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.draw_haar_like_feature" title="skimage.feature.draw_haar_like_feature"><code>skimage.feature.draw_haar_like_feature</code></a>(…)</p></td> <td><p>Visualization of Haar-like features.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.draw_multiblock_lbp" title="skimage.feature.draw_multiblock_lbp"><code>skimage.feature.draw_multiblock_lbp</code></a>(image, …)</p></td> <td><p>Multi-block local binary pattern visualization.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.greycomatrix" title="skimage.feature.greycomatrix"><code>skimage.feature.greycomatrix</code></a>(image, …[, …])</p></td> <td><p>Calculate the grey-level co-occurrence matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.greycoprops" title="skimage.feature.greycoprops"><code>skimage.feature.greycoprops</code></a>(P[, prop])</p></td> <td><p>Calculate texture properties of a GLCM.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.haar_like_feature" title="skimage.feature.haar_like_feature"><code>skimage.feature.haar_like_feature</code></a>(int_image, …)</p></td> <td><p>Compute the Haar-like features for a region of interest (ROI) of an integral image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code>skimage.feature.haar_like_feature_coord</code></a>(…)</p></td> <td><p>Compute the coordinates of Haar-like features.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.hessian_matrix" title="skimage.feature.hessian_matrix"><code>skimage.feature.hessian_matrix</code></a>(image[, …])</p></td> <td><p>Compute Hessian matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.hessian_matrix_det" title="skimage.feature.hessian_matrix_det"><code>skimage.feature.hessian_matrix_det</code></a>(image[, …])</p></td> <td><p>Compute the approximate Hessian Determinant over an image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.hessian_matrix_eigvals" title="skimage.feature.hessian_matrix_eigvals"><code>skimage.feature.hessian_matrix_eigvals</code></a>(H_elems)</p></td> <td><p>Compute eigenvalues of Hessian matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.hog" title="skimage.feature.hog"><code>skimage.feature.hog</code></a>(image[, orientations, …])</p></td> <td><p>Extract Histogram of Oriented Gradients (HOG) for a given image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.local_binary_pattern" title="skimage.feature.local_binary_pattern"><code>skimage.feature.local_binary_pattern</code></a>(image, P, R)</p></td> <td><p>Gray scale and rotation invariant LBP (Local Binary Patterns).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.masked_register_translation" title="skimage.feature.masked_register_translation"><code>skimage.feature.masked_register_translation</code></a>(…)</p></td> <td><p><strong>Deprecated function</strong>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.match_descriptors" title="skimage.feature.match_descriptors"><code>skimage.feature.match_descriptors</code></a>(…[, …])</p></td> <td><p>Brute-force matching of descriptors.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.match_template" title="skimage.feature.match_template"><code>skimage.feature.match_template</code></a>(image, template)</p></td> <td><p>Match a template to a 2-D or 3-D image using normalized correlation.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.multiblock_lbp" title="skimage.feature.multiblock_lbp"><code>skimage.feature.multiblock_lbp</code></a>(int_image, r, …)</p></td> <td><p>Multi-block local binary pattern (MB-LBP).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.multiscale_basic_features" title="skimage.feature.multiscale_basic_features"><code>skimage.feature.multiscale_basic_features</code></a>(image)</p></td> <td><p>Local features for a single- or multi-channel nd image.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code>skimage.feature.peak_local_max</code></a>(image[, …])</p></td> <td><p>Find peaks in an image as coordinate list or boolean mask.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.plot_matches" title="skimage.feature.plot_matches"><code>skimage.feature.plot_matches</code></a>(ax, image1, …)</p></td> <td><p>Plot matched features.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.register_translation" title="skimage.feature.register_translation"><code>skimage.feature.register_translation</code></a>(…[, …])</p></td> <td><p><strong>Deprecated function</strong>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.shape_index" title="skimage.feature.shape_index"><code>skimage.feature.shape_index</code></a>(image[, sigma, …])</p></td> <td><p>Compute the shape index.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.structure_tensor" title="skimage.feature.structure_tensor"><code>skimage.feature.structure_tensor</code></a>(image[, …])</p></td> <td><p>Compute structure tensor using sum of squared differences.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.structure_tensor_eigenvalues" title="skimage.feature.structure_tensor_eigenvalues"><code>skimage.feature.structure_tensor_eigenvalues</code></a>(A_elems)</p></td> <td><p>Compute eigenvalues of structure tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.structure_tensor_eigvals" title="skimage.feature.structure_tensor_eigvals"><code>skimage.feature.structure_tensor_eigvals</code></a>(…)</p></td> <td><p>Compute eigenvalues of structure tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.BRIEF" title="skimage.feature.BRIEF"><code>skimage.feature.BRIEF</code></a>([descriptor_size, …])</p></td> <td><p>BRIEF binary descriptor extractor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.CENSURE" title="skimage.feature.CENSURE"><code>skimage.feature.CENSURE</code></a>([min_scale, …])</p></td> <td><p>CENSURE keypoint detector.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.Cascade" title="skimage.feature.Cascade"><code>skimage.feature.Cascade</code></a></p></td> <td><p>Class for cascade of classifiers that is used for object detection.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#skimage.feature.ORB" title="skimage.feature.ORB"><code>skimage.feature.ORB</code></a>([downscale, n_scales, …])</p></td> <td><p>Oriented FAST and rotated BRIEF feature detector and binary descriptor extractor.</p></td> </tr>  </table>  <h2 id="blob-dog">blob_dog</h2> <dl class="function"> <dt id="skimage.feature.blob_dog">
<code>skimage.feature.blob_dog(image, min_sigma=1, max_sigma=50, sigma_ratio=1.6, threshold=2.0, overlap=0.5, *, exclude_border=False)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/blob.py#L217-L375"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Finds blobs in the given grayscale image.</p> <p>Blobs are found using the Difference of Gaussian (DoG) method <a class="reference internal" href="#rf5218630e229-1" id="id1">[1]</a>. For each blob found, the method returns its coordinates and the standard deviation of the Gaussian kernel that detected the blob.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D or 3D ndarray</code> </dt>
<dd>
<p>Input grayscale image, blobs are assumed to be light on dark background (white on black).</p> </dd> <dt>
<code>min_sigmascalar or sequence of scalars, optional</code> </dt>
<dd>
<p>The minimum standard deviation for Gaussian kernel. Keep this low to detect smaller blobs. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.</p> </dd> <dt>
<code>max_sigmascalar or sequence of scalars, optional</code> </dt>
<dd>
<p>The maximum standard deviation for Gaussian kernel. Keep this high to detect larger blobs. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.</p> </dd> <dt>
<code>sigma_ratiofloat, optional</code> </dt>
<dd>
<p>The ratio between the standard deviation of Gaussian Kernels used for computing the Difference of Gaussians</p> </dd> <dt>
<code>thresholdfloat, optional.</code> </dt>
<dd>
<p>The absolute lower bound for scale space maxima. Local maxima smaller than thresh are ignored. Reduce this to detect blobs with less intensities.</p> </dd> <dt>
<code>overlapfloat, optional</code> </dt>
<dd>
<p>A value between 0 and 1. If the area of two blobs overlaps by a fraction greater than <code>threshold</code>, the smaller blob is eliminated.</p> </dd> <dt>
<code>exclude_bordertuple of ints, int, or False, optional</code> </dt>
<dd>
<p>If tuple of ints, the length of the tuple must match the input array’s dimensionality. Each element of the tuple will exclude peaks from within <code>exclude_border</code>-pixels of the border of the image along that dimension. If nonzero int, <code>exclude_border</code> excludes peaks from within <code>exclude_border</code>-pixels of the border of the image. If zero or False, peaks are identified regardless of their distance from the border.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>A(n, image.ndim + sigma) ndarray</code> </dt>
<dd>
<p>A 2d array with each row representing 2 coordinate values for a 2D image, and 3 coordinate values for a 3D image, plus the sigma(s) used. When a single sigma is passed, outputs are: <code>(r, c, sigma)</code> or <code>(p, r, c, sigma)</code> where <code>(r, c)</code> or <code>(p, r, c)</code> are coordinates of the blob and <code>sigma</code> is the standard deviation of the Gaussian kernel which detected the blob. When an anisotropic gaussian is used (sigmas per dimension), the detected sigma is returned for each dimension.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="skimage.filters.html#skimage.filters.difference_of_gaussians" title="skimage.filters.difference_of_gaussians"><code>skimage.filters.difference_of_gaussians</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <p>The radius of each blob is approximately <span class="math notranslate nohighlight">\(\sqrt{2}\sigma\)</span> for a 2-D image and <span class="math notranslate nohighlight">\(\sqrt{3}\sigma\)</span> for a 3-D image.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rf5218630e229-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach">https://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data, feature
&gt;&gt;&gt; feature.blob_dog(data.coins(), threshold=.5, max_sigma=40)
array([[120.      , 272.      ,  16.777216],
       [193.      , 213.      ,  16.777216],
       [263.      , 245.      ,  16.777216],
       [185.      , 347.      ,  16.777216],
       [128.      , 154.      ,  10.48576 ],
       [198.      , 155.      ,  10.48576 ],
       [124.      , 337.      ,  10.48576 ],
       [ 45.      , 336.      ,  16.777216],
       [195.      , 102.      ,  16.777216],
       [125.      ,  45.      ,  16.777216],
       [261.      , 173.      ,  16.777216],
       [194.      , 277.      ,  16.777216],
       [127.      , 102.      ,  10.48576 ],
       [125.      , 208.      ,  10.48576 ],
       [267.      , 115.      ,  10.48576 ],
       [263.      , 302.      ,  16.777216],
       [196.      ,  43.      ,  10.48576 ],
       [260.      ,  46.      ,  16.777216],
       [267.      , 359.      ,  16.777216],
       [ 54.      , 276.      ,  10.48576 ],
       [ 58.      , 100.      ,  10.48576 ],
       [ 52.      , 155.      ,  16.777216],
       [ 52.      , 216.      ,  16.777216],
       [ 54.      ,  42.      ,  16.777216]])
</pre> </dd>
</dl>   <h2 id="blob-doh">blob_doh</h2> <dl class="function"> <dt id="skimage.feature.blob_doh">
<code>skimage.feature.blob_doh(image, min_sigma=1, max_sigma=30, num_sigma=10, threshold=0.01, overlap=0.5, log_scale=False)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/blob.py#L538-L646"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Finds blobs in the given grayscale image.</p> <p>Blobs are found using the Determinant of Hessian method <a class="reference internal" href="#ra19a7aed16ca-1" id="id3">[1]</a>. For each blob found, the method returns its coordinates and the standard deviation of the Gaussian Kernel used for the Hessian matrix whose determinant detected the blob. Determinant of Hessians is approximated using <a class="reference internal" href="#ra19a7aed16ca-2" id="id4">[2]</a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D ndarray</code> </dt>
<dd>
<p>Input grayscale image.Blobs can either be light on dark or vice versa.</p> </dd> <dt>
<code>min_sigmafloat, optional</code> </dt>
<dd>
<p>The minimum standard deviation for Gaussian Kernel used to compute Hessian matrix. Keep this low to detect smaller blobs.</p> </dd> <dt>
<code>max_sigmafloat, optional</code> </dt>
<dd>
<p>The maximum standard deviation for Gaussian Kernel used to compute Hessian matrix. Keep this high to detect larger blobs.</p> </dd> <dt>
<code>num_sigmaint, optional</code> </dt>
<dd>
<p>The number of intermediate values of standard deviations to consider between <code>min_sigma</code> and <code>max_sigma</code>.</p> </dd> <dt>
<code>thresholdfloat, optional.</code> </dt>
<dd>
<p>The absolute lower bound for scale space maxima. Local maxima smaller than thresh are ignored. Reduce this to detect less prominent blobs.</p> </dd> <dt>
<code>overlapfloat, optional</code> </dt>
<dd>
<p>A value between 0 and 1. If the area of two blobs overlaps by a fraction greater than <code>threshold</code>, the smaller blob is eliminated.</p> </dd> <dt>
<code>log_scalebool, optional</code> </dt>
<dd>
<p>If set intermediate values of standard deviations are interpolated using a logarithmic scale to the base <code>10</code>. If not, linear interpolation is used.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>A(n, 3) ndarray</code> </dt>
<dd>
<p>A 2d array with each row representing 3 values, <code>(y,x,sigma)</code> where <code>(y,x)</code> are coordinates of the blob and <code>sigma</code> is the standard deviation of the Gaussian kernel of the Hessian Matrix whose determinant detected the blob.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The radius of each blob is approximately <code>sigma</code>. Computation of Determinant of Hessians is independent of the standard deviation. Therefore detecting larger blobs won’t take more time. In methods line <a class="reference internal" href="#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code>blob_dog()</code></a> and <a class="reference internal" href="#skimage.feature.blob_log" title="skimage.feature.blob_log"><code>blob_log()</code></a> the computation of Gaussians for larger <code>sigma</code> takes more time. The downside is that this method can’t be used for detecting blobs of radius less than <code>3px</code> due to the box filters used in the approximation of Hessian Determinant.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="ra19a7aed16ca-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian">https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian</a></p> </dd> <dt class="label" id="ra19a7aed16ca-2">
<code>2</code> </dt> <dd>
<p>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool, “SURF: Speeded Up Robust Features” <a class="reference external" href="ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf.html">ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data, feature
&gt;&gt;&gt; img = data.coins()
&gt;&gt;&gt; feature.blob_doh(img)
array([[197.        , 153.        ,  20.33333333],
       [124.        , 336.        ,  20.33333333],
       [126.        , 153.        ,  20.33333333],
       [195.        , 100.        ,  23.55555556],
       [192.        , 212.        ,  23.55555556],
       [121.        , 271.        ,  30.        ],
       [126.        , 101.        ,  20.33333333],
       [193.        , 275.        ,  23.55555556],
       [123.        , 205.        ,  20.33333333],
       [270.        , 363.        ,  30.        ],
       [265.        , 113.        ,  23.55555556],
       [262.        , 243.        ,  23.55555556],
       [185.        , 348.        ,  30.        ],
       [156.        , 302.        ,  30.        ],
       [123.        ,  44.        ,  23.55555556],
       [260.        , 173.        ,  30.        ],
       [197.        ,  44.        ,  20.33333333]])
</pre> </dd>
</dl>   <h2 id="blob-log">blob_log</h2> <dl class="function"> <dt id="skimage.feature.blob_log">
<code>skimage.feature.blob_log(image, min_sigma=1, max_sigma=50, num_sigma=10, threshold=0.2, overlap=0.5, log_scale=False, *, exclude_border=False)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/blob.py#L378-L535"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Finds blobs in the given grayscale image.</p> <p>Blobs are found using the Laplacian of Gaussian (LoG) method <a class="reference internal" href="#r520e53dd5fa2-1" id="id7">[1]</a>. For each blob found, the method returns its coordinates and the standard deviation of the Gaussian kernel that detected the blob.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D or 3D ndarray</code> </dt>
<dd>
<p>Input grayscale image, blobs are assumed to be light on dark background (white on black).</p> </dd> <dt>
<code>min_sigmascalar or sequence of scalars, optional</code> </dt>
<dd>
<p>the minimum standard deviation for Gaussian kernel. Keep this low to detect smaller blobs. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.</p> </dd> <dt>
<code>max_sigmascalar or sequence of scalars, optional</code> </dt>
<dd>
<p>The maximum standard deviation for Gaussian kernel. Keep this high to detect larger blobs. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.</p> </dd> <dt>
<code>num_sigmaint, optional</code> </dt>
<dd>
<p>The number of intermediate values of standard deviations to consider between <code>min_sigma</code> and <code>max_sigma</code>.</p> </dd> <dt>
<code>thresholdfloat, optional.</code> </dt>
<dd>
<p>The absolute lower bound for scale space maxima. Local maxima smaller than thresh are ignored. Reduce this to detect blobs with less intensities.</p> </dd> <dt>
<code>overlapfloat, optional</code> </dt>
<dd>
<p>A value between 0 and 1. If the area of two blobs overlaps by a fraction greater than <code>threshold</code>, the smaller blob is eliminated.</p> </dd> <dt>
<code>log_scalebool, optional</code> </dt>
<dd>
<p>If set intermediate values of standard deviations are interpolated using a logarithmic scale to the base <code>10</code>. If not, linear interpolation is used.</p> </dd> <dt>
<code>exclude_bordertuple of ints, int, or False, optional</code> </dt>
<dd>
<p>If tuple of ints, the length of the tuple must match the input array’s dimensionality. Each element of the tuple will exclude peaks from within <code>exclude_border</code>-pixels of the border of the image along that dimension. If nonzero int, <code>exclude_border</code> excludes peaks from within <code>exclude_border</code>-pixels of the border of the image. If zero or False, peaks are identified regardless of their distance from the border.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>A(n, image.ndim + sigma) ndarray</code> </dt>
<dd>
<p>A 2d array with each row representing 2 coordinate values for a 2D image, and 3 coordinate values for a 3D image, plus the sigma(s) used. When a single sigma is passed, outputs are: <code>(r, c, sigma)</code> or <code>(p, r, c, sigma)</code> where <code>(r, c)</code> or <code>(p, r, c)</code> are coordinates of the blob and <code>sigma</code> is the standard deviation of the Gaussian kernel which detected the blob. When an anisotropic gaussian is used (sigmas per dimension), the detected sigma is returned for each dimension.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The radius of each blob is approximately <span class="math notranslate nohighlight">\(\sqrt{2}\sigma\)</span> for a 2-D image and <span class="math notranslate nohighlight">\(\sqrt{3}\sigma\)</span> for a 3-D image.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r520e53dd5fa2-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian">https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data, feature, exposure
&gt;&gt;&gt; img = data.coins()
&gt;&gt;&gt; img = exposure.equalize_hist(img)  # improves detection
&gt;&gt;&gt; feature.blob_log(img, threshold = .3)
array([[124.        , 336.        ,  11.88888889],
       [198.        , 155.        ,  11.88888889],
       [194.        , 213.        ,  17.33333333],
       [121.        , 272.        ,  17.33333333],
       [263.        , 244.        ,  17.33333333],
       [194.        , 276.        ,  17.33333333],
       [266.        , 115.        ,  11.88888889],
       [128.        , 154.        ,  11.88888889],
       [260.        , 174.        ,  17.33333333],
       [198.        , 103.        ,  11.88888889],
       [126.        , 208.        ,  11.88888889],
       [127.        , 102.        ,  11.88888889],
       [263.        , 302.        ,  17.33333333],
       [197.        ,  44.        ,  11.88888889],
       [185.        , 344.        ,  17.33333333],
       [126.        ,  46.        ,  11.88888889],
       [113.        , 323.        ,   1.        ]])
</pre> </dd>
</dl>   <h2 id="canny">canny</h2> <dl class="function"> <dt id="skimage.feature.canny">
<code>skimage.feature.canny(image, sigma=1.0, low_threshold=None, high_threshold=None, mask=None, use_quantiles=False)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/_canny.py#L53-L297"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Edge filter an image using the Canny algorithm.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D array</code> </dt>
<dd>
<p>Grayscale input image to detect edges on; can be of any dtype.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation of the Gaussian filter.</p> </dd> <dt>
<code>low_thresholdfloat, optional</code> </dt>
<dd>
<p>Lower bound for hysteresis thresholding (linking edges). If None, low_threshold is set to 10% of dtype’s max.</p> </dd> <dt>
<code>high_thresholdfloat, optional</code> </dt>
<dd>
<p>Upper bound for hysteresis thresholding (linking edges). If None, high_threshold is set to 20% of dtype’s max.</p> </dd> <dt>
<code>maskarray, dtype=bool, optional</code> </dt>
<dd>
<p>Mask to limit the application of Canny to a certain area.</p> </dd> <dt>
<code>use_quantilesbool, optional</code> </dt>
<dd>
<p>If True then treat low_threshold and high_threshold as quantiles of the edge magnitude image, rather than absolute edge magnitude values. If True then the thresholds must be in the range [0, 1].</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>output2D array (image)</code> </dt>
<dd>
<p>The binary edge map.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
<code>skimage.sobel</code> </dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <p>The steps of the algorithm are as follows:</p> <ul class="simple"> <li>Smooth the image using a Gaussian with <code>sigma</code> width.</li> <li>Apply the horizontal and vertical Sobel operators to get the gradients within the image. The edge strength is the norm of the gradient.</li> <li>Thin potential edges to 1-pixel wide curves. First, find the normal to the edge at each point. This is done by looking at the signs and the relative magnitude of the X-Sobel and Y-Sobel to sort the points into 4 categories: horizontal, vertical, diagonal and antidiagonal. Then look in the normal and reverse directions to see if the values in either of those directions are greater than the point in question. Use interpolation to get a mix of points instead of picking the one that’s the closest to the normal.</li> <li>Perform a hysteresis thresholding: first label all points above the high threshold as edges. Then recursively label any point above the low threshold that is 8-connected to a labeled point as an edge.</li> </ul> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r5f5bcbc11495-1">
<code>1</code> </dt> <dd>
<p>Canny, J., A Computational Approach To Edge Detection, IEEE Trans. Pattern Analysis and Machine Intelligence, 8:679-714, 1986 <a class="reference external" href="https://doi.org/10.1109/TPAMI.1986.4767851">DOI:10.1109/TPAMI.1986.4767851</a></p> </dd> <dt class="label" id="r5f5bcbc11495-2">
<code>2</code> </dt> <dd>
<p>William Green’s Canny tutorial <a class="reference external" href="https://en.wikipedia.org/wiki/Canny_edge_detector">https://en.wikipedia.org/wiki/Canny_edge_detector</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import feature
&gt;&gt;&gt; # Generate noisy image of a square
&gt;&gt;&gt; im = np.zeros((256, 256))
&gt;&gt;&gt; im[64:-64, 64:-64] = 1
&gt;&gt;&gt; im += 0.2 * np.random.rand(*im.shape)
&gt;&gt;&gt; # First trial with the Canny filter, with the default smoothing
&gt;&gt;&gt; edges1 = feature.canny(im)
&gt;&gt;&gt; # Increase the smoothing for better results
&gt;&gt;&gt; edges2 = feature.canny(im, sigma=3)
</pre> </dd>
</dl>   <h2 id="corner-fast">corner_fast</h2> <dl class="function"> <dt id="skimage.feature.corner_fast">
<code>skimage.feature.corner_fast(image, n=12, threshold=0.15)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L762-L824"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Extract FAST corners for a given image.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D ndarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>nint, optional</code> </dt>
<dd>
<p>Minimum number of consecutive pixels out of 16 pixels on the circle that should all be either brighter or darker w.r.t testpixel. A point c on the circle is darker w.r.t test pixel p if <code>Ic &lt; Ip - threshold</code> and brighter if <code>Ic &gt; Ip + threshold</code>. Also stands for the n in <code>FAST-n</code> corner detector.</p> </dd> <dt>
<code>thresholdfloat, optional</code> </dt>
<dd>
<p>Threshold used in deciding whether the pixels on the circle are brighter, darker or similar w.r.t. the test pixel. Decrease the threshold when more corners are desired and vice-versa.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>responsendarray</code> </dt>
<dd>
<p>FAST corner response image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r92fff83e7342-1">
<code>1</code> </dt> <dd>
<p>Rosten, E., &amp; Drummond, T. (2006, May). Machine learning for high-speed corner detection. In European conference on computer vision (pp. 430-443). Springer, Berlin, Heidelberg. <a class="reference external" href="https://doi.org/10.1007/11744023_34">DOI:10.1007/11744023_34</a> <a class="reference external" href="http://www.edwardrosten.com/work/rosten_2006_machine.pdf">http://www.edwardrosten.com/work/rosten_2006_machine.pdf</a></p> </dd> <dt class="label" id="r92fff83e7342-2">
<code>2</code> </dt> <dd>
<p>Wikipedia, “Features from accelerated segment test”, <a class="reference external" href="https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test">https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import corner_fast, corner_peaks
&gt;&gt;&gt; square = np.zeros((12, 12))
&gt;&gt;&gt; square[3:9, 3:9] = 1
&gt;&gt;&gt; square.astype(int)
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; corner_peaks(corner_fast(square, 9), min_distance=1)
array([[3, 3],
       [3, 8],
       [8, 3],
       [8, 8]])
</pre> </dd>
</dl>   <h2 id="corner-foerstner">corner_foerstner</h2> <dl class="function"> <dt id="skimage.feature.corner_foerstner">
<code>skimage.feature.corner_foerstner(image, sigma=1)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L678-L759"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute Foerstner corner measure response image.</p> <p>This corner detector uses information from the auto-correlation matrix A:</p> <pre data-language="python">A = [(imx**2)   (imx*imy)] = [Axx Axy]
    [(imx*imy)   (imy**2)]   [Axy Ayy]
</pre> <p>Where imx and imy are first derivatives, averaged with a gaussian filter. The corner measure is then defined as:</p> <pre data-language="python">w = det(A) / trace(A)           (size of error ellipse)
q = 4 * det(A) / trace(A)**2    (roundness of error ellipse)
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, which is used as weighting function for the auto-correlation matrix.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>wndarray</code> </dt>
<dd>
<p>Error ellipse sizes.</p> </dd> <dt>
<code>qndarray</code> </dt>
<dd>
<p>Roundness of error ellipse.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r9d429c80f73f-1">
<code>1</code> </dt> <dd>
<p>Förstner, W., &amp; Gülch, E. (1987, June). A fast operator for detection and precise location of distinct points, corners and centres of circular features. In Proc. ISPRS intercommission conference on fast processing of photogrammetric data (pp. 281-305). <a class="reference external" href="https://cseweb.ucsd.edu/classes/sp02/cse252/foerstner/foerstner.pdf">https://cseweb.ucsd.edu/classes/sp02/cse252/foerstner/foerstner.pdf</a></p> </dd> <dt class="label" id="r9d429c80f73f-2">
<code>2</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import corner_foerstner, corner_peaks
&gt;&gt;&gt; square = np.zeros([10, 10])
&gt;&gt;&gt; square[2:8, 2:8] = 1
&gt;&gt;&gt; square.astype(int)
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; w, q = corner_foerstner(square)
&gt;&gt;&gt; accuracy_thresh = 0.5
&gt;&gt;&gt; roundness_thresh = 0.3
&gt;&gt;&gt; foerstner = (q &gt; roundness_thresh) * (w &gt; accuracy_thresh) * w
&gt;&gt;&gt; corner_peaks(foerstner, min_distance=1)
array([[2, 2],
       [2, 7],
       [7, 2],
       [7, 7]])
</pre> </dd>
</dl>   <h2 id="corner-harris">corner_harris</h2> <dl class="function"> <dt id="skimage.feature.corner_harris">
<code>skimage.feature.corner_harris(image, method='k', k=0.05, eps=1e-06, sigma=1)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L536-L613"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute Harris corner measure response image.</p> <p>This corner detector uses information from the auto-correlation matrix A:</p> <pre data-language="python">A = [(imx**2)   (imx*imy)] = [Axx Axy]
    [(imx*imy)   (imy**2)]   [Axy Ayy]
</pre> <p>Where imx and imy are first derivatives, averaged with a gaussian filter. The corner measure is then defined as:</p> <pre data-language="python">det(A) - k * trace(A)**2
</pre> <p>or:</p> <pre data-language="python">2 * det(A) / (trace(A) + eps)
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>method{‘k’, ‘eps’}, optional</code> </dt>
<dd>
<p>Method to compute the response image from the auto-correlation matrix.</p> </dd> <dt>
<code>kfloat, optional</code> </dt>
<dd>
<p>Sensitivity factor to separate corners from edges, typically in range <code>[0, 0.2]</code>. Small values of k result in detection of sharp corners.</p> </dd> <dt>
<code>epsfloat, optional</code> </dt>
<dd>
<p>Normalisation factor (Noble’s corner measure).</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, which is used as weighting function for the auto-correlation matrix.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>responsendarray</code> </dt>
<dd>
<p>Harris response image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rc19c7843bb6d-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import corner_harris, corner_peaks
&gt;&gt;&gt; square = np.zeros([10, 10])
&gt;&gt;&gt; square[2:8, 2:8] = 1
&gt;&gt;&gt; square.astype(int)
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; corner_peaks(corner_harris(square), min_distance=1)
array([[2, 2],
       [2, 7],
       [7, 2],
       [7, 7]])
</pre> </dd>
</dl>   <h2 id="corner-kitchen-rosenfeld">corner_kitchen_rosenfeld</h2> <dl class="function"> <dt id="skimage.feature.corner_kitchen_rosenfeld">
<code>skimage.feature.corner_kitchen_rosenfeld(image, mode='constant', cval=0)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L488-L533"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute Kitchen and Rosenfeld corner measure response image.</p> <p>The corner measure is calculated as follows:</p> <pre data-language="python">(imxx * imy**2 + imyy * imx**2 - 2 * imxy * imx * imy)
    / (imx**2 + imy**2)
</pre> <p>Where imx and imy are the first and imxx, imxy, imyy the second derivatives.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>mode{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</code> </dt>
<dd>
<p>How to handle values outside the image borders.</p> </dd> <dt>
<code>cvalfloat, optional</code> </dt>
<dd>
<p>Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>responsendarray</code> </dt>
<dd>
<p>Kitchen and Rosenfeld response image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rd1dae2ae49ff-1">
<code>1</code> </dt> <dd>
<p>Kitchen, L., &amp; Rosenfeld, A. (1982). Gray-level corner detection. Pattern recognition letters, 1(2), 95-102. <a class="reference external" href="https://doi.org/10.1016/0167-8655(82)90020-4">DOI:10.1016/0167-8655(82)90020-4</a></p> </dd> </dl> </dd>
</dl>   <h2 id="corner-moravec">corner_moravec</h2> <dl class="function"> <dt id="skimage.feature.corner_moravec">
<code>skimage.feature.corner_moravec(image, window_size=1)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L1108-L1152"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute Moravec corner measure response image.</p> <p>This is one of the simplest corner detectors and is comparatively fast but has several limitations (e.g. not rotation invariant).</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>window_sizeint, optional</code> </dt>
<dd>
<p>Window size.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>responsendarray</code> </dt>
<dd>
<p>Moravec response image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rdf16f0a1a068-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import corner_moravec
&gt;&gt;&gt; square = np.zeros([7, 7])
&gt;&gt;&gt; square[3, 3] = 1
&gt;&gt;&gt; square.astype(int)
array([[0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; corner_moravec(square).astype(int)
array([[0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 1, 1, 0, 0],
       [0, 0, 1, 2, 1, 0, 0],
       [0, 0, 1, 1, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0]])
</pre> </dd>
</dl>   <h2 id="corner-orientations">corner_orientations</h2> <dl class="function"> <dt id="skimage.feature.corner_orientations">
<code>skimage.feature.corner_orientations(image, corners, mask)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L1155-L1219"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the orientation of corners.</p> <p>The orientation of corners is computed using the first order central moment i.e. the center of mass approach. The corner orientation is the angle of the vector from the corner coordinate to the intensity centroid in the local neighborhood around the corner calculated using first order central moment.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D array</code> </dt>
<dd>
<p>Input grayscale image.</p> </dd> <dt>
<code>corners(N, 2) array</code> </dt>
<dd>
<p>Corner coordinates as <code>(row, col)</code>.</p> </dd> <dt>
<code>mask2D array</code> </dt>
<dd>
<p>Mask defining the local neighborhood of the corner used for the calculation of the central moment.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>orientations(N, 1) array</code> </dt>
<dd>
<p>Orientations of corners in the range [-pi, pi].</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r0592d7afdba5-1">
<code>1</code> </dt> <dd>
<p>Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski “ORB : An efficient alternative to SIFT and SURF” <a class="reference external" href="http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf">http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf</a></p> </dd> <dt class="label" id="r0592d7afdba5-2">
<code>2</code> </dt> <dd>
<p>Paul L. Rosin, “Measuring Corner Properties” <a class="reference external" href="http://users.cs.cf.ac.uk/Paul.Rosin/corner2.pdf">http://users.cs.cf.ac.uk/Paul.Rosin/corner2.pdf</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.morphology import octagon
&gt;&gt;&gt; from skimage.feature import (corner_fast, corner_peaks,
...                              corner_orientations)
&gt;&gt;&gt; square = np.zeros((12, 12))
&gt;&gt;&gt; square[3:9, 3:9] = 1
&gt;&gt;&gt; square.astype(int)
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; corners = corner_peaks(corner_fast(square, 9), min_distance=1)
&gt;&gt;&gt; corners
array([[3, 3],
       [3, 8],
       [8, 3],
       [8, 8]])
&gt;&gt;&gt; orientations = corner_orientations(square, corners, octagon(3, 2))
&gt;&gt;&gt; np.rad2deg(orientations)
array([  45.,  135.,  -45., -135.])
</pre> </dd>
</dl>   <h2 id="corner-peaks">corner_peaks</h2> <dl class="function"> <dt id="skimage.feature.corner_peaks">
<code>skimage.feature.corner_peaks(image, min_distance=1, threshold_abs=None, threshold_rel=None, exclude_border=True, indices=True, num_peaks=inf, footprint=None, labels=None, *, num_peaks_per_label=inf, p_norm=inf)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L1005-L1105"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Find peaks in corner measure response image.</p> <p>This differs from <a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code>skimage.feature.peak_local_max</code></a> in that it suppresses multiple connected peaks with the same accumulator value.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>min_distanceint, optional</code> </dt>
<dd>
<p>The minimal allowed distance separating peaks.</p> </dd> <dt>
<code>**</code> </dt>
<dd>
<p>See <a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code>skimage.feature.peak_local_max()</code></a>.</p> </dd> <dt>
<code>p_normfloat</code> </dt>
<dd>
<p>Which Minkowski p-norm to use. Should be in the range [1, inf]. A finite large p may cause a ValueError if overflow can occur. <code>inf</code> corresponds to the Chebyshev distance and 2 to the Euclidean distance.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outputndarray or ndarray of bools</code> </dt>
<dd>
<ul class="simple"> <li>If <code>indices = True</code> : (row, column, …) coordinates of peaks.</li> <li>If <code>indices = False</code> : Boolean array shaped like <code>image</code>, with peaks represented by True values.</li> </ul> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code>skimage.feature.peak_local_max</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.18: </span>The default value of <code>threshold_rel</code> has changed to None, which corresponds to letting <a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code>skimage.feature.peak_local_max</code></a> decide on the default. This is equivalent to <code>threshold_rel=0</code>.</p> </div> <p>The <code>num_peaks</code> limit is applied before suppression of connected peaks. To limit the number of peaks after suppression, set <code>num_peaks=np.inf</code> and post-process the output of this function.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import peak_local_max
&gt;&gt;&gt; response = np.zeros((5, 5))
&gt;&gt;&gt; response[2:4, 2:4] = 1
&gt;&gt;&gt; response
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 1., 1., 0.],
       [0., 0., 1., 1., 0.],
       [0., 0., 0., 0., 0.]])
&gt;&gt;&gt; peak_local_max(response)
array([[2, 2],
       [2, 3],
       [3, 2],
       [3, 3]])
&gt;&gt;&gt; corner_peaks(response)
array([[2, 2]])
</pre> </dd>
</dl>   <h2 id="corner-shi-tomasi">corner_shi_tomasi</h2> <dl class="function"> <dt id="skimage.feature.corner_shi_tomasi">
<code>skimage.feature.corner_shi_tomasi(image, sigma=1)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L616-L675"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute Shi-Tomasi (Kanade-Tomasi) corner measure response image.</p> <p>This corner detector uses information from the auto-correlation matrix A:</p> <pre data-language="python">A = [(imx**2)   (imx*imy)] = [Axx Axy]
    [(imx*imy)   (imy**2)]   [Axy Ayy]
</pre> <p>Where imx and imy are first derivatives, averaged with a gaussian filter. The corner measure is then defined as the smaller eigenvalue of A:</p> <pre data-language="python">((Axx + Ayy) - sqrt((Axx - Ayy)**2 + 4 * Axy**2)) / 2
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, which is used as weighting function for the auto-correlation matrix.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>responsendarray</code> </dt>
<dd>
<p>Shi-Tomasi response image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r26d4c89afc0d-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import corner_shi_tomasi, corner_peaks
&gt;&gt;&gt; square = np.zeros([10, 10])
&gt;&gt;&gt; square[2:8, 2:8] = 1
&gt;&gt;&gt; square.astype(int)
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; corner_peaks(corner_shi_tomasi(square), min_distance=1)
array([[2, 2],
       [2, 7],
       [7, 2],
       [7, 7]])
</pre> </dd>
</dl>   <h2 id="corner-subpix">corner_subpix</h2> <dl class="function"> <dt id="skimage.feature.corner_subpix">
<code>skimage.feature.corner_subpix(image, corners, window_size=11, alpha=0.99)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L827-L1002"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Determine subpixel position of corners.</p> <p>A statistical test decides whether the corner is defined as the intersection of two edges or a single peak. Depending on the classification result, the subpixel corner location is determined based on the local covariance of the grey-values. If the significance level for either statistical test is not sufficient, the corner cannot be classified, and the output subpixel position is set to NaN.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>corners(N, 2) ndarray</code> </dt>
<dd>
<p>Corner coordinates <code>(row, col)</code>.</p> </dd> <dt>
<code>window_sizeint, optional</code> </dt>
<dd>
<p>Search window size for subpixel estimation.</p> </dd> <dt>
<code>alphafloat, optional</code> </dt>
<dd>
<p>Significance level for corner classification.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>positions(N, 2) ndarray</code> </dt>
<dd>
<p>Subpixel corner positions. NaN for “not classified” corners.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="ra33874b5943a-1">
<code>1</code> </dt> <dd>
<p>Förstner, W., &amp; Gülch, E. (1987, June). A fast operator for detection and precise location of distinct points, corners and centres of circular features. In Proc. ISPRS intercommission conference on fast processing of photogrammetric data (pp. 281-305). <a class="reference external" href="https://cseweb.ucsd.edu/classes/sp02/cse252/foerstner/foerstner.pdf">https://cseweb.ucsd.edu/classes/sp02/cse252/foerstner/foerstner.pdf</a></p> </dd> <dt class="label" id="ra33874b5943a-2">
<code>2</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import corner_harris, corner_peaks, corner_subpix
&gt;&gt;&gt; img = np.zeros((10, 10))
&gt;&gt;&gt; img[:5, :5] = 1
&gt;&gt;&gt; img[5:, 5:] = 1
&gt;&gt;&gt; img.astype(int)
array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])
&gt;&gt;&gt; coords = corner_peaks(corner_harris(img), min_distance=2)
&gt;&gt;&gt; coords_subpix = corner_subpix(img, coords, window_size=7)
&gt;&gt;&gt; coords_subpix
array([[4.5, 4.5]])
</pre> </dd>
</dl>   <h2 id="daisy">daisy</h2> <dl class="function"> <dt id="skimage.feature.daisy">
<code>skimage.feature.daisy(image, step=4, radius=15, rings=3, histograms=8, orientations=8, normalization='l1', sigmas=None, ring_radii=None, visualize=False)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/_daisy.py#L9-L222"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Extract DAISY feature descriptors densely for the given image.</p> <p>DAISY is a feature descriptor similar to SIFT formulated in a way that allows for fast dense extraction. Typically, this is practical for bag-of-features image representations.</p> <p>The implementation follows Tola et al. <a class="reference internal" href="#r3f18658b3c6d-1" id="id23">[1]</a> but deviate on the following points:</p>  <ul class="simple"> <li>Histogram bin contribution are smoothed with a circular Gaussian window over the tonal range (the angular range).</li> <li>The sigma values of the spatial Gaussian smoothing in this code do not match the sigma values in the original code by Tola et al. <a class="reference internal" href="#r3f18658b3c6d-2" id="id24">[2]</a>. In their code, spatial smoothing is applied to both the input image and the center histogram. However, this smoothing is not documented in <a class="reference internal" href="#r3f18658b3c6d-1" id="id25">[1]</a> and, therefore, it is omitted.</li> </ul>  <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>image(M, N) array</code> </dt>
<dd>
<p>Input image (grayscale).</p> </dd> <dt>
<code>stepint, optional</code> </dt>
<dd>
<p>Distance between descriptor sampling points.</p> </dd> <dt>
<code>radiusint, optional</code> </dt>
<dd>
<p>Radius (in pixels) of the outermost ring.</p> </dd> <dt>
<code>ringsint, optional</code> </dt>
<dd>
<p>Number of rings.</p> </dd> <dt>
<code>histogramsint, optional</code> </dt>
<dd>
<p>Number of histograms sampled per ring.</p> </dd> <dt>
<code>orientationsint, optional</code> </dt>
<dd>
<p>Number of orientations (bins) per histogram.</p> </dd> <dt>
<code>normalization[ ‘l1’ | ‘l2’ | ‘daisy’ | ‘off’ ], optional</code> </dt>
<dd>
<p>How to normalize the descriptors</p>  <ul class="simple"> <li>‘l1’: L1-normalization of each descriptor.</li> <li>‘l2’: L2-normalization of each descriptor.</li> <li>‘daisy’: L2-normalization of individual histograms.</li> <li>‘off’: Disable normalization.</li> </ul>  </dd> <dt>
<code>sigmas1D array of float, optional</code> </dt>
<dd>
<p>Standard deviation of spatial Gaussian smoothing for the center histogram and for each ring of histograms. The array of sigmas should be sorted from the center and out. I.e. the first sigma value defines the spatial smoothing of the center histogram and the last sigma value defines the spatial smoothing of the outermost ring. Specifying sigmas overrides the following parameter.</p>  <p><code>rings = len(sigmas) - 1</code></p>  </dd> <dt>
<code>ring_radii1D array of int, optional</code> </dt>
<dd>
<p>Radius (in pixels) for each ring. Specifying ring_radii overrides the following two parameters.</p>  <p><code>rings = len(ring_radii)</code> <code>radius = ring_radii[-1]</code></p>  <p>If both sigmas and ring_radii are given, they must satisfy the following predicate since no radius is needed for the center histogram.</p>  <p><code>len(ring_radii) == len(sigmas) + 1</code></p>  </dd> <dt>
<code>visualizebool, optional</code> </dt>
<dd>
<p>Generate a visualization of the DAISY descriptors</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl> <dt>
<code>descsarray</code> </dt>
<dd>
<p>Grid of DAISY descriptors for the given image as an array dimensionality (P, Q, R) where</p>  <p><code>P = ceil((M - radius*2) / step)</code> <code>Q = ceil((N - radius*2) / step)</code> <code>R = (rings * histograms + 1) * orientations</code></p>  </dd> <dt>
<code>descs_img(M, N, 3) array (only if visualize==True)</code> </dt>
<dd>
<p>Visualization of the DAISY descriptors.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r3f18658b3c6d-1">
<code>1(1,2)</code> </dt> <dd>
<p>Tola et al. “Daisy: An efficient dense descriptor applied to wide- baseline stereo.” Pattern Analysis and Machine Intelligence, IEEE Transactions on 32.5 (2010): 815-830.</p> </dd> <dt class="label" id="r3f18658b3c6d-2">
<code>2</code> </dt> <dd>
<p><a class="reference external" href="http://cvlab.epfl.ch/software/daisy">http://cvlab.epfl.ch/software/daisy</a></p> </dd> </dl> </dd>
</dl>   <h2 id="draw-haar-like-feature">draw_haar_like_feature</h2> <dl class="function"> <dt id="skimage.feature.draw_haar_like_feature">
<code>skimage.feature.draw_haar_like_feature(image, r, c, width, height, feature_coord, color_positive_block=(1.0, 0.0, 0.0), color_negative_block=(0.0, 1.0, 0.0), alpha=0.5, max_n_features=None, random_state=None)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/haar.py#L222-L321"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Visualization of Haar-like features.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image(M, N) ndarray</code> </dt>
<dd>
<p>The region of an integral image for which the features need to be computed.</p> </dd> <dt>
<code>rint</code> </dt>
<dd>
<p>Row-coordinate of top left corner of the detection window.</p> </dd> <dt>
<code>cint</code> </dt>
<dd>
<p>Column-coordinate of top left corner of the detection window.</p> </dd> <dt>
<code>widthint</code> </dt>
<dd>
<p>Width of the detection window.</p> </dd> <dt>
<code>heightint</code> </dt>
<dd>
<p>Height of the detection window.</p> </dd> <dt>
<code>feature_coordndarray of list of tuples or None, optional</code> </dt>
<dd>
<p>The array of coordinates to be extracted. This is useful when you want to recompute only a subset of features. In this case <code>feature_type</code> needs to be an array containing the type of each feature, as returned by <a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code>haar_like_feature_coord()</code></a>. By default, all coordinates are computed.</p> </dd> <dt>
<code>color_positive_rectangletuple of 3 floats</code> </dt>
<dd>
<p>Floats specifying the color for the positive block. Corresponding values define (R, G, B) values. Default value is red (1, 0, 0).</p> </dd> <dt>
<code>color_negative_blocktuple of 3 floats</code> </dt>
<dd>
<p>Floats specifying the color for the negative block Corresponding values define (R, G, B) values. Default value is blue (0, 1, 0).</p> </dd> <dt>
<code>alphafloat</code> </dt>
<dd>
<p>Value in the range [0, 1] that specifies opacity of visualization. 1 - fully transparent, 0 - opaque.</p> </dd> <dt>
<code>max_n_featuresint, default=None</code> </dt>
<dd>
<p>The maximum number of features to be returned. By default, all features are returned.</p> </dd> <dt>
<code>random_stateint, RandomState instance or None, optional</code> </dt>
<dd>
<p>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>. The random state is used when generating a set of features smaller than the total number of available features.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>features(M, N), ndarray</code> </dt>
<dd>
<p>An image in which the different features will be added.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from skimage.feature import haar_like_feature_coord
&gt;&gt;&gt; from skimage.feature import draw_haar_like_feature
&gt;&gt;&gt; feature_coord, _ = haar_like_feature_coord(2, 2, 'type-4')
&gt;&gt;&gt; image = draw_haar_like_feature(np.zeros((2, 2)),
...                                0, 0, 2, 2,
...                                feature_coord,
...                                max_n_features=1)
&gt;&gt;&gt; image
array([[[0. , 0.5, 0. ],
        [0.5, 0. , 0. ]],

       [[0.5, 0. , 0. ],
        [0. , 0.5, 0. ]]])
</pre> </dd>
</dl>   <h2 id="draw-multiblock-lbp">draw_multiblock_lbp</h2> <dl class="function"> <dt id="skimage.feature.draw_multiblock_lbp">
<code>skimage.feature.draw_multiblock_lbp(image, r, c, width, height, lbp_code=0, color_greater_block=(1, 1, 1), color_less_block=(0, 0.69, 0.96), alpha=0.5)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/texture.py#L386-L493"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Multi-block local binary pattern visualization.</p> <p>Blocks with higher sums are colored with alpha-blended white rectangles, whereas blocks with lower sums are colored alpha-blended cyan. Colors and the <code>alpha</code> parameter can be changed.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray of float or uint</code> </dt>
<dd>
<p>Image on which to visualize the pattern.</p> </dd> <dt>
<code>rint</code> </dt>
<dd>
<p>Row-coordinate of top left corner of a rectangle containing feature.</p> </dd> <dt>
<code>cint</code> </dt>
<dd>
<p>Column-coordinate of top left corner of a rectangle containing feature.</p> </dd> <dt>
<code>widthint</code> </dt>
<dd>
<p>Width of one of 9 equal rectangles that will be used to compute a feature.</p> </dd> <dt>
<code>heightint</code> </dt>
<dd>
<p>Height of one of 9 equal rectangles that will be used to compute a feature.</p> </dd> <dt>
<code>lbp_codeint</code> </dt>
<dd>
<p>The descriptor of feature to visualize. If not provided, the descriptor with 0 value will be used.</p> </dd> <dt>
<code>color_greater_blocktuple of 3 floats</code> </dt>
<dd>
<p>Floats specifying the color for the block that has greater intensity value. They should be in the range [0, 1]. Corresponding values define (R, G, B) values. Default value is white (1, 1, 1).</p> </dd> <dt>
<code>color_greater_blocktuple of 3 floats</code> </dt>
<dd>
<p>Floats specifying the color for the block that has greater intensity value. They should be in the range [0, 1]. Corresponding values define (R, G, B) values. Default value is cyan (0, 0.69, 0.96).</p> </dd> <dt>
<code>alphafloat</code> </dt>
<dd>
<p>Value in the range [0, 1] that specifies opacity of visualization. 1 - fully transparent, 0 - opaque.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outputndarray of float</code> </dt>
<dd>
<p>Image with MB-LBP visualization.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="re2978af1b6c8-1">
<code>1</code> </dt> <dd>
<p>Face Detection Based on Multi-Block LBP Representation. Lun Zhang, Rufeng Chu, Shiming Xiang, Shengcai Liao, Stan Z. Li <a class="reference external" href="http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf">http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf</a></p> </dd> </dl> </dd>
</dl>   <h2 id="greycomatrix">greycomatrix</h2> <dl class="function"> <dt id="skimage.feature.greycomatrix">
<code>skimage.feature.greycomatrix(image, distances, angles, levels=None, symmetric=False, normed=False)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/texture.py#L15-L155"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate the grey-level co-occurrence matrix.</p> <p>A grey level co-occurrence matrix is a histogram of co-occurring greyscale values at a given offset over an image.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagearray_like</code> </dt>
<dd>
<p>Integer typed input image. Only positive valued images are supported. If type is other than uint8, the argument <code>levels</code> needs to be set.</p> </dd> <dt>
<code>distancesarray_like</code> </dt>
<dd>
<p>List of pixel pair distance offsets.</p> </dd> <dt>
<code>anglesarray_like</code> </dt>
<dd>
<p>List of pixel pair angles in radians.</p> </dd> <dt>
<code>levelsint, optional</code> </dt>
<dd>
<p>The input image should contain integers in [0, <code>levels</code>-1], where levels indicate the number of grey-levels counted (typically 256 for an 8-bit image). This argument is required for 16-bit images or higher and is typically the maximum of the image. As the output matrix is at least <code>levels</code> x <code>levels</code>, it might be preferable to use binning of the input image rather than large values for <code>levels</code>.</p> </dd> <dt>
<code>symmetricbool, optional</code> </dt>
<dd>
<p>If True, the output matrix <code>P[:, :, d, theta]</code> is symmetric. This is accomplished by ignoring the order of value pairs, so both (i, j) and (j, i) are accumulated when (i, j) is encountered for a given offset. The default is False.</p> </dd> <dt>
<code>normedbool, optional</code> </dt>
<dd>
<p>If True, normalize each matrix <code>P[:, :, d, theta]</code> by dividing by the total number of accumulated co-occurrences for the given offset. The elements of the resulting matrix sum to 1. The default is False.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>P4-D ndarray</code> </dt>
<dd>
<p>The grey-level co-occurrence histogram. The value <code>P[i,j,d,theta]</code> is the number of times that grey-level <code>j</code> occurs at a distance <code>d</code> and at an angle <code>theta</code> from grey-level <code>i</code>. If <code>normed</code> is <code>False</code>, the output is of type uint32, otherwise it is float64. The dimensions are: levels x levels x number of distances x number of angles.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r4810813e96aa-1">
<code>1</code> </dt> <dd>
<p>The GLCM Tutorial Home Page, <a class="reference external" href="http://www.fp.ucalgary.ca/mhallbey/tutorial.htm">http://www.fp.ucalgary.ca/mhallbey/tutorial.htm</a></p> </dd> <dt class="label" id="r4810813e96aa-2">
<code>2</code> </dt> <dd>
<p>Haralick, RM.; Shanmugam, K., “Textural features for image classification” IEEE Transactions on systems, man, and cybernetics 6 (1973): 610-621. <a class="reference external" href="https://doi.org/10.1109/TSMC.1973.4309314">DOI:10.1109/TSMC.1973.4309314</a></p> </dd> <dt class="label" id="r4810813e96aa-3">
<code>3</code> </dt> <dd>
<p>Pattern Recognition Engineering, Morton Nadler &amp; Eric P. Smith</p> </dd> <dt class="label" id="r4810813e96aa-4">
<code>4</code> </dt> <dd>
<p>Wikipedia, <a class="reference external" href="https://en.wikipedia.org/wiki/Co-occurrence_matrix">https://en.wikipedia.org/wiki/Co-occurrence_matrix</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <p>Compute 2 GLCMs: One for a 1-pixel offset to the right, and one for a 1-pixel offset upwards.</p> <pre data-language="python">&gt;&gt;&gt; image = np.array([[0, 0, 1, 1],
...                   [0, 0, 1, 1],
...                   [0, 2, 2, 2],
...                   [2, 2, 3, 3]], dtype=np.uint8)
&gt;&gt;&gt; result = greycomatrix(image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4],
...                       levels=4)
&gt;&gt;&gt; result[:, :, 0, 0]
array([[2, 2, 1, 0],
       [0, 2, 0, 0],
       [0, 0, 3, 1],
       [0, 0, 0, 1]], dtype=uint32)
&gt;&gt;&gt; result[:, :, 0, 1]
array([[1, 1, 3, 0],
       [0, 1, 1, 0],
       [0, 0, 0, 2],
       [0, 0, 0, 0]], dtype=uint32)
&gt;&gt;&gt; result[:, :, 0, 2]
array([[3, 0, 2, 0],
       [0, 2, 2, 0],
       [0, 0, 1, 2],
       [0, 0, 0, 0]], dtype=uint32)
&gt;&gt;&gt; result[:, :, 0, 3]
array([[2, 0, 0, 0],
       [1, 1, 2, 0],
       [0, 0, 2, 1],
       [0, 0, 0, 0]], dtype=uint32)
</pre> </dd>
</dl>  <h3 id="examples-using-skimage-feature-greycomatrix">Examples using <code>skimage.feature.greycomatrix</code>
</h3> <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using grey level co-occurrence matrices (GLCMs)...">
<div class="figure align-default" id="id63"> <img alt="GLCM Texture Features" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></span></p> </div> </div>   <h2 id="greycoprops">greycoprops</h2> <dl class="function"> <dt id="skimage.feature.greycoprops">
<code>skimage.feature.greycoprops(P, prop='contrast')</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/texture.py#L158-L278"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate texture properties of a GLCM.</p> <p>Compute a feature of a grey level co-occurrence matrix to serve as a compact summary of the matrix. The properties are computed as follows:</p> <ul> <li>‘contrast’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1} P_{i,j}(i-j)^2\)</span>
</li> <li>‘dissimilarity’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1}P_{i,j}|i-j|\)</span>
</li> <li>‘homogeneity’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1}\frac{P_{i,j}}{1+(i-j)^2}\)</span>
</li> <li>‘ASM’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1} P_{i,j}^2\)</span>
</li> <li>‘energy’: <span class="math notranslate nohighlight">\(\sqrt{ASM}\)</span>
</li> <li>
<dl> <dt>‘correlation’:</dt>
<dd>
<div class="math notranslate nohighlight"> \[\sum_{i,j=0}^{levels-1} P_{i,j}\left[\frac{(i-\mu_i) \ (j-\mu_j)}{\sqrt{(\sigma_i^2)(\sigma_j^2)}}\right]\]</div> </dd> </dl> </li> </ul> <p>Each GLCM is normalized to have a sum of 1 before the computation of texture properties.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Pndarray</code> </dt>
<dd>
<p>Input array. <code>P</code> is the grey-level co-occurrence histogram for which to compute the specified property. The value <code>P[i,j,d,theta]</code> is the number of times that grey-level j occurs at a distance d and at an angle theta from grey-level i.</p> </dd> <dt>
<code>prop{‘contrast’, ‘dissimilarity’, ‘homogeneity’, ‘energy’, ‘correlation’, ‘ASM’}, optional</code> </dt>
<dd>
<p>The property of the GLCM to compute. The default is ‘contrast’.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>results2-D ndarray</code> </dt>
<dd>
<p>2-dimensional array. <code>results[d, a]</code> is the property ‘prop’ for the d’th distance and the a’th angle.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="ra999ee4f1c5d-1">
<code>1</code> </dt> <dd>
<p>The GLCM Tutorial Home Page, <a class="reference external" href="http://www.fp.ucalgary.ca/mhallbey/tutorial.htm">http://www.fp.ucalgary.ca/mhallbey/tutorial.htm</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <p>Compute the contrast for GLCMs with distances [1, 2] and angles [0 degrees, 90 degrees]</p> <pre data-language="python">&gt;&gt;&gt; image = np.array([[0, 0, 1, 1],
...                   [0, 0, 1, 1],
...                   [0, 2, 2, 2],
...                   [2, 2, 3, 3]], dtype=np.uint8)
&gt;&gt;&gt; g = greycomatrix(image, [1, 2], [0, np.pi/2], levels=4,
...                  normed=True, symmetric=True)
&gt;&gt;&gt; contrast = greycoprops(g, 'contrast')
&gt;&gt;&gt; contrast
array([[0.58333333, 1.        ],
       [1.25      , 2.75      ]])
</pre> </dd>
</dl>  <h3 id="examples-using-skimage-feature-greycoprops">Examples using <code>skimage.feature.greycoprops</code>
</h3> <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using grey level co-occurrence matrices (GLCMs)...">
<div class="figure align-default" id="id64"> <img alt="GLCM Texture Features" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></span></p> </div> </div>   <h2 id="haar-like-feature">haar_like_feature</h2> <dl class="function"> <dt id="skimage.feature.haar_like_feature">
<code>skimage.feature.haar_like_feature(int_image, r, c, width, height, feature_type=None, feature_coord=None)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/haar.py#L87-L219"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the Haar-like features for a region of interest (ROI) of an integral image.</p> <p>Haar-like features have been successfully used for image classification and object detection <a class="reference internal" href="#rbcb83f52fce4-1" id="id34">[1]</a>. It has been used for real-time face detection algorithm proposed in <a class="reference internal" href="#rbcb83f52fce4-2" id="id35">[2]</a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>int_image(M, N) ndarray</code> </dt>
<dd>
<p>Integral image for which the features need to be computed.</p> </dd> <dt>
<code>rint</code> </dt>
<dd>
<p>Row-coordinate of top left corner of the detection window.</p> </dd> <dt>
<code>cint</code> </dt>
<dd>
<p>Column-coordinate of top left corner of the detection window.</p> </dd> <dt>
<code>widthint</code> </dt>
<dd>
<p>Width of the detection window.</p> </dd> <dt>
<code>heightint</code> </dt>
<dd>
<p>Height of the detection window.</p> </dd> <dt>
<code>feature_typestr or list of str or None, optional</code> </dt>
<dd>
<p>The type of feature to consider:</p> <ul class="simple"> <li>‘type-2-x’: 2 rectangles varying along the x axis;</li> <li>‘type-2-y’: 2 rectangles varying along the y axis;</li> <li>‘type-3-x’: 3 rectangles varying along the x axis;</li> <li>‘type-3-y’: 3 rectangles varying along the y axis;</li> <li>‘type-4’: 4 rectangles varying along x and y axis.</li> </ul> <p>By default all features are extracted.</p> <p>If using with <code>feature_coord</code>, it should correspond to the feature type of each associated coordinate feature.</p> </dd> <dt>
<code>feature_coordndarray of list of tuples or None, optional</code> </dt>
<dd>
<p>The array of coordinates to be extracted. This is useful when you want to recompute only a subset of features. In this case <code>feature_type</code> needs to be an array containing the type of each feature, as returned by <a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code>haar_like_feature_coord()</code></a>. By default, all coordinates are computed.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>haar_features(n_features,) ndarray of int or float</code> </dt>
<dd>
<p>Resulting Haar-like features. Each value is equal to the subtraction of sums of the positive and negative rectangles. The data type depends of the data type of <code>int_image</code>: <code>int</code> when the data type of <code>int_image</code> is <code>uint</code> or <code>int</code> and <code>float</code> when the data type of <code>int_image</code> is <code>float</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>When extracting those features in parallel, be aware that the choice of the backend (i.e. multiprocessing vs threading) will have an impact on the performance. The rule of thumb is as follows: use multiprocessing when extracting features for all possible ROI in an image; use threading when extracting the feature at specific location for a limited number of ROIs. Refer to the example <a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a> for more insights.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rbcb83f52fce4-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Haar-like_feature">https://en.wikipedia.org/wiki/Haar-like_feature</a></p> </dd> <dt class="label" id="rbcb83f52fce4-2">
<code>2</code> </dt> <dd>
<p>Oren, M., Papageorgiou, C., Sinha, P., Osuna, E., &amp; Poggio, T. (1997, June). Pedestrian detection using wavelet templates. In Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on (pp. 193-199). IEEE. <a class="reference external" href="http://tinyurl.com/y6ulxfta">http://tinyurl.com/y6ulxfta</a> <a class="reference external" href="https://doi.org/10.1109/CVPR.1997.609319">DOI:10.1109/CVPR.1997.609319</a></p> </dd> <dt class="label" id="rbcb83f52fce4-3">
<code>3</code> </dt> <dd>
<p>Viola, Paul, and Michael J. Jones. “Robust real-time face detection.” International journal of computer vision 57.2 (2004): 137-154. <a class="reference external" href="https://www.merl.com/publications/docs/TR2004-043.pdf">https://www.merl.com/publications/docs/TR2004-043.pdf</a> <a class="reference external" href="https://doi.org/10.1109/CVPR.2001.990517">DOI:10.1109/CVPR.2001.990517</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from skimage.transform import integral_image
&gt;&gt;&gt; from skimage.feature import haar_like_feature
&gt;&gt;&gt; img = np.ones((5, 5), dtype=np.uint8)
&gt;&gt;&gt; img_ii = integral_image(img)
&gt;&gt;&gt; feature = haar_like_feature(img_ii, 0, 0, 5, 5, 'type-3-x')
&gt;&gt;&gt; feature
array([-1, -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -4, -1,
       -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -1, -2, -3, -1, -2, -3, -1,
       -2, -1, -2, -1, -2, -1, -1, -1])
</pre> <p>You can compute the feature for some pre-computed coordinates.</p> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import haar_like_feature_coord
&gt;&gt;&gt; feature_coord, feature_type = zip(
...     *[haar_like_feature_coord(5, 5, feat_t)
...       for feat_t in ('type-2-x', 'type-3-x')])
&gt;&gt;&gt; # only select one feature over two
&gt;&gt;&gt; feature_coord = np.concatenate([x[::2] for x in feature_coord])
&gt;&gt;&gt; feature_type = np.concatenate([x[::2] for x in feature_type])
&gt;&gt;&gt; feature = haar_like_feature(img_ii, 0, 0, 5, 5,
...                             feature_type=feature_type,
...                             feature_coord=feature_coord)
&gt;&gt;&gt; feature
array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
        0,  0,  0,  0,  0,  0,  0,  0, -1, -3, -1, -3, -1, -3, -1, -3, -1,
       -3, -1, -3, -1, -3, -2, -1, -3, -2, -2, -2, -1])
</pre> </dd>
</dl>   <h2 id="haar-like-feature-coord">haar_like_feature_coord</h2> <dl class="function"> <dt id="skimage.feature.haar_like_feature_coord">
<code>skimage.feature.haar_like_feature_coord(width, height, feature_type=None)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/haar.py#L36-L84"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the coordinates of Haar-like features.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>widthint</code> </dt>
<dd>
<p>Width of the detection window.</p> </dd> <dt>
<code>heightint</code> </dt>
<dd>
<p>Height of the detection window.</p> </dd> <dt>
<code>feature_typestr or list of str or None, optional</code> </dt>
<dd>
<p>The type of feature to consider:</p> <ul class="simple"> <li>‘type-2-x’: 2 rectangles varying along the x axis;</li> <li>‘type-2-y’: 2 rectangles varying along the y axis;</li> <li>‘type-3-x’: 3 rectangles varying along the x axis;</li> <li>‘type-3-y’: 3 rectangles varying along the y axis;</li> <li>‘type-4’: 4 rectangles varying along x and y axis.</li> </ul> <p>By default all features are extracted.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>feature_coord(n_features, n_rectangles, 2, 2), ndarray of list of tuple coord</code> </dt>
<dd>
<p>Coordinates of the rectangles for each feature.</p> </dd> <dt>
<code>feature_type(n_features,), ndarray of str</code> </dt>
<dd>
<p>The corresponding type for each feature.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from skimage.transform import integral_image
&gt;&gt;&gt; from skimage.feature import haar_like_feature_coord
&gt;&gt;&gt; feat_coord, feat_type = haar_like_feature_coord(2, 2, 'type-4')
&gt;&gt;&gt; feat_coord 
array([ list([[(0, 0), (0, 0)], [(0, 1), (0, 1)],
              [(1, 1), (1, 1)], [(1, 0), (1, 0)]])], dtype=object)
&gt;&gt;&gt; feat_type
array(['type-4'], dtype=object)
</pre> </dd>
</dl>   <h2 id="hessian-matrix">hessian_matrix</h2> <dl class="function"> <dt id="skimage.feature.hessian_matrix">
<code>skimage.feature.hessian_matrix(image, sigma=1, mode='constant', cval=0, order='rc')</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L133-L199"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute Hessian matrix.</p> <p>The Hessian matrix is defined as:</p> <pre data-language="python">H = [Hrr Hrc]
    [Hrc Hcc]
</pre> <p>which is computed by convolving the image with the second derivatives of the Gaussian kernel in the respective r- and c-directions.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>sigmafloat</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, which is used as weighting function for the auto-correlation matrix.</p> </dd> <dt>
<code>mode{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</code> </dt>
<dd>
<p>How to handle values outside the image borders.</p> </dd> <dt>
<code>cvalfloat, optional</code> </dt>
<dd>
<p>Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>order{‘rc’, ‘xy’}, optional</code> </dt>
<dd>
<p>This parameter allows for the use of reverse or forward order of the image axes in gradient computation. ‘rc’ indicates the use of the first axis initially (Hrr, Hrc, Hcc), whilst ‘xy’ indicates the usage of the last axis initially (Hxx, Hxy, Hyy)</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Hrrndarray</code> </dt>
<dd>
<p>Element of the Hessian matrix for each pixel in the input image.</p> </dd> <dt>
<code>Hrcndarray</code> </dt>
<dd>
<p>Element of the Hessian matrix for each pixel in the input image.</p> </dd> <dt>
<code>Hccndarray</code> </dt>
<dd>
<p>Element of the Hessian matrix for each pixel in the input image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import hessian_matrix
&gt;&gt;&gt; square = np.zeros((5, 5))
&gt;&gt;&gt; square[2, 2] = 4
&gt;&gt;&gt; Hrr, Hrc, Hcc = hessian_matrix(square, sigma=0.1, order='rc')
&gt;&gt;&gt; Hrc
array([[ 0.,  0.,  0.,  0.,  0.],
       [ 0.,  1.,  0., -1.,  0.],
       [ 0.,  0.,  0.,  0.,  0.],
       [ 0., -1.,  0.,  1.,  0.],
       [ 0.,  0.,  0.,  0.,  0.]])
</pre> </dd>
</dl>   <h2 id="hessian-matrix-det">hessian_matrix_det</h2> <dl class="function"> <dt id="skimage.feature.hessian_matrix_det">
<code>skimage.feature.hessian_matrix_det(image, sigma=1, approximate=True)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L202-L244"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the approximate Hessian Determinant over an image.</p> <p>The 2D approximate method uses box filters over integral images to compute the approximate Hessian Determinant, as described in <a class="reference internal" href="#r48e33a732c34-1" id="id39">[1]</a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagearray</code> </dt>
<dd>
<p>The image over which to compute Hessian Determinant.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, used for the Hessian matrix.</p> </dd> <dt>
<code>approximatebool, optional</code> </dt>
<dd>
<p>If <code>True</code> and the image is 2D, use a much faster approximate computation. This argument has no effect on 3D and higher images.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outarray</code> </dt>
<dd>
<p>The array of the Determinant of Hessians.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>For 2D images when <code>approximate=True</code>, the running time of this method only depends on size of the image. It is independent of <code>sigma</code> as one would expect. The downside is that the result for <code>sigma</code> less than <code>3</code> is not accurate, i.e., not similar to the result obtained if someone computed the Hessian and took its determinant.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r48e33a732c34-1">
<code>1</code> </dt> <dd>
<p>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool, “SURF: Speeded Up Robust Features” <a class="reference external" href="ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf.html">ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf</a></p> </dd> </dl> </dd>
</dl>   <h2 id="hessian-matrix-eigvals">hessian_matrix_eigvals</h2> <dl class="function"> <dt id="skimage.feature.hessian_matrix_eigvals">
<code>skimage.feature.hessian_matrix_eigvals(H_elems)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L384-L413"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute eigenvalues of Hessian matrix.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>H_elemslist of ndarray</code> </dt>
<dd>
<p>The upper-diagonal elements of the Hessian matrix, as returned by <a class="reference internal" href="#skimage.feature.hessian_matrix" title="skimage.feature.hessian_matrix"><code>hessian_matrix</code></a>.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>eigsndarray</code> </dt>
<dd>
<p>The eigenvalues of the Hessian matrix, in decreasing order. The eigenvalues are the leading dimension. That is, <code>eigs[i, j, k]</code> contains the ith-largest eigenvalue at position (j, k).</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import hessian_matrix, hessian_matrix_eigvals
&gt;&gt;&gt; square = np.zeros((5, 5))
&gt;&gt;&gt; square[2, 2] = 4
&gt;&gt;&gt; H_elems = hessian_matrix(square, sigma=0.1, order='rc')
&gt;&gt;&gt; hessian_matrix_eigvals(H_elems)[0]
array([[ 0.,  0.,  2.,  0.,  0.],
       [ 0.,  1.,  0.,  1.,  0.],
       [ 2.,  0., -2.,  0.,  2.],
       [ 0.,  1.,  0.,  1.,  0.],
       [ 0.,  0.,  2.,  0.,  0.]])
</pre> </dd>
</dl>   <h2 id="hog">hog</h2> <dl class="function"> <dt id="skimage.feature.hog">
<code>skimage.feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3), block_norm='L2-Hys', visualize=False, transform_sqrt=False, feature_vector=True, multichannel=None)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/_hog.py#L46-L295"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Extract Histogram of Oriented Gradients (HOG) for a given image.</p> <p>Compute a Histogram of Oriented Gradients (HOG) by</p>  <ol class="arabic simple"> <li>(optional) global image normalization</li> <li>computing the gradient image in <code>row</code> and <code>col</code>
</li> <li>computing gradient histograms</li> <li>normalizing across blocks</li> <li>flattening into a feature vector</li> </ol>  <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>image(M, N[, C]) ndarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>orientationsint, optional</code> </dt>
<dd>
<p>Number of orientation bins.</p> </dd> <dt>
<code>pixels_per_cell2-tuple (int, int), optional</code> </dt>
<dd>
<p>Size (in pixels) of a cell.</p> </dd> <dt>
<code>cells_per_block2-tuple (int, int), optional</code> </dt>
<dd>
<p>Number of cells in each block.</p> </dd> <dt>
<code>block_normstr {‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’}, optional</code> </dt>
<dd>
<p>Block normalization method:</p> <dl class="simple"> <dt>
<code>L1</code> </dt>
<dd>
<p>Normalization using L1-norm.</p> </dd> <dt>
<code>L1-sqrt</code> </dt>
<dd>
<p>Normalization using L1-norm, followed by square root.</p> </dd> <dt>
<code>L2</code> </dt>
<dd>
<p>Normalization using L2-norm.</p> </dd> <dt>
<code>L2-Hys</code> </dt>
<dd>
<p>Normalization using L2-norm, followed by limiting the maximum values to 0.2 (<code>Hys</code> stands for <code>hysteresis</code>) and renormalization using L2-norm. (default) For details, see <a class="reference internal" href="#ra159ccd8c91f-3" id="id41">[3]</a>, <a class="reference internal" href="#ra159ccd8c91f-4" id="id42">[4]</a>.</p> </dd> </dl> </dd> <dt>
<code>visualizebool, optional</code> </dt>
<dd>
<p>Also return an image of the HOG. For each cell and orientation bin, the image contains a line segment that is centered at the cell center, is perpendicular to the midpoint of the range of angles spanned by the orientation bin, and has intensity proportional to the corresponding histogram value.</p> </dd> <dt>
<code>transform_sqrtbool, optional</code> </dt>
<dd>
<p>Apply power law compression to normalize the image before processing. DO NOT use this if the image contains negative values. Also see <code>notes</code> section below.</p> </dd> <dt>
<code>feature_vectorbool, optional</code> </dt>
<dd>
<p>Return the data as a feature vector by calling .ravel() on the result just before returning.</p> </dd> <dt>
<code>multichannelboolean, optional</code> </dt>
<dd>
<p>If True, the last <code>image</code> dimension is considered as a color channel, otherwise as spatial.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>out(n_blocks_row, n_blocks_col, n_cells_row, n_cells_col, n_orient) ndarray</code> </dt>
<dd>
<p>HOG descriptor for the image. If <code>feature_vector</code> is True, a 1D (flattened) array is returned.</p> </dd> <dt>
<code>hog_image(M, N) ndarray, optional</code> </dt>
<dd>
<p>A visualisation of the HOG image. Only provided if <code>visualize</code> is True.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The presented code implements the HOG extraction method from <a class="reference internal" href="#ra159ccd8c91f-2" id="id43">[2]</a> with the following changes: (I) blocks of (3, 3) cells are used ((2, 2) in the paper); (II) no smoothing within cells (Gaussian spatial window with sigma=8pix in the paper); (III) L1 block normalization is used (L2-Hys in the paper).</p> <p>Power law compression, also known as Gamma correction, is used to reduce the effects of shadowing and illumination variations. The compression makes the dark regions lighter. When the kwarg <code>transform_sqrt</code> is set to <code>True</code>, the function computes the square root of each color channel and then applies the hog algorithm to the image.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="ra159ccd8c91f-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients</a></p> </dd> <dt class="label" id="ra159ccd8c91f-2">
<code>2</code> </dt> <dd>
<p>Dalal, N and Triggs, B, Histograms of Oriented Gradients for Human Detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2005 San Diego, CA, USA, <a class="reference external" href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf">https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf</a>, <a class="reference external" href="https://doi.org/10.1109/CVPR.2005.177">DOI:10.1109/CVPR.2005.177</a></p> </dd> <dt class="label" id="ra159ccd8c91f-3">
<code>3</code> </dt> <dd>
<p>Lowe, D.G., Distinctive image features from scale-invatiant keypoints, International Journal of Computer Vision (2004) 60: 91, <a class="reference external" href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf</a>, <a class="reference external" href="https://doi.org/10.1023/B:VISI.0000029664.99615.94">DOI:10.1023/B:VISI.0000029664.99615.94</a></p> </dd> <dt class="label" id="ra159ccd8c91f-4">
<code>4</code> </dt> <dd>
<p>Dalal, N, Finding People in Images and Videos, Human-Computer Interaction [cs.HC], Institut National Polytechnique de Grenoble - INPG, 2006, <a class="reference external" href="https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf">https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf</a></p> </dd> </dl> </dd>
</dl>   <h2 id="local-binary-pattern">local_binary_pattern</h2> <dl class="function"> <dt id="skimage.feature.local_binary_pattern">
<code>skimage.feature.local_binary_pattern(image, P, R, method='default')</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/texture.py#L281-L337"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Gray scale and rotation invariant LBP (Local Binary Patterns).</p> <p>LBP is an invariant descriptor that can be used for texture classification.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image(N, M) array</code> </dt>
<dd>
<p>Graylevel image.</p> </dd> <dt>
<code>Pint</code> </dt>
<dd>
<p>Number of circularly symmetric neighbour set points (quantization of the angular space).</p> </dd> <dt>
<code>Rfloat</code> </dt>
<dd>
<p>Radius of circle (spatial resolution of the operator).</p> </dd> <dt>
<code>method{‘default’, ‘ror’, ‘uniform’, ‘var’}</code> </dt>
<dd>
<p>Method to determine the pattern.</p> <ul class="simple"> <li>
<dl class="simple"> <dt>‘default’: original local binary pattern which is gray scale but not</dt>
<dd>
<p>rotation invariant.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>‘ror’: extension of default implementation which is gray scale and</dt>
<dd>
<p>rotation invariant.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>‘uniform’: improved rotation invariance with uniform patterns and</dt>
<dd>
<p>finer quantization of the angular space which is gray scale and rotation invariant.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>‘nri_uniform’: non rotation-invariant uniform patterns variant</dt>
<dd>
<p>which is only gray scale invariant <a class="reference internal" href="#r648eb9e75080-2" id="id48">[2]</a>.</p> </dd> </dl> </li> <li>
<dl class="simple"> <dt>‘var’: rotation invariant variance measures of the contrast of local</dt>
<dd>
<p>image texture which is rotation but not gray scale invariant.</p> </dd> </dl> </li> </ul> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>output(N, M) array</code> </dt>
<dd>
<p>LBP image.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r648eb9e75080-1">
<code>1</code> </dt> <dd>
<p>Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns. Timo Ojala, Matti Pietikainen, Topi Maenpaa. <a class="reference external" href="http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf">http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf</a>, 2002.</p> </dd> <dt class="label" id="r648eb9e75080-2">
<code>2</code> </dt> <dd>
<p>Face recognition with local binary patterns. Timo Ahonen, Abdenour Hadid, Matti Pietikainen, <a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.214.6851">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.214.6851</a>, 2004.</p> </dd> </dl> </dd>
</dl>   <h2 id="masked-register-translation">masked_register_translation</h2> <dl class="function"> <dt id="skimage.feature.masked_register_translation">
<code>skimage.feature.masked_register_translation(src_image, target_image, src_mask, target_mask=None, overlap_ratio=0.3)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/__init__.py#L33-L41"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p><strong>Deprecated function</strong>. Use <code>skimage.registration.phase_cross_correlation</code> instead.</p> </dd>
</dl>   <h2 id="match-descriptors">match_descriptors</h2> <dl class="function"> <dt id="skimage.feature.match_descriptors">
<code>skimage.feature.match_descriptors(descriptors1, descriptors2, metric=None, p=2, max_distance=inf, cross_check=True, max_ratio=1.0)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/match.py#L5-L97"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Brute-force matching of descriptors.</p> <p>For each descriptor in the first set this matcher finds the closest descriptor in the second set (and vice-versa in the case of enabled cross-checking).</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>descriptors1(M, P) array</code> </dt>
<dd>
<p>Descriptors of size P about M keypoints in the first image.</p> </dd> <dt>
<code>descriptors2(N, P) array</code> </dt>
<dd>
<p>Descriptors of size P about N keypoints in the second image.</p> </dd> <dt>
<code>metric{‘euclidean’, ‘cityblock’, ‘minkowski’, ‘hamming’, …} , optional</code> </dt>
<dd>
<p>The metric to compute the distance between two descriptors. See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html#scipy.spatial.distance.cdist" title="(in SciPy v1.5.4)"><code>scipy.spatial.distance.cdist</code></a> for all possible types. The hamming distance should be used for binary descriptors. By default the L2-norm is used for all descriptors of dtype float or double and the Hamming distance is used for binary descriptors automatically.</p> </dd> <dt>
<code>pint, optional</code> </dt>
<dd>
<p>The p-norm to apply for <code>metric='minkowski'</code>.</p> </dd> <dt>
<code>max_distancefloat, optional</code> </dt>
<dd>
<p>Maximum allowed distance between descriptors of two keypoints in separate images to be regarded as a match.</p> </dd> <dt>
<code>cross_checkbool, optional</code> </dt>
<dd>
<p>If True, the matched keypoints are returned after cross checking i.e. a matched pair (keypoint1, keypoint2) is returned if keypoint2 is the best match for keypoint1 in second image and keypoint1 is the best match for keypoint2 in first image.</p> </dd> <dt>
<code>max_ratiofloat, optional</code> </dt>
<dd>
<p>Maximum ratio of distances between first and second closest descriptor in the second set of descriptors. This threshold is useful to filter ambiguous matches between the two descriptor sets. The choice of this value depends on the statistics of the chosen descriptor, e.g., for SIFT descriptors a value of 0.8 is usually chosen, see D.G. Lowe, “Distinctive Image Features from Scale-Invariant Keypoints”, International Journal of Computer Vision, 2004.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>matches(Q, 2) array</code> </dt>
<dd>
<p>Indices of corresponding matches in first and second set of descriptors, where <code>matches[:, 0]</code> denote the indices in the first and <code>matches[:, 1]</code> the indices in the second set of descriptors.</p> </dd> </dl> </dd> </dl> </dd>
</dl>   <h2 id="match-template">match_template</h2> <dl class="function"> <dt id="skimage.feature.match_template">
<code>skimage.feature.match_template(image, template, pad_input=False, mode='constant', constant_values=0)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/template.py#L31-L179"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Match a template to a 2-D or 3-D image using normalized correlation.</p> <p>The output is an array with values between -1.0 and 1.0. The value at a given position corresponds to the correlation coefficient between the image and the template.</p> <p>For <code>pad_input=True</code> matches correspond to the center and otherwise to the top-left corner of the template. To find the best match you must search for peaks in the response (output) image.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>image(M, N[, D]) array</code> </dt>
<dd>
<p>2-D or 3-D input image.</p> </dd> <dt>
<code>template(m, n[, d]) array</code> </dt>
<dd>
<p>Template to locate. It must be <code>(m &lt;= M, n &lt;= N[, d &lt;= D])</code>.</p> </dd> <dt>
<code>pad_inputbool</code> </dt>
<dd>
<p>If True, pad <code>image</code> so that output is the same size as the image, and output values correspond to the template center. Otherwise, the output is an array with shape <code>(M - m + 1, N - n + 1)</code> for an <code>(M, N)</code> image and an <code>(m, n)</code> template, and matches correspond to origin (top-left corner) of the template.</p> </dd> <dt>
<code>modesee numpy.pad, optional</code> </dt>
<dd>
<p>Padding mode.</p> </dd> <dt>
<code>constant_valuessee numpy.pad, optional</code> </dt>
<dd>
<p>Constant values used in conjunction with <code>mode='constant'</code>.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outputarray</code> </dt>
<dd>
<p>Response image with correlation coefficients.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>Details on the cross-correlation are presented in <a class="reference internal" href="#r7bfca17c0278-1" id="id51">[1]</a>. This implementation uses FFT convolutions of the image and the template. Reference <a class="reference internal" href="#r7bfca17c0278-2" id="id52">[2]</a> presents similar derivations but the approximation presented in this reference is not used in our implementation.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r7bfca17c0278-1">
<code>1</code> </dt> <dd>
<p>J. P. Lewis, “Fast Normalized Cross-Correlation”, Industrial Light and Magic.</p> </dd> <dt class="label" id="r7bfca17c0278-2">
<code>2</code> </dt> <dd>
<p>Briechle and Hanebeck, “Template Matching using Fast Normalized Cross Correlation”, Proceedings of the SPIE (2001). <a class="reference external" href="https://doi.org/10.1117/12.421129">DOI:10.1117/12.421129</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; template = np.zeros((3, 3))
&gt;&gt;&gt; template[1, 1] = 1
&gt;&gt;&gt; template
array([[0., 0., 0.],
       [0., 1., 0.],
       [0., 0., 0.]])
&gt;&gt;&gt; image = np.zeros((6, 6))
&gt;&gt;&gt; image[1, 1] = 1
&gt;&gt;&gt; image[4, 4] = -1
&gt;&gt;&gt; image
array([[ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  1.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0., -1.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.]])
&gt;&gt;&gt; result = match_template(image, template)
&gt;&gt;&gt; np.round(result, 3)
array([[ 1.   , -0.125,  0.   ,  0.   ],
       [-0.125, -0.125,  0.   ,  0.   ],
       [ 0.   ,  0.   ,  0.125,  0.125],
       [ 0.   ,  0.   ,  0.125, -1.   ]])
&gt;&gt;&gt; result = match_template(image, template, pad_input=True)
&gt;&gt;&gt; np.round(result, 3)
array([[-0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ],
       [-0.125,  1.   , -0.125,  0.   ,  0.   ,  0.   ],
       [-0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ],
       [ 0.   ,  0.   ,  0.   ,  0.125,  0.125,  0.125],
       [ 0.   ,  0.   ,  0.   ,  0.125, -1.   ,  0.125],
       [ 0.   ,  0.   ,  0.   ,  0.125,  0.125,  0.125]])
</pre> </dd>
</dl>   <h2 id="multiblock-lbp">multiblock_lbp</h2> <dl class="function"> <dt id="skimage.feature.multiblock_lbp">
<code>skimage.feature.multiblock_lbp(int_image, r, c, width, height)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/texture.py#L340-L383"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Multi-block local binary pattern (MB-LBP).</p> <p>The features are calculated similarly to local binary patterns (LBPs), (See <a class="reference internal" href="#skimage.feature.local_binary_pattern" title="skimage.feature.local_binary_pattern"><code>local_binary_pattern()</code></a>) except that summed blocks are used instead of individual pixel values.</p> <p>MB-LBP is an extension of LBP that can be computed on multiple scales in constant time using the integral image. Nine equally-sized rectangles are used to compute a feature. For each rectangle, the sum of the pixel intensities is computed. Comparisons of these sums to that of the central rectangle determine the feature, similarly to LBP.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>int_image(N, M) array</code> </dt>
<dd>
<p>Integral image.</p> </dd> <dt>
<code>rint</code> </dt>
<dd>
<p>Row-coordinate of top left corner of a rectangle containing feature.</p> </dd> <dt>
<code>cint</code> </dt>
<dd>
<p>Column-coordinate of top left corner of a rectangle containing feature.</p> </dd> <dt>
<code>widthint</code> </dt>
<dd>
<p>Width of one of the 9 equal rectangles that will be used to compute a feature.</p> </dd> <dt>
<code>heightint</code> </dt>
<dd>
<p>Height of one of the 9 equal rectangles that will be used to compute a feature.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outputint</code> </dt>
<dd>
<p>8-bit MB-LBP feature descriptor.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="ra36744213751-1">
<code>1</code> </dt> <dd>
<p>Face Detection Based on Multi-Block LBP Representation. Lun Zhang, Rufeng Chu, Shiming Xiang, Shengcai Liao, Stan Z. Li <a class="reference external" href="http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf">http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf</a></p> </dd> </dl> </dd>
</dl>   <h2 id="multiscale-basic-features">multiscale_basic_features</h2> <dl class="function"> <dt id="skimage.feature.multiscale_basic_features">
<code>skimage.feature.multiscale_basic_features(image, multichannel=False, intensity=True, edges=True, texture=True, sigma_min=0.5, sigma_max=16, num_sigma=None, num_workers=None)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/_basic_features.py#L99-L172"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Local features for a single- or multi-channel nd image.</p> <p>Intensity, gradient intensity and local structure are computed at different scales thanks to Gaussian blurring.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image, which can be grayscale or multichannel.</p> </dd> <dt>
<code>multichannelbool, default False</code> </dt>
<dd>
<p>True if the last dimension corresponds to color channels.</p> </dd> <dt>
<code>intensitybool, default True</code> </dt>
<dd>
<p>If True, pixel intensities averaged over the different scales are added to the feature set.</p> </dd> <dt>
<code>edgesbool, default True</code> </dt>
<dd>
<p>If True, intensities of local gradients averaged over the different scales are added to the feature set.</p> </dd> <dt>
<code>texturebool, default True</code> </dt>
<dd>
<p>If True, eigenvalues of the Hessian matrix after Gaussian blurring at different scales are added to the feature set.</p> </dd> <dt>
<code>sigma_minfloat, optional</code> </dt>
<dd>
<p>Smallest value of the Gaussian kernel used to average local neighbourhoods before extracting features.</p> </dd> <dt>
<code>sigma_maxfloat, optional</code> </dt>
<dd>
<p>Largest value of the Gaussian kernel used to average local neighbourhoods before extracting features.</p> </dd> <dt>
<code>num_sigmaint, optional</code> </dt>
<dd>
<p>Number of values of the Gaussian kernel between sigma_min and sigma_max. If None, sigma_min multiplied by powers of 2 are used.</p> </dd> <dt>
<code>num_workersint or None, optional</code> </dt>
<dd>
<p>The number of parallel threads to use. If set to <code>None</code>, the full set of available cores are used.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>featuresnp.ndarray</code> </dt>
<dd>
<p>Array of shape <code>image.shape + (n_features,)</code></p> </dd> </dl> </dd> </dl> </dd>
</dl>  <h3 id="examples-using-skimage-feature-multiscale-basic-features">Examples using <code>skimage.feature.multiscale_basic_features</code>
</h3> <div class="sphx-glr-thumbcontainer" tooltip="A pixel-based segmentation is computed here using local features based on local intensity, edge...">
<div class="figure align-default" id="id65"> <img alt="Trainable segmentation using local features and random forests" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/segmentation/plot_trainable_segmentation.html#sphx-glr-auto-examples-segmentation-plot-trainable-segmentation-py"><span class="std std-ref">Trainable segmentation using local features and random forests</span></a></span></p> </div> </div>   <h2 id="peak-local-max">peak_local_max</h2> <dl class="function"> <dt id="skimage.feature.peak_local_max">
<code>skimage.feature.peak_local_max(image, min_distance=1, threshold_abs=None, threshold_rel=None, exclude_border=True, indices=True, num_peaks=inf, footprint=None, labels=None, num_peaks_per_label=inf, p_norm=inf)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/peak.py#L113-L319"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Find peaks in an image as coordinate list or boolean mask.</p> <p>Peaks are the local maxima in a region of <code>2 * min_distance + 1</code> (i.e. peaks are separated by at least <code>min_distance</code>).</p> <p>If both <code>threshold_abs</code> and <code>threshold_rel</code> are provided, the maximum of the two is chosen as the minimum intensity threshold of peaks.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.18: </span>Prior to version 0.18, peaks of the same height within a radius of <code>min_distance</code> were all returned, but this could cause unexpected behaviour. From 0.18 onwards, an arbitrary peak within the region is returned. See issue gh-2592.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>min_distanceint, optional</code> </dt>
<dd>
<p>The minimal allowed distance separating peaks. To find the maximum number of peaks, use <code>min_distance=1</code>.</p> </dd> <dt>
<code>threshold_absfloat, optional</code> </dt>
<dd>
<p>Minimum intensity of peaks. By default, the absolute threshold is the minimum intensity of the image.</p> </dd> <dt>
<code>threshold_relfloat, optional</code> </dt>
<dd>
<p>Minimum intensity of peaks, calculated as <code>max(image) * threshold_rel</code>.</p> </dd> <dt>
<code>exclude_borderint, tuple of ints, or bool, optional</code> </dt>
<dd>
<p>If positive integer, <code>exclude_border</code> excludes peaks from within <code>exclude_border</code>-pixels of the border of the image. If tuple of non-negative ints, the length of the tuple must match the input array’s dimensionality. Each element of the tuple will exclude peaks from within <code>exclude_border</code>-pixels of the border of the image along that dimension. If True, takes the <code>min_distance</code> parameter as value. If zero or False, peaks are identified regardless of their distance from the border.</p> </dd> <dt>
<code>indicesbool, optional</code> </dt>
<dd>
<p>If True, the output will be an array representing peak coordinates. The coordinates are sorted according to peaks values (Larger first). If False, the output will be a boolean array shaped as <code>image.shape</code> with peaks present at True elements. <code>indices</code> is deprecated and will be removed in version 0.20. Default behavior will be to always return peak coordinates. You can obtain a mask as shown in the example below.</p> </dd> <dt>
<code>num_peaksint, optional</code> </dt>
<dd>
<p>Maximum number of peaks. When the number of peaks exceeds <code>num_peaks</code>, return <code>num_peaks</code> peaks based on highest peak intensity.</p> </dd> <dt>
<code>footprintndarray of bools, optional</code> </dt>
<dd>
<p>If provided, <code>footprint == 1</code> represents the local region within which to search for peaks at every point in <code>image</code>.</p> </dd> <dt>
<code>labelsndarray of ints, optional</code> </dt>
<dd>
<p>If provided, each unique region <code>labels == value</code> represents a unique region to search for peaks. Zero is reserved for background.</p> </dd> <dt>
<code>num_peaks_per_labelint, optional</code> </dt>
<dd>
<p>Maximum number of peaks for each label.</p> </dd> <dt>
<code>p_normfloat</code> </dt>
<dd>
<p>Which Minkowski p-norm to use. Should be in the range [1, inf]. A finite large p may cause a ValueError if overflow can occur. <code>inf</code> corresponds to the Chebyshev distance and 2 to the Euclidean distance.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outputndarray or ndarray of bools</code> </dt>
<dd>
<ul class="simple"> <li>If <code>indices = True</code> : (row, column, …) coordinates of peaks.</li> <li>If <code>indices = False</code> : Boolean array shaped like <code>image</code>, with peaks represented by True values.</li> </ul> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="#skimage.feature.corner_peaks" title="skimage.feature.corner_peaks"><code>skimage.feature.corner_peaks</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <p>The peak local maximum function returns the coordinates of local peaks (maxima) in an image. Internally, a maximum filter is used for finding local maxima. This operation dilates the original image. After comparison of the dilated and original image, this function returns the coordinates or a mask of the peaks where the dilated image equals the original image.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; img1 = np.zeros((7, 7))
&gt;&gt;&gt; img1[3, 4] = 1
&gt;&gt;&gt; img1[3, 2] = 1.5
&gt;&gt;&gt; img1
array([[0. , 0. , 0. , 0. , 0. , 0. , 0. ],
       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],
       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],
       [0. , 0. , 1.5, 0. , 1. , 0. , 0. ],
       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],
       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],
       [0. , 0. , 0. , 0. , 0. , 0. , 0. ]])
</pre> <pre data-language="python">&gt;&gt;&gt; peak_local_max(img1, min_distance=1)
array([[3, 2],
       [3, 4]])
</pre> <pre data-language="python">&gt;&gt;&gt; peak_local_max(img1, min_distance=2)
array([[3, 2]])
</pre> <pre data-language="python">&gt;&gt;&gt; img2 = np.zeros((20, 20, 20))
&gt;&gt;&gt; img2[10, 10, 10] = 1
&gt;&gt;&gt; img2[15, 15, 15] = 1
&gt;&gt;&gt; peak_idx = peak_local_max(img2, exclude_border=0)
&gt;&gt;&gt; peak_idx
array([[10, 10, 10],
       [15, 15, 15]])
</pre> <pre data-language="python">&gt;&gt;&gt; peak_mask = np.zeros_like(img2, dtype=bool)
&gt;&gt;&gt; peak_mask[tuple(peak_idx.T)] = True
&gt;&gt;&gt; np.argwhere(peak_mask)
array([[10, 10, 10],
       [15, 15, 15]])
</pre> </dd>
</dl>  <h3 id="examples-using-skimage-feature-peak-local-max">Examples using <code>skimage.feature.peak_local_max</code>
</h3> <div class="sphx-glr-thumbcontainer" tooltip="The peak_local_max function returns the coordinates of local peaks (maxima) in an image. Intern...">
<div class="figure align-default" id="id66"> <img alt="Finding local maxima" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/segmentation/plot_peak_local_max.html#sphx-glr-auto-examples-segmentation-plot-peak-local-max-py"><span class="std std-ref">Finding local maxima</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="The watershed is a classical algorithm used for **segmentation**, that is, for separating diffe...">
<div class="figure align-default" id="id67"> <img alt="Watershed segmentation" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/segmentation/plot_watershed.html#sphx-glr-auto-examples-segmentation-plot-watershed-py"><span class="std std-ref">Watershed segmentation</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we analyze a microscopy image of human cells. We use data provided by Jason Mo...">
<div class="figure align-default" id="id68"> <img alt="Segment human cells (in mitosis)" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="https://scikit-image.org/docs/0.18.x/auto_examples/applications/plot_human_mitosis.html#sphx-glr-auto-examples-applications-plot-human-mitosis-py"><span class="std std-ref">Segment human cells (in mitosis)</span></a></span></p> </div> </div>   <h2 id="plot-matches">plot_matches</h2> <dl class="function"> <dt id="skimage.feature.plot_matches">
<code>skimage.feature.plot_matches(ax, image1, image2, keypoints1, keypoints2, matches, keypoints_color='k', matches_color=None, only_matches=False, alignment='horizontal')</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/util.py#L43-L137"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Plot matched features.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>axmatplotlib.axes.Axes</code> </dt>
<dd>
<p>Matches and image are drawn in this ax.</p> </dd> <dt>
<code>image1(N, M [, 3]) array</code> </dt>
<dd>
<p>First grayscale or color image.</p> </dd> <dt>
<code>image2(N, M [, 3]) array</code> </dt>
<dd>
<p>Second grayscale or color image.</p> </dd> <dt>
<code>keypoints1(K1, 2) array</code> </dt>
<dd>
<p>First keypoint coordinates as <code>(row, col)</code>.</p> </dd> <dt>
<code>keypoints2(K2, 2) array</code> </dt>
<dd>
<p>Second keypoint coordinates as <code>(row, col)</code>.</p> </dd> <dt>
<code>matches(Q, 2) array</code> </dt>
<dd>
<p>Indices of corresponding matches in first and second set of descriptors, where <code>matches[:, 0]</code> denote the indices in the first and <code>matches[:, 1]</code> the indices in the second set of descriptors.</p> </dd> <dt>
<code>keypoints_colormatplotlib color, optional</code> </dt>
<dd>
<p>Color for keypoint locations.</p> </dd> <dt>
<code>matches_colormatplotlib color, optional</code> </dt>
<dd>
<p>Color for lines which connect keypoint matches. By default the color is chosen randomly.</p> </dd> <dt>
<code>only_matchesbool, optional</code> </dt>
<dd>
<p>Whether to only plot matches and not plot the keypoint locations.</p> </dd> <dt>
<code>alignment{‘horizontal’, ‘vertical’}, optional</code> </dt>
<dd>
<p>Whether to show images side by side, <code>'horizontal'</code>, or one above the other, <code>'vertical'</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl>   <h2 id="register-translation">register_translation</h2> <dl class="function"> <dt id="skimage.feature.register_translation">
<code>skimage.feature.register_translation(src_image, target_image, upsample_factor=1, space='real', return_error=True)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/__init__.py#L44-L51"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p><strong>Deprecated function</strong>. Use <code>skimage.registration.phase_cross_correlation</code> instead.</p> </dd>
</dl>   <h2 id="shape-index">shape_index</h2> <dl class="function"> <dt id="skimage.feature.shape_index">
<code>skimage.feature.shape_index(image, sigma=1, mode='constant', cval=0)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L416-L485"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the shape index.</p> <p>The shape index, as defined by Koenderink &amp; van Doorn <a class="reference internal" href="#rc8faae48965f-1" id="id56">[1]</a>, is a single valued measure of local curvature, assuming the image as a 3D plane with intensities representing heights.</p> <p>It is derived from the eigen values of the Hessian, and its value ranges from -1 to 1 (and is undefined (=NaN) in <em>flat</em> regions), with following ranges representing following shapes:</p> <table class="docutils align-default" id="id69"> <caption><span class="caption-text">Ranges of the shape index and corresponding shapes.</span></caption>  <thead> <tr>
<th class="head"><p>Interval (s in …)</p></th> <th class="head"><p>Shape</p></th> </tr> </thead>  <tr>
<td><p>[ -1, -7/8)</p></td> <td><p>Spherical cup</p></td> </tr> <tr>
<td><p>[-7/8, -5/8)</p></td> <td><p>Through</p></td> </tr> <tr>
<td><p>[-5/8, -3/8)</p></td> <td><p>Rut</p></td> </tr> <tr>
<td><p>[-3/8, -1/8)</p></td> <td><p>Saddle rut</p></td> </tr> <tr>
<td><p>[-1/8, +1/8)</p></td> <td><p>Saddle</p></td> </tr> <tr>
<td><p>[+1/8, +3/8)</p></td> <td><p>Saddle ridge</p></td> </tr> <tr>
<td><p>[+3/8, +5/8)</p></td> <td><p>Ridge</p></td> </tr> <tr>
<td><p>[+5/8, +7/8)</p></td> <td><p>Dome</p></td> </tr> <tr>
<td><p>[+7/8, +1]</p></td> <td><p>Spherical cap</p></td> </tr>  </table> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, which is used for smoothing the input data before Hessian eigen value calculation.</p> </dd> <dt>
<code>mode{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</code> </dt>
<dd>
<p>How to handle values outside the image borders</p> </dd> <dt>
<code>cvalfloat, optional</code> </dt>
<dd>
<p>Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>sndarray</code> </dt>
<dd>
<p>Shape index</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rc8faae48965f-1">
<code>1</code> </dt> <dd>
<p>Koenderink, J. J. &amp; van Doorn, A. J., “Surface shape and curvature scales”, Image and Vision Computing, 1992, 10, 557-564. <a class="reference external" href="https://doi.org/10.1016/0262-8856(92)90076-F">DOI:10.1016/0262-8856(92)90076-F</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import shape_index
&gt;&gt;&gt; square = np.zeros((5, 5))
&gt;&gt;&gt; square[2, 2] = 4
&gt;&gt;&gt; s = shape_index(square, sigma=0.1)
&gt;&gt;&gt; s
array([[ nan,  nan, -0.5,  nan,  nan],
       [ nan, -0. ,  nan, -0. ,  nan],
       [-0.5,  nan, -1. ,  nan, -0.5],
       [ nan, -0. ,  nan, -0. ,  nan],
       [ nan,  nan, -0.5,  nan,  nan]])
</pre> </dd>
</dl>   <h2 id="structure-tensor">structure_tensor</h2> <dl class="function"> <dt id="skimage.feature.structure_tensor">
<code>skimage.feature.structure_tensor(image, sigma=1, mode='constant', cval=0, order=None)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L45-L130"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute structure tensor using sum of squared differences.</p> <p>The (2-dimensional) structure tensor A is defined as:</p> <pre data-language="python">A = [Arr Arc]
    [Arc Acc]
</pre> <p>which is approximated by the weighted sum of squared differences in a local window around each pixel in the image. This formula can be extended to a larger number of dimensions (see <a class="reference internal" href="#r0bb93eb224ab-1" id="id58">[1]</a>).</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>imagendarray</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation used for the Gaussian kernel, which is used as a weighting function for the local summation of squared differences.</p> </dd> <dt>
<code>mode{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</code> </dt>
<dd>
<p>How to handle values outside the image borders.</p> </dd> <dt>
<code>cvalfloat, optional</code> </dt>
<dd>
<p>Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>order{‘rc’, ‘xy’}, optional</code> </dt>
<dd>
<p>NOTE: Only applies in 2D. Higher dimensions must always use ‘rc’ order. This parameter allows for the use of reverse or forward order of the image axes in gradient computation. ‘rc’ indicates the use of the first axis initially (Arr, Arc, Acc), whilst ‘xy’ indicates the usage of the last axis initially (Axx, Axy, Ayy).</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>A_elemslist of ndarray</code> </dt>
<dd>
<p>Upper-diagonal elements of the structure tensor for each pixel in the input image.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="#skimage.feature.structure_tensor_eigenvalues" title="skimage.feature.structure_tensor_eigenvalues"><code>structure_tensor_eigenvalues</code></a>
</dt>
 </dl> </div> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="r0bb93eb224ab-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Structure_tensor">https://en.wikipedia.org/wiki/Structure_tensor</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import structure_tensor
&gt;&gt;&gt; square = np.zeros((5, 5))
&gt;&gt;&gt; square[2, 2] = 1
&gt;&gt;&gt; Arr, Arc, Acc = structure_tensor(square, sigma=0.1, order='rc')
&gt;&gt;&gt; Acc
array([[0., 0., 0., 0., 0.],
       [0., 1., 0., 1., 0.],
       [0., 4., 0., 4., 0.],
       [0., 1., 0., 1., 0.],
       [0., 0., 0., 0., 0.]])
</pre> </dd>
</dl>   <h2 id="structure-tensor-eigenvalues">structure_tensor_eigenvalues</h2> <dl class="function"> <dt id="skimage.feature.structure_tensor_eigenvalues">
<code>skimage.feature.structure_tensor_eigenvalues(A_elems)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L306-L340"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute eigenvalues of structure tensor.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>A_elemslist of ndarray</code> </dt>
<dd>
<p>The upper-diagonal elements of the structure tensor, as returned by <a class="reference internal" href="#skimage.feature.structure_tensor" title="skimage.feature.structure_tensor"><code>structure_tensor</code></a>.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>ndarray</dt>
<dd>
<p>The eigenvalues of the structure tensor, in decreasing order. The eigenvalues are the leading dimension. That is, the coordinate [i, j, k] corresponds to the ith-largest eigenvalue at position (j, k).</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="#skimage.feature.structure_tensor" title="skimage.feature.structure_tensor"><code>structure_tensor</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import structure_tensor
&gt;&gt;&gt; from skimage.feature import structure_tensor_eigenvalues
&gt;&gt;&gt; square = np.zeros((5, 5))
&gt;&gt;&gt; square[2, 2] = 1
&gt;&gt;&gt; A_elems = structure_tensor(square, sigma=0.1, order='rc')
&gt;&gt;&gt; structure_tensor_eigenvalues(A_elems)[0]
array([[0., 0., 0., 0., 0.],
       [0., 2., 4., 2., 0.],
       [0., 4., 0., 4., 0.],
       [0., 2., 4., 2., 0.],
       [0., 0., 0., 0., 0.]])
</pre> </dd>
</dl>   <h2 id="structure-tensor-eigvals">structure_tensor_eigvals</h2> <dl class="function"> <dt id="skimage.feature.structure_tensor_eigvals">
<code>skimage.feature.structure_tensor_eigvals(Axx, Axy, Ayy)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/corner.py#L343-L381"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute eigenvalues of structure tensor.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Axxndarray</code> </dt>
<dd>
<p>Element of the structure tensor for each pixel in the input image.</p> </dd> <dt>
<code>Axyndarray</code> </dt>
<dd>
<p>Element of the structure tensor for each pixel in the input image.</p> </dd> <dt>
<code>Ayyndarray</code> </dt>
<dd>
<p>Element of the structure tensor for each pixel in the input image.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>l1ndarray</code> </dt>
<dd>
<p>Larger eigen value for each input matrix.</p> </dd> <dt>
<code>l2ndarray</code> </dt>
<dd>
<p>Smaller eigen value for each input matrix.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import structure_tensor, structure_tensor_eigvals
&gt;&gt;&gt; square = np.zeros((5, 5))
&gt;&gt;&gt; square[2, 2] = 1
&gt;&gt;&gt; Arr, Arc, Acc = structure_tensor(square, sigma=0.1, order='rc')
&gt;&gt;&gt; structure_tensor_eigvals(Acc, Arc, Arr)[0]
array([[0., 0., 0., 0., 0.],
       [0., 2., 4., 2., 0.],
       [0., 4., 0., 4., 0.],
       [0., 2., 4., 2., 0.],
       [0., 0., 0., 0., 0.]])
</pre> </dd>
</dl>   <h2 id="brief">BRIEF</h2> <dl class="class"> <dt id="skimage.feature.BRIEF">
<code>class skimage.feature.BRIEF(descriptor_size=256, patch_size=49, mode='normal', sigma=1, sample_seed=1)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/brief.py#L11-L184"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.feature.util.DescriptorExtractor</code></p> <p>BRIEF binary descriptor extractor.</p> <p>BRIEF (Binary Robust Independent Elementary Features) is an efficient feature point descriptor. It is highly discriminative even when using relatively few bits and is computed using simple intensity difference tests.</p> <p>For each keypoint, intensity comparisons are carried out for a specifically distributed number N of pixel-pairs resulting in a binary descriptor of length N. For binary descriptors the Hamming distance can be used for feature matching, which leads to lower computational cost in comparison to the L2 norm.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>descriptor_sizeint, optional</code> </dt>
<dd>
<p>Size of BRIEF descriptor for each keypoint. Sizes 128, 256 and 512 recommended by the authors. Default is 256.</p> </dd> <dt>
<code>patch_sizeint, optional</code> </dt>
<dd>
<p>Length of the two dimensional square patch sampling region around the keypoints. Default is 49.</p> </dd> <dt>
<code>mode{‘normal’, ‘uniform’}, optional</code> </dt>
<dd>
<p>Probability distribution for sampling location of decision pixel-pairs around keypoints.</p> </dd> <dt>
<code>sample_seedint, optional</code> </dt>
<dd>
<p>Seed for the random sampling of the decision pixel-pairs. From a square window with length <code>patch_size</code>, pixel pairs are sampled using the <code>mode</code> parameter to build the descriptors using intensity comparison. The value of <code>sample_seed</code> must be the same for the images to be matched while building the descriptors.</p> </dd> <dt>
<code>sigmafloat, optional</code> </dt>
<dd>
<p>Standard deviation of the Gaussian low-pass filter applied to the image to alleviate noise sensitivity, which is strongly recommended to obtain discriminative and good descriptors.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import (corner_harris, corner_peaks, BRIEF,
...                              match_descriptors)
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; square1 = np.zeros((8, 8), dtype=np.int32)
&gt;&gt;&gt; square1[2:6, 2:6] = 1
&gt;&gt;&gt; square1
array([[0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)
&gt;&gt;&gt; square2 = np.zeros((9, 9), dtype=np.int32)
&gt;&gt;&gt; square2[2:7, 2:7] = 1
&gt;&gt;&gt; square2
array([[0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 1, 1, 1, 1, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)
&gt;&gt;&gt; keypoints1 = corner_peaks(corner_harris(square1), min_distance=1)
&gt;&gt;&gt; keypoints2 = corner_peaks(corner_harris(square2), min_distance=1)
&gt;&gt;&gt; extractor = BRIEF(patch_size=5)
&gt;&gt;&gt; extractor.extract(square1, keypoints1)
&gt;&gt;&gt; descriptors1 = extractor.descriptors
&gt;&gt;&gt; extractor.extract(square2, keypoints2)
&gt;&gt;&gt; descriptors2 = extractor.descriptors
&gt;&gt;&gt; matches = match_descriptors(descriptors1, descriptors2)
&gt;&gt;&gt; matches
array([[0, 0],
       [1, 1],
       [2, 2],
       [3, 3]])
&gt;&gt;&gt; keypoints1[matches[:, 0]]
array([[2, 2],
       [2, 5],
       [5, 2],
       [5, 5]])
&gt;&gt;&gt; keypoints2[matches[:, 1]]
array([[2, 2],
       [2, 6],
       [6, 2],
       [6, 6]])
</pre> <dl class="field-list"> <dt class="field-odd">Attributes</dt> <dd class="field-odd">
<dl> <dt>
<code>descriptors(Q, descriptor_size) array of dtype bool</code> </dt>
<dd>
<p>2D ndarray of binary descriptors of size <code>descriptor_size</code> for Q keypoints after filtering out border keypoints with value at an index <code>(i, j)</code> either being <code>True</code> or <code>False</code> representing the outcome of the intensity comparison for i-th keypoint on j-th decision pixel-pair. It is <code>Q == np.sum(mask)</code>.</p> </dd> <dt>
<code>mask(N, ) array of dtype bool</code> </dt>
<dd>
<p>Mask indicating whether a keypoint has been filtered out (<code>False</code>) or is described in the <code>descriptors</code> array (<code>True</code>).</p> </dd> </dl> </dd> </dl> <dl class="method"> <dt id="skimage.feature.BRIEF.__init__">
<code>__init__(descriptor_size=256, patch_size=49, mode='normal', sigma=1, sample_seed=1)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/brief.py#L114-L128"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.feature.BRIEF.extract">
<code>extract(image, keypoints)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/brief.py#L130-L184"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Extract BRIEF binary descriptors for given keypoints in image.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D array</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>keypoints(N, 2) array</code> </dt>
<dd>
<p>Keypoint coordinates as <code>(row, col)</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl>   <h2 id="censure">CENSURE</h2> <dl class="class"> <dt id="skimage.feature.CENSURE">
<code>class skimage.feature.CENSURE(min_scale=1, max_scale=7, mode='DoB', non_max_threshold=0.15, line_threshold=10)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/censure.py#L111-L296"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.feature.util.FeatureDetector</code></p> <p>CENSURE keypoint detector.</p> <dl class="simple"> <dt>
<code>min_scaleint, optional</code> </dt>
<dd>
<p>Minimum scale to extract keypoints from.</p> </dd> <dt>
<code>max_scaleint, optional</code> </dt>
<dd>
<p>Maximum scale to extract keypoints from. The keypoints will be extracted from all the scales except the first and the last i.e. from the scales in the range [min_scale + 1, max_scale - 1]. The filter sizes for different scales is such that the two adjacent scales comprise of an octave.</p> </dd> <dt>
<code>mode{‘DoB’, ‘Octagon’, ‘STAR’}, optional</code> </dt>
<dd>
<p>Type of bi-level filter used to get the scales of the input image. Possible values are ‘DoB’, ‘Octagon’ and ‘STAR’. The three modes represent the shape of the bi-level filters i.e. box(square), octagon and star respectively. For instance, a bi-level octagon filter consists of a smaller inner octagon and a larger outer octagon with the filter weights being uniformly negative in both the inner octagon while uniformly positive in the difference region. Use STAR and Octagon for better features and DoB for better performance.</p> </dd> <dt>
<code>non_max_thresholdfloat, optional</code> </dt>
<dd>
<p>Threshold value used to suppress maximas and minimas with a weak magnitude response obtained after Non-Maximal Suppression.</p> </dd> <dt>
<code>line_thresholdfloat, optional</code> </dt>
<dd>
<p>Threshold for rejecting interest points which have ratio of principal curvatures greater than this value.</p> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="recc8560c357f-1">
<code>1</code> </dt> <dd>
<p>Motilal Agrawal, Kurt Konolige and Morten Rufus Blas “CENSURE: Center Surround Extremas for Realtime Feature Detection and Matching”, <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-540-88693-8_8">https://link.springer.com/chapter/10.1007/978-3-540-88693-8_8</a> <a class="reference external" href="https://doi.org/10.1007/978-3-540-88693-8_8">DOI:10.1007/978-3-540-88693-8_8</a></p> </dd> <dt class="label" id="recc8560c357f-2">
<code>2</code> </dt> <dd>
<p>Adam Schmidt, Marek Kraft, Michal Fularz and Zuzanna Domagala “Comparative Assessment of Point Feature Detectors and Descriptors in the Context of Robot Navigation” <a class="reference external" href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-268aaf28-0faf-4872-a4df-7e2e61cb364c/c/Schmidt_comparative.pdf">http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-268aaf28-0faf-4872-a4df-7e2e61cb364c/c/Schmidt_comparative.pdf</a> <a class="reference external" href="https://doi.org/10.1.1.465.1117">DOI:10.1.1.465.1117</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.data import astronaut
&gt;&gt;&gt; from skimage.color import rgb2gray
&gt;&gt;&gt; from skimage.feature import CENSURE
&gt;&gt;&gt; img = rgb2gray(astronaut()[100:300, 100:300])
&gt;&gt;&gt; censure = CENSURE()
&gt;&gt;&gt; censure.detect(img)
&gt;&gt;&gt; censure.keypoints
array([[  4, 148],
       [ 12,  73],
       [ 21, 176],
       [ 91,  22],
       [ 93,  56],
       [ 94,  22],
       [ 95,  54],
       [100,  51],
       [103,  51],
       [106,  67],
       [108,  15],
       [117,  20],
       [122,  60],
       [125,  37],
       [129,  37],
       [133,  76],
       [145,  44],
       [146,  94],
       [150, 114],
       [153,  33],
       [154, 156],
       [155, 151],
       [184,  63]])
&gt;&gt;&gt; censure.scales
array([2, 6, 6, 2, 4, 3, 2, 3, 2, 6, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 4, 2,
       2])
</pre> <dl class="field-list simple"> <dt class="field-odd">Attributes</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>keypoints(N, 2) array</code> </dt>
<dd>
<p>Keypoint coordinates as <code>(row, col)</code>.</p> </dd> <dt>
<code>scales(N, ) array</code> </dt>
<dd>
<p>Corresponding scales.</p> </dd> </dl> </dd> </dl> <dl class="method"> <dt id="skimage.feature.CENSURE.__init__">
<code>__init__(min_scale=1, max_scale=7, mode='DoB', non_max_threshold=0.15, line_threshold=10)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/censure.py#L198-L216"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.feature.CENSURE.detect">
<code>detect(image)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/censure.py#L218-L296"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Detect CENSURE keypoints along with the corresponding scale.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D ndarray</code> </dt>
<dd>
<p>Input image.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl>   <h2 id="cascade">Cascade</h2> <dl class="class"> <dt id="skimage.feature.Cascade">
<code>class skimage.feature.Cascade</code> </dt> <dd>
<p>Bases: <a class="reference external" href="https://docs.python.org/3.9/library/functions.html#object" title="(in Python v3.9)"><code>object</code></a></p> <p>Class for cascade of classifiers that is used for object detection.</p> <p>The main idea behind cascade of classifiers is to create classifiers of medium accuracy and ensemble them into one strong classifier instead of just creating a strong one. The second advantage of cascade classifier is that easy examples can be classified only by evaluating some of the classifiers in the cascade, making the process much faster than the process of evaluating a one strong classifier.</p> <dl class="field-list simple"> <dt class="field-odd">Attributes</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>epscnp.float32_t</code> </dt>
<dd>
<p>Accuracy parameter. Increasing it, makes the classifier detect less false positives but at the same time the false negative score increases.</p> </dd> <dt>
<code>stages_numberPy_ssize_t</code> </dt>
<dd>
<p>Amount of stages in a cascade. Each cascade consists of stumps i.e. trained features.</p> </dd> <dt>
<code>stumps_numberPy_ssize_t</code> </dt>
<dd>
<p>The overall amount of stumps in all the stages of cascade.</p> </dd> <dt>
<code>features_numberPy_ssize_t</code> </dt>
<dd>
<p>The overall amount of different features used by cascade. Two stumps can use the same features but has different trained values.</p> </dd> <dt>
<code>window_widthPy_ssize_t</code> </dt>
<dd>
<p>The width of a detection window that is used. Objects smaller than this window can’t be detected.</p> </dd> <dt>
<code>window_heightPy_ssize_t</code> </dt>
<dd>
<p>The height of a detection window.</p> </dd> <dt>
<code>stagesStage*</code> </dt>
<dd>
<p>A link to the c array that stores stages information using Stage struct.</p> </dd> <dt>
<code>featuresMBLBP*</code> </dt>
<dd>
<p>Link to the c array that stores MBLBP features using MBLBP struct.</p> </dd> <dt>
<code>LUTscnp.uint32_t*</code> </dt>
<dd>
<p>The ling to the array with look-up tables that are used by trained MBLBP features (MBLBPStumps) to evaluate a particular region.</p> </dd> </dl> </dd> </dl> <dl class="method"> <dt id="skimage.feature.Cascade.__init__">
<code>__init__()</code> </dt> <dd>
<p>Initialize cascade classifier.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>xml_filefile’s path or file’s object</code> </dt>
<dd>
<p>A file in a OpenCv format from which all the cascade classifier’s parameters are loaded.</p> </dd> <dt>
<code>epscnp.float32_t</code> </dt>
<dd>
<p>Accuracy parameter. Increasing it, makes the classifier detect less false positives but at the same time the false negative score increases.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="method"> <dt id="skimage.feature.Cascade.detect_multi_scale">
<code>detect_multi_scale()</code> </dt> <dd>
<p>Search for the object on multiple scales of input image.</p> <p>The function takes the input image, the scale factor by which the searching window is multiplied on each step, minimum window size and maximum window size that specify the interval for the search windows that are applied to the input image to detect objects.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>img2-D or 3-D ndarray</code> </dt>
<dd>
<p>Ndarray that represents the input image.</p> </dd> <dt>
<code>scale_factorcnp.float32_t</code> </dt>
<dd>
<p>The scale by which searching window is multiplied on each step.</p> </dd> <dt>
<code>step_ratiocnp.float32_t</code> </dt>
<dd>
<p>The ratio by which the search step in multiplied on each scale of the image. 1 represents the exaustive search and usually is slow. By setting this parameter to higher values the results will be worse but the computation will be much faster. Usually, values in the interval [1, 1.5] give good results.</p> </dd> <dt>
<code>min_sizetyple (int, int)</code> </dt>
<dd>
<p>Minimum size of the search window.</p> </dd> <dt>
<code>max_sizetyple (int, int)</code> </dt>
<dd>
<p>Maximum size of the search window.</p> </dd> <dt>
<code>min_neighbour_numberint</code> </dt>
<dd>
<p>Minimum amount of intersecting detections in order for detection to be approved by the function.</p> </dd> <dt>
<code>intersection_score_thresholdcnp.float32_t</code> </dt>
<dd>
<p>The minimum value of value of ratio (intersection area) / (small rectangle ratio) in order to merge two detections into one.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>outputlist of dicts</code> </dt>
<dd>
<p>Dict have form {‘r’: int, ‘c’: int, ‘width’: int, ‘height’: int}, where ‘r’ represents row position of top left corner of detected window, ‘c’ - col position, ‘width’ - width of detected window, ‘height’ - height of detected window.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="attribute"> <dt id="skimage.feature.Cascade.eps">
<code>eps</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.feature.Cascade.features_number">
<code>features_number</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.feature.Cascade.stages_number">
<code>stages_number</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.feature.Cascade.stumps_number">
<code>stumps_number</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.feature.Cascade.window_height">
<code>window_height</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.feature.Cascade.window_width">
<code>window_width</code> </dt> 
</dl> </dd>
</dl>   <h2 id="orb">ORB</h2> <dl class="class"> <dt id="skimage.feature.ORB">
<code>class skimage.feature.ORB(downscale=1.2, n_scales=8, n_keypoints=500, fast_n=9, fast_threshold=0.08, harris_k=0.04)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/orb.py#L22-L348"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.feature.util.FeatureDetector</code>, <code>skimage.feature.util.DescriptorExtractor</code></p> <p>Oriented FAST and rotated BRIEF feature detector and binary descriptor extractor.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>n_keypointsint, optional</code> </dt>
<dd>
<p>Number of keypoints to be returned. The function will return the best <code>n_keypoints</code> according to the Harris corner response if more than <code>n_keypoints</code> are detected. If not, then all the detected keypoints are returned.</p> </dd> <dt>
<code>fast_nint, optional</code> </dt>
<dd>
<p>The <code>n</code> parameter in <a class="reference internal" href="#skimage.feature.corner_fast" title="skimage.feature.corner_fast"><code>skimage.feature.corner_fast</code></a>. Minimum number of consecutive pixels out of 16 pixels on the circle that should all be either brighter or darker w.r.t test-pixel. A point c on the circle is darker w.r.t test pixel p if <code>Ic &lt; Ip - threshold</code> and brighter if <code>Ic &gt; Ip + threshold</code>. Also stands for the n in <code>FAST-n</code> corner detector.</p> </dd> <dt>
<code>fast_thresholdfloat, optional</code> </dt>
<dd>
<p>The <code>threshold</code> parameter in <code>feature.corner_fast</code>. Threshold used to decide whether the pixels on the circle are brighter, darker or similar w.r.t. the test pixel. Decrease the threshold when more corners are desired and vice-versa.</p> </dd> <dt>
<code>harris_kfloat, optional</code> </dt>
<dd>
<p>The <code>k</code> parameter in <a class="reference internal" href="#skimage.feature.corner_harris" title="skimage.feature.corner_harris"><code>skimage.feature.corner_harris</code></a>. Sensitivity factor to separate corners from edges, typically in range <code>[0, 0.2]</code>. Small values of <code>k</code> result in detection of sharp corners.</p> </dd> <dt>
<code>downscalefloat, optional</code> </dt>
<dd>
<p>Downscale factor for the image pyramid. Default value 1.2 is chosen so that there are more dense scales which enable robust scale invariance for a subsequent feature description.</p> </dd> <dt>
<code>n_scalesint, optional</code> </dt>
<dd>
<p>Maximum number of scales from the bottom of the image pyramid to extract the features from.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rb3ecaf5c48ec-1">
<code>1</code> </dt> <dd>
<p>Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski “ORB: An efficient alternative to SIFT and SURF” <a class="reference external" href="http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf">http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf</a></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.feature import ORB, match_descriptors
&gt;&gt;&gt; img1 = np.zeros((100, 100))
&gt;&gt;&gt; img2 = np.zeros_like(img1)
&gt;&gt;&gt; np.random.seed(1)
&gt;&gt;&gt; square = np.random.rand(20, 20)
&gt;&gt;&gt; img1[40:60, 40:60] = square
&gt;&gt;&gt; img2[53:73, 53:73] = square
&gt;&gt;&gt; detector_extractor1 = ORB(n_keypoints=5)
&gt;&gt;&gt; detector_extractor2 = ORB(n_keypoints=5)
&gt;&gt;&gt; detector_extractor1.detect_and_extract(img1)
&gt;&gt;&gt; detector_extractor2.detect_and_extract(img2)
&gt;&gt;&gt; matches = match_descriptors(detector_extractor1.descriptors,
...                             detector_extractor2.descriptors)
&gt;&gt;&gt; matches
array([[0, 0],
       [1, 1],
       [2, 2],
       [3, 3],
       [4, 4]])
&gt;&gt;&gt; detector_extractor1.keypoints[matches[:, 0]]
array([[42., 40.],
       [47., 58.],
       [44., 40.],
       [59., 42.],
       [45., 44.]])
&gt;&gt;&gt; detector_extractor2.keypoints[matches[:, 1]]
array([[55., 53.],
       [60., 71.],
       [57., 53.],
       [72., 55.],
       [58., 57.]])
</pre> <dl class="field-list"> <dt class="field-odd">Attributes</dt> <dd class="field-odd">
<dl> <dt>
<code>keypoints(N, 2) array</code> </dt>
<dd>
<p>Keypoint coordinates as <code>(row, col)</code>.</p> </dd> <dt>
<code>scales(N, ) array</code> </dt>
<dd>
<p>Corresponding scales.</p> </dd> <dt>
<code>orientations(N, ) array</code> </dt>
<dd>
<p>Corresponding orientations in radians.</p> </dd> <dt>
<code>responses(N, ) array</code> </dt>
<dd>
<p>Corresponding Harris corner responses.</p> </dd> <dt>
<code>descriptors(Q, descriptor_size) array of dtype bool</code> </dt>
<dd>
<p>2D array of binary descriptors of size <code>descriptor_size</code> for Q keypoints after filtering out border keypoints with value at an index <code>(i, j)</code> either being <code>True</code> or <code>False</code> representing the outcome of the intensity comparison for i-th keypoint on j-th decision pixel-pair. It is <code>Q == np.sum(mask)</code>.</p> </dd> </dl> </dd> </dl> <dl class="method"> <dt id="skimage.feature.ORB.__init__">
<code>__init__(downscale=1.2, n_scales=8, n_keypoints=500, fast_n=9, fast_threshold=0.08, harris_k=0.04)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/orb.py#L117-L131"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.feature.ORB.detect">
<code>detect(image)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/orb.py#L163-L211"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Detect oriented FAST keypoints along with the corresponding scale.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D array</code> </dt>
<dd>
<p>Input image.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="method"> <dt id="skimage.feature.ORB.detect_and_extract">
<code>detect_and_extract(image)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/orb.py#L278-L348"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Detect oriented FAST keypoints and extract rBRIEF descriptors.</p> <p>Note that this is faster than first calling <a class="reference internal" href="#skimage.feature.ORB.detect" title="skimage.feature.ORB.detect"><code>detect</code></a> and then <a class="reference internal" href="#skimage.feature.ORB.extract" title="skimage.feature.ORB.extract"><code>extract</code></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D array</code> </dt>
<dd>
<p>Input image.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="method"> <dt id="skimage.feature.ORB.extract">
<code>extract(image, keypoints, scales, orientations)</code> <a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/feature/orb.py#L225-L276"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Extract rBRIEF binary descriptors for given keypoints in image.</p> <p>Note that the keypoints must be extracted using the same <code>downscale</code> and <code>n_scales</code> parameters. Additionally, if you want to extract both keypoints and descriptors you should use the faster <a class="reference internal" href="#skimage.feature.ORB.detect_and_extract" title="skimage.feature.ORB.detect_and_extract"><code>detect_and_extract</code></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>image2D array</code> </dt>
<dd>
<p>Input image.</p> </dd> <dt>
<code>keypoints(N, 2) array</code> </dt>
<dd>
<p>Keypoint coordinates as <code>(row, col)</code>.</p> </dd> <dt>
<code>scales(N, ) array</code> </dt>
<dd>
<p>Corresponding scales.</p> </dd> <dt>
<code>orientations(N, ) array</code> </dt>
<dd>
<p>Corresponding orientations in radians.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 the scikit-image team<br>Licensed under the BSD 3-clause License.<br>
    <a href="https://scikit-image.org/docs/0.18.x/api/skimage.feature.html" class="_attribution-link">https://scikit-image.org/docs/0.18.x/api/skimage.feature.html</a>
  </p>
</div>
