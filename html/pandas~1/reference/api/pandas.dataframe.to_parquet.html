<h1>pandas.DataFrame.to_parquet</h1> <dl class="py method"> <dt class="sig sig-object py" id="pandas.DataFrame.to_parquet"> <span class="sig-prename descclassname"><span class="pre">DataFrame.</span></span><span class="sig-name descname"><span class="pre">to_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compression</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'snappy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pandas-dev/pandas/blob/v1.5.0/pandas/core/frame.py#L2876-L2984"><span class="viewcode-link"><span class="pre">[source]</span></span></a>
</dt> <dd>
<p>Write a DataFrame to the binary parquet format.</p> <p>This function writes the dataframe as a <a class="reference external" href="https://parquet.apache.org/">parquet file</a>. You can choose different parquet backends, and have the option of compression. See <a class="reference internal" href="../../user_guide/io.html#io-parquet"><span class="std std-ref">the user guide</span></a> for more details.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<strong>path</strong><span class="classifier">:str, path object, file-like object, or None, default None</span>
</dt>
<dd>
<p>String, path object (implementing <code class="docutils literal notranslate"><span class="pre">os.PathLike[str]</span></code>), or file-like object implementing a binary <code class="docutils literal notranslate"><span class="pre">write()</span></code> function. If None, the result is returned as bytes. If a string or path, it will be used as Root Directory path when writing a partitioned dataset.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 1.2.0.</span></p> </div> <p>Previously this was “fname”</p> </dd> <dt>
<strong>engine</strong><span class="classifier">:{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’</span>
</dt>
<dd>
<p>Parquet library to use. If ‘auto’, then the option <code class="docutils literal notranslate"><span class="pre">io.parquet.engine</span></code> is used. The default <code class="docutils literal notranslate"><span class="pre">io.parquet.engine</span></code> behavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if ‘pyarrow’ is unavailable.</p> </dd> <dt>
<strong>compression</strong><span class="classifier">:{‘snappy’, ‘gzip’, ‘brotli’, None}, default ‘snappy’</span>
</dt>
<dd>
<p>Name of the compression to use. Use <code class="docutils literal notranslate"><span class="pre">None</span></code> for no compression.</p> </dd> <dt>
<strong>index</strong><span class="classifier">:bool, default None</span>
</dt>
<dd>
<p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, include the dataframe’s index(es) in the file output. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, they will not be written to the file. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, similar to <code class="docutils literal notranslate"><span class="pre">True</span></code> the dataframe’s index(es) will be saved. However, instead of being saved as values, the RangeIndex will be stored as a range in the metadata so it doesn’t require much space and is faster. Other indexes will be included as columns in the file output.</p> </dd> <dt>
<strong>partition_cols</strong><span class="classifier">:list, optional, default None</span>
</dt>
<dd>
<p>Column names by which to partition the dataset. Columns are partitioned in the order they are given. Must be None if path is not a string.</p> </dd> <dt>
<strong>storage_options</strong><span class="classifier">:dict, optional</span>
</dt>
<dd>
<p>Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded to <code class="docutils literal notranslate"><span class="pre">urllib.request.Request</span></code> as header options. For other URLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are forwarded to <code class="docutils literal notranslate"><span class="pre">fsspec.open</span></code>. Please see <code class="docutils literal notranslate"><span class="pre">fsspec</span></code> and <code class="docutils literal notranslate"><span class="pre">urllib</span></code> for more details, and for more examples on storage options refer <a class="reference external" href="https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files">here</a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.2.0.</span></p> </div> </dd> <dt><strong>**kwargs</strong></dt>
<dd>
<p>Additional arguments passed to the parquet library. See <a class="reference internal" href="../../user_guide/io.html#io-parquet"><span class="std std-ref">pandas io</span></a> for more details.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>bytes if no path argument is provided else None</dt>
 </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="pandas.read_parquet.html#pandas.read_parquet" title="pandas.read_parquet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read_parquet</span></code></a></dt>
<dd>
<p>Read a parquet file.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_orc.html#pandas.DataFrame.to_orc" title="pandas.DataFrame.to_orc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_orc</span></code></a></dt>
<dd>
<p>Write an orc file.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_csv.html#pandas.DataFrame.to_csv" title="pandas.DataFrame.to_csv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_csv</span></code></a></dt>
<dd>
<p>Write a csv file.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_sql.html#pandas.DataFrame.to_sql" title="pandas.DataFrame.to_sql"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_sql</span></code></a></dt>
<dd>
<p>Write to a sql table.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_hdf.html#pandas.DataFrame.to_hdf" title="pandas.DataFrame.to_hdf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_hdf</span></code></a></dt>
<dd>
<p>Write to hdf.</p> </dd> </dl> </div> <p class="rubric">Notes</p> <p>This function requires either the <a class="reference external" href="https://pypi.org/project/fastparquet">fastparquet</a> or <a class="reference external" href="https://arrow.apache.org/docs/python/">pyarrow</a> library.</p> <p class="rubric">Examples</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})
&gt;&gt;&gt; df.to_parquet('df.parquet.gzip',
...               compression='gzip')  
&gt;&gt;&gt; pd.read_parquet('df.parquet.gzip')  
   col1  col2
0     1     3
1     2     4
</pre></div> </div> <p>If you want to get a buffer to the parquet content you can use a io.BytesIO object, as long as you don’t use partition_cols, which creates multiple files.</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; import io
&gt;&gt;&gt; f = io.BytesIO()
&gt;&gt;&gt; df.to_parquet(f)
&gt;&gt;&gt; f.seek(0)
0
&gt;&gt;&gt; content = f.read()
</pre></div> </div> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2008&ndash;2022, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pandas.pydata.org/pandas-docs/version/1.5.0/reference/api/pandas.DataFrame.to_parquet.html" class="_attribution-link">https://pandas.pydata.org/pandas-docs/version/1.5.0/reference/api/pandas.DataFrame.to_parquet.html</a>
  </p>
</div>
