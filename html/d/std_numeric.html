<h1>std.numeric</h1>  <p>This module is a port of a growing fragment of the <span class="d_param">numeric</span> header in Alexander Stepanov's <a href="https://en.wikipedia.org/wiki/Standard_Template_Library">Standard Template Library</a>, with a few additions. </p>
<dl>
<dt>License:</dt>
<dd>
<a href="http://www.boost.org/LICENSE_1_0.txt">Boost License 1.0</a>. </dd>
</dl> <dl>
<dt>Authors:</dt>
<dd>
<a href="http://erdani.org">Andrei Alexandrescu</a>, Don Clugston, Robert Jacques, Ilya Yaroshenko </dd>
</dl> <dl>
<dt>Source</dt>
<dd> <span class="phobos_src"><a class="https" href="https://github.com/dlang/phobos/blob/master/std/numeric.d">std/numeric.d</a></span>
</dd>
</dl> <dl>
<dt class="d_decl" id="CustomFloatFlags">enum <strong id="CustomFloatFlags">CustomFloatFlags</strong>: int; </dt> <dd>
<p>Format flags for CustomFloat.</p> <dl>
<dt class="d_decl" id="CustomFloatFlags.signed"><strong id="signed">signed</strong></dt> <dd>
<p>Adds a sign bit to allow for signed numbers.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.storeNormalized"><strong id="storeNormalized">storeNormalized</strong></dt> <dd>
<p>Store values in normalized form by default. The actual precision of the significand is extended by 1 bit by assuming an implicit leading bit of 1 instead of 0. i.e. <code>1.nnnn</code> instead of <code>0.nnnn</code>. True for all <a href="https://en.wikipedia.org/wiki/IEEE_floating_point">IEE754</a> types</p> </dd> <dt class="d_decl" id="CustomFloatFlags.allowDenorm"><strong id="allowDenorm">allowDenorm</strong></dt> <dd>
<p>Stores the significand in <a href="https://en.wikipedia.org/wiki/IEEE_754-1985#Denormalized_numbers"> IEEE754 denormalized</a> form when the exponent is 0. Required to express the value 0.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.infinity"><strong id="infinity">infinity</strong></dt> <dd>
<p>Allows the storage of <a href="https://en.wikipedia.org/wiki/IEEE_754-1985#Positive_and_negative_infinity"> IEEE754 infinity</a> values.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.nan"><strong id="nan">nan</strong></dt> <dd>
<p>Allows the storage of <a href="https://en.wikipedia.org/wiki/NaN">IEEE754 Not a Number</a> values.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.probability"><strong id="probability">probability</strong></dt> <dd>
<p>If set, select an exponent bias such that max_exp = 1. i.e. so that the maximum value is &gt;= 1.0 and &lt; 2.0. Ignored if the exponent bias is manually specified.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.negativeUnsigned"><strong id="negativeUnsigned">negativeUnsigned</strong></dt> <dd>
<p>If set, unsigned custom floats are assumed to be negative.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.allowDenormZeroOnly"><strong id="allowDenormZeroOnly">allowDenormZeroOnly</strong></dt> <dd>
<p>If set, 0 is the only allowed <a href="https://en.wikipedia.org/wiki/IEEE_754-1985#Denormalized_numbers"> IEEE754 denormalized</a> number. Requires allowDenorm and storeNormalized.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.ieee"><strong id="ieee">ieee</strong></dt> <dd>
<p>Include all of the <a href="https://en.wikipedia.org/wiki/IEEE_floating_point">IEEE754</a> options.</p> </dd> <dt class="d_decl" id="CustomFloatFlags.none"><strong id="none">none</strong></dt> <dd>
<p>Include none of the above options.</p> </dd> </dl> </dd> <dt class="d_decl" id="CustomFloat">template <strong id="CustomFloat">CustomFloat</strong>(uint bits) if (bits == 8 || bits == 16 || bits == 32 || bits == 64 || bits == 80)<br><br>template <strong id="CustomFloat">CustomFloat</strong>(uint precision, uint exponentWidth, CustomFloatFlags flags = CustomFloatFlags.ieee) if (((flags &amp; flags.signed) + precision + exponentWidth) % 8 == 0 &amp;&amp; (precision + exponentWidth &gt; 0))<br><br>struct <strong id="CustomFloat">CustomFloat</strong>(uint precision, uint exponentWidth, CustomFloatFlags flags, uint bias) if (isCorrectCustomFloat(precision, exponentWidth, flags)); </dt> <dd>
<p>Allows user code to define custom floating-point formats. These formats are for storage only; all operations on them are performed by first implicitly extracting them to <code>real</code> first. After the operation is completed the result can be stored in a custom floating-point value via assignment.</p>
<dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : sin, cos;

// Define a 16-bit floating point values
CustomFloat!16                                x;     // Using the number of bits
CustomFloat!(10, 5)                           y;     // Using the precision and exponent width
CustomFloat!(10, 5,CustomFloatFlags.ieee)     z;     // Using the precision, exponent width and format flags
CustomFloat!(10, 5,CustomFloatFlags.ieee, 15) w;     // Using the precision, exponent width, format flags and exponent offset bias

// Use the 16-bit floats mostly like normal numbers
w = x*y - 1;

// Functions calls require conversion
z = sin(+x)           + cos(+y);                     // Use unary plus to concisely convert to a real
z = sin(x.get!float)  + cos(y.get!float);            // Or use get!T
z = sin(cast(float) x) + cos(cast(float) y);           // Or use cast(T) to explicitly convert

// Define a 8-bit custom float for storing probabilities
alias Probability = CustomFloat!(4, 4, CustomFloatFlags.ieee^CustomFloatFlags.probability^CustomFloatFlags.signed );
auto p = Probability(0.5);
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="FPTemporary">template <strong id="FPTemporary">FPTemporary</strong>(F) if (isFloatingPoint!F)</dt> <dd>
<p>Defines the fastest type to use when storing temporaries of a calculation intended to ultimately yield a result of type <code>F</code> (where <code>F</code> must be one of <code>float</code>, <code>double</code>, or <code>real</code>). When doing a multi-step computation, you may want to store intermediate results as <code>FPTemporary!F</code>. </p>
<p>The necessity of <code>FPTemporary</code> stems from the optimized floating-point operations and registers present in virtually all processors. When adding numbers in the example above, the addition may in fact be done in <code>real</code> precision internally. In that case, storing the intermediate <code>result</code> in <code>double format</code> is not only less precise, it is also (surprisingly) slower, because a conversion from <code>real</code> to <code>double</code> is performed every pass through the loop. This being a lose-lose situation, <code>FPTemporary!F</code> has been defined as the <i>fastest</i> type to use for calculations at precision <code>F</code>. There is no need to define a type for the <i>most accurate</i> calculations, as that is always <code>real</code>. <br><br> Finally, there is no guarantee that using <code>FPTemporary!F</code> will always be fastest, as the speed of floating-point calculations depends on very many factors.</p> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : approxEqual;

// Average numbers in an array
double avg(in double[] a)
{
    if (a.length == 0) return 0;
    FPTemporary!double result = 0;
    foreach (e; a) result += e;
    return result / a.length;
}

auto a = [1.0, 2.0, 3.0];
assert(approxEqual(avg(a), 2));
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="secantMethod">template <strong id="secantMethod">secantMethod</strong>(alias fun)</dt> <dd>
<p>Implements the <a href="http://tinyurl.com/2zb9yr">secant method</a> for finding a root of the function <code>fun</code> starting from points <code>[xn_1, x_n]</code> (ideally close to the root). <code>Num</code> may be <code>float</code>, <code>double</code>, or <code>real</code>.</p>
<dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : approxEqual, cos;

float f(float x)
{
    return cos(x) - x*x*x;
}
auto x = secantMethod!(f)(0f, 1f);
assert(approxEqual(x, 0.865474));
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="findRoot">T <strong id="findRoot">findRoot</strong>(T, DF, DT)(scope DF f, const T a, const T b, scope DT tolerance)<br><small>  Constraints: if (isFloatingPoint!T &amp;&amp; is(typeof(tolerance(T.init, T.init)) : bool) &amp;&amp; is(typeof(f(T.init)) == R, R) &amp;&amp; isFloatingPoint!R); </small><br><br>T <strong id="findRoot">findRoot</strong>(T, DF)(scope DF f, const T a, const T b); </dt> <dd>
<p>Find a real root of a real function f(x) via bracketing. </p>
<p>Given a function <code>f</code> and a range <code>[a .. b]</code> such that <code>f(a)</code> and <code>f(b)</code> have opposite signs or at least one of them equals Â±0, returns the value of <code>x</code> in the range which is closest to a root of <code>f(x)</code>. If <code>f(x)</code> has more than one root in the range, one will be chosen arbitrarily. If <code>f(x)</code> returns NaN, NaN will be returned; otherwise, this algorithm is guaranteed to succeed. <br><br> Uses an algorithm based on TOMS748, which uses inverse cubic interpolation whenever possible, otherwise reverting to parabolic or secant interpolation. Compared to TOMS748, this implementation improves worst-case performance by a factor of more than 100, and typical performance by a factor of 2. For 80-bit reals, most problems require 8 to 15 calls to <code>f(x)</code> to achieve full machine precision. The worst-case performance (pathological cases) is approximately twice the number of bits. </p> <dl>
<dt>References</dt>
<dd> "On Enclosing Simple Roots of Nonlinear Equations", G. Alefeld, F.A. Potra, Yixun Shi, Mathematics of Computation 61, pp733-744 (1993). Fortran code available from <a href="http://%20www.netlib.org">www.netlib.org</a> as algorithm TOMS478.</dd>
</dl> </dd> <dt class="d_decl" id="findRoot.2">Tuple!(T, T, R, R) <strong id="findRoot">findRoot</strong>(T, R, DF, DT)(scope DF f, const T ax, const T bx, const R fax, const R fbx, scope DT tolerance)<br><small>  Constraints: if (isFloatingPoint!T &amp;&amp; is(typeof(tolerance(T.init, T.init)) : bool) &amp;&amp; is(typeof(f(T.init)) == R) &amp;&amp; isFloatingPoint!R); </small><br><br>Tuple!(T, T, R, R) <strong id="findRoot">findRoot</strong>(T, R, DF)(scope DF f, const T ax, const T bx, const R fax, const R fbx); <br><br>T <strong id="findRoot">findRoot</strong>(T, R)(scope R delegate(T) f, const T a, const T b, scope bool delegate(T lo, T hi) tolerance = (T a, T b) =&gt; false); </dt> <dd>
<p>Find root of a real function f(x) by bracketing, allowing the termination condition to be specified. </p>
<dl>
<dt>Parameters:</dt>
<dd><table>
<tr>
<td>DF <code>f</code>
</td> <td>Function to be analyzed</td>
</tr> <tr>
<td>T <code>ax</code>
</td> <td>Left bound of initial range of <code>f</code> known to contain the root.</td>
</tr> <tr>
<td>T <code>bx</code>
</td> <td>Right bound of initial range of <code>f</code> known to contain the root.</td>
</tr> <tr>
<td>R <code>fax</code>
</td> <td>Value of <code>f(ax)</code>.</td>
</tr> <tr>
<td>R <code>fbx</code>
</td> <td>Value of <code>f(bx)</code>. <code>fax</code> and <code>fbx</code> should have opposite signs. (<code>f(ax)</code> and <code>f(bx)</code> are commonly known in advance.)</td>
</tr> <tr>
<td>DT <code>tolerance</code>
</td> <td>Defines an early termination condition. Receives the current upper and lower bounds on the root. The delegate must return <code>true</code> when these bounds are acceptable. If this function always returns <code>false</code>, full machine precision will be achieved.</td>
</tr> </table></dd>
</dl> <dl>
<dt>Returns:</dt>
<dd>A tuple consisting of two ranges. The first two elements are the range (in <code>x</code>) of the root, while the second pair of elements are the corresponding function values at those points. If an exact root was found, both of the first two elements will contain the root, and the second pair of elements will be 0.</dd>
</dl> </dd> <dt class="d_decl" id="findLocalMin">Tuple!(T, "x", Unqual!(ReturnType!DF), "y", T, "error") <strong id="findLocalMin">findLocalMin</strong>(T, DF)(scope DF f, const T ax, const T bx, const T relTolerance = sqrt(T.epsilon), const T absTolerance = sqrt(T.epsilon))<br><small>  Constraints: if (isFloatingPoint!T &amp;&amp; __traits(compiles, () { T _ = DF.init(T.init); } )); </small>
</dt> <dd>
<p>Find a real minimum of a real function <code>f(x)</code> via bracketing. Given a function <code>f</code> and a range <code>(ax .. bx)</code>, returns the value of <code>x</code> in the range which is closest to a minimum of <code>f(x)</code>. <code>f</code> is never evaluted at the endpoints of <code>ax</code> and <code>bx</code>. If <code>f(x)</code> has more than one minimum in the range, one will be chosen arbitrarily. If <code>f(x)</code> returns NaN or -Infinity, <code>(x, f(x), NaN)</code> will be returned; otherwise, this algorithm is guaranteed to succeed. </p>
<dl>
<dt>Parameters:</dt>
<dd><table>
<tr>
<td>DF <code>f</code>
</td> <td>Function to be analyzed</td>
</tr> <tr>
<td>T <code>ax</code>
</td> <td>Left bound of initial range of f known to contain the minimum.</td>
</tr> <tr>
<td>T <code>bx</code>
</td> <td>Right bound of initial range of f known to contain the minimum.</td>
</tr> <tr>
<td>T <code>relTolerance</code>
</td> <td>Relative tolerance.</td>
</tr> <tr>
<td>T <code>absTolerance</code>
</td> <td>Absolute tolerance.</td>
</tr> </table></dd>
</dl> <dl>
<dt>Preconditions</dt>
<dd> <code>ax</code> and <code>bx</code> shall be finite reals. <br> <code>relTolerance</code> shall be normal positive real. <br> <code>absTolerance</code> shall be normal positive real no less then <code>T.epsilon*2</code>. </dd>
</dl> <dl>
<dt>Returns:</dt>
<dd>A tuple consisting of <code>x</code>, <code>y = f(x)</code> and <code>error = 3 * (absTolerance * fabs(x) + relTolerance)</code>.  The method used is a combination of golden section search and successive parabolic interpolation. Convergence is never much slower than that for a Fibonacci search. </dd>
</dl> <dl>
<dt>References</dt>
<dd> "Algorithms for Minimization without Derivatives", Richard Brent, Prentice-Hall, Inc. (1973) </dd>
</dl> <dl>
<dt>See Also:</dt>
<dd>
<a href="#findRoot"><code>findRoot</code></a>, <a href="std_math.html#isNormal"><code>std.math.isNormal</code></a>
</dd>
</dl> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : approxEqual;

auto ret = findLocalMin((double x) =&gt; (x-4)^^2, -1e7, 1e7);
assert(ret.x.approxEqual(4.0));
assert(ret.y.approxEqual(0.0));
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="euclideanDistance">CommonType!(ElementType!Range1, ElementType!Range2) <strong id="euclideanDistance">euclideanDistance</strong>(Range1, Range2)(Range1 a, Range2 b)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2); </small><br><br>CommonType!(ElementType!Range1, ElementType!Range2) <strong id="euclideanDistance">euclideanDistance</strong>(Range1, Range2, F)(Range1 a, Range2 b, F limit)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2); </small>
</dt> <dd>
<p>Computes <a href="https://en.wikipedia.org/wiki/Euclidean_distance">Euclidean distance</a> between input ranges <code>a</code> and <code>b</code>. The two ranges must have the same length. The three-parameter version stops computation as soon as the distance is greater than or equal to <code>limit</code> (this is useful to save computation if a small distance is sought).</p> </dd> <dt class="d_decl" id="dotProduct">CommonType!(ElementType!Range1, ElementType!Range2) <strong id="dotProduct">dotProduct</strong>(Range1, Range2)(Range1 a, Range2 b)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2 &amp;&amp; !(isArray!Range1 &amp;&amp; isArray!Range2)); </small><br><br>CommonType!(F1, F2) <strong id="dotProduct">dotProduct</strong>(F1, F2)(in F1[] avector, in F2[] bvector); <br><br>F <strong id="dotProduct">dotProduct</strong>(F, uint N)(ref scope const F[N] a, ref scope const F[N] b)<br><small>  Constraints: if (N &lt;= 16); </small>
</dt> <dd>
<p>Computes the <a href="https://en.wikipedia.org/wiki/Dot_product">dot product</a> of input ranges <code>a</code> and <code>b</code>. The two ranges must have the same length. If both ranges define length, the check is done once; otherwise, it is done at each iteration.</p> </dd> <dt class="d_decl" id="cosineSimilarity">CommonType!(ElementType!Range1, ElementType!Range2) <strong id="cosineSimilarity">cosineSimilarity</strong>(Range1, Range2)(Range1 a, Range2 b)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2); </small>
</dt> <dd>
<p>Computes the <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> of input ranges <code>a</code> and <code>b</code>. The two ranges must have the same length. If both ranges define length, the check is done once; otherwise, it is done at each iteration. If either range has all-zero elements, return 0.</p> </dd> <dt class="d_decl" id="normalize">bool <strong id="normalize">normalize</strong>(R)(R range, ElementType!R sum = 1)<br><small>  Constraints: if (isForwardRange!R); </small>
</dt> <dd>
<p>Normalizes values in <code>range</code> by multiplying each element with a number chosen such that values sum up to <code>sum</code>. If elements in <code>range</code> sum to zero, assigns <code>sum / range.length</code> to all. Normalization makes sense only if all elements in <code>range</code> are positive. <code>normalize</code> assumes that is the case without checking it. </p>
<dl>
<dt>Returns:</dt>
<dd>
<code>true</code> if normalization completed normally, <code>false</code> if all elements in <code>range</code> were zero or if <code>range</code> is empty.</dd>
</dl> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">double[] a = [];
assert(!normalize(a));
a = [ 1.0, 3.0 ];
assert(normalize(a));
writeln(a); // [0.25, 0.75]
assert(normalize!(typeof(a))(a, 50)); // a = [12.5, 37.5]
a = [ 0.0, 0.0 ];
assert(!normalize(a));
writeln(a); // [0.5, 0.5]
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="sumOfLog2s">ElementType!Range <strong id="sumOfLog2s">sumOfLog2s</strong>(Range)(Range r)<br><small>  Constraints: if (isInputRange!Range &amp;&amp; isFloatingPoint!(ElementType!Range)); </small>
</dt> <dd>
<p>Compute the sum of binary logarithms of the input range <code>r</code>. The error of this method is much smaller than with a naive sum of log2.</p>
<dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : isNaN;

writeln(sumOfLog2s(new double[0])); // 0
writeln(sumOfLog2s([0.0L])); // -real.infinity
writeln(sumOfLog2s([-0.0L])); // -real.infinity
writeln(sumOfLog2s([2.0L])); // 1
assert(sumOfLog2s([-2.0L]).isNaN());
assert(sumOfLog2s([real.nan]).isNaN());
assert(sumOfLog2s([-real.nan]).isNaN());
writeln(sumOfLog2s([real.infinity])); // real.infinity
assert(sumOfLog2s([-real.infinity]).isNaN());
writeln(sumOfLog2s([0.25, 0.25, 0.25, 0.125])); // -9
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="entropy">ElementType!Range <strong id="entropy">entropy</strong>(Range)(Range r)<br><small>  Constraints: if (isInputRange!Range); </small><br><br>ElementType!Range <strong id="entropy">entropy</strong>(Range, F)(Range r, F max)<br><small>  Constraints: if (isInputRange!Range &amp;&amp; !is(CommonType!(ElementType!Range, F) == void)); </small>
</dt> <dd>
<p>Computes <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">entropy</a> of input range <code>r</code> in bits. This function assumes (without checking) that the values in <code>r</code> are all in <code>[0, 1]</code>. For the entropy to be meaningful, often <code>r</code> should be normalized too (i.e., its values should sum to 1). The two-parameter version stops evaluating as soon as the intermediate result is greater than or equal to <code>max</code>.</p> </dd> <dt class="d_decl" id="kullbackLeiblerDivergence">CommonType!(ElementType!Range1, ElementType!Range2) <strong id="kullbackLeiblerDivergence">kullbackLeiblerDivergence</strong>(Range1, Range2)(Range1 a, Range2 b)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2); </small>
</dt> <dd>
<p>Computes the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler divergence</a> between input ranges <code>a</code> and <code>b</code>, which is the sum <code>ai * log(ai / bi)</code>. The base of logarithm is 2. The ranges are assumed to contain elements in <code>[0, 1]</code>. Usually the ranges are normalized probability distributions, but this is not required or checked by <code>kullbackLeiblerDivergence</code>. If any element <code>bi</code> is zero and the corresponding element <code>ai</code> nonzero, returns infinity. (Otherwise, if <code>ai == 0 &amp;&amp; bi == 0</code>, the term <code>ai * log(ai / bi)</code> is considered zero.) If the inputs are normalized, the result is positive.</p>
<dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : approxEqual;

double[] p = [ 0.0, 0, 0, 1 ];
writeln(kullbackLeiblerDivergence(p, p)); // 0
double[] p1 = [ 0.25, 0.25, 0.25, 0.25 ];
writeln(kullbackLeiblerDivergence(p1, p1)); // 0
writeln(kullbackLeiblerDivergence(p, p1)); // 2
writeln(kullbackLeiblerDivergence(p1, p)); // double.infinity
double[] p2 = [ 0.2, 0.2, 0.2, 0.4 ];
assert(approxEqual(kullbackLeiblerDivergence(p1, p2), 0.0719281));
assert(approxEqual(kullbackLeiblerDivergence(p2, p1), 0.0780719));
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="jensenShannonDivergence">CommonType!(ElementType!Range1, ElementType!Range2) <strong id="jensenShannonDivergence">jensenShannonDivergence</strong>(Range1, Range2)(Range1 a, Range2 b)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2 &amp;&amp; is(CommonType!(ElementType!Range1, ElementType!Range2))); </small><br><br>CommonType!(ElementType!Range1, ElementType!Range2) <strong id="jensenShannonDivergence">jensenShannonDivergence</strong>(Range1, Range2, F)(Range1 a, Range2 b, F limit)<br><small>  Constraints: if (isInputRange!Range1 &amp;&amp; isInputRange!Range2 &amp;&amp; is(typeof(CommonType!(ElementType!Range1, ElementType!Range2).init &gt;= F.init) : bool)); </small>
</dt> <dd>
<p>Computes the <a href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence">Jensen-Shannon divergence</a> between <code>a</code> and <code>b</code>, which is the sum <code>(ai * log(2 * ai / (ai + bi)) + bi * log(2 * bi / (ai + bi))) / 2</code>. The base of logarithm is 2. The ranges are assumed to contain elements in <code>[0, 1]</code>. Usually the ranges are normalized probability distributions, but this is not required or checked by <code>jensenShannonDivergence</code>. If the inputs are normalized, the result is bounded within <code>[0, 1]</code>. The three-parameter version stops evaluations as soon as the intermediate result is greater than or equal to <code>limit</code>.</p>
<dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : approxEqual;

double[] p = [ 0.0, 0, 0, 1 ];
writeln(jensenShannonDivergence(p, p)); // 0
double[] p1 = [ 0.25, 0.25, 0.25, 0.25 ];
writeln(jensenShannonDivergence(p1, p1)); // 0
assert(approxEqual(jensenShannonDivergence(p1, p), 0.548795));
double[] p2 = [ 0.2, 0.2, 0.2, 0.4 ];
assert(approxEqual(jensenShannonDivergence(p1, p2), 0.0186218));
assert(approxEqual(jensenShannonDivergence(p2, p1), 0.0186218));
assert(approxEqual(jensenShannonDivergence(p2, p1, 0.005), 0.00602366));
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="gapWeightedSimilarity">F <strong id="gapWeightedSimilarity">gapWeightedSimilarity</strong>(alias comp = "a == b", R1, R2, F)(R1 s, R2 t, F lambda)<br><small>  Constraints: if (isRandomAccessRange!R1 &amp;&amp; hasLength!R1 &amp;&amp; isRandomAccessRange!R2 &amp;&amp; hasLength!R2); </small>
</dt> <dd>
<p>The so-called "all-lengths gap-weighted string kernel" computes a similarity measure between <code>s</code> and <code>t</code> based on all of their common subsequences of all lengths. Gapped subsequences are also included. </p>
<p>To understand what <code>gapWeightedSimilarity(s, t, lambda)</code> computes, consider first the case <code>lambda = 1</code> and the strings <code>s = ["Hello", "brave", "new", "world"]</code> and <code>t = ["Hello", "new", "world"]</code>. In that case, <code>gapWeightedSimilarity</code> counts the following matches: <br><br> <ol>
<li>three matches of length 1, namely <code>"Hello"</code>, <code>"new"</code>, and <code>"world"</code>;</li> <li>three matches of length 2, namely (<code>"Hello", "new"</code>), (<code>"Hello", "world"</code>), and (<code>"new", "world"</code>);</li> <li>one match of length 3, namely (<code>"Hello", "new", "world"</code>).</li>
</ol> <br><br> The call <code>gapWeightedSimilarity(s, t, 1)</code> simply counts all of these matches and adds them up, returning 7. <br><br> <pre data-language="d">string[] s = ["Hello", "brave", "new", "world"];
string[] t = ["Hello", "new", "world"];
assert(gapWeightedSimilarity(s, t, 1) == 7);
</pre> <br><br> Note how the gaps in matching are simply ignored, for example (<code>"Hello", "new"</code>) is deemed as good a match as (<code>"new", "world"</code>). This may be too permissive for some applications. To eliminate gapped matches entirely, use <code>lambda = 0</code>: <br><br> <pre data-language="d">string[] s = ["Hello", "brave", "new", "world"];
string[] t = ["Hello", "new", "world"];
assert(gapWeightedSimilarity(s, t, 0) == 4);
</pre> <br><br> The call above eliminated the gapped matches (<code>"Hello", "new"</code>), (<code>"Hello", "world"</code>), and (<code>"Hello", "new", "world"</code>) from the tally. That leaves only 4 matches. <br><br> The most interesting case is when gapped matches still participate in the result, but not as strongly as ungapped matches. The result will be a smooth, fine-grained similarity measure between the input strings. This is where values of <code>lambda</code> between 0 and 1 enter into play: gapped matches are <i>exponentially penalized with the number of gaps</i> with base <code>lambda</code>. This means that an ungapped match adds 1 to the return value; a match with one gap in either string adds <code>lambda</code> to the return value; ...; a match with a total of <code>n</code> gaps in both strings adds <code>pow(lambda, n)</code> to the return value. In the example above, we have 4 matches without gaps, 2 matches with one gap, and 1 match with three gaps. The latter match is (<code>"Hello", "world"</code>), which has two gaps in the first string and one gap in the second string, totaling to three gaps. Summing these up we get <code>4 + 2 * lambda + pow(lambda, 3)</code>. <br><br> <pre data-language="d">string[] s = ["Hello", "brave", "new", "world"];
string[] t = ["Hello", "new", "world"];
assert(gapWeightedSimilarity(s, t, 0.5) == 4 + 0.5 * 2 + 0.125);
</pre> <br><br> <code>gapWeightedSimilarity</code> is useful wherever a smooth similarity measure between sequences allowing for approximate matches is needed. The examples above are given with words, but any sequences with elements comparable for equality are allowed, e.g. characters or numbers. <code>gapWeightedSimilarity</code> uses a highly optimized dynamic programming implementation that needs <code>16 * min(s.length, t.length)</code> extra bytes of memory and <span class="bigoh">Î(<code>s.length * t.length</code>)</span> time to complete.</p> </dd> <dt class="d_decl" id="gapWeightedSimilarityNormalized">Select!(isFloatingPoint!F, F, double) <strong id="gapWeightedSimilarityNormalized">gapWeightedSimilarityNormalized</strong>(alias comp = "a == b", R1, R2, F)(R1 s, R2 t, F lambda, F sSelfSim = F.init, F tSelfSim = F.init)<br><small>  Constraints: if (isRandomAccessRange!R1 &amp;&amp; hasLength!R1 &amp;&amp; isRandomAccessRange!R2 &amp;&amp; hasLength!R2); </small>
</dt> <dd>
<p>The similarity per <code>gapWeightedSimilarity</code> has an issue in that it grows with the lengths of the two strings, even though the strings are not actually very similar. For example, the range <code>["Hello", "world"]</code> is increasingly similar with the range <code>["Hello", "world", "world", "world",...]</code> as more instances of <code>"world"</code> are appended. To prevent that, <code>gapWeightedSimilarityNormalized</code> computes a normalized version of the similarity that is computed as <code>gapWeightedSimilarity(s, t, lambda) / sqrt(gapWeightedSimilarity(s, t, lambda) * gapWeightedSimilarity(s, t, lambda))</code>. The function <code>gapWeightedSimilarityNormalized</code> (a so-called normalized kernel) is bounded in <code>[0, 1]</code>, reaches <code>0</code> only for ranges that don't match in any position, and <code>1</code> only for identical ranges. </p>
<p>The optional parameters <code>sSelfSim</code> and <code>tSelfSim</code> are meant for avoiding duplicate computation. Many applications may have already computed <code>gapWeightedSimilarity(s, s, lambda)</code> and/or <code>gapWeightedSimilarity(t, t, lambda)</code>. In that case, they can be passed as <code>sSelfSim</code> and <code>tSelfSim</code>, respectively.</p> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">import std.math : approxEqual, sqrt;

string[] s = ["Hello", "brave", "new", "world"];
string[] t = ["Hello", "new", "world"];
writeln(gapWeightedSimilarity(s, s, 1)); // 15
writeln(gapWeightedSimilarity(t, t, 1)); // 7
writeln(gapWeightedSimilarity(s, t, 1)); // 7
assert(approxEqual(gapWeightedSimilarityNormalized(s, t, 1),
                7.0 / sqrt(15.0 * 7), 0.01));
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="GapWeightedSimilarityIncremental">struct <strong id="GapWeightedSimilarityIncremental">GapWeightedSimilarityIncremental</strong>(Range, F = double) if (isRandomAccessRange!Range &amp;&amp; hasLength!Range); <br><br>GapWeightedSimilarityIncremental!(R, F) <strong id="gapWeightedSimilarityIncremental">gapWeightedSimilarityIncremental</strong>(R, F)(R r1, R r2, F penalty); </dt> <dd>
<p>Similar to <code>gapWeightedSimilarity</code>, just works in an incremental manner by first revealing the matches of length 1, then gapped matches of length 2, and so on. The memory requirement is <span class="bigoh">Î(<code>s.length * t.length</code>)</span>. The time complexity is <span class="bigoh">Î(<code>s.length * t.length</code>)</span> time for computing each step. Continuing on the previous example: </p>
<p>The implementation is based on the pseudocode in Fig. 4 of the paper <a href="http://jmlr.csail.mit.edu/papers/volume6/rousu05a/rousu05a.pdf">"Efï¬cient Computation of Gapped Substring Kernels on Large Alphabets"</a> by Rousu et al., with additional algorithmic and systems-level optimizations.</p> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">string[] s = ["Hello", "brave", "new", "world"];
string[] t = ["Hello", "new", "world"];
auto simIter = gapWeightedSimilarityIncremental(s, t, 1.0);
assert(simIter.front == 3); // three 1-length matches
simIter.popFront();
assert(simIter.front == 3); // three 2-length matches
simIter.popFront();
assert(simIter.front == 1); // one 3-length match
simIter.popFront();
assert(simIter.empty);     // no more match
</pre> </dd>
</dl> <dl>
<dt class="d_decl" id="GapWeightedSimilarityIncremental.this">this(Range s, Range t, F lambda); </dt> <dd>
<p>Constructs an object given two ranges <code>s</code> and <code>t</code> and a penalty <code>lambda</code>. Constructor completes in <span class="bigoh">Î(<code>s.length * t.length</code>)</span> time and computes all matches of length 1.</p> </dd> <dt class="d_decl" id="GapWeightedSimilarityIncremental.opSlice">ref GapWeightedSimilarityIncremental <strong id="opSlice">opSlice</strong>(); </dt> <dd>
<dl>
<dt>Returns:</dt>
<dd>
<code>this</code>.</dd>
</dl> </dd> <dt class="d_decl" id="GapWeightedSimilarityIncremental.popFront">void <strong id="popFront">popFront</strong>(); </dt> <dd>
<p>Computes the match of the popFront length. Completes in <span class="bigoh">Î(<code>s.length * t.length</code>)</span> time.</p> </dd> <dt class="d_decl" id="GapWeightedSimilarityIncremental.front">@property F <strong id="front">front</strong>(); </dt> <dd>
<dl>
<dt>Returns:</dt>
<dd>The gapped similarity at the current match length (initially 1, grows with each call to <code>popFront</code>).</dd>
</dl> </dd> <dt class="d_decl" id="GapWeightedSimilarityIncremental.empty">@property bool <strong id="empty">empty</strong>(); </dt> <dd>
<dl>
<dt>Returns:</dt>
<dd>Whether there are more matches.</dd>
</dl> </dd> </dl> </dd> <dt class="d_decl" id="gcd">T <strong id="gcd">gcd</strong>(T)(T a, T b)<br><small>  Constraints: if (isIntegral!T); </small><br><br>auto <strong id="gcd">gcd</strong>(T)(T a, T b)<br><small>  Constraints: if (!isIntegral!T &amp;&amp; is(typeof(T.init % T.init)) &amp;&amp; is(typeof(T.init == 0 || T.init &gt; 0))); </small>
</dt> <dd>
<p>Computes the greatest common divisor of <code>a</code> and <code>b</code> by using an efficient algorithm such as <a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclid's</a> or <a href="https://en.wikipedia.org/wiki/Binary_GCD_algorithm">Stein's</a> algorithm. </p>
<dl>
<dt>Parameters:</dt>
<dd><table>
<tr>
<td>T</td> <td>Any numerical type that supports the modulo operator <code>%</code>. If bit-shifting <code>&lt;&lt;</code> and <code>&gt;&gt;</code> are also supported, Stein's algorithm will be used; otherwise, Euclid's algorithm is used as a fallback.</td>
</tr> </table></dd>
</dl> <dl>
<dt>Returns:</dt>
<dd>The greatest common divisor of the given arguments.</dd>
</dl> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">writeln(gcd(2 * 5 * 7 * 7, 5 * 7 * 11)); // 5 * 7
const int a = 5 * 13 * 23 * 23, b = 13 * 59;
writeln(gcd(a, b)); // 13
</pre> </dd>
</dl> </dd> <dt class="d_decl" id="Fft">class <strong id="Fft">Fft</strong>; </dt> <dd>
<p>A class for performing fast Fourier transforms of power of two sizes. This class encapsulates a large amount of state that is reusable when performing multiple FFTs of sizes smaller than or equal to that specified in the constructor. This results in substantial speedups when performing multiple FFTs with a known maximum size. However, a free function API is provided for convenience if you need to perform a one-off FFT. </p>
<dl>
<dt>References</dt>
<dd> <a href="http://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm">en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm</a>
</dd>
</dl> <dl>
<dt class="d_decl" id="Fft.this">this(size_t size); </dt> <dd>
<p>Create an <code>Fft</code> object for computing fast Fourier transforms of power of two sizes of <code>size</code> or smaller. <code>size</code> must be a power of two.</p> </dd> <dt class="d_decl" id="Fft.fft">const Complex!F[] <strong id="fft">fft</strong>(F = double, R)(R range)<br><small>  Constraints: if (isFloatingPoint!F &amp;&amp; isRandomAccessRange!R); </small>
</dt> <dd>
<p>Compute the Fourier transform of range using the <span class="bigoh">Î(<code>N log N</code>)</span> Cooley-Tukey Algorithm. <code>range</code> must be a random-access range with slicing and a length equal to <code>size</code> as provided at the construction of this object. The contents of range can be either numeric types, which will be interpreted as pure real values, or complex types with properties or members <code>.re</code> and <code>.im</code> that can be read. </p>
<dl>
<dt>Note</dt>
<dd> Pure real FFTs are automatically detected and the relevant optimizations are performed. </dd>
</dl> <dl>
<dt>Returns:</dt>
<dd>An array of complex numbers representing the transformed data in the frequency domain. </dd>
</dl> <dl>
<dt>Conventions</dt>
<dd> The exponent is negative and the factor is one, i.e., output[j] := sum[ exp(-2 PI i j k / N) input[k] ].</dd>
</dl> </dd> <dt class="d_decl" id="Fft.fft.2">const void <strong id="fft">fft</strong>(Ret, R)(R range, Ret buf)<br><small>  Constraints: if (isRandomAccessRange!Ret &amp;&amp; isComplexLike!(ElementType!Ret) &amp;&amp; hasSlicing!Ret); </small>
</dt> <dd>
<p>Same as the overload, but allows for the results to be stored in a user- provided buffer. The buffer must be of the same length as range, must be a random-access range, must have slicing, and must contain elements that are complex-like. This means that they must have a .re and a .im member or property that can be both read and written and are floating point numbers.</p> </dd> <dt class="d_decl" id="Fft.inverseFft">const Complex!F[] <strong id="inverseFft">inverseFft</strong>(F = double, R)(R range)<br><small>  Constraints: if (isRandomAccessRange!R &amp;&amp; isComplexLike!(ElementType!R) &amp;&amp; isFloatingPoint!F); </small>
</dt> <dd>
<p>Computes the inverse Fourier transform of a range. The range must be a random access range with slicing, have a length equal to the size provided at construction of this object, and contain elements that are either of type std.complex.Complex or have essentially the same compile-time interface. </p>
<dl>
<dt>Returns:</dt>
<dd>The time-domain signal. </dd>
</dl> <dl>
<dt>Conventions</dt>
<dd> The exponent is positive and the factor is 1/N, i.e., output[j] := (1 / N) sum[ exp(+2 PI i j k / N) input[k] ].</dd>
</dl> </dd> <dt class="d_decl" id="Fft.inverseFft.2">const void <strong id="inverseFft">inverseFft</strong>(Ret, R)(R range, Ret buf)<br><small>  Constraints: if (isRandomAccessRange!Ret &amp;&amp; isComplexLike!(ElementType!Ret) &amp;&amp; hasSlicing!Ret); </small>
</dt> <dd>
<p>Inverse FFT that allows a user-supplied buffer to be provided. The buffer must be a random access range with slicing, and its elements must be some complex-like type.</p> </dd> </dl> </dd> <dt class="d_decl" id="fft">Complex!F[] <strong id="fft">fft</strong>(F = double, R)(R range); <br><br>void <strong id="fft">fft</strong>(Ret, R)(R range, Ret buf); <br><br>Complex!F[] <strong id="inverseFft">inverseFft</strong>(F = double, R)(R range); <br><br>void <strong id="inverseFft">inverseFft</strong>(Ret, R)(R range, Ret buf); </dt> <dd>
<p>Convenience functions that create an <code>Fft</code> object, run the FFT or inverse FFT and return the result. Useful for one-off FFTs. </p>
<dl>
<dt>Note</dt>
<dd> In addition to convenience, these functions are slightly more efficient than manually creating an Fft object for a single use, as the Fft object is deterministically destroyed before these functions return.</dd>
</dl> </dd> <dt class="d_decl" id="decimalToFactorial">pure nothrow @nogc @safe size_t <strong id="decimalToFactorial">decimalToFactorial</strong>(ulong decimal, ref ubyte[21] fac); </dt> <dd>
<p>This function transforms <code>decimal</code> value into a value in the factorial number system stored in <code>fac</code>. </p>
<p>A factorial number is constructed as: <code>fac[0] * 0! + fac[1] * 1! + ... fac[20] * 20!</code> </p> <dl>
<dt>Parameters:</dt>
<dd><table>
<tr>
<td>ulong <code>decimal</code>
</td> <td>The decimal value to convert into the factorial number system.</td>
</tr> <tr>
<td>ubyte[21] <code>fac</code>
</td> <td>The array to store the factorial number. The array is of size 21 as <code>ulong.max</code> requires 21 digits in the factorial number system.</td>
</tr> </table></dd>
</dl> <dl>
<dt>Returns:</dt>
<dd>A variable storing the number of digits of the factorial number stored in <code>fac</code>.</dd>
</dl> <dl>
<dt>Examples:</dt>
<dd>
<pre data-language="d">ubyte[21] fac;
size_t idx = decimalToFactorial(2982, fac);

writeln(fac[0]); // 4
writeln(fac[1]); // 0
writeln(fac[2]); // 4
writeln(fac[3]); // 1
writeln(fac[4]); // 0
writeln(fac[5]); // 0
writeln(fac[6]); // 0
</pre> </dd>
</dl> </dd> </dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 1999&ndash;2021 The D Language Foundation<br>Licensed under the Boost License 1.0.<br>
    <a href="https://dlang.org/phobos/std_numeric.html" class="_attribution-link">https://dlang.org/phobos/std_numeric.html</a>
  </p>
</div>
